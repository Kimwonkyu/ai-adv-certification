
chapter_name = "RAG & Agent"

questions = []

# --- 100 MCQs ---
mcq_data = [
    # 1. RAG의 기본 개념 및 필요성 (1-20)
    ("RAG(Retrieval-Augmented Generation)의 가장 주된 도입 목적은?", ["모델의 파라미터를 실시간으로 갱신하기 위해", "LLM의 할루시네이션(환각)을 줄이고 최신/외부 정보를 참조하게 하기 위해", "모델의 생성 속도를 비약적으로 높이기 위해", "인터넷 연결이 필요 없는 모델을 만들기 위해", "모델의 크기를 획기적으로 줄이기 위해"], "LLM의 할루시네이션(환각)을 줄이고 최신/외부 정보를 참조하게 하기 위해", "RAG는 신뢰할 수 있는 외부 지식 베이스를 검색하여 답변의 근거로 활용함으로써 오답률을 낮춥니다.", "RAG의 목적", "5001"),
    ("RAG 시스템의 3단계 흐름(Retrieval - Augmentation - Generation) 중 'Retrieval' 단계에서 하는 일은?", ["가장 적절한 답변을 생성한다.", "질문과 관련된 가장 유사한 문서 조각을 검색해온다.", "프롬프트를 보기 좋게 꾸민다.", "사용자의 지갑 주소를 확인한다.", "모델을 새로 학습시킨다."], "질문과 관련된 가장 유사한 문서 조각을 검색해온다.", "벡터 데이터베이스 등에서 질문의 의미와 부합하는 정보를 찾아내는 과정입니다.", "Retrieval", "5002"),
    ("RAG에서 데이터를 검색할 때 주로 쓰이는 '벡터 유사도' 방식 중 가장 대표적인 것은?", ["산술 평균", "코사인 유사도 (Cosine Similarity)", "랜덤 추출", "알파벳 순서 정렬", "파일 크기 비교"], "코사인 유사도 (Cosine Similarity)", "두 벡터 사이의 각도를 이용해 텍스트의 의미적 유사성을 측정하는 핵심 기법입니다.", "코사인 유사도", "5003"),
    ("검색 증강 생성(RAG)이 Fine-tuning보다 유리한 상황은?", ["모델의 말투나 어조를 완전히 바꾸고 싶을 때", "정보가 수시로 업데이트되는 실시간 뉴스를 다뤄야 할 때", "모델의 내부 가중치를 영구적으로 고정하고 싶을 때", "데이터셋의 용량이 매우 작을 때", "인터넷이 전혀 안 되는 환경일 때"], "정보가 수시로 업데이트되는 실시간 뉴스를 다뤄야 할 때", "RAG는 데이터베이스만 업데이트하면 즉시 최신 정보를 반영할 수 있어 효율적입니다.", "RAG vs Fine-tuning", "5004"),
    ("RAG 파이프라인 중 문서를 저장하기 위해 잘게 쪼개는 과정을 무엇이라 하는가?", ["Embedding", "Chunking (청킹)", "Scaling", "Masking", "Labeling"], "Chunking (청킹)", "모델의 인풋 제한(Context Window)에 맞춰 문서를 의미 있는 단위로 나누는 작업입니다.", "Chunking", "5005"),
    ("나눠진 텍스트 조각(Chunks)을 수치 형태의 벡터로 변환하는 모델을 무엇이라 부르는가?", ["LLM", "Embedding Model (임베딩 모델)", "Tokenizer", "Quantizer", "Compiler"], "Embedding Model (임베딩 모델)", "자연어의 의미를 고차원 공간상의 좌표(벡터)로 변환해주는 역할을 합니다.", "Embedding Model", "5006"),
    ("변환된 벡터들을 저장하고 의미 기반 검색을 지원하는 특수한 데이터베이스는?", ["MySQL", "Redis", "Vector Database (벡터 DB)", "MongoDB", "Oracle"], "Vector Database (벡터 DB)", "Pinecone, Chroma, Milvus 등 벡터 검색에 최적화된 DB를 활용합니다.", "Vector DB", "5007"),
    ("RAG에서 'Augmentation' 단계의 역할로 적절한 것은?", ["모델의 가중치를 키우는 행위", "검색된 결과물과 원래의 질문을 조합하여 풍부한 프롬프트를 만드는 것", "인터넷 속도를 높이는 작업", "모델의 성능 점수를 매기는 것", "데이터를 모두 지우는 것"], "검색된 결과물과 원래의 질문을 조합하여 풍부한 프롬프트를 만드는 것", "검색된 지식을 모델이 참고할 수 있도록 지시문과 함께 배치하는 단계입니다.", "Augmentation", "5008"),
    ("임베딩 벡터의 '차원(Dimension)'이 의미하는 바는?", ["데이터의 개수", "수치 데이터를 표현하는 화살표의 길이", "의미적 특징을 담고 있는 수치 리스트의 개수", "모델의 레이어 개수", "학습에 걸리는 시간"], "의미적 특징을 담고 있는 수치 리스트의 개수", "차원이 높을수록 더 정교한 의미를 담을 수 있지만 연산량도 늘어납니다.", "차원의 의미", "5009"),
    ("RAG 시스템 성능 평가 시, 생성된 답변이 검색된 문서에 실제로 근거하고 있는지 측정하는 지표는?", ["Hit Rate", "Faithfulness (충실도)", "Context Precision", "Answer Relevance", "Latency"], "Faithfulness (충실도)", "모델이 지어내서 대답(할루시네이션)하지 않고 근거에 충실했는지를 봅니다.", "Faithfulness", "5010"),
    ("LLM이 단순히 답만 하는 게 아니라, 도구를 사용하거나 자율적으로 판단하여 동작하는 주체를 무엇이라 하는가?", ["Chatbot", "Scanner", "LLM Agent (에이전트)", "Parser", "Optimizer"], "LLM Agent (에이전트)", "주어진 목표를 달성하기 위해 '생각(Thought)'과 '행동(Action)'을 반복하는 시스템입니다.", "Agent", "5011"),
    ("에이전트가 문제 해결을 위해 '생각 - 행동 - 관찰' 루프를 타는 대표적인 추론 방식은?", ["Chain of Thought (CoT)", "ReAct (Reasoning + Acting)", "Few-shot", "Top-P Sampling", "Fine-tuning"], "ReAct (Reasoning + Acting)", "사유와 행동, 외부 환경 관찰을 결합하여 복잡한 목표를 수행하는 방식입니다.", "ReAct", "5012"),
    ("에이전트가 외부 세계와 상호작용하기 위해 갖추고 있는 기능(예: 검색, 계산기, API 호출)을 일컫는 말은?", ["Parameters", "Weights", "Tools (도구)", "Layers", "Biases"], "Tools (도구)", "LangChain 등 프레임워크에서 에이전트가 실행할 수 있는 함수들을 정의한 것입니다.", "Tools", "5013"),
    ("랭체인(LangChain) 프레임워크에서 선언적인 파이프라인 구성을 위해 사용하는 문법은?", ["HTML/CSS", "LCEL (LangChain Expression Language)", "SQL Query", "Direct API Call", "Regular Expression"], "LCEL (LangChain Expression Language)", "파이프 연산자(|)를 사용해 데이터의 흐름을 직관적으로 연결합니다.", "LCEL", "5014"),
    ("에이전트가 이전 대화 내역이나 실행 결과를 기억하고 활용하기 위해 필요한 구성 요소는?", ["CPU", "GPU", "Memory (메모리)", "Disk", "Monitor"], "Memory (메모리)", "ConversationBufferMemory 등을 통해 대화의 맥락을 유지합니다.", "Agent Memory", "5015"),
    ("RAG 시스템에서 청킹(Chunking)을 너무 크게 했을 때 발생할 수 있는 부작용은?", ["검색 적중률이 너무 높아진다.", "불필요한 정보(Noise)가 섞여 모델의 답변이 흐려진다.", "비용이 전혀 들지 않는다.", "모델의 지능이 낮아진다.", "한국어 답변이 안 나온다."], "불필요한 정보(Noise)가 섞여 모델의 답변이 흐려진다.", "너무 큰 덩어리는 질문과 핵심적인 관련이 없는 내용까지 포함하여 추론을 방해할 수 있습니다.", "과한 청킹", "5016"),
    ("반대로 청킹을 너무 작게(10글자 등) 했을 때의 문제점은?", ["문맥(Context)이 단절되어 문서의 의미를 파악하기 힘들다.", "검색 속도가 100배 빨라진다.", "모델이 모든 내용을 외워버린다.", "서버가 중단된다.", "답변이 너무 길어진다."], "문맥(Context)이 단절되어 문서의 의미를 파악하기 힘들다.", "파편화된 정보만으로는 질문에 대한 충분한 배경 지식을 전달하기 어렵습니다.", "부족한 청킹", "5017"),
    ("벡터 DB 검색 성능 지표 중 'Hit Rate'의 의미로 옳은 것은?", ["서버가 다운된 횟수", "검색 결과 상위 K개 안에 실제 정답 문서가 포함된 비율", "화면을 클릭한 횟수", "데이터를 삭제한 개수", "비밀번호를 틀린 횟수"], "검색 결과 상위 K개 안에 실제 정답 문서가 포함된 비율", "검색 단계가 얼마나 질문과 연관된 문서를 잘 찾아오는지를 나타내는 기본 지표입니다.", "Hit Rate", "5018"),
    ("RAG 파이프라인 중 검색된 결과의 순위를 다시 매겨 정확도를 높이는 단계를 무엇이라 하나?", ["Pre-ranking", "Re-ranking (리랭킹)", "Decoding", "Encoding", "Flattening"], "Re-ranking (리랭킹)", "단순 벡터 유사도 계산 후, 더 정교한 모델로 실제 관련성을 재검증하는 과정입니다.", "Re-ranking", "5019"),
    ("에이전트 설계 시 '멀티 에이전트' 시스템의 장점은?", ["한 명의 에이전트가 모든 일을 다 하게 한다.", "역할별로 특화된 에이전트들이 협력하여 대규모 복잡한 문제를 효율적으로 푼다.", "비용을 무조건 줄여준다.", "AI 개발을 중단할 수 있다.", "컴퓨터 사양을 낮춰준다."], "역할별로 특화된 에이전트들이 협력하여 대규모 복잡한 문제를 효율적으로 푼다.", "기획 에이전트, 서칭 에이전트, 코딩 에이전트 등으로 분업하여 품질을 높입니다.", "Multi-Agent", "5020"),

    # 2. RAG 및 에이전트 상세 기술 (21-40)
    ("텍스트를 유의미한 단위로 나누기 위해 문장 구분자나 줄바꿈을 기준으로 재귀적으로 쪼개는 청커는?", ["CharacterTextSplitter", "RecursiveCharacterTextSplitter", "TokenTextSplitter", "RandomSplitter", "NoneSplitter"], "RecursiveCharacterTextSplitter", "의미적 단위를 최대한 보존하며 적절한 크기에 도달할 때까지 쪼개는 권장 방식입니다.", "Recursive Splitter", "5021"),
    ("RAG 환경에서 'Top-K' 값을 높이면 어떤 일이 벌어지는가?", ["검색 결과에 더 많은 문서 조각을 포함시킨다.", "답변의 글자 수가 무조건 줄어든다.", "모델이 더 빨리 답한다.", "비용이 할인된다.", "한글이 영어로 변한다."], "검색 결과에 더 많은 문서 조각을 포함시킨다.", "다양한 참조 문서를 넣을 수 있지만, 너무 많으면 문맥 초과나 노이즈가 발생할 수 있습니다.", "Top-K 조절", "5022"),
    ("임베딩 모델을 선택할 때 고려해야 할 'MTEB' 벤치마크란?", ["모델의 크기 측정기", "다양한 텍스트 임베딩 성능을 평가하는 표준 리더보드", "서버의 발열 측정", "모니터의 주사율", "인터넷 속도"], "다양한 텍스트 임베딩 성능을 평가하는 표준 리더보드", "성능이 검증된 임베딩 모델을 선택하기 위한 공신력 있는 참조 지표입니다.", "MTEB", "5023"),
    ("벡터 DB의 인덱싱 기법 중 '고속 근사 최근접 이웃(ANN)' 검색을 위해 쓰이는 대표적 알고리즘은?", ["B-Tree", "HNSW (Hierarchical Navigable Small World)", "Hash Table", "Bubble Sort", "Quick Search"], "HNSW (Hierarchical Navigable Small World)", "방대한 벡터 데이터 속에서 가장 유사한 좌표를 빠르게 찾는 핵심 알고리즘입니다.", "HNSW", "5024"),
    ("랭체인에서 PDF 문서를 읽어오기 위해 사용하는 컴포넌트의 타입은?", ["Document Writer", "Document Loader", "Document Deleter", "Document Hider", "Document Copier"], "Document Loader", "비정형 파일에서 텍스트와 메타데이터를 추출하는 시작점입니다.", "Loader", "5025"),
    ("검색된 문서의 연관성이 떨어지는 경우 질문을 더 검색하기 좋은 형태로 다시 쓰는 기법은?", ["Query Rewriting (쿼리 재작성)", "Text Deleting", "Word Counting", "Grammar Error", "Stop"], "Query Rewriting (쿼리 재작성)", "사용자의 모호한 질문을 AI가 풍부한 키워드로 변환하여 검색 정확도를 높입니다.", "Query Rewriting", "5026"),
    ("에이전트가 어떤 도구를 써야 할지 모델에게 알려주기 위해 제공하는 정보는?", ["도구의 소스 코드 전체", "도구의 이름, 기능 설명, 입력받을 인자(Parameter)의 스킴", "도구 제작자의 이름", "도구의 용량", "도구의 가격"], "도구의 이름, 기능 설명, 입력받을 인자(Parameter)의 스킴", "모델은 이 설명을 읽고 현재 상황에서 어떤 도구가 필요한지 논리적으로 판단합니다.", "Tool description", "5027"),
    ("RAG 시스템 운영 시 'Ground Truth'의 역할은?", ["실제 답변 데이터", "성능 측정 시 비교 대상이 되는 정답(기준값) 데이터셋", "서버의 위치", "모델의 이름", "사용자의 개인정보"], "성능 측정 시 비교 대상이 되는 정답(기준값) 데이터셋", "시스템이 낸 답이 실제 정답과 얼마나 유사한지 점수를 매기기 위한 기준입니다.", "Ground Truth", "5028"),
    ("임베딩 벡터 사이의 거리가 '가까울수록' 텍스트의 의미는 어떠한가?", ["아무 상관 없다.", "의미가 매우 유사하다.", "의미가 정반대다.", "철자가 완전히 다르다.", "영어로 쓰여 있다."], "의미가 매우 유사하다.", "벡터 공간상의 가까운 거리는 자연어 처리에서 의미적 연관성이 깊음을 뜻합니다.", "벡터 거리 의미", "5029"),
    ("검색 성능을 높이기 위해 벡터 유사도와 전통적인 키워드 매칭(BM25)을 섞어 쓰는 방식은?", ["Random Search", "Hybrid Search (하이브리드 검색)", "Linear Search", "Binary Search", "Manual Search"], "Hybrid Search (하이브리드 검색)", "의미적 유사성과 고유 대명사 매칭의 강점을 모두 활용하는 강력한 전략입니다.", "Hybrid Search", "5030"),
    ("에이전트가 루프에 빠져 무한히 도구를 실행하는 것을 방지하기 위한 안전장치는?", ["인터넷 끊기", "Max Iterations (최대 반복 횟수) 설정", "컴퓨터 끄기", "키보드 빼기", "질문 무시하기"], "Max Iterations (최대 반복 횟수) 설정", "일정 횟수 이상 도구를 돌려도 답이 안 나오면 중단하도록 하여 비용과 시간을 보호합니다.", "Max Iterations", "5031"),
    ("LCEL 문법에서 'prompt | model | parser' 구조일 때 'parser'의 역할은?", ["모델의 지능을 높임", "모델이 내놓은 텍스트 응답을 JSON이나 리스트 등 정형화된 데이터로 변환함", "프롬프트를 삭제함", "비용을 결제함", "오타를 냄"], "모델이 내놓은 텍스트 응답을 JSON이나 리스트 등 정형화된 데이터로 변환함", "AI의 답변을 소프트웨어 시스템에서 즉시 사용할 수 있는 데이터로 가공합니다.", "Output Parser", "5032"),
    ("벡터 DB의 메타데이터 필터링(Metadata Filtering)이 유용한 시나리오는?", ["유사도만으로 충분할 때", "특정 날짜 이후의 문서나 특정 작성자의 글만 검색 범위로 한정하고 싶을 때", "데이터가 아예 없을 때", "모델을 튜닝할 때", "영어를 안 쓸 때"], "특정 날짜 이후의 문서나 특정 작성자의 글만 검색 범위로 한정하고 싶을 때", "의미 기반 검색에 '조건'을 추가해 결과의 정확도를 비약적으로 높입니다.", "Metadata Filtering", "5033"),
    ("에이전트가 문제를 해결하는 과정을 사용자가 실시간으로 보게 하는 기술은?", ["Stealing", "Streaming (스트리밍)", "Cracking", "Stopping", "Hiding"], "Streaming (스트리밍)", "사고 과정(Thought)과 결과가 나오는 즉시 화면에 노출하여 UX를 개선합니다.", "Streaming", "5034"),
    ("사내 RAG 시스템 구축 시 데이터 보안을 위해 가장 권장되는 방식은?", ["모든 데이터를 공용 챗봇에 입력한다.", "보안이 확보된 내부망에 벡터 DB와 임베딩 서버를 구축한다.", "데이터를 암호화하지 않고 보관한다.", "누구나 검색 가능하게 설정한다.", "모든 사내 문서를 인터넷에 공개한다."], "보안이 확보된 내부망에 벡터 DB와 임베딩 서버를 구축한다.", "민감한 기업 정보가 외부로 새나가지 않도록 폐쇄적인 파이프라인을 유지해야 합니다.", "RAG 보안", "5035"),
    ("RAG 시스템에서 '환각'을 유발하는 가장 흔한 원인은?", ["모델이 너무 똑똑해서", "질문과 전혀 상관없는 문서 조각이 검색 결과로 제공될 때", "인터넷이 너무 빨라서", "화면이 너무 커서", "키보드 타이핑이 빨라서"], "질문과 전혀 상관없는 문서 조각이 검색 결과로 제공될 때", "잘못된 정보를 근거로 주면 모델은 그 정보에 맞춰 엉뚱한 결론을 내리게 됩니다.", "환각 원인", "5036"),
    ("청킹 시 앞뒤 조각의 내용을 일부 겹치게(Overlap) 설정하는 이유는?", ["데이터를 낭비하려고", "문장의 중간이 잘려 문맥의 의미가 훼손되는 것을 방지하기 위해", "똑같은 말을 반복하려고", "글자 수를 늘리려고", "비용을 높이려고"], "문장의 중간이 잘려 문맥의 의미가 훼손되는 것을 방지하기 위해", "조금씩 겹쳐야 문서의 전체적인 맥락이 끊기지 않고 벡터에 잘 반영됩니다.", "Overlap", "5037"),
    ("에이전트가 도구 사용을 거부하고 '직접 답'을 하려고만 한다면 고쳐야 할 부분은?", ["모델 가중치", "도구 사용법을 명확히 하고, 반드시 도구를 쓰도록 강조한 프롬프트(지침)", "마우스 마찰력", "방 안의 온도", "모니터 주사율"], "도구 사용법을 명확히 하고, 반드시 도구를 쓰도록 강조한 프롬프트(지침)", "시스템 프롬프트의 지시 강도를 높여 도구 사용의 당위성을 인지시켜야 합니다.", "도구 사용 지시", "5038"),
    ("RAGAS 프레임워크가 평가에 사용하는 주된 동력은?", ["사람의 설문조사", "LLM(거대 언어 모델) 자체를 평가자로 활용 (LLM-as-a-judge)", "단어 개수 세기", "파일 크기 측정", "랜덤 점수 부여"], "LLM(거대 언어 모델) 자체를 평가자로 활용 (LLM-as-a-judge)", "사람보다 빠르고 객관적인 기준(수식)으로 RAG의 품질 점수를 자동 산출합니다.", "RAGAS", "5039"),
    ("교재 5장을 학습하며 우리가 만들 수 있는 최종적인 형태는?", ["단순한 말동무 챗봇", "특정 도메인의 전문 지식을 검색하고 직접 작업을 수행하는 인텔리전트 에이전트", "타이핑 연습 게임", "인터넷 검색 엔진", "컴퓨터 수리 도구"], "특정 도메인의 전문 지식을 검색하고 직접 작업을 수행하는 인텔리전트 에이전트", "AI의 지능과 외부 데이터, 외부 도구가 결합된 진정한 애플리케이션의 핵심입니다.", "학습 결과", "5040"),

    # 3. 상황별 RAG/Agent 응용 시나리오 (41-70)
    ("복잡한 법률 판례를 RAG로 구축할 때 가장 중요한 청킹 전략은?", ["그냥 100글자씩 자르기", "법조항 섹션이나 판결 요지 단위로 의미를 보존하며 자르기", "아무렇게나 자르기", "자르지 않기", "영어로만 자르기"], "법조항 섹션이나 판결 요지 단위로 의미를 보존하며 자르기", "법률 문서는 구조가 중요하므로 의미적 완결성을 가진 단위로 나누어야 검색 정확도가 높습니다.", "법률 RAG", "5041"),
    ("에이전트가 '오늘 날씨'를 알려달라는 질문을 받았을 때 필요한 도구는?", ["계산기", "실시간 날씨 정보 API 연동 도구", "이미지 생성기", "소설 쓰기 도구", "파일 삭제기"], "실시간 날씨 정보 API 연동 도구", "학습 데이터에는 오늘 날씨가 없으므로 외부 API 호출이 필수적입니다.", "날씨 에이전트", "5042"),
    ("검색 속도를 개선하기 위해 로컬 컴퓨터 메모리에 벡터를 올리는 라이브러리는?", ["FAISS (Facebook AI Similarity Search)", "Excel", "Notepad", "PowerPoint", "Calculator"], "FAISS (Facebook AI Similarity Search)", "고밀도 벡터 검색을 CPU/GPU에서 고속으로 수행해주는 오픈소스 라이브러리입니다.", "FAISS", "5043"),
    ("RAG 시스템 구축 후 답변이 너무 느리다면 체크해야 할 단계는?", ["사용한 글꼴", "임베딩 생성 시간 및 검색 단계의 레이턴시(Latency)", "사용자의 의자 높이", "마우스 패드 재질", "방 안의 습도"], "임베딩 생성 시간 및 검색 단계의 레이턴시(Latency)", "문서 로딩이나 벡터 검색 과정에서 병목이 생기는지 확인해야 합니다.", "속도 개선", "5044"),
    ("에이전트가 SQL 쿼리를 직접 짜서 DB를 조회하게 할 때의 위험성과 해법은?", ["위험성 없음", "잘못된 쿼리로 데이터가 삭제될 수 있으므로 전용 읽기 권한(Read-only) 계정을 부여한다.", "AI는 SQL을 모른다.", "데이터가 너무 많아진다.", "컴퓨터가 폭발한다."], "잘못된 쿼리로 데이터가 삭제될 수 있으므로 전용 읽기 권한(Read-only) 계정을 부여한다.", "보안과 데이터 무결성을 위해 실행 권한을 최소화하는 하드닝 작업이 필요합니다.", "SQL 에이전트 보안", "5045"),
    ("고객 상담 RAG에서 '질문-답변 쌍'을 수만 개 저장했을 때 효과적인 필터링은?", ["무조건 다 읽기", "카테고리 메타데이터를 활용한 필터링 후 검색", "가나다 순 검색", "최근 저장 순 검색", "파일 이름 검색"], "카테고리 메타데이터를 활용한 필터링 후 검색", "검색 범위를 미리 좁히면 속도와 정확도가 동시에 향상됩니다.", "대량 데이터 검색", "5046"),
    ("사용자의 질문이 너무 짧아(예: '그거 알려줘') 검색이 안 될 때 에이전트의 대처는?", ["모른다고 화내기", "질문의 의도를 다시 물어보며 정보를 구체화해달라고 요청하기", "아무거나 알려주기", "인터넷 연결 끊기", "로그아웃 시키기"], "질문의 의도를 다시 물어보며 정보를 구체화해달라고 요청하기", "대화형 에이전트의 강점을 살려 부족한 정보를 사용자에게 되묻는 지능적 행동입니다.", "질문 구체화", "5047"),
    ("임베딩 모델의 성능이 한국어에서 떨어진다면?", ["한국어를 포기한다.", "한국어 데이터로 학습된 특화 임베딩 모델(Ko-Embedding)을 검토한다.", "영어로만 모든 문서를 바꾼다.", "키보드를 한글용으로 바꾼다.", "파이썬 버전을 높인다."], "한국어 데이터로 학습된 특화 임베딩 모델(Ko-Embedding)을 검토한다.", "언어적 뉘앙스를 잘 파악하는 로컬 특화 모델이 RAG 품질을 좌우합니다.", "한국어 임베딩", "5048"),
    ("검색된 문서 내용이 상충할 때(A문서는 된다, B문서는 안 된다) 모델에게 줄 가이드는?", ["아무거나 믿어라", "최신 날짜의 문서를 우선시하거나, 상충하는 내용을 모두 보여주며 판단을 돕게 한다.", "답변을 하지 마라", "화내라", "둘을 합쳐서 제3의 답변을 지어내라"], "최신 날짜의 문서를 우선시하거나, 상충하는 내용을 모두 보여주며 판단을 돕게 한다.", "정보의 일관성을 관리하는 정책을 프롬프트나 로직에 반영해야 합니다.", "정보 상충 해결", "5049"),
    ("RAG 시스템을 웹 서비스로 배포할 때 사용하는 LangChain 호환 도구는?", ["LangServe", "HTML Edit", "Paint", "Excel Online", "Minesweeper"], "LangServe", "작성한 체인을 REST API 형태로 즉시 공개해주는 배포 특화 도구입니다.", "LangServe", "5050"),
    ("에이전트가 도구를 실행한 후 나온 '결과'를 ReAct에서 부르는 용어는?", ["Thought", "Action", "Observation (관찰)", "Final Answer", "Input"], "Observation (관찰)", "도구의 출력값을 통해 모델이 현 상황을 파악하는 단계를 의미합니다.", "Observation", "5051"),
    ("RAG 개발 시 문서를 벡터화하는 작업을 미리 해두는 과정을 무엇이라 하나?", ["Online Ingestion", "Offline Indexing / Ingestion", "Real-time Chat", "Slow Reading", "Deleting"], "Offline Indexing / Ingestion", "사용자 질문 전에 데이터를 미리 준비해두는 배치 작업입니다.", "Indexing", "5052"),
    ("모델이 답변 도중 '출처: 교재 123페이지'라고 적게 하려면?", ["모델이 알아서 한다.", "프롬프트에 '검색된 문서의 메타데이터 중 페이지 정보를 반드시 명시해'라고 지시한다.", "페이지를 다 외우게 한다.", "가짜 번호를 적는다.", "페이지 번호를 다 지운다."], "프롬프트에 '검색된 문서의 메타데이터 중 페이지 정보를 반드시 명시해'라고 지시한다.", "근거 제시(Citation)는 RAG 시스템의 신뢰도를 높여주는 강력한 장치입니다.", "출처 명시", "5053"),
    ("여러 개의 질문을 한 번에 처리하는 에이전트 효율화 기법은?", ["한 개씩 한다.", "Async(비동기) 처리나 배치 처리를 활용한다.", "컴퓨터를 여러 대 산다.", "사용자를 기다리게 한다.", "질문을 지운다."], "Async(비동기) 처리나 배치 처리를 활용한다.", "동시에 여러 지식 소스를 검색하거나 도구를 돌려 응답 시간을 단축합니다.", "비동기 처리", "5054"),
    ("RAG 시스템 성능 측정 도구 'Ragas'에서 Faithfulness가 0.1이라면?", ["아주 훌륭하다.", "모델이 검색된 근거와 무관한 소설을 쓰고 있다는 매우 위험한 신호다.", "컴퓨터가 고장 났다.", "점수가 원래 낮다.", "무시해도 된다."], "모델이 검색된 근거와 무관한 소설을 쓰고 있다는 매우 위험한 신호다.", "근거 충실도가 낮으므로 프롬프트를 고치거나 검색 품질을 점검해야 합니다.", "저점수 분석", "5055"),
    ("에이전트가 '반복 루프'에 빠졌을 때 터미널 로그에서 확인해야 할 것은?", ["프롬프트 색깔", "Thought와 Action이 동일한 내용으로 반복되는지 여부", "내 아이디", "오늘 날짜", "파이썬 로고"], "Thought와 Action이 동일한 내용으로 반복되는지 여부", "논리가 막혔거나 도구 설명이 모호할 때 발생하는 전형적인 에이전트 에러입니다.", "루프 확인", "5056"),
    ("청킹 시 '의미 구조'를 파악하여 제목과 본문을 연결해두면 좋은 점은?", ["파일 이름이 예뻐진다.", "검색 시 본문만 나오는 게 아니라 제목이라는 문맥 정보도 함께 제공되어 정확도가 오른다.", "똑같은 지식이 두 번 저장된다.", "용량이 늘어난다.", "속도가 느려진다."], "검색 시 본문만 나오는 게 아니라 제목이라는 문맥 정보도 함께 제공되어 정확도가 오른다.", "상위 카테고리 정보가 포함된 청크는 모델이 정보를 파악하는 데 훨씬 유리합니다.", "구조화 청킹", "5057"),
    ("RAG 시스템에서 '토큰 비용'을 가장 많이 잡아먹는 단계는?", ["모델의 1글자 답변", "다량의 검색 결과 조각을 프롬프트에 통째로 밀어넣는 Augmentation 단계", "마우스 클릭", "파일 저장", "윈도우 업데이트"], "다량의 검색 결과 조각을 프롬프트에 통째로 밀어넣는 Augmentation 단계", "검색 결과를 너무 많이 넣으면 입력 토큰량이 급증하여 비용이 상승합니다.", "비용 병목", "5058"),
    ("에이전트에게 '전문가 페르소나'를 부여하는 것이 도구 사용과 관련이 있나?", ["상관없다.", "네, 전문가로서 어떤 상황에 어떤 도구를 쓰는 것이 논리적인지 더 잘 판단하게 돕는다.", "전혀 아니다.", "모델이 기분 나빠한다.", "돈이 더 든다."], "네, 전문가로서 어떤 상황에 어떤 도구를 쓰는 것이 논리적인지 더 잘 판단하게 돕는다.", "페르소나는 에이전트의 판단 로직 전반에 가이드라인 역할을 합니다.", "페르소나와 도구", "5059"),
    ("최종적으로 RAG와 에이전트를 결합했을 때의 모습은?", ["단순 텍스트 생성기", "외부 지식을 스스로 찾아 학습하고 실제 업무(API 호출 등)를 수행하는 인공지능 비서", "인터넷 게시판", "성적표 계산기", "게임 캐릭터"], "외부 지식을 스스로 찾아 학습하고 실제 업무(API 호출 등)를 수행하는 인공지능 비서", "생성 AI가 실질적인 비즈니스 가치를 창출하는 가장 강력한 워크플로우입니다.", "에이전틱 RAG", "5060"),

    # 추가 40문제 (응용)
    ("LangChain의 'Memory' 옵션 중 'ConversationSummaryMemory'의 장점은?", ["모든 대화를 다 저장한다.", "긴 대화 내역을 요약해서 보관하므로 토큰 사용량을 효율적으로 관리할 수 있다.", "비밀번호를 외운다.", "사진을 저장한다.", "인터넷이 빨라진다."], "긴 대화 내역을 요약해서 보관하므로 토큰 사용량을 효율적으로 관리할 수 있다.", "대화가 길어져도 핵심 맥락을 유지하면서 비용을 절감하는 영리한 방법입니다.", "Summary Memory", "5061"),
    ("검색된 문서가 너무 많아 모델의 Context Window를 초과할 때의 대처법은?", ["모델을 바꾼다.", "검색 결과를 요약해서 넣거나 리랭킹을 통해 상위 3개만 추려 넣는다.", "컴퓨터를 끈다.", "글자를 작게 적는다.", "영어로 번역한다."], "검색 결과를 요약해서 넣거나 리랭킹을 통해 상위 3개만 추려 넣는다.", "입력 제한을 지키면서 알짜 정보만 전달하는 엔지니어링이 필요합니다.", "컨텍스트 초과 대처", "5062"),
    ("RAG 시스템에서 'Semantic Search'가 'Keyword Search'보다 나은 점은?", ["오타가 나면 검색이 안 된다.", "단어가 일치하지 않아도 의미적으로 유사한 내용을 찾아낼 수 있다.", "속도가 훨씬 빠르다.", "가격이 무료다.", "모델이 안 필요하다."], "단어가 일치하지 않아도 의미적으로 유사한 내용을 찾아낼 수 있다.", "자연어의 맥락을 파악하므로 사용자 의도에 훨씬 부합하는 결과를 줍니다.", "의미 검색 장점", "5063"),
    ("에이전트 프롬프트에 'Thought:'라고 형식을 지정해주는 이유는?", ["모델을 놀리려고", "모델이 자신의 추론 과정을 명시적으로 적도록 강제하여 정답률을 높이기 위해", "서버 이름을 지으려고", "글자 수 채우려고", "내 이름 쓰려고"], "모델이 자신의 추론 과정을 명시적으로 적도록 강제하여 정답률을 높이기 위해", "CoT와 마찬가지로 중간 사고 단계를 거치게 함으로써 실수를 방지합니다.", "Thought 형식", "5064"),
    ("RAG 시스템 평가 지표 중 'Answer Relevance'가 낮다면 원인은?", ["검색은 잘 됐으나 모델이 질문과 무관한 엉뚱한 답변을 함", "인터넷이 끊김", "모델이 너무 똑똑함", "사용자가 질문을 안 함", "파일이 삭제됨"], "검색은 잘 됐으나 모델이 질문과 무관한 엉뚱한 답변을 함", "검색 품질보다는 모델의 생성 능력이나 가이드라인(프롬프트)에 문제가 있는 경우입니다.", "Answer Relevance", "5065"),
    ("에이전트가 도구를 사용할 때 'Observation' 값을 읽지 못한다면?", ["모델을 때린다.", "도구의 반환 형식이 문자열(String) 등 모델이 읽기 쉬운 형태인지 확인한다.", "파일을 다 지운다.", "모니터를 닦는다.", "인터넷을 바꾼다."], "도구의 반환 형식이 문자열(String) 등 모델이 읽기 쉬운 형태인지 확인한다.", "데이터 파이프라인의 입출력 형식이 맞아야 에이전트가 다음 판단을 내릴 수 있습니다.", "관찰값 확인", "5066"),
    ("사내 RAG 서버에서 'PDF 테이블'이 텍스트로만 읽혀 구조가 깨진다면?", ["표를 직접 그린다.", "표 구조를 인식하는 전용 Loader나 레이아웃 분석 모델을 활용한다.", "표를 무시한다.", "숫자만 다 지운다.", "PDF를 사진으로 찍는다."], "표 구조를 인식하는 전용 Loader나 레이아웃 분석 모델을 활용한다.", "데이터의 레이아웃을 보존하며 파싱하는 기술이 고도화된 RAG의 품질을 결정합니다.", "표 인식", "5067"),
    ("LangChain의 'RouterChain'을 사용하여 얻을 수 있는 효과는?", ["모든 명령을 한 곳으로 보낸다.", "질문의 주제에 따라 서로 다른 프롬프트나 DB 검색 경로로 자동 배정한다.", "인터넷 속도가 빨라진다.", "비용이 무조건 0원이다.", "컴퓨터가 알아서 꺼진다."], "질문의 주제에 따라 서로 다른 프롬프트나 DB 검색 경로로 자동 배정한다.", "효율적인 작업 분배를 통해 전문성 있는 답변을 가능하게 합니다.", "RouterChain", "5068"),
    ("RAG 개발 시 '임베딩 모델'과 '생성 모델'의 회사가 달라도 되나?", ["절대 안 된다.", "상관없지만, 임베딩 모델의 차원과 벡터 DB 설정은 일치해야 한다.", "회사 이름이 같아야 한다.", "모델을 섞으면 폭발한다.", "아무도 시도하지 않았다."], "상관없지만, 임베딩 모델의 차원과 벡터 DB 설정은 일치해야 한다.", "다양한 모델을 조합(Mix & Match)하여 최적의 가성비를 찾는 것이 실무입니다.", "모델 조합", "5069"),
    ("에이전트가 '반복적인 질문'을 받을 때 성능을 높이는 메모리 기법은?", ["다 잊어버리기", "이전 답변을 캐싱(Caching)하여 동일한 질문엔 빠르게 답하기", "질문을 무시하기", "일부러 틀리기", "돈을 더 내기"], "이전 답변을 캐싱(Caching)하여 동일한 질문엔 빠르게 답하기", "반복적인 인프라 비용과 응답 지연을 방지하는 실용적인 방법입니다.", "캐싱", "5070"),
    ("RAG 파이프라인 중 'Semantic Chunking'이란?", ["글자 수로 자르기", "의미가 변하는 지점을 감지하여 논리적 단락 단위로 자르기", "아무렇게나 자르기", "영어로 자르기", "숫자만 자르기"], "의미가 변하는 지점을 감지하여 논리적 단락 단위로 자르기", "단순 글자 수보다 훨씬 정교하게 지식의 맥락을 보존하는 청킹 방식입니다.", "Semantic Chunking", "5071"),
    ("에이전트의 '자율성'을 제한하고 사람이 승인할 때만 실행하게 하는 설정은?", ["AI의 반란 방지", "Human-in-the-loop (사람의 개입)", "AI 정지", "사용자 차단", "서버 종료"], "Human-in-the-loop (사람의 개입)", "안전이 중요한 작업(예: 결제, 이메일 발송)에서 필수적인 설계 패턴입니다.", "Human-in-the-loop", "5072"),
    ("RAG 시스템 평가 시 'Context Precision'이란?", ["답변이 얼마나 긴가", "검색된 문서들 중 실제 질문과 관련된 문서가 상위에 잘 배치되었는가", "화질이 좋은가", "글꼴이 예쁜가", "오타가 없는가"], "검색된 문서들 중 실제 질문과 관련된 문서가 상위에 잘 배치되었는가", "검색 품질의 정교함을 나타내는 지표 중 하나입니다.", "Context Precision", "5073"),
    ("에이전트가 어떤 도구를 썼는지 사용자에게 보여주지 않는 'Private Agent'를 만드는 법은?", ["그냥 숨기기", "중간 과정(Intermediate Steps)을 사용자 응답 메시지에서 제외하도록 구현하기", "아무것도 안 하기", "파일 지우기", "비밀번호 걸기"], "중간 과정(Intermediate Steps)을 사용자 응답 메시지에서 제외하도록 구현하기", "사용자에게는 결과만 깔끔하게 보여주기 위한 UX 설계입니다.", "Private Agent", "5074"),
    ("벡터 DB 인덱싱 중 '브루트 포스(Brute-force)' 방식의 특징은?", ["가장 빠르다.", "모든 벡터와 하나하나 대조하므로 매우 정확하지만 데이터가 많으면 심각하게 느리다.", "아무도 안 쓴다.", "가장 싸다.", "예쁘다."], "모든 벡터와 하나하나 대조하므로 매우 정확하지만 데이터가 많으면 심각하게 느리다.", "데이터 양이 적을 때나 정확도 100%가 필요할 때만 제한적으로 쓰입니다.", "Brute-force", "5075"),
    ("에이전팅 시스템의 발열이나 리소스 낭비를 막기 위해 필요한 것은?", ["에어컨", "에이전트의 실행 시간을 제한하는 타임아웃(Timeout) 설정", "컴퓨터 끄기", "찬물 끼얹기", "질문 무시"], "에이전트의 실행 시간을 제한하는 타임아웃(Timeout) 설정", "응답 지연이 너무 길어지면 자원을 반납하게 하여 시스템 안정성을 지킵니다.", "Timeout", "5076"),
    ("RAG에서 'Multimodal Retrieval'의 특징은?", ["글자만 찾기", "이미지, 오디오 등 텍스트 이외의 데이터도 벡터로 검색하기", "여러 번 찾기", "한 명만 찾기", "거짓말 찾기"], "이미지, 오디오 등 텍스트 이외의 데이터도 벡터로 검색하기", "다양한 매체의 정보를 의미 기반으로 통합 검색하는 고난도 기술입니다.", "Multimodal RAG", "5077"),
    ("에이전트가 답변을 낼 때 '저는 AI라서 몰라요'라고만 한다면?", ["AI가 맞다.", "프롬프트의 페르소나와 작업 수행 의지를 보강하고 제약 사항을 완화한다.", "AI를 그만 쓴다.", "질문을 지운다.", "다른 사람에게 물어본다."], "프롬프트의 페르소나와 작업 수행 의지를 보강하고 제약 사항을 완화한다.", "모델의 방어적인 태도를 능동적인 문제 해결 모드로 전환시켜야 합니다.", "능동성 주입", "5078"),
    ("벡터 DB의 데이터를 주기적으로 동기화해야 하는 이유는?", ["용량을 채우려고", "원본 지식 베이스의 변경 사항이 RAG 시스템에 최신 상태로 반영되어야 하므로", "인터넷 속도 때문에", "컴퓨터가 심심해서", "비용을 내려고"], "원본 지식 베이스의 변경 사항이 RAG 시스템에 최신 상태로 반영되어야 하므로", "정보가 죽은 정보가 되지 않도록 지속적으로 신선함을 유지하는 파이프라인이 필수입니다.", "데이터 동기화", "5079"),
    ("성공적인 RAG/에이전트 개발자가 되기 위한 마음가짐은?", ["한 번에 완벽할 수 있다.", "데이터, 임베딩, 검색, 생성을 끊임없이 실험하고 측정하며 다듬어야 한다.", "남의 코드를 복사만 한다.", "운에 맡긴다.", "컴퓨터를 비싼 걸 산다."], "데이터, 임베딩, 검색, 생성을 끊임없이 실험하고 측정하며 다듬어야 한다.", "모든 단계가 유기적으로 얽혀 있으므로 전 과정을 세심하게 튜닝하는 끈기가 핵심입니다.", "엔지니어의 태도", "5080"),

    # 남은 20문제
    ("RAG 시스템에서 '질문(Query)'을 임베딩할 때와 '문서(Document)'를 임베딩할 때의 모델은?", ["서로 다른 회사 제품이어야 한다.", "반드시 동일한 임베딩 모델과 동일한 벡터 차원을 사용해야 한다.", "모델을 안 써도 된다.", "아무거나 써도 된다.", "영문 모델만 써야 한다."], "반드시 동일한 임베딩 모델과 동일한 벡터 차원을 사용해야 한다.", "같은 의미 공간(Vector Space) 상에 있어야 유사도 비교가 가능합니다.", "동일 모델 사용", "5081"),
    ("에이전트가 도구의 '파라미터' 형식을 자꾸 틀린다면?", ["모델을 비난한다.", "도구 정의 시 Pydantic 등을 사용해 데이터 형식을 명확히 정의하고 프롬프트로 가이드한다.", "타이핑을 대신 해준다.", "형식을 없앤다.", "인터넷을 바꾼다."], "도구 정의 시 Pydantic 등을 사용해 데이터 형식을 명확히 정의하고 프롬프트로 가이드한다.", "모델이 어떤 데이터 타입을 넣어야 하는지 엄격하게 인지시키는 것이 에이전트의 안정성입니다.", "파라미터 가이드", "5082"),
    ("RAG 파이프라인 성능을 시각적으로 모니터링해주는 랭체인 서비스는?", ["LangSmith", "LangPaint", "LangExcel", "LangWorld", "LangView"], "LangSmith", "복잡한 체인의 단계별 입출력을 트래킹하여 디버깅을 돕는 필수 서비스입니다.", "LangSmith", "5083"),
    ("검색된 문서의 '날짜'가 틀리다면 어떤 정보를 업데이트해야 하나?", ["모델 이름", "벡터 데이터베이스 내 조각들의 메타데이터(Metadata)", "내 나이", "모니터 시계", "키보드 한영키"], "벡터 데이터베이스 내 조각들의 메타데이터(Metadata)", "메타데이터는 가공된 데이터의 상세 속성을 담고 있어 정확한 필터링과 출처 표시를 돕습니다.", "메타데이터 수정", "5084"),
    ("에이전트가 도구 사용 도중 '에러 메시지'를 받으면 어떻게 대처하나?", ["즉시 중단한다.", "루프 체계에 따라 에러 메시지를 다시 '관찰'값으로 받아 스스로 수정을 시도하게 설계한다.", "사용자에게 욕한다.", "컴퓨터를 끈다.", "무시한다."], "루프 체계에 따라 에러 메시지를 다시 '관찰'값으로 받아 스스로 수정을 시도하게 설계한다.", "에러 자가 수정은 고도로 능동적인 에이전트의 특징입니다.", "에러 자가 수정", "5085"),
    ("RAG에서 'Context Relevance'가 0점이라면?", ["답변이 짧다.", "검색된 문서가 원래 질문과 아무런 상관이 없는 쓰레기 정보였다는 뜻이다.", "만점이다.", "컴퓨터가 꺼졌다.", "파일이 많다."], "검색된 문서가 원래 질문과 아무런 상관이 없는 쓰레기 정보였다는 뜻이다.", "검색 알고리즘이나 임베딩 모델의 품질을 원점에서 재검토해야 함을 시사합니다.", "Context Relevance 중요성", "5086"),
    ("에이전트의 '최종 답변'에 도달했음을 알려주는 지시자는?", ["Stop", "Final Answer:", "The End", "Bye", "Logout"], "Final Answer:", "이 접두어(Prefix) 뒤의 텍스트가 사용자에게 전달될 최종 결과임을 모델에게 인지시킵니다.", "Final Answer", "5087"),
    ("RAG에서 'Hybrid Search' 도입 시 조절하는 알파(Alpha) 값의 의미는?", ["모델의 지능", "벡터 검색(의미)과 키워드 검색(정확)의 비중을 가중하여 합계 점수를 내는 비율", "인터넷 속도", "비용 할인율", "글자 크기"], "벡터 검색(의미)과 키워드 검색(정확)의 비중을 가중하여 합계 점수를 내는 비율", "0.5는 반반, 1.0은 오직 벡터 검색만 하는 등 밸런스를 맞추는 값입니다.", "Alpha 값", "5088"),
    ("에이전트 시스템에서 '라우팅(Routing)'이란?", ["네트워크 선 연결하기", "사용자의 의도에 따라 어떤 에이전트나 어떤 파이프라인으로 보낼지 정하는 교통정리", "길 찾기", "비행기 타기", "가장 빠른 길 검색"], "사용자의 의도에 따라 어떤 에이전트나 어떤 파이프라인으로 보낼지 정하는 교통정리", "효율적인 자원 배분과 요구사항 해결을 위한 분기 로직입니다.", "Routing", "5089"),
    ("RAG 시스템 운영 시 '토큰 절약'을 위해 문장의 중요 실질어만 남기는 처리는?", ["Text Deletion", "Stopword Removal (불용어 제거)", "Copy & Paste", "Bold Text", "Underline"], "Stopword Removal (불용어 제거)", "은, 는, 이, 가 같은 불필요한 단어를 걷어내어 토큰 효율을 높이는 기교입니다.", "불용어 제거", "5090"),
    ("에이전트 도구로 '웹 검색'을 추가했을 때의 이점은?", ["전기가 아껴진다.", "모델 학습 데이터 이후의 최신 정보를 실시간으로 탐색할 수 있다.", "AI가 사람처럼 변한다.", "돈을 더 많이 번다.", "재미있다."], "모델 학습 데이터 이후의 최신 정보를 실시간으로 탐색할 수 있다.", "RAG와 결합된 웹 서칭은 에이전트의 지식 한계를 무한히 확장합니다.", "웹 검색 도구", "5091"),
    ("임베딩 모델의 '차원'이 1536이라면 벡터는 어떤 모양인가?", ["1536개의 숫자가 담긴 리스트 주머니", "1536개의 단어", "1536미터 길이의 줄", "1536개의 그림", "1536층 건물"], "1536개의 숫자가 담긴 리스트 주머니", "고차원 공간상의 한 지점을 가리키는 1536개의 수치 좌표입니다.", "차원 모양", "5092"),
    ("RAG 파이프라인 중 'Document Preprocessing' 단계에서 하는 것은?", ["데이터 지우기", "HTML 태그 제거, 노이즈 텍스트 필터링, 정규화 등 데이터 정제", "이름 바꾸기", "폴더 이동하기", "파일 압축하기"], "HTML 태그 제거, 노이즈 텍스트 필터링, 정규화 등 데이터 정제", "깨끗한 데이터가 들어가야 벡터 값도 명확하고 답변도 깔끔하게 나옵니다.", "전처리", "5093"),
    ("에이전트가 '생각(Thought)' 단계에서 자신의 한계를 인지하면?", ["포기한다.", "사용자에게 추가 정보를 요청하거나 작업 불가 상황임을 보고한다.", "허풍을 친다.", "울음을 터트린다.", "로그아웃한다."], "사용자에게 추가 정보를 요청하거나 작업 불가 상황임을 보고한다.", "자신의 능력 범위를 알고 정직하게 소통하는 것 또한 훌륭한 에이전트의 기능입니다.", "한계 인지", "5094"),
    ("RAG 시스템 성능이 '임의의 질문'에 대해 들쭉날쭉하다면?", ["운이 없다.", "다양한 시나리오가 담긴 벤치마킹 데이터셋으로 전수 검사를 수행해 병목을 찾는다.", "컴퓨터를 바꾼다.", "질문을 줄인다.", "모델 가격을 낮춘다."], "다양한 시나리오가 담긴 벤치마킹 데이터셋으로 전수 검사를 수행해 병목을 찾는다.", "일관성 있는 품질을 위해 체계적인 테스트와 튜닝이 뒷받침되어야 합니다.", "품질 안정화", "5095"),
    ("에이전트의 '자율 행동' 도중 비용이 폭주하지 않게 하려면?", ["돈을 안 낸다.", "입출력 토큰 제한과 중간 단계 실행 횟수의 엄격한 한도(Budget)를 둔다.", "서버를 부순다.", "질문을 무시한다.", "천천히 타이핑한다."], "입출력 토큰 제한하고 중간 단계 실행 횟수의 엄격한 한도(Budget)를 둔다.", "운영 안정성과 경제성을 위해 반드시 적용해야 할 관리 장치입니다.", "비용 관리", "5096"),
    ("RAG에서 'Small-to-Big Retrieval'이란?", ["작은 AI가 찾고 큰 AI가 답하기", "검색은 작은 조각(Sentence)으로 하고, 답은 그 주변 문맥(Paragraph)까지 포함해 하기", "파일 크기를 키우기", "데이터를 늘리기", "비용을 비싸게 하기"], "검색은 작은 조각(Sentence)으로 하고, 답은 그 주변 문맥(Paragraph)까지 포함해 하기", "검색 적중률과 문맥 전달력이라는 두 마리 토끼를 다 잡는 기법입니다.", "Small-to-Big", "5097"),
    ("에이전트 도구가 '파일 생성' 기능을 가졌을 때의 보안 관리법은?", ["마음대로 쓰게 둔다.", "시스템 전용 샌드박스(Sandbox) 환경에서만 작동하게 격리하여 보안을 지킨다.", "파일을 못 만들게 한다.", "사용자 비번을 준다.", "파일 이름을 공란으로 한다."], "시스템 전용 샌드박스(Sandbox) 환경에서만 작동하게 격리하여 보안을 지킨다.", "외부 시스템에 영향을 주지 않도록 안전한 테두리 안에서 돌려야 합니다.", "도구 보안", "5098"),
    ("RAG 시스템 구축 후 '만족도 설문' 결과가 나쁘다면?", ["사용자를 차단한다.", "사용자 피드백을 Context에 넣어 수동으로 튜닝하거나 검색 상위 노출 순서를 보정한다.", "서비스를 종료한다.", "모델을 욕한다.", "가격표를 올린다."], "사용자 피드백을 Context에 넣어 수동으로 튜닝하거나 검색 상위 노출 순서를 보정한다.", "서비스는 항상 사용자의 실질적인 만족을 향해 피드백 루프를 돌아야 합니다.", "피드백 반영", "5099"),
    ("에이전트와 RAG 기술의 공통된 최종 목표는?", ["AI를 인간보다 똑똑하게 만들기", "LLM을 실제 비즈니스 도메인에 연결하여 실질적이고 정확한 가치를 창출하는 것", "인터넷 속도 경쟁", "전력 소비 늘리기", "글자 많이 쓰기"], "LLM을 실제 비즈니스 도메인에 연결하여 실질적이고 정확한 가치를 창출하는 것", "인간의 지적 활동을 돕고 자동화하는 현실적인 솔루션으로서의 가치입니다.", "최종 목표", "5100")
]

for q, o, a, w, h, i in mcq_data:
    questions.append({"chapter_name": chapter_name, "type": "객관식", "difficulty": "medium", "id": i, "question": q, "options": o, "answer": a, "why": w, "hint": h})

# --- 20 Code Completion Questions ---
cc_data = [
    ("검색 증강", "____: 검색 결합 생성 기술. (이 부분을 채우세요)", "RAG", "Retrieval-Augmented Generation"),
    ("지능형 주체", "____: 스스로 판단하고 도구를 쓰는 AI. (이 부분을 채우세요)", "Agent", "자율적으로 비서를 수행하는 주체입니다."),
    ("문서 쪼개기", "____ing: 수천 페이지 문서를 조각냄. (이 부분을 채우세요)", "Chunk", "청킹이라고 부르는 과정입니다."),
    ("수치화 모델", "____ing Model: 텍스트를 벡터로 변환. (이 부분을 채우세요)", "Embedd", "임베딩 모델을 의미합니다."),
    ("전용 저장소", "____ Database: 고차원 벡터 전용 DB. (이 부분을 채우세요)", "Vector", "유사도 검색에 특화된 DB입니다."),
    ("유사도 측정", "____ Similarity: 각도 기반 유사도. (이 부분을 채우세요)", "Cosine", "코사인 유사도입니다."),
    ("보강 단계", "Context ____: 검색 내용을 질문에 합침. (이 부분을 채우세요)", "Augmentation", "증강 또는 보강 단계입니다."),
    ("추론 패턴", "____ (Reasoning + Acting): 에이전틱 사고법. (이 부분을 채우세요)", "ReAct", "사고와 행동의 결합 패턴입니다."),
    ("에이전트 도구", "____: 계산기, 검색 등 함수 꾸러미. (이 부분을 채우세요)", "Tools", "에이전트가 활용하는 기능들입니다."),
    ("프레임워크", "____Chain: AI 앱 빌딩 라이브러리. (이 부분을 채우세요)", "Lang", "가장 대표적인 프레임워크인 랭체인입니다."),
    ("문서 불러오기", "PyPDF____: PDF 읽기 클래스. (이 부분을 채우세요)", "Loader", "로더(Loader)를 뜻합니다."),
    ("유사도 검색어", "db._____search(query): 유사도 검색 함수. (이 부분을 채우세요)", "similarity", "정확한 함수명은 similarity_search입니다."),
    ("문법 체계", "____ (LangChain Expression Language): 문법. (이 부분을 채우세요)", "LCEL", "랭체인 표현 언어의 약자입니다."),
    ("평가 도구", "____: RAG 성능 점수 측정 라이브러리. (이 부분을 채우세요)", "Ragas", "평가 라이브러리 이름입니다."),
    ("환각 지표", "____ness: 근거 충실도 지표. (이 부분을 채우세요)", "Faithful", "정확하게는 Faithfulness입니다."),
    ("조각간 중첩", "Chunk ____: 문맥 보존을 위해 겹침. (이 부분을 채우세요)", "Overlap", "청크 오버랩 기술입니다."),
    ("고속 인덱스", "____ (Hierarchical Navigable Small World). (이 부분을 채우세요)", "HNSW", "벡터 검색 가속용 인덱스 알고리즘입니다."),
    ("순위 재조정", "Re-____ing: 검색 후 정확도 순위 조절. (이 부분을 채우세요)", "rank", "리랭킹 기법입니다."),
    ("에이전트 메모리", "____BufferMemory: 대화 내역 저장소. (이 부분을 채우세요)", "Conversation", "대화 요지를 기억하는 메모리입니다."),
    ("지능형 경로", "____ing Agent: 질문 주제별 분리 주체. (이 부분을 채우세요)", "Rout", "라우팅(Routing)을 수행하는 에이전트입니다.")
]

for i, (title, code, ans, explain) in enumerate(cc_data):
    questions.append({
        "chapter_name": chapter_name, "type": "코드 완성형", "difficulty": "medium", "id": str(5101 + i),
        "question": f"{title} 개념을 완성하세요.\n```text\n{code}\n```",
        "answer": ans,
        "why": explain,
        "hint": title,
    })

def get_questions():
    return questions
