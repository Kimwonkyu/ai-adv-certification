{
    "questions": [
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 '얕은 복사(Shallow Copy)'와 '깊은 복사(Deep Copy)'의 주된 차이점은 무엇인가요?",
            "options": [
                "얕은 복사는 속도가 빠르고 깊은 복사는 속도가 느리다.",
                "얕은 복사는 최상위 객체만 새로 만들고 내부 객체는 참조를 공유하지만, 깊은 복사는 내부 객체까지 모두 새로 만든다.",
                "얕은 복사는 리스트에만 사용 가능하다.",
                "깊은 복사는 파이썬 2에서만 지원한다.",
                "두 복사 방식은 결과적으로 동일하다."
            ],
            "answer": "얕은 복사는 최상위 객체만 새로 만들고 내부 객체는 참조를 공유하지만, 깊은 복사는 내부 객체까지 모두 새로 만든다.",
            "why": "copy.copy()는 얕은 복사를, copy.deepcopy()는 깊은 복사를 수행하여 중첩된 가변 객체 수정 시 의도치 않은 변경을 방지합니다.",
            "hint": "중첩된 요소(리스트 안의 리스트 등)의 독립성 여부를 생각하세요.",
            "trap_points": [
                "단순 대입(=)은 복사가 아닌 참조 전달임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬의 '제네레이터(Generator)'에 대한 설명으로 옳은 것은?",
            "options": [
                "모든 요소를 한꺼번에 메모리에 로드한다.",
                "yield 키워드를 사용하여 값을 하나씩 생성하며 메모리를 절약한다.",
                "한 번 호출하면 다시는 사용할 수 없다.",
                "항상 리스트 타입을 반환한다.",
                "클래스 내부에서만 정의할 수 있다."
            ],
            "answer": "yield 키워드를 사용하여 값을 하나씩 생성하며 메모리를 절약한다.",
            "why": "제네레이터는 필요한 시점에만 값을 생성(Lazy Evaluation)하므로 대용량 데이터 처리에 매우 효율적입니다.",
            "hint": "산출하다(Yield)라는 단어를 기억하세요.",
            "trap_points": [
                "메모리 부족 에러를 방지하는 핵심 기술임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 @ 기호를 사용하여 기존 함수에 기능을 추가하거나 수정하는 도구는?",
            "options": [
                "Generator",
                "Decorator",
                "Iterator",
                "Descriptor",
                "Selector"
            ],
            "answer": "Decorator",
            "why": "데코레이터는 함수를 인자로 받아 다른 함수를 반환하는 고차 함수로, 로그 출력이나 권한 확인 등에 쓰입니다.",
            "hint": "장식하다라는 뜻입니다.",
            "trap_points": [
                "클로저(Closure) 개념이 사용됨"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬의 리스트(List)와 세트(Set)에서 요소의 존재 여부(in 연산)를 확인할 때 시간 복잡도 차이는?",
            "options": [
                "둘 다 O(1)이다.",
                "리스트는 O(n), 세트는 O(1)이다.",
                "리스트는 O(1), 세트는 O(n)이다.",
                "둘 다 O(n)이다.",
                "리스트는 O(log n), 세트는 O(1)이다."
            ],
            "answer": "리스트는 O(n), 세트는 O(1)이다.",
            "why": "세트는 해시 테이블을 사용하므로 요소 개수와 상관없이 거의 즉시 값을 찾을 수 있지만, 리스트는 처음부터 끝까지 훑어야 합니다.",
            "hint": "해싱(Hashing) 기술의 속도를 생각하세요.",
            "trap_points": [
                "데이터가 많을수록 세트를 쓰는 것이 검색 속도에서 압도적임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬 클래스에서 __str__ 메서드와 __repr__ 메서드의 주된 차이는?",
            "options": [
                "둘은 똑같은 기능을 한다.",
                "__str__은 사용자용(print), __repr__은 개발용(객체 재현) 정보를 제공하는 관례가 있다.",
                "__repr__은 주석을 다는 용도이다.",
                "__str__은 소문자로만 출력한다.",
                "__repr__은 필수적으로 구현해야 한다."
            ],
            "answer": "__str__은 사용자용(print), __repr__은 개발용(객체 재현) 정보를 제공하는 관례가 있다.",
            "why": "__str__은 보기 좋은 문자열을, __repr__은 객체를 다시 생성할 수 있을 정도의 상세 정보를 담습니다.",
            "hint": "표현(Representation)과 스트링(String)의 차이입니다.",
            "trap_points": [
                "디버깅 시에는 __repr__이 더 중요함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬 3.10 이상에서 도입된, 여러 갈래의 조건을 체크하는 match-case 문의 명칭은?",
            "options": [
                "Switch Pattern",
                "Structural Pattern Matching",
                "Case Selection",
                "Conditional Flow",
                "Multi-branching"
            ],
            "answer": "Structural Pattern Matching",
            "why": "단순 값 비교뿐만 아니라 객체의 구조나 타입을 매칭하여 분기 처리할 수 있는 강력한 기능입니다.",
            "hint": "구조적 패턴 매칭입니다.",
            "trap_points": [
                "다른 언어의 switch 문보다 훨씬 고도화된 기능을 제공함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 'Hello' * 3의 결과는 무엇인가요?",
            "options": [
                "Hello3",
                "에러 발생",
                "HelloHelloHello",
                "['Hello', 'Hello', 'Hello']",
                "Hello Hello Hello"
            ],
            "answer": "HelloHelloHello",
            "why": "파이썬의 시퀀스 자료형(문자열, 리스트 등)에 정수를 곱하면 해당 횟수만큼 반복됩니다.",
            "hint": "곱하기는 반복입니다.",
            "trap_points": [
                "공백이 자동으로 추가되지 않음에 주의"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "short_answer",
            "question": "파이썬 패키지를 설치할 때 특정 버전을 강제하는 기호는? (예: requests 2.25.1)",
            "answer": "==",
            "why": "pip install requests==2.25.1 처럼 사용하면 정확히 해당 버전만 설치합니다.",
            "hint": "같다(Equal)는 의미의 기호를 두 번 씁니다.",
            "trap_points": [
                ">= 는 해당 버전 이상을 의미함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "딕셔너리에서 키가 없으면 자동으로 기본값을 생성해 주는 클래스는?",
            "options": [
                "dict",
                "defaultdict",
                "OrderedDict",
                "Counter",
                "ChainMap"
            ],
            "answer": "defaultdict",
            "why": "collections 모듈의 defaultdict은 키가 존재하지 않을 때 KeyError를 내지 않고 설정된 팩토리 함수를 실행해 기본값을 할당합니다.",
            "hint": "기본값(Default)을 가진 딕셔너리입니다.",
            "trap_points": [
                "빈 도 작성 시 += 연산 등을 안전하게 수행하기 위해 필수적임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬의 'MRO (Method Resolution Order)'가 결정하는 것은?",
            "options": [
                "인터넷 요청 순서",
                "메모리 할당 순서",
                "다중 상속 시 메서드를 찾는 순서",
                "변수 선언 순서",
                "파일 읽기 순서"
            ],
            "answer": "다중 상속 시 메서드를 찾는 순서",
            "why": "C3 Linearization 알고리즘을 사용하여 부모 클래스들의 우선순위를 계층적으로 결정합니다.",
            "hint": "메서드 해결 순서의 약자입니다.",
            "trap_points": [
                "class.mro() 또는 class.__mro__를 통해 확인 가능함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 리스트를 슬라이싱할 때, `list[::-1]`이 의미하는 것은?",
            "options": [
                "리스트의 첫 번째 요소",
                "리스트의 마지막 요소",
                "리스트를 역순으로 뒤집은 결과",
                "리스트의 모든 짝수 번째 요소",
                "에러 발생"
            ],
            "answer": "리스트를 역순으로 뒤집은 결과",
            "why": "슬라이싱 [start:stop:step] 에서 step이 -1이면 뒤에서부터 하나씩 읽어오는 것을 뜻합니다.",
            "hint": "거꾸로 돌아가는 간격(Step)을 생각하세요.",
            "trap_points": [
                "원본은 바뀌지 않고 새 리스트를 반환함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "short_answer",
            "question": "파이썬에서 한 줄에 여러 개의 변수를 선언하고 할당하는 표현 방식(예: a, b = 1, 2)을 무엇이라 하나요?",
            "answer": "언패킹 (Unpacking) 또는 다중 할당",
            "why": "우변의 튜플 데이터를 좌변의 변수들에 나누어 담는 과정입니다.",
            "hint": "짐을 푼다는 뜻입니다.",
            "trap_points": [
                "좌변과 우변의 개수가 맞지 않으면 ValueError가 발생함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 '가비지 컬렉션(Garbage Collection)'의 주요 메커니즘은?",
            "options": [
                "수동으로 메모리 해제",
                "레퍼런스 카운팅 (Reference Counting) 및 순환 참조 감지",
                "하드디스크로 데이터 백업",
                "변수 이름 지우기",
                "파일 닫기"
            ],
            "answer": "레퍼런스 카운팅 (Reference Counting) 및 순환 참조 감지",
            "why": "참조 횟수가 0이 된 객체를 자동으로 삭제하며, 서로를 가리키는 순환 참조는 별도의 GC 알고리즘으로 해결합니다.",
            "hint": "참조(Reference) 횟수를 세는 방식입니다.",
            "trap_points": [
                "sys.getrefcount()로 참조 횟수를 확인할 수 있음"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬의 `assert` 키워드의 주된 용도는?",
            "options": [
                "값을 무조건 출력하기 위해",
                "실무 코드에서 에러를 무시하기 위해",
                "특정 조건이 참인지 확인하고, 거짓이면 에러를 발생시켜 디버깅을 돕기 위해",
                "사용자로부터 입력을 받기 위해",
                "네트워크를 연결하기 위해"
            ],
            "answer": "특정 조건이 참인지 확인하고, 거짓이면 에러를 발생시켜 디버깅을 돕기 위해",
            "why": "개발 단계에서 가정(Assumption)이 맞는지 검증하여 버그를 조기에 발견하도록 돕습니다.",
            "hint": "단언하다, 확언하다의 뜻입니다.",
            "trap_points": [
                "최적화 옵션(-O) 실행 시 assert 문은 무시될 수 있으므로 비즈니스 로직 검증용으로는 부적절함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬 클래스 정의에서 `__slots__`를 정의하는 이유는?",
            "options": [
                "속성을 더 많이 만들기 위해",
                "메모리 사용량을 줄이고 속성 접근 속도를 높이기 위해",
                "파일 속도를 빠르게 하기 위해",
                "영어로만 코딩하기 위해",
                "이미지를 저장하기 위해"
            ],
            "answer": "메모리 사용량을 줄이고 속성 접근 속도를 높이기 위해",
            "why": "객체마다 생성되는 __dict__ 를 사용하지 않고 고정된 공간을 확보하여 메모리 효율을 극대화합니다.",
            "hint": "슬롯(Slot)처럼 공간을 미리 지정합니다.",
            "trap_points": [
                "수만 개 이상의 객체를 생성할 때 효과가 매우 큼"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Python 기초",
            "type": "short_answer",
            "question": "파이썬 3.8부터 도입된, 표현식 내부에서 변수에 할당까지 수행하는 연산자(:=)의 별명은?",
            "answer": "바다표범 연산자 (Walrus Operator)",
            "why": ":= 기호가 바다표범의 눈과 엄니를 닮았다고 해서 붙여진 이름입니다.",
            "hint": "바다에 사는 큰 포유류 이름입니다.",
            "trap_points": [
                "조건문이나 반복문 내부에서 코드를 간결하게 줄여줌"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬 패키지를 만들 때 해당 디렉토리가 패키지임을 알리기 위해 사용하는 특수 파일명은? (최신 버전은 선택이나 과거 필수)",
            "options": [
                "__start__.py",
                "__main__.py",
                "__init__.py",
                "__pack__.py",
                "setup.py"
            ],
            "answer": "__init__.py",
            "why": "해당 디렉토리를 파이썬이 패키지로 인식하게 하며, 패키지 초기화 코드를 담기도 합니다.",
            "hint": "초기화(Initialize)를 의미하는 축약어입니다.",
            "trap_points": [
                "__main__.py는 패키지 실행 시 진입점 역할을 함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas에서 가로로 긴 데이터를 세로로 길게(Unpivot) 변형하는 메서드는?",
            "options": [
                "pivot()",
                "melt()",
                "stack()",
                "unstack()",
                "merge()"
            ],
            "answer": "melt()",
            "why": "melt()는 특정 열을 식별자로 유지하고 나머지 열들을 행으로 녹여내어(melt) 분석하기 좋은 형태로 바꿉니다.",
            "hint": "녹이다라는 뜻의 단어입니다.",
            "trap_points": [
                "pivot()의 정반대 작업이라고 이해하면 쉬움"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Numpy 배열 연산에서 `a[a > 5]` 와 같이 조건에 맞는 요소만 추출하는 기법은?",
            "options": [
                "Slicing",
                "Boolean Indexing (불리언 인덱싱)",
                "Fancy Indexing",
                "Filtering",
                "Masking"
            ],
            "answer": "Boolean Indexing (불리언 인덱싱)",
            "why": "조건식의 결과로 생성된 True/False 배열을 인덱스로 사용하여 데이터를 선택합니다.",
            "hint": "참/거짓(Boolean)을 이용한 인덱싱입니다.",
            "trap_points": [
                "데이터 분석에서 특정 조건을 만족하는 데이터를 추출할 때 가장 많이 쓰임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "정규표현식에서 '단어의 비경계(알파벳/숫자가 아닌 문자 사이)'를 의미하는 기호는?",
            "options": [
                "\\b",
                "\\B",
                "\\w",
                "\\W",
                "\\s"
            ],
            "answer": "\\B",
            "why": "\\b는 단어 경계(공백 등)를 의미하고, \\B는 단어 내부 등 비경계를 의미합니다.",
            "hint": "대문자는 보통 소문자의 반대 의미를 가집니다.",
            "trap_points": [
                "\\b는 검색 시 독립된 단어만 찾고 싶을 때 매우 중요함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas에서 두 날짜 사이의 차이를 나타내는 객체 타입은?",
            "options": [
                "Timestamp",
                "DatetimeIndex",
                "Timedelta",
                "Period",
                "Duration"
            ],
            "answer": "Timedelta",
            "why": "Timedelta는 두 시점 사이의 기간(3 days, 01:00:00 등)을 저장하는 자료형입니다.",
            "hint": "시간의 변화량(Delta)을 생각하세요.",
            "trap_points": [
                "날짜 - 날짜 = 타임델타입니다."
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Numpy에서 배열의 순서를 무작위로 섞는 함수는?",
            "options": [
                "np.sort()",
                "np.shuffle()",
                "np.random.shuffle()",
                "np.random.rand()",
                "np.mix()"
            ],
            "answer": "np.random.shuffle()",
            "why": "shuffle() 함수는 원본 배열의 요소를 무작위로 섞습니다.",
            "hint": "카드를 섞다라는 뜻입니다.",
            "trap_points": [
                "np.random.permutation()은 원본 유지 후 섞인 복사본을 반환함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "short_answer",
            "question": "Pandas에서 여러 개의 열을 하나의 열로 합치는 과정에서, 인덱스를 다중 층(Hierarchical Index)으로 쌓아 올리는 메서드는?",
            "answer": "stack()",
            "why": "컬럼 인덱스를 행 인덱스의 하위 레벨로 이동시켜 세로로 길게 쌓습니다.",
            "hint": "쌓다라는 뜻입니다.",
            "trap_points": [
                "unstack()은 다시 가로로 펼치는 반대 기능임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "텍스트 분석 시 단어의 빈도 순위를 기반으로 중요도를 산출할 때, Zipf의 법칙(Zipf's Law)이 말하는 것은?",
            "options": [
                "모든 단어는 동일한 빈도로 나타난다.",
                "빈도가 가장 높은 단어가 나머지 단어보다 압도적으로 많이 나타난다 (롱테일 분포).",
                "단어 길이가 길수록 많이 쓰인다.",
                "분석할수록 데이터가 줄어든다.",
                "영어만 정확하다."
            ],
            "answer": "빈도가 가장 높은 단어가 나머지 단어보다 압도적으로 많이 나타난다 (롱테일 분포).",
            "why": "상위 몇 개 단어가 전체 말뭉치의 대부분을 차지한다는 법칙으로, 불용어 제거의 근거가 됩니다.",
            "hint": "일부 단어의 독점 현상을 생각하세요.",
            "trap_points": [
                "파레토 법칙(80/20)의 텍스트 버전이라고 볼 수 있음"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas에서 CSV 파일을 읽을 때, 한글이 깨지는 것을 방지하기 위해 주로 지정하는 인코딩은?",
            "options": [
                "utf-8",
                "cp949",
                "ascii",
                "latin1",
                "utf-16"
            ],
            "answer": "cp949",
            "why": "MS 윈도우 환경에서 저장된 한글 엑셀/CSV 파일은 보통 CP949(EUC-KR 확장) 인코딩을 사용합니다.",
            "hint": "한국어 전용 인코딩 중 하나입니다.",
            "trap_points": [
                "최근에는 utf-8-sig 도 많이 쓰임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Numpy에서 행렬 연산 중 전치(Transpose)와 역행렬(Inverse)을 곱하여 생성되는 행렬의 특징은?",
            "options": [
                "항상 0이다.",
                "단위 행렬(Identity Matrix)이 된다.",
                "모든 요소가 1이다.",
                "값이 무한대이다.",
                "결과가 달라진다."
            ],
            "answer": "단위 행렬(Identity Matrix)이 된다.",
            "why": "정방 행렬에 역행렬을 곱하면 대각 성분이 1인 단위 행렬이 나옵니다 (A * A^-1 = I).",
            "hint": "행렬의 '1'과 같은 존재입니다.",
            "trap_points": [
                "역행렬이 존재하지 않는 행렬(Singular Matrix)은 계산 불가함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "short_answer",
            "question": "정규표현식에서 특수 문자( . * + 등) 자체를 문자로 인식하게 하기 위해 앞에 붙이는 기호는?",
            "answer": "\\ (역슬래시)",
            "why": "역슬래시를 붙여 메타 문자의 의미를 무효화(Escaping)합니다.",
            "hint": "이스케이프 문자입니다.",
            "trap_points": [
                "파이썬 문자열에서는 r'...' 처럼 raw string을 권장함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas에서 특정 열의 고유한(Unique) 값의 '개수'만 결과로 받고 싶을 때 사용하는 메서드는?",
            "options": [
                "df['A'].unique()",
                "df['A'].nunique()",
                "df['A'].count()",
                "df['A'].len()",
                "df['A'].size()"
            ],
            "answer": "df['A'].nunique()",
            "why": "unique()는 값들을 리스트로 반환하고, nunique()는 그 개수를 숫자로 반환합니다.",
            "hint": "Unique 앞에 n(number)이 붙었습니다.",
            "trap_points": [
                "결측치를 포함할지 말지 옵션으로 정할 수 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "텍스트 전처리 시 '의미를 보존하면서도 컴퓨터가 더 잘 이해하게' 하려고 어미를 쳐내는 과정을 무엇이라 하나요?",
            "options": [
                "Tokenization",
                "Stemming",
                "Encoding",
                "Scaling",
                "Refining"
            ],
            "answer": "Stemming",
            "why": "포터(Porter) 알고리즘 등을 써서 단어 뒤의 'ing', 'ed' 등을 잘라내어 어간을 추출합니다.",
            "hint": "줄기(Stem)를 뽑아낸다는 뜻입니다.",
            "trap_points": [
                "의미가 훼손되어 원형을 못 알아볼 수 있음(예: flies -> fli)"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Numpy에서 두 배열의 유사도를 한눈에 평가하기 위해 행렬의 모든 요소의 평균을 구하는 메서드는?",
            "options": [
                "sum()",
                "mean()",
                "std()",
                "var()",
                "median()"
            ],
            "answer": "mean()",
            "why": "평균값(mean)은 데이터의 중심 경향성을 보여주는 가장 기본적인 척도입니다.",
            "hint": "평균의 영어 이름입니다.",
            "trap_points": [
                "이상치에 민감하다는 단점이 있음"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas에서 데이터프레임을 엑셀 파일로 저장할 때 사용하는 메서드는?",
            "options": [
                "to_csv()",
                "to_excel()",
                "save_excel()",
                "write_excel()",
                "export_excel()"
            ],
            "answer": "to_excel()",
            "why": "openpyxl 라이브러리를 사용하여 엑셀 형식으로 데이터를 출력합니다.",
            "hint": "엑셀(Excel)로(to) 보내기.",
            "trap_points": [
                "시트 이름을 지정하거나 여러 시트에 저장할 수 있음"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Numpy 배열 [1, 2, 3] 에 단순히 10을 더하면 [11, 12, 13] 이 되는 현상을 설명하는 특성은?",
            "options": [
                "Broadcasting",
                "Reshaping",
                "Slicing",
                "Indexing",
                "Concatenating"
            ],
            "answer": "Broadcasting",
            "why": "스칼라 값이 배열의 모든 요소에 동일하게 적용되도록 넘파이가 자동으로 확장 연산을 수행합니다.",
            "hint": "이미 기획안과 샘플에서 강조했던 넘파이의 백미입니다.",
            "trap_points": [
                "반복문 없이 연산이 가능하게 하여 성능을 획기적으로 높임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "short_answer",
            "question": "Pandas에서 데이터프레임의 인덱스와 열을 서로 바꾸는(Transpose) 속성은?",
            "answer": "T",
            "why": "df.T 를 수행하면 행과 열이 뒤집힙니다.",
            "hint": "대문자 T 하나입니다.",
            "trap_points": [
                "속성이므로 함수처럼 ()를 붙이지 않음"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas에서 시계렬 데이터의 빈도를 일정 간격(예: 1시간 단위 -> 1일 단위)으로 다시 리샘플링하는 메서드는?",
            "options": [
                "resample()",
                "reindex()",
                "groupby()",
                "pivot()",
                "reshape()"
            ],
            "answer": "resample()",
            "why": "resample('D').mean() 과 같이 사용하여 고해상도 데이터를 저해상도로 합칠 때 필수적입니다.",
            "hint": "샘플링을 다시(Re) 한다.",
            "trap_points": [
                "인덱스가 DatetimeIndex여야 사용 가능함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "트랜스포머의 'Self-Attention'이 RNN보다 긴 문장을 잘 처리하는 핵심 이유는?",
            "options": [
                "메모리를 적게 써서",
                "문장의 모든 단어 사이의 거리가 1로 고정(직접 연결)되어 정보 손실이 적기 때문에",
                "영문법에 최적화되어서",
                "이미지 기술을 도입해서",
                "답변을 짧게 해서"
            ],
            "answer": "문장의 모든 단어 사이의 거리가 1로 고정(직접 연결)되어 정보 손실이 적기 때문에",
            "why": "RNN은 정보를 전달하며 희석되지만, 어텐션은 모든 토큰 상호작용을 한 단계의 연산으로 직접 수행합니다.",
            "hint": "단어들이 서로 '즉각적으로' 소통한다고 생각하세요.",
            "trap_points": [
                "이 방식 때문에 연산량은 문장 길이의 제곱으로 늘어남"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "LLM에서 'Hallucination(환각)' 현상을 기술적으로 줄이기 위한 방법이 아닌 것은?",
            "options": [
                "RAG 시스템 도입",
                "Temperature 값을 0으로 설정",
                "프롬프트에 '근거 문서 내에서만 답하라'는 제약 추가",
                "전용 리더 모델(Verifier)로 답변 검증",
                "모델의 층(Layer)을 랜덤하게 삭제"
            ],
            "answer": "모델의 층(Layer)을 랜덤하게 삭제",
            "why": "레이어 삭제는 모델의 지능을 파괴할 뿐 환각과는 무관하거나 오히려 악화시킵니다.",
            "hint": "비정상적인 조작을 찾으세요.",
            "trap_points": [
                "환각은 확률 모델의 본성이라 100% 제거는 불가능함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "LLM의 'Scaling Law (스케일링 법칙)'이 의미하는 핵심 내용은?",
            "options": [
                "모델 크기가 작을수록 좋다.",
                "데이터 양, 모델 파라미터 수, 연산량이 늘어날수록 성능은 예측 가능하게 향상된다.",
                "스케일링은 가격만 올린다.",
                "이미지만 잘 처리하게 된다.",
                "언어 모델은 곧 사라진다."
            ],
            "answer": "데이터 양, 모델 파라미터 수, 연산량이 늘어날수록 성능은 예측 가능하게 향상된다.",
            "why": "거대 자본 투입의 근거가 된 법칙으로, 일정 임계치를 넘으면 모델 성능이 폭발적으로 지수함수적 향상을 보입니다.",
            "hint": "규모(Scale)의 경제를 생각하세요.",
            "trap_points": [
                "최근에는 모델 크기보다 고품질 데이터의 질이 더 중요하다는 반론도 제기됨"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "트랜스포머 모델의 레이어 정규화(Layer Normalization)가 수행되는 주된 목적은?",
            "options": [
                "데이터를 삭제하기 위해",
                "학습 속도를 안정화하고 그래디언트 소실을 방지하기 위해",
                "답변 형식을 JSON으로 바꾸기 위해",
                "이미지로 변환하기 위해",
                "토큰 수를 줄이기 위해"
            ],
            "answer": "학습 속도를 안정화하고 그래디언트 소실을 방지하기 위해",
            "why": "블록 내부의 값들이 너무 커지거나 작아지지 않도록 범위를 조절하여 딥러닝 학습의 안정성을 제공합니다.",
            "hint": "균형을 맞추는(Normalization) 작업입니다.",
            "trap_points": [
                "배치 정규화(Batch Norm)와는 다른 방식임에 주의"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "LLM에서 생성 다양성을 조절하는 'Top-P Sampling (Nucleus Sampling)'이란?",
            "options": [
                "상위 K개만 고른다.",
                "누적 확률이 P가 될 때까지의 상위 토큰들만 후보군으로 삼는다.",
                "확률이 P인 단어만 고른다.",
                "P는 소수를 의미한다.",
                "랜덤하게 다 고른다."
            ],
            "answer": "누적 확률이 P가 될 때까지의 상위 토큰들만 후보군으로 삼는다.",
            "why": "확률 분포의 꼬리 부분을 동적으로 잘라내어 문맥에 따라 후보군 수를 조절하는 효율적 방식입니다.",
            "hint": "핵심(Nucleus)이 되는 상위 확률 덩어리를 고릅니다.",
            "trap_points": [
                "P=0.9 면 전체 확률의 90%를 차지하는 단어들 중에서만 생성함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "short_answer",
            "question": "구글에서 발표하여 트랜스포머 혁명을 일으킨 논문의 제목은?",
            "answer": "Attention Is All You Need",
            "why": "어텐션 메커니즘만으로 강력한 모델을 만들 수 있음을 증명하며 현대 AI의 시대를 열었습니다.",
            "hint": "주의(Attention)가 당신에게 필요한 전부에요.",
            "trap_points": [
                "2017년 발표되어 '만물 어텐션설'을 유행시킴"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "트랜스포머에서 잔차 연결(Residual Connection)이 해결한 가장 큰 기술적 난제는?",
            "options": [
                "층이 깊어지면 그래디언트가 소실되어 학습이 안 되는 문제",
                "토큰 수가 늘어나는 문제",
                "메모리가 부족한 문제",
                "영어가 서툰 문제",
                "답변이 짧은 문제"
            ],
            "answer": "층이 깊어지면 그래디언트가 소실되어 학습이 안 되는 문제",
            "why": "이전 층의 입력을 다음 층으로 직접 더해줌으로써 정보 손실 없이 매우 깊은 인공신경망 학습을 가능하게 했습니다.",
            "hint": "중간 단계를 건너뛰어 지름길(Short-cut)을 열어줍니다.",
            "trap_points": [
                "모든 현대 LLM 아키텍처의 필수 요소임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "LLM 학습 시 사용되는 기술 중 '학습 데이터를 효율적으로 섞어서 모델이 패턴을 암기하는 걸 방지'하는 과정은?",
            "options": [
                "Shuffling",
                "Padding",
                "Masking",
                "Scaling",
                "Prompting"
            ],
            "answer": "Shuffling",
            "why": "데이터의 순서 자체도 모델이 편향되게 학습할 수 있는 요소이므로 무작위로 섞는 과정이 중요합니다.",
            "hint": "섞다라는 뜻입니다.",
            "trap_points": [
                "미니 배치 학습에서 매 에포크마다 수행됨"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "모델이 답변의 확률적 토큰을 고를 때, 이미 나온 단어들이 다시 나오지 않도록 페널티를 주는 파라미터는?",
            "options": [
                "Temperature",
                "Presence Penalty (또는 Frequency Penalty)",
                "Top-P",
                "Max Tokens",
                "Stop sequence"
            ],
            "answer": "Presence Penalty (또는 Frequency Penalty)",
            "why": "반복 문구 생성을 줄여 답변의 품질과 정보 밀도를 높이기 위해 사용합니다.",
            "hint": "존재(Presence) 혹은 빈도(Frequency)에 대한 벌(Penalty)입니다.",
            "trap_points": [
                "값이 너무 높으면 필요한 고유 명사 재사용도 막힐 수 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "short_answer",
            "question": "LLM이 코딩, 수학 등 정답이 있는 영역에서 고난도의 단계적 사고를 수행하는 능력을 무엇이라 하나요?",
            "answer": "Reasoning (추론)",
            "why": "지식 인출을 넘어 인과 관계를 파악하고 논리적으로 문제를 해결하는 지능의 정수입니다.",
            "hint": "이유(Reason)를 찾는 과정입니다.",
            "trap_points": [
                "최신 추론 특화 모델(o1, R1 등)이 이 성능에 집중함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트 내에 '구분자(### 등)'를 사용하여 지시 사항과 데이터를 분리하는 주된 이유는?",
            "options": [
                "예쁘게 보이려고",
                "모델이 어디가 지시(Instruction)이고 어디가 입력(Input)인지 명확히 인지하게 하여 오답률을 낮추기 위해",
                "토큰 비용을 아끼려고",
                "영문법에 맞추기 위해",
                "네트워크를 안정화하려고"
            ],
            "answer": "모델이 어디가 지시(Instruction)이고 어디가 입력(Input)인지 명확히 인지하게 하여 오답률을 낮추기 위해",
            "why": "경계가 모호하면 입력 데이터를 지시 사항으로 착각하는 '프롬프트 인젝션'과 유사한 혼동이 발생할 수 있습니다.",
            "hint": "경계선(Delimiter)의 명확함을 생각하세요.",
            "trap_points": [
                "다양한 기호 사용 가능하지만 일관성이 중요함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "LangChain에서 프롬프트의 결과물을 파이썬 딕셔너리나 JSON 객체로 자동 변환해 주는 기능은?",
            "options": [
                "ChatModel",
                "JsonOutputParser",
                "PromptTemplate",
                "Chain",
                "Storage"
            ],
            "answer": "JsonOutputParser",
            "why": "Pydantic 등과 연동하여 모델의 텍스트 응답을 프로그래밍적으로 즉시 사용 가능한 데이터 구조로 바꿉니다.",
            "hint": "JSON + 출력 + 분석기.",
            "trap_points": [
                "모델이 형식을 어길 경우 재시도(Retry) 로직과 결합하기도 함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트에 페르소나(Persona)를 부여할 때 입문자(Junior)와 숙련자(Senior)의 차이는?",
            "options": [
                "숙련자는 답을 더 빨리 한다.",
                "숙련자는 전문 용어와 복잡한 배경 지식을 포함한 심도 있는 답변을 하고, 입문자는 쉬운 단어로 요약한다.",
                "숙련자는 돈이 더 많이 든다.",
                "입문자는 영어로만 답한다.",
                "차이가 전혀 없다."
            ],
            "answer": "숙련자는 전문 용어와 복잡한 배경 지식을 포함한 심도 있는 답변을 하고, 입문자는 쉬운 단어로 요약한다.",
            "why": "페르소나는 모델의 내부적인 가중치를 특정 분포에 쏠리게 하여 지식 인출의 수위를 결정합니다.",
            "hint": "대상의 전문성을 지정하는 것입니다.",
            "trap_points": [
                "구체적인 직업군(예: 10년차 파이썬 개발자)을 명시하면 효과가 더 좋음"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트 내에서 예시(Few-shot)를 한두 개 줬을 때와 수십 개 줬을 때의 트레이드오프는?",
            "options": [
                "예시가 많을수록 성능은 좋아지지만 토큰 비용이 급증하고 모델의 인지 한계에 다다른다.",
                "예시가 많으면 모델이 화를 낸다.",
                "예시가 적으면 답변이 느려진다.",
                "예시 개수는 상관없다.",
                "무조건 많은 게 장땡이다."
            ],
            "answer": "예시가 많을수록 성능은 좋아지지만 토큰 비용이 급증하고 모델의 인지 한계에 다다른다.",
            "why": "인컨텍스트 러닝에도 효율 지점이 있으며, 너무 긴 예시는 비용만 높이고 핵심 지시 사항을 희석시킬 수 있습니다.",
            "hint": "비용(토큰)과 성능의 저울질입니다.",
            "trap_points": [
                "보통 3~5개의 대표적인 예시가 가장 가성비가 좋음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "모델에게 '거짓말 하지 마' 대신 '항상 신뢰할 수 있는 출처를 인용하여 사실만 말해'라고 긍정형으로 말하는 기법을 무엇이라 하나요?",
            "options": [
                "Negative Prompting",
                "Positive Instruction (예: Do vs Don't)",
                "Style Transfer",
                "Role Play",
                "Contextualization"
            ],
            "answer": "Positive Instruction (예: Do vs Don't)",
            "why": "금지 사항보다 수행해야 할 구체적인 올바른 행동을 명시할 때 모델은 더 성능이 높게 나타납니다.",
            "hint": "하라(Do)가 하지 마라(Don't)보다 명확합니다.",
            "trap_points": [
                "모델은 확률적 생성이므로 '안 하는 것'의 다음 토큰 예측이 더 어렵기 때문임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "short_answer",
            "question": "사용자의 질문에 대해 거꾸로 모델이 '질문하기'를 유도하여 모호함을 해소하는 기법은?",
            "answer": "Reverse Prompting (또는 질문 유도)",
            "why": "정보가 부족할 때 모델이 추측(Guess)하지 않고 확인(Clarify)하게 하여 할루시네이션을 원천 봉쇄합니다.",
            "hint": "순서를 뒤집었다(Reverse)는 의미입니다.",
            "trap_points": [
                "'모르면 질문해'라는 제약과 함께 쓰면 매우 강력함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "최근 LLM 동향 중 '프롬프트를 아주 짧게 쓰는 것'보다 '상세한 맥락과 예시를 구체적으로 넣는 것'이 유리해지는 하드웨어적 이유는?",
            "options": [
                "컴퓨터가 똑똑해져서",
                "모델의 컨텍스트 윈도우(Context Window)가 비약적으로 커졌기 때문 (예: 1M 토큰)",
                "키보드 타자 속도가 빨라져서",
                "글자 가독성이 좋아서",
                "메모리 가격이 내려가서"
            ],
            "answer": "모델의 컨텍스트 윈도우(Context Window)가 비약적으로 커졌기 때문 (예: 1M 토큰)",
            "why": "과거에는 토큰 한계로 요약이 중요했지만, 이제는 통째로 다 넣고 모델에게 찾게 시키는 것이 정확도가 더 높습니다.",
            "hint": "모델의 '기억 창문' 크기를 생각하세요.",
            "trap_points": [
                "하지만 토큰 비용은 여전히 고려 대상임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "수학 문제를 풀릴 때 'Chain of Thought' 없이 풀린 결과와 포함해서 풀린 결과의 가장 큰 차이는?",
            "options": [
                "답은 똑같다.",
                "CoT는 풀이 과정을 적으며 중간 논리에 집중하기 때문에 최종 정답 확률이 훨씬 높다.",
                "CoT를 쓰면 답이 틀린다.",
                "CoT는 더 예쁘게 적는다.",
                "속도가 100배 빨라진다."
            ],
            "answer": "CoT는 풀이 과정을 적으며 중간 논리에 집중하기 때문에 최종 정답 확률이 훨씬 높다.",
            "why": "복잡한 문제는 중간 경로(Path)를 하나만 틀려도 답이 틀리므로, 단계별 추론이 필수적입니다.",
            "hint": "생각의 연결 고리가 정답을 지탱해줍니다.",
            "trap_points": [
                "비용(토큰)이 늘어나는 단점도 있음"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "short_answer",
            "question": "프롬프트 마지막에 '{' 기호를 선제적으로 입력하여 모델이 JSON 형식을 강제로 시작하도록 유도하는 기술은?",
            "answer": "JSON Prefilling (또는 앞글자 채우기)",
            "why": "모델의 첫 번째 토큰을 강제함으로써 전체 답변 구조를 고정시키는 강력한 통제 기법입니다.",
            "hint": "미리 채우다(Pre-fill).",
            "trap_points": [
                "Anthropic 모델군에서 공식적으로 권장하는 방식임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "LangChain의 `Custom Tool`을 에이전트에게 제공할 때 프롬프트 상으로 가장 정밀하게 작성해야 하는 부분은?",
            "options": [
                "도구의 가격",
                "도구의 이름과 설명(Description)",
                "도구가 만들어진 날짜",
                "도구 개발자 이름",
                "도구의 용량"
            ],
            "answer": "도구의 이름과 설명(Description)",
            "why": "모델은 도구의 코드 자체를 보지 못하고 오직 '설명'을 읽고 해당 도구를 쓸지 말지 결정하기 때문입니다.",
            "hint": "모델이 읽고 판단할 수 있는 '매뉴얼'입니다.",
            "trap_points": [
                "설명이 모호하면 에이전트가 엉뚱한 도구를 호출하게 됨"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG에서 ‘효율적인 검색’을 위해 질문을 벡터화하기 전, 질문의 본질을 파악하여 다른 도메인의 질문으로 변환하는 것을 무엇이라 하나요?",
            "options": [
                "Query Translation",
                "Query Expansion (질문 확장)",
                "Query Decomposition",
                "HyDE",
                "Multi-Query"
            ],
            "answer": "Query Expansion (질문 확장)",
            "why": "유사한 단어나 개념을 덧붙여 검색 성공률을 높이는 기법입니다.",
            "hint": "질문을 더 넓게(Expansion) 만든다.",
            "trap_points": [
                "동의어 사전을 이용하거나 LLM을 이용해 확장함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "여러 문서 덩어리(Chunk)가 검색되었을 때, 이를 그대로 LLM에 넘기기보다 ‘가장 중요한 덩어리’ 수십 개만 정밀하게 재배열하는 과정은?",
            "options": [
                "Filtering",
                "Sorting",
                "Re-ranking",
                "Cleaning",
                "Mapping"
            ],
            "answer": "Re-ranking",
            "why": "검색 모델(Retriever)은 속도가 빠르지만 정확도가 낮으므로, 느리지만 정확한 리랭커 모델로 보강합니다.",
            "hint": "순위(Ranking)를 다시(Re) 매긴다.",
            "trap_points": [
                "비용과 속도의 균형을 잡기 위한 필수 단계임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG 시스템에서 '검색된 문서들로부터 정답을 도출하기 위한 논리적 근거가 충분한지' 평가하는 RAGAS 지표는?",
            "options": [
                "Faithfulness",
                "Answer Relevance",
                "Context Precision",
                "Context Recall",
                "Aspect Critique"
            ],
            "answer": "Answer Relevance",
            "why": "사용자의 질문에 대해 검색된 컨텍스트가 얼마나 직접적으로 연관되어 답변의 질을 보장하는지 측정합니다.",
            "hint": "정답(Answer)과 얼마나 관련성(Relevance)이 있는지.",
            "trap_points": [
                "Faithfulness는 문서 내 정보 준수 여부를, Relevance는 정답 자체의 관련성을 봅니다"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "벡터 DB 검색 시 ‘의미적으로는 유사하지만 다른 주제’의 문서가 검색되는 문제를 해결하기 위한 방법은?",
            "options": [
                "메타데이터 필터링 (Metadata Filtering)",
                "더 큰 모델 사용",
                "인터넷 속도 강화",
                "질문 글자 수 늘리기",
                "데이터 지우기"
            ],
            "answer": "메타데이터 필터링 (Metadata Filtering)",
            "why": "카테고리, 날짜, 작성자 등 논리적 특징으로 범위를 좁히고 검색을 수행하면 정확도가 올라갑니다.",
            "hint": "데이터의 속성 정보를 이용합니다.",
            "trap_points": [
                "하드웨어적 필터링이므로 의미 검색보다 연산이 확실함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "short_answer",
            "question": "질문을 받으면 도구를 사용해야 할지 말지 스스로 판단하고 실행하는 LLM의 실질적 행동 주체를 무엇이라 하나요?",
            "answer": "AI Agent (에이전트)",
            "why": "단순 출력을 넘어 목표지향적 행동(Action)을 수행하는 AI의 진화된 형태입니다.",
            "hint": "주체적으로 행동하는 개체입니다.",
            "trap_points": [
                "에이전트는 반복(Loop)적인 사고가 가능함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "LangChain에서 에이전트의 사고 흐름과 상태를 그래프 형태로 관리하여 복잡한 로직을 구현하는 라이브러리는?",
            "options": [
                "LangDB",
                "LangGraph",
                "LangFlow",
                "LangChain-Core",
                "LangPlus"
            ],
            "answer": "LangGraph",
            "why": "순환 구조(Cyclic)를 지원하여 에이전트가 실패 시 이전 단계로 돌아가거나 무한 루프를 도는 것을 관리하기에 최적입니다.",
            "hint": "그래프(Graph) 구조를 활용합니다.",
            "trap_points": [
                "최신 기업용 에이전트는 대부분 이 방식으로 구축됨"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG에서 ‘HyDE (Hypothetical Document Embedding)’ 기법이 수행하는 과정은?",
            "options": [
                "문서를 다 지우기",
                "질문에 대해 LLM이 먼저 가상의(가짜) 답변을 생성하게 한 뒤, 그 가짜 답변으로 실제 문서를 검색하기",
                "사용자 정보를 가제로 만들기",
                "임베딩 모델을 랜덤하게 바꾸기",
                "검색 결과를 삭제하기"
            ],
            "answer": "질문에 대해 LLM이 먼저 가상의(가짜) 답변을 생성하게 한 뒤, 그 가짜 답변으로 실제 문서를 검색하기",
            "why": "사용자의 질문보다 모델이 대충 만든 답변이 실제 저장소의 문서 형태와 더 비슷할 때가 많아 검색 확률이 높아집니다.",
            "hint": "가상(Hypothetical)의 문서를 이용합니다.",
            "trap_points": [
                "가짜 지식이 섞여도 유사한 형태를 찾는 게 목적이므로 검색 효율이 올라감"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "벡터 DB에서 ‘고밀도 벡터(Dense Vector)’와 ‘희소 벡터(Sparse Vector)’를 함께 사용하여 검색 품질을 높이는 방식은?",
            "options": [
                "Single Retrieval",
                "Hybrid Search",
                "Dual Encoding",
                "Cross Matching",
                "Random Selection"
            ],
            "answer": "Hybrid Search",
            "why": "의미를 잘 찾는 고밀도 벡터와 정확한 어휘를 잘 찾는 희소 벡터의 장점을 결합합니다.",
            "hint": "두 가지 이상의 짬뽕 방식입니다.",
            "trap_points": [
                "RRF (Reciprocal Rank Fusion) 알고리즘으로 점수를 합침"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "short_answer",
            "question": "에이전트가 어떤 도구를 실행할지 그 매개변수와 이름을 JSON 형태로 출력하게 하는 LLM의 기초 기술 명칭은?",
            "answer": "Function Calling (함수 호출)",
            "why": "LLM이 구조화된 입력을 만들게 하여 실제 서버의 함수와 연동할 수 있게 해주는 약속입니다.",
            "hint": "함수(Function)를 부르는(Calling) 것.",
            "trap_points": [
                "모델이 직접 함수를 실행하는 것이 아닌 '실행 계획'만 주는 것임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "문서를 작은 청크로 쪼개어 검색하고, 실제 답변 생성 시에는 그 청크들이 포함된 원본 ‘페이지 전체’를 LLM에 전달하는 전략은?",
            "options": [
                "Small2Big (또는 Parent Document Retrieval)",
                "Big2Small",
                "Fixed Window",
                "Sliding Frame",
                "Multi-Vector"
            ],
            "answer": "Small2Big (또는 Parent Document Retrieval)",
            "why": "검색 효율을 위해 작은 조각을 뒤지지만, 모델은 문맥 파악을 위해 풍부한 주변 정보가 필요하기 때문입니다.",
            "hint": "작은(Small) 것으로 찾아서 큰(Big) 것을 준다.",
            "trap_points": [
                "성능 향상이 매우 뚜렷한 고급 리트리버 기법임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝의 대표적인 방법인 LoRA에서 ‘Alpha’ 값이 조절하는 것은?",
            "options": [
                "모델의 층 개수",
                "어댑터 가중치가 원본 가중치에 미치는 영향력(Scaling)",
                "데이터의 양",
                "학습 속도",
                "비용"
            ],
            "answer": "어댑터 가중치가 원본 가중치에 미치는 영향력(Scaling)",
            "why": "학습된 델타 가중치에 alpha / rank 값을 곱하여 최종 가중치에 반영하는 정도를 튜닝합니다.",
            "hint": "스케일링(Scaling) 계수입니다.",
            "trap_points": [
                "보통 rank와 같거나 2배 정도로 설정함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝된 모델의 성능 평가 지표인 'Perplexity (퍼플렉서티)'가 의미하는 것은?",
            "options": [
                "모델의 답변 속도",
                "모델이 다음 단어를 예측할 때 느끼는 '당혹감'(낮을수록 모델이 확신을 갖고 정답에 가깝다고 판단함)",
                "모델의 파일 크기",
                "모델의 가독성",
                "모델의 가격"
            ],
            "answer": "모델이 다음 단어를 예측할 때 느끼는 '당혹감'(낮을수록 모델이 확신을 갖고 정답에 가깝다고 판단함)",
            "why": "언어 모델이 주어진 문장에 대해 얼마나 헷갈리고 있는지를 수치화한 지표입니다.",
            "hint": "당혹감을 뜻하는 영어 단어입니다.",
            "trap_points": [
                "낮을수록 좋은 언어 모델이지만 실제 정답 정밀도와는 다를 수 있음"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝 시 ‘치명적 망각(Catastrophic Forgetting)’이 발생하는 시점은?",
            "options": [
                "데이터를 아예 안 넣었을 때",
                "특정 데이터셋으로 너무 반복해서 학습하여 모델이 가진 기존의 보편적 지능이 무너졌을 때",
                "모델 용량이 너무 클 때",
                "학습 속도가 너무 늦을 때",
                "영어로만 코딩할 때"
            ],
            "answer": "특정 데이터셋으로 너무 반복해서 학습하여 모델이 가진 기존의 보편적 지능이 무너졌을 때",
            "why": "새로운 지식에 파라미터가 과하게 적응하면서 기존의 중요한 뉴런 정보들이 상실되기 때문입니다.",
            "hint": "비극적인 잊어버림 현상입니다.",
            "trap_points": [
                "이를 방지하기 위해 KL divergence 제약을 둠"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "모델의 가중치를 파괴하지 않고, 두 개 이상의 서로 다른 파인튜닝된 모델 가중치를 합쳐서 시너지를 내는 기술은?",
            "options": [
                "Model Merging (모델 머징)",
                "Model Distillation",
                "Model Scaling",
                "Model Quantization",
                "Model Backing"
            ],
            "answer": "Model Merging (모델 머징)",
            "why": "추가 학습 없이 가중치들을 가중 평균하거나 특수 알고리즘(SLERP 등)으로 합쳐서 종합 성능을 올립니다.",
            "hint": "합치다라는 뜻입니다.",
            "trap_points": [
                "허깅페이스 오픈 모델 랭킹 상위권은 대부분 머징된 모델들임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "short_answer",
            "question": "학습 데이터가 부족할 때, 데이터의 내용을 약간씩 변형(순서 변경, 유의어 교체 등)하여 양을 늘리는 기법은?",
            "answer": "Data Augmentation (데이터 증강)",
            "why": "부족한 샘플 수를 인위적으로 확장하여 모델의 일반화 성능을 높입니다.",
            "hint": "증강(Augment)하다.",
            "trap_points": [
                "기존 의미가 훼손되지 않는 선에서 변형해야 함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "학습 모델이 너무 비대하여 실시간 서비스가 불가능할 때, 성능손실을 최소화하며 크기를 줄이는 전략이 아닌 것은?",
            "options": [
                "Quantization (양자화)",
                "Pruning (가지치기)",
                "Distillation (증류)",
                "Parameter Scaling (파라미터 증설)",
                "Model Merging 후 최적화"
            ],
            "answer": "Parameter Scaling (파라미터 증설)",
            "why": "파라미터 증설은 모델을 더 키우는 것이므로 효율화 목적과는 정반대됩니다.",
            "hint": "크기를 '줄이는' 것이 아닌 것을 찾으세요.",
            "trap_points": [
                "최근에는 4비트 양자화가 가장 효율적인 대안임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "DeepSeek R1 아키텍처에서 '보상 모델'의 자리를 대신하며 강화학습 효율을 극대화한 'Rule-based verifier'의 특징은?",
            "options": [
                "사람이 직접 채점한다.",
                "수학 정답이나 코드 컴파일 결과처럼 명확한 '규칙'으로 보상을 준다.",
                "운으로 결정한다.",
                "영어로만 채점한다.",
                "과거 데이터를 무시한다."
            ],
            "answer": "수학 정답이나 코드 컴파일 결과처럼 명확한 '규칙'으로 보상을 준다.",
            "why": "보상 모델 자체가 가진 할루시네이션(점수 잘못 주기) 위험을 배제하고 수학적 진리만으로 모델을 연마시킵니다.",
            "hint": "검증기(Verifier) 기반의 규칙입니다.",
            "trap_points": [
                "추론 성능을 비약적으로 올린 핵심 비결임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝 데이터셋 구축 시 ‘입력 프롬프트’와 ‘정답’ 사이에 <thought> 태그를 넣어 생각하는 과정을 보여주는 기법은?",
            "options": [
                "Chain of Thought Tuning",
                "CoT-SFT",
                "Direct Answer Tuning",
                "Implicit Tuning",
                "Hidden Tuning"
            ],
            "answer": "CoT-SFT",
            "why": "논리적 추론 과정을 직접 지도 학습 데이터에 포함시켜 모델이 '생각하는 습관'을 갖게 만듭니다.",
            "hint": "생각의 사슬(CoT)을 활용한 지도 학습(SFT).",
            "trap_points": [
                "모델의 추론 성능이 극대화되는 기반이 됨"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "short_answer",
            "question": "파인튜닝된 모델이 특정 주제에 대해 답변을 거부하게 만들거나, 특정 정치색을 띠지 않게 정렬하는 최종적이고 미세한 단계를 무엇이라 하나요?",
            "answer": "Safety Alignment (안전 정렬)",
            "why": "윤리 규정, 안전 지침 등을 모델에 내면화시키는 과정입니다.",
            "hint": "안전(Safety) + 정렬(Alignment).",
            "trap_points": [
                "사용자의 부적절한 질문에 대해 단호하게 거절하는 능력을 학습함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "모델 공유 사이트(Hugging Face 등)에서 모델 이름에 'GGUF'가 붙어 있다면 이는 무엇을 뜻하나요?",
            "options": [
                "가장 성능이 좋은 원본 모델이다.",
                "로컬 PC(Llama.cpp 등)나 모바일에서 돌리기 좋게 양자화된 전용 포맷이다.",
                "영어로만 된 모델이다.",
                "학습이 덜 된 모델이다.",
                "비싼 GPU가 있어야만 도는 모델이다."
            ],
            "answer": "로컬 PC(Llama.cpp 등)나 모바일에서 돌리기 좋게 양자화된 전용 포맷이다.",
            "why": "CP 추론 최적화와 메모리 점유율을 극도로 낮춘 파일 형식으로 개인 개발자들에게 가장 인기가 높습니다.",
            "hint": "GG로 시작하는 가벼운 포맷입니다.",
            "trap_points": [
                "파일 하나로 실행 가능하며 설저이 매우 간편함"
            ],
            "difficulty": "easy"
        }
    ]
}