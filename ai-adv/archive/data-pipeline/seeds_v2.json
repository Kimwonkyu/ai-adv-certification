{
    "questions": [
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 리스트의 요소를 수정하지 않고 새로운 리스트를 생성하는 '리스트 컴프리헨션'의 올바른 문법은?",
            "options": [
                "list(x for x in data)",
                "[x for x in data]",
                "{x for x in data}",
                "(x for x in data)",
                "x for x in data"
            ],
            "answer": "[x for x in data]",
            "why": "리스트 컴프리헨션은 대괄호 [] 내부에 반복문과 조건을 사용하여 간결하게 새로운 리스트를 생성하는 파이썬의 핵심 문법입니다.",
            "hint": "리스트(List)는 어떤 괄호를 쓰나요?",
            "trap_points": [
                "()는 제네레이터, {}는 세트/딕셔너리 컴프리헨션임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬 클래스에서 인스턴스 자신을 가리키는 첫 번째 매개변수의 관례적 명칭은?",
            "options": [
                "this",
                "cls",
                "self",
                "me",
                "base"
            ],
            "answer": "self",
            "why": "파이썬의 메서드는 첫 번째 인자로 인스턴스 자신을 받도록 설계되어 있으며, 이를 'self'라고 명명하는 것이 PEP8 권장 사항입니다.",
            "hint": "S로 시작하는 4글자 단어입니다.",
            "trap_points": [
                "Java의 this와 혼동 주의"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas DataFrame에서 특정 열 'A'의 고유 값들의 빈도를 계산하는 메서드는?",
            "options": [
                "df['A'].count()",
                "df['A'].value_counts()",
                "df['A'].unique()",
                "df['A'].nunique()",
                "df['A'].sum()"
            ],
            "answer": "df['A'].value_counts()",
            "why": "value_counts()는 각 고유 값들의 출현 빈도를 내림차순으로 계산하여 Series로 반환합니다.",
            "hint": "값(Value)의 개수(Counts)를 세어줍니다.",
            "trap_points": [
                "count()는 전체 데이터 개수만 세어줌"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "텍스트 수치화 기법 중 단어의 빈도뿐만 아니라 희귀성을 고려하여 가중치를 부여하는 방식은?",
            "options": [
                "Bag of Words",
                "N-gram",
                "TF-IDF",
                "Word2Vec",
                "One-hot Encoding"
            ],
            "answer": "TF-IDF",
            "why": "TF-IDF는 단어 빈도(TF)에 역문서 빈도(IDF)를 곱하여, 특정 문서에만 자주 등장하는 중요 단어에 높은 가중치를 부여합니다.",
            "hint": "IDF는 Inverse Document Frequency의 약자입니다.",
            "trap_points": [
                "Bag of Words는 빈도만 고려함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "트랜스포머의 인코더 블록에서 입력된 토큰 위치 정보를 반영하기 위해 더해주는 값은?",
            "options": [
                "Positional Encoding",
                "Layer Normalization",
                "Attention Mask",
                "Softmax Score",
                "Skip Connection"
            ],
            "answer": "Positional Encoding",
            "why": "트랜스포머는 RNN과 달리 병렬 처리를 위해 순서 정보가 없으므로, 사인/코사인 함수 등을 이용한 위치 정보를 벡터에 추가합니다.",
            "hint": "위치(Position)를 부호화(Encoding)합니다.",
            "trap_points": [
                "Attention Mask는 특정 부분을 가리는 용도임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "RLHF 단계에서 인간의 선호도를 모델에 반영하기 위해 학습시키는 별도의 모델 명칭은?",
            "options": [
                "Base Model",
                "Instruction Model",
                "Reward Model (보상 모델)",
                "Policy Model",
                "Target Model"
            ],
            "answer": "Reward Model (보상 모델)",
            "why": "인간이 매긴 순위를 학습하여 어떤 답변이 더 좋은지 점수를 매기는 '보상 모델'을 만든 뒤, 이를 통해 본 모델을 강화학습시킵니다.",
            "hint": "좋은 행동에 상(Reward)을 줍니다.",
            "trap_points": [
                "DPO는 이 모델이 필요 없다는 것이 차별점임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "LLM에게 '너는 전문 변호사야'라고 하여 답변의 스타일과 관점을 고정시키는 프롬프트 요소는?",
            "options": [
                "Context",
                "Format",
                "Persona (또는 Role)",
                "Task",
                "Example"
            ],
            "answer": "Persona (또는 Role)",
            "why": "페르소나 설정은 모델의 말투, 전문성 수준, 가치관을 특정 역할에 맞게 유도하는 기법입니다.",
            "hint": "가면, 역할을 뜻하는 심리학/문화 용어입니다.",
            "trap_points": [
                "최근 연구에서는 지식 문제 해결 자체에는 효과가 미미할 수 있음"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "사용자의 질문에 대해 단계별 풀이 과정을 출력하도록 유도하는 기법은?",
            "options": [
                "Zero-shot",
                "Chain of Thought (CoT)",
                "Few-shot",
                "Step-back Prompting",
                "Negative Prompting"
            ],
            "answer": "Chain of Thought (CoT)",
            "why": "CoT는 '생각의 사슬'을 따라 논리적 추론 과정을 먼저 적게 함으로써 복잡한 문제의 정답률을 높입니다.",
            "hint": "사고의 흐름, 사슬(Chain)을 생각하세요.",
            "trap_points": [
                "단순히 예시를 보여주는 Few-shot과는 다름"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG 시스템에서 유사도 검색 시 '의미적으로는 같으나 다른 단어'를 찾지 못하는 키워드 검색의 한계를 보완하는 기술은?",
            "options": [
                "BM25",
                "TF-IDF",
                "Vector Embedding (임베딩)",
                "Regex",
                "SQL Like"
            ],
            "answer": "Vector Embedding (임베딩)",
            "why": "임베딩은 텍스트를 벡터로 변환하여 '왕'과 '군주'처럼 철자는 다르지만 의미가 유사한 단어를 거리 기반으로 찾아낼 수 있습니다.",
            "hint": "텍스트를 숫자의 나열(Vector)로 바꿉니다.",
            "trap_points": [
                "BM25는 키워드 일치를 중시함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "사용자의 질문을 기반으로 필요한 도구(Tool)를 선택하고 실행 계획을 스스로 세우는 구조는?",
            "options": [
                "Static Pipeline",
                "Fixed Workflow",
                "AI Agent",
                "Legacy Bot",
                "Rule-based System"
            ],
            "answer": "AI Agent",
            "why": "에이전트는 LLM의 추론 능력을 활용하여 목표 달성을 위한 작업 단계(생각, 행동, 관찰)를 능동적으로 제어합니다.",
            "hint": "대리인, 주체적으로 행동하는 존재를 뜻합니다.",
            "trap_points": [
                "단순히 문서를 찾는 RAG보다 한 단계 상위 개념임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "LoRA 파인튜닝 시 학습 데이터에 과하게 적응하여 범용 능력이 떨어지는 현상은?",
            "options": [
                "Regularization",
                "Overfitting (과적합)",
                "Underfitting",
                "Normalization",
                "Quantization"
            ],
            "answer": "Overfitting (과적합)",
            "why": "특정 데이터셋의 패턴만 완벽히 외워버려 새로운 질문이나 다른 도메인에 대한 대응력이 상상히 저하되는 현상입니다.",
            "hint": "너무(Over) 딱 맞게(Fitting) 된 상황입니다.",
            "trap_points": [
                "망각(Forgetting)과는 구분되는 개념임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "오픈 모델(Llama 등)을 CPU만 있는 환경이나 메모리가 부족한 Mac에서 효율적으로 실행하기 위해 주로 사용하는 포맷은?",
            "options": [
                "PyTorch (.pt)",
                "TensorFlow (.pb)",
                "GGUF",
                "ONNX",
                "Safetensors"
            ],
            "answer": "GGUF",
            "why": "GGUF(llama.cpp 계열)는 양자화된 가중치를 담은 단일 파일 포맷으로, CPU 추론 최적화와 함께 상용 LLM 도구(Ollama 등)에서 널리 쓰입니다.",
            "hint": "GG로 시작하는 4글자 포맷입니다.",
            "trap_points": [
                "Safetensors는 보안에 안전한 가중치 저장 방식이지만 CPU 최적화 포맷은 아님"
            ],
            "difficulty": "medium"
        }
    ]
}