# [ì‹¤ìŠµ] LangChainìœ¼ë¡œ ë°ì´í„° ìƒì„±í•˜ê¸°




ì´ë²ˆ ì‹¤ìŠµì—ì„œëŠ” Continuous Pretrainê³¼ Instruction Tuningì„ ìœ„í•œ ë°ì´í„° ìƒì„±ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.


!pip install langchain langchain-community langchain-openai langchain-ollama
from langchain.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate
from langchain.prompts import FewShotPromptTemplate
from langchain.schema.output_parser import StrOutputParser

import os
import json
from dotenv import load_dotenv

load_dotenv('.env',override=True)
# os.environ['OPENAI_API_KEY']=''
# LLM ì„¤ì •í•˜ê¸°

ë¬´ë£Œ API: Geminië¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ë¶„ë‹¹ 10íšŒ ì œí•œì„ ê³ ë ¤í•˜ì—¬ Rate Limiterë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
from langchain_core.rate_limiters import InMemoryRateLimiter
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI


# rate limiterë¥¼ LLMì— ì ìš©
llm = ChatOpenAI(
    model="gpt-4.1",
    temperature=0,
   #  verbosity='low'
)
llm.invoke("ì•ˆë…•")
## Instruction Data ë§Œë“¤ê¸°   

ë„ë©”ì¸ ì§€ì‹ì„ Continuous Pretrainìœ¼ë¡œ í•™ìŠµí•œ ëª¨ë¸ì„ ì‹¤ì œë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ”   
Instruction Tuningì´ ì¶”ê°€ë¡œ ìˆ˜í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

ê°„ë‹¨í•œ ì˜ë£Œ ìƒë‹´ì„ ì œê³µí•˜ëŠ” ì§ˆì˜ì‘ë‹µ ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤.

**(ëŒ€ë¶€ë¶„ì˜ LLMì€ ì˜ë£Œ, ë²•ë¥  ë“±ì˜ ìƒë‹´ì„ ì‹¤ì œ ìƒí™©ì—ì„œ ì§ì ‘ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ëŠ” ê²ƒì— ëŒ€í•œ ì œí•œì´ ì¡´ì¬í•©ë‹ˆë‹¤.)**
disease_list = open('./disease_list.txt','r', encoding='cp949').read().strip().split(',')
disease_list
from langchain.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate
from langchain.prompts import FewShotPromptTemplate
from langchain.schema.output_parser import StrOutputParser

import os
import json
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from itertools import product
from typing import List, Dict
import json
from tqdm import tqdm
from datetime import datetime
import time
import random
import re

# ì¹´í…Œê³ ë¦¬ ì˜µì…˜ ì •ì˜
category_options = {
    'question_type': [
        'medication_general',      
        'medication_side_effects', 
        'symptoms_general',        
        'symptoms_severity',       
        'diagnosis_process',       
        'test_results',           
        'treatment_options',       
        'treatment_duration',      
        'lifestyle_diet',         
        'lifestyle_exercise',      
        'prognosis_general',      
        'prevention_methods'       
    ],
    'patient_type': [
        'new_patient',            
    ],
    'age_group': [
        'child',                  
        'elderly'                 
    ],
    'verbosity': [
        '200ì ì´ë‚´ë¡œ', '500ì ì´ë‚´ë¡œ', '1000ì ì´ë‚´ë¡œ'
    ]
}

# ë‹¤ì–‘ì„±ì„ ìœ„í•œ ìƒí™© ì„¤ì •
PATIENT_SITUATIONS = {
    'child': [
        "5ì‚´ ì•„ë“¤", "7ì‚´ ë”¸", "10ì‚´ ì•„ì´", "ì´ˆë“±í•™ìƒ ìë…€", "4ì‚´ ì†ë…€", 
        "9ì‚´ ì¡°ì¹´", "6ì‚´ ì•„ë“¤", "11ì‚´ ë”¸", "ì´ˆë“± 3í•™ë…„ ì•„ì´", "ìœ ì¹˜ì›ìƒ",
        "8ì‚´ ì•„ì´", "ì´ˆë“± 1í•™ë…„", "12ì‚´ ì•„ë“¤", "3ì‚´ ë”¸", "ì´ˆë“± 6í•™ë…„"
    ],
    'elderly': [
        "72ì„¸ ì–´ë¨¸ë‹ˆ", "68ì„¸ ì•„ë²„ì§€", "75ì„¸ ì‹œì–´ë¨¸ë‹ˆ", "80ì„¸ í• ë¨¸ë‹ˆ", 
        "70ì„¸ ì¥ì¸ì–´ë¥¸", "65ì„¸ ì´ëª¨", "78ì„¸ í• ì•„ë²„ì§€", "73ì„¸ ì–´ë¨¸ë‹˜",
        "69ì„¸ ì‹œì•„ë²„ì§€", "76ì„¸ ì¹œì •ì•„ë²„ì§€", "82ì„¸ í• ì•„ë²„ì§€", "71ì„¸ ì‚¼ì´Œ",
        "77ì„¸ ê³ ëª¨", "74ì„¸ ì¥ëª¨ë‹˜", "67ì„¸ í°ì•„ë²„ì§€"
    ],
    'self_age': [
        "30ëŒ€ ì§ì¥ì¸", "40ëŒ€ ì£¼ë¶€", "50ëŒ€ ìì˜ì—…ì", "35ì„¸ íšŒì‚¬ì›",
        "42ì„¸ êµì‚¬", "38ì„¸ ê°„í˜¸ì‚¬", "45ì„¸ ì‚¬ì—…ê°€", "28ì„¸ ëŒ€í•™ì›ìƒ",
        "55ì„¸ ê³µë¬´ì›", "33ì„¸ í”„ë¦¬ëœì„œ", "48ì„¸ ì˜ì‚¬", "36ì„¸ ì—”ì§€ë‹ˆì–´",
        "29ì„¸ ë””ìì´ë„ˆ", "52ì„¸ ìš”ë¦¬ì‚¬", "41ì„¸ ë³€í˜¸ì‚¬"
    ],
    'duration': [
        "3ì¼ ì „ë¶€í„°", "ì¼ì£¼ì¼ì§¸", "2ì£¼ ì „ë¶€í„°", "í•œ ë‹¬ ì „ë¶€í„°", "ìµœê·¼ ë©°ì¹ ê°„",
        "ì–´ì œë¶€í„°", "5ì¼ì§¸", "ë³´ë¦„ ì „ë¶€í„°", "ì—´í˜ ì •ë„", "ì´í‹€ ì „ë¶€í„°",
        "4ì¼ ì „ë¶€í„°", "3ì£¼ì§¸", "6ì¼ ë™ì•ˆ", "ë°˜ë‹¬ ì „ë¶€í„°", "í•œ ì‹œê°„ ì „ë¶€í„°"
    ],
    'severity': [
        "ì¡°ê¸ˆì”©", "ê°‘ìê¸°", "ì ì  ì‹¬í•´ì ¸ì„œ", "ê°€ë”ì”©", "ê³„ì†í•´ì„œ",
        "ë°˜ë³µì ìœ¼ë¡œ", "ê°„í—ì ìœ¼ë¡œ", "ì‹¬í•˜ê²Œ", "ì•½ê°„", "ìì£¼",
        "ë•Œë•Œë¡œ", "ê¸‰ê²©íˆ", "ì„œì„œíˆ", "ì£¼ê¸°ì ìœ¼ë¡œ", "ë§¤ì¼"
    ],

}

# Q&A ìƒì„± í”„ë¡¬í”„íŠ¸
qa_prompt = ChatPromptTemplate([
    ('system', '''You are an AI assistant creating diverse doctor-patient Q&A pairs for medical AI training.

Task: Generate two DIFFERENT patient questions and doctor answers.

DIVERSITY REQUIREMENTS:
- Each Q&A must use completely different patient situations
- Vary ages: {child_examples} / {elderly_examples} / {self_examples}
- Vary durations: {duration_examples}
- Vary severity: {severity_examples}
- Make questions natural and realistic
- Answers should be professional, accurate, and helpful

Output Format (STRICT JSON):
{{
    "qa_1": {{
        "question": "êµ¬ì²´ì ì¸ ìƒí™©ì´ í¬í•¨ëœ í™˜ì ì§ˆë¬¸",
        "answer": "ì „ë¬¸ì ì´ê³  ì¹œì ˆí•œ ì˜ì‚¬ ë‹µë³€"
    }},
    "qa_2": {{
        "question": "ì™„ì „íˆ ë‹¤ë¥¸ ìƒí™©ì˜ í™˜ì ì§ˆë¬¸",
        "answer": "í•´ë‹¹ ìƒí™©ì— ë§ì¶˜ ì˜ì‚¬ ë‹µë³€"
    }}
}}

Write everything in Korean. Each Q&A must be unique and different.'''),
    
    ('user', '''ì§ˆë³‘: {disease}
ì§ˆë¬¸ ìœ í˜•: {question_type}
í™˜ì ìœ í˜•: {patient_type}
ì—°ë ¹ëŒ€: {age_group}
Answer Verbosity : {verbosity}

ì„œë¡œ ë‹¤ë¥¸ ìƒí™©ì˜ Q&A 2ê°œë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.''')
])

def parse_qa_response(text: str) -> dict:
    """ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ Q&A ë°ì´í„° ì¶”ì¶œ"""
    try:
        if hasattr(text, 'content'):
            text = text.content
        return json.loads(text)
    except:
        text = str(text).strip()
        if '```json' in text:
            text = text.split('```json')[1].split('```')[0]
        elif '```' in text:
            text = text.split('```')[1].split('```')[0]
        
        try:
            return json.loads(text)
        except:
            return None

def generate_medical_qa_dataset_batch(diseases: List[str], llm) -> List[Dict]:
    """ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë¹ ë¥¸ Q&A ë°ì´í„°ì…‹ ìƒì„±"""
    
    qa_dataset = []
    failed_generations = []
    
    # ì „ì²´ ì¡°í•© ìƒì„±
    combinations = list(product(
        diseases,
        category_options['question_type'],
        category_options['patient_type'],
        category_options['age_group'],
        category_options['verbosity']
    ))
    
    print(f"ğŸ“Š Total combinations: {len(combinations)}")
    print(f"ğŸ¯ Expected Q&A pairs: {len(combinations) * 2}")
    
    # ë°°ì¹˜ í¬ê¸° ì„¤ì • (API ì œí•œ ê³ ë ¤)
    BATCH_SIZE = 80  # í•œë²ˆì— 80ê°œì”© ì²˜ë¦¬
    
    # LLM ì²´ì¸ ìƒì„±
    chain = qa_prompt | llm
    
    # ì „ì²´ ì…ë ¥ íŒŒë¼ë¯¸í„° ì¤€ë¹„
    all_params = []
    for disease, q_type, p_type, age, verbosity in combinations:
        params = {
            'disease': disease,
            'question_type': q_type,
            'patient_type': p_type,
            'age_group': age,
            'verbosity': verbosity,
            'child_examples': ', '.join(random.sample(PATIENT_SITUATIONS['child'], 4)),
            'elderly_examples': ', '.join(random.sample(PATIENT_SITUATIONS['elderly'], 4)),
            'self_examples': ', '.join(random.sample(PATIENT_SITUATIONS['self_age'], 4)),
            'duration_examples': ', '.join(random.sample(PATIENT_SITUATIONS['duration'], 4)),
            'severity_examples': ', '.join(random.sample(PATIENT_SITUATIONS['severity'], 4))
        }
        all_params.append(params)
    
    # ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸°
    batches = [all_params[i:i+BATCH_SIZE] for i in range(0, len(all_params), BATCH_SIZE)]
    
    print(f"ğŸš€ Processing {len(batches)} batches of {BATCH_SIZE} items each")
    
    # ë°°ì¹˜ ì²˜ë¦¬
    for batch_idx, batch_params in enumerate(tqdm(batches, desc="Processing batches")):
        try:
            # ë°°ì¹˜ ì‹¤í–‰
            batch_results = chain.batch(batch_params)
            
            # ê²°ê³¼ ì²˜ë¦¬
            for params, result in zip(batch_params, batch_results):
                try:
                    # íŒŒì‹±
                    qa_data = parse_qa_response(result)
                    
                    if qa_data is None:
                        raise ValueError("Failed to parse")
                    
                    # ê°œë³„ Q&A ì €ì¥
                    for i, (qa_key, qa_content) in enumerate(qa_data.items(), 1):
                        if 'question' in qa_content and 'answer' in qa_content:
                            qa_item = {
                                'id': f"{params['disease']}_{params['question_type']}_{params['age_group']}_{len(qa_dataset)}",
                                'disease': params['disease'],
                                'question_type': params['question_type'],
                                'patient_type': params['patient_type'],
                                'age_group': params['age_group'],
                                'pair_number': i,
                                'question': qa_content['question'],
                                'answer': qa_content['answer'],
                                'timestamp': datetime.now().isoformat()
                            }
                            qa_dataset.append(qa_item)
                
                except Exception as e:
                    failed_generations.append({
                        'disease': params['disease'],
                        'question_type': params['question_type'],
                        'error': str(e)[:100]
                    })
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (2 ë°°ì¹˜ë§ˆë‹¤)
            if (batch_idx + 1) % 2 == 0:
                checkpoint = {
                    'metadata': {
                        'processed_batches': batch_idx + 1,
                        'total_qa_pairs': len(qa_dataset),
                        'failed': len(failed_generations)
                    },
                    'qa_dataset': qa_dataset
                }
                with open(f'qa_checkpoint_batch_{batch_idx+1}.json', 'w', encoding='utf-8') as f:
                    json.dump(checkpoint, f, ensure_ascii=False, indent=2)
                print(f"\nğŸ’¾ Checkpoint: {len(qa_dataset)} Q&As saved")
            
            # API ì œí•œ ë°©ì§€ (í•„ìš”ì‹œ)
            time.sleep(1)
            
        except Exception as e:
            print(f"\nâŒ Batch {batch_idx} failed: {str(e)[:100]}")
            for params in batch_params:
                failed_generations.append({
                    'disease': params['disease'],
                    'question_type': params['question_type'],
                    'batch_error': str(e)[:100]
                })
    
    return qa_dataset, failed_generations

def save_final_dataset(qa_dataset: List[Dict], failed: List[Dict]):
    """ìµœì¢… ë°ì´í„°ì…‹ JSON ì €ì¥"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # í†µê³„ ì •ë³´
    stats = {
        'total_qa_pairs': len(qa_dataset),
        'unique_diseases': len(set(item['disease'] for item in qa_dataset)),
        'unique_question_types': len(set(item['question_type'] for item in qa_dataset)),
        'failed_attempts': len(failed),
        'success_rate': f"{(len(qa_dataset) / (len(qa_dataset) + len(failed)*2) * 100):.1f}%" if qa_dataset else "0%",
        'generation_date': timestamp
    }
    
    # ìµœì¢… ë°ì´í„°
    final_data = {
        'metadata': stats,
        'qa_dataset': qa_dataset,
        'failed_generations': failed
    }
    
    # JSON ì €ì¥
    filename = f'medical_qa_dataset.json'
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… Dataset saved!")
    print(f"ğŸ“Š Total Q&A pairs: {stats['total_qa_pairs']}")
    print(f"ğŸ“Š Success rate: {stats['success_rate']}")
    print(f"ğŸ“ File: {filename}")
    
    return filename

# ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    try:
        start_time = time.time()
        print("ğŸš€ Starting BATCH Medical Q&A Generation")
        print(f"ğŸ“‹ {len(disease_list)} diseases Ã— 12 types Ã— 2 age groups = {len(disease_list)*24} combinations")
        print(f"âš¡ Using batch processing for speed")
        print("=" * 50)
        
        # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë°ì´í„°ì…‹ ìƒì„±
        qa_dataset, failed_generations = generate_medical_qa_dataset_batch(disease_list, llm)
        
        # ìµœì¢… ì €ì¥
        filename = save_final_dataset(qa_dataset, failed_generations)
        
        elapsed = (time.time() - start_time) / 60
        print(f"\nâœ¨ Completed in {elapsed:.1f} minutes!")
        print(f"âš¡ Speed: {len(qa_dataset)/elapsed:.1f} Q&As per minute")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ Interrupted")
        if 'qa_dataset' in locals():
            save_final_dataset(qa_dataset, failed_generations)
    
    except Exception as e:
        print(f"\nâŒ Error: {str(e)}")
        if 'qa_dataset' in locals():
            save_final_dataset(qa_dataset, failed_generations)
import json

with open('./medical_qa_dataset.json', 'r', encoding='utf-8') as file:
    qa_corpus = json.load(file)

qa_corpus['qa_dataset']
with open('medical_qa_data.json', 'w', encoding='utf-8') as f:
    json.dump(qa_corpus['qa_dataset'], f, ensure_ascii=False, indent=2)

print('medical QA ìƒì„± ì™„ë£Œ')
