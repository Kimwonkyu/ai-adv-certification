***

## 1. Numpy  핵심 포인트

- Numpy 특징
  - 파이썬 대표 수치 연산 라이브러리, 내부는 C로 구현되어 백터·행렬·텐서 연산이 빠름.
  - 대부분의 ML/DL 라이브러리가 Numpy 기반으로 동작.

- 배열/행렬 생성 & 연산
  - 생성: `np.array`, `np.zeros((m,n))`, `np.ones((m,n))`, `np.arange(start, stop, step)`, `np.random.randn(m,n)`.
  - 백터 연산: 요소별 연산(+,-,*,/), 내적 `np.dot(v1, v2)`, 노름 `np.linalg.norm(v)`.
  - 행렬 연산: 행렬곱 `A @ B` 또는 `np.matmul(A,B)`, 전치 `A.T`.

***

## 2. Pandas로 표 형태 데이터 다루기

- 기본 개념
  - 정형(테이블) 데이터 분석용 핵심 라이브러리.
  - 구조: Series(1차원), DataFrame(2차원, 여러 Series의 결합).

- DataFrame 기본 조작
  - 구조 확인: `df.shape`, `df.colums`, `df.info()`, `df.describe()`.
  - 파일 입출력: 로드 `pd.read_csv()`, `pd.read_json()`, 저장 `df.to_csv()`, `df.to_json()` 확인 `df.head()`, `df.tail()`.

- 선택/필터링/파생변수
  - 조건 필터링: `df[df['age'] >= 20) & (df['gender'] == 'male')]` (AND), `|`는 OR.
  - 파생 변수: `df['level'] = df['age'].apply(lamda x: '성인' if x>=20 else '미성년')`, 문자열 포함 여뷰: `df['skills'].str.contai("Python")`.

- 고급 처리
  - 그룹 통계: `df.groubby('col').agg({'x':'mean', 'y':'sum'})`.
  - 문자열/시계열: `.str.len()`, `.str.split().str.len()`, `pd.to_datetime()`, `.dt.year` 등.
  - 병합/조인: `df1.merge(df2, on='user', how='left')` (SQL JOIN과 유사).
  - 피벗 테이블: `df.pivot_table(values='age', index='department', aggfunc='mean')`.

***

## 3. 텍스트 전처리 5단계

- 개요
  - LLM 미사용 분석에서는 텍스트가 노이즈에 취약하므로, 모델 입력 전 정리 및 표준화 필요.
  - 전처리 주요 단계: 정규 표현식 → 정제(Cleaning) → 토큰화 → 정규화 → 불용어 제거.

- 정규표현식(Regex)
  - 패턴 기반 검색/치환: 이베일, 날짜, 숫자 추출.
  - 자주 쓰는 패턴: `\d+`(숫자), `[가-힣]+`(한글), `[a-zA-Z]+`(영문), `\s+`(공백), `.`(줄바꿈 제외 임의 문자).

- 텍스트 정제(Cleaning)
  - HTML 태그, URL, 이모지, 특수문자 제거 후 공백 정리.
  - 예: `re.sub(r'<[^>]>', '', text)`, `re.sub(r'http\s+', '' text)`, 불필요 특수문자 제거 후 `strip()`.

- 토큰화(Tokenization)
  - 텍스트를 의미 단위로 분리(문장/단어/형태소 단위).
  - N-gram: 연속된 n개 단어 묶음으로 문맥 반영 (예: bigram, trigram).

- 정규화(Normalization)
  - 대소문자 통일, 숫자를 `NUM` 등으로 치환, 반복 문자 축소, 중복 공백 제거.
  - 예: 숫자 치환 `re.sub(r'\d+', 'NUM', text)`, 반복 문자 축소 `re.sub(r'(.)\1{2,}',r'\1\1', text)`.

- 불용어(Stopwords) 제거
  - 의미가 약한 조사·접속사 제거(예: "이" ,"있", "것" ,"그리고").
  - 예: `[w for w in text.split() if w not in stopwords]` 형태로 필터링.

***

## 4. 텍스트 수치화: BOW, TF-IDF, 유사도

- 텍스트 → 숫자
  - 기계학습/통계분석을 위해 텍스트를 벡터로 변환 필요.
  - 주요 기법: Bag of Words, TF-IDF, N-gram.

- Bag of Words (BOW)
  - 문서에서 단어 출현 횟수를 세어 벡터로 표현, 단어 순서는 무시.
  - 장점: 구조 단순, 구현·계산이 빠름.
  - 단점: 순서·맥락 정보 손실, 벡터가 희소(sparse)하여 메모리/계산 비효율.

- TF-IDF
  - TF(단어 빈도 비율) X IDF(역문서 빈도, 희귀할수록 ⇡)로 단어 중요도 반영.
  - 희귀하지만 특정 문서에 많이 나오는 단어의 가중치를  높여 인덱싱에 활용.

- 문서 유사도
  - 코사인 유사도: 두 분서 벡터 방향의 유사성 측정, 값 범위 \(-1)~1 근처(설명상 -1 반대, 0 직교, 1 동일 방향).
  - 유클리드 거리: 두 벡터의 직선 거리, 벡터 크기의 영향을 받으며 0 이상.
  - 활용: 검색, 추천, RAG 등에서 문서 유사도 계산에 사용.

***


  