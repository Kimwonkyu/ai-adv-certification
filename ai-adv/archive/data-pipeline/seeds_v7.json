{
    "questions": [
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 리스트의 가장 마지막 요소를 꺼내고 리스트에서 삭제하는 메서드는?",
            "options": [
                "list.pop()",
                "list.remove()",
                "list.delete()",
                "list.clear()",
                "list.extract()"
            ],
            "answer": "list.pop()",
            "why": "pop()은 인덱스를 지정하지 않으면 마지막 요소를 반환하고 리스트에서 제거합니다.",
            "hint": "튀어나오다(Pop)라는 뜻입니다.",
            "trap_points": [
                "remove()는 값을 찾아 삭제하며 반환값은 없습니다."
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬 3에서 두 정수의 나눗셈 결과(예: 5 / 2)의 기본 자료형은?",
            "options": [
                "int",
                "float",
                "complex",
                "str",
                "bool"
            ],
            "answer": "float",
            "why": "파이썬 3에서는 / 연산 시 결과가 정수로 나누어떨어지더라도 항상 실수(float)를 반환합니다.",
            "hint": "정수가 아닌 '실수'가 나옵니다.",
            "trap_points": [
                "정수 몫을 구하려면 // 연산자를 써야 함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "클래스 내부에서 속성 이름 앞에 __ (언더바 두 개)를 붙여 이름 충돌을 방지하는 기능을 무엇이라 하나요?",
            "options": [
                "Encapsulation",
                "Name Mangling",
                "Decorating",
                "Abstracting",
                "Overriding"
            ],
            "answer": "Name Mangling",
            "why": "파이썬은 완전한 private을 지원하지 않지만, __를 쓰면 '_클래스명__속성명'으로 이름을 바꿔 외부 접근을 어렵게 만듭니다.",
            "hint": "이름을 으깨거나 훼손한다는 뜻입니다.",
            "trap_points": [
                "_ (언더바 하나)는 관례적인 내부용 표시임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "딕셔너리에서 모든 '값(Value)'들만 모아서 반환하는 메서드는?",
            "options": [
                "keys()",
                "items()",
                "values()",
                "data()",
                "get_all()"
            ],
            "answer": "values()",
            "why": "values()는 딕셔너리에 저장된 모든 값들의 뷰(view)를 반환합니다.",
            "hint": "값의 영어 단어입니다.",
            "trap_points": [
                "items()는 키와 값의 쌍(Tuple)을 반환함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "함수에서 반환값이 없을 때 파이썬이 기본적으로 반환하는 객체는?",
            "options": [
                "False",
                "0",
                "None",
                "Empty string",
                "Error"
            ],
            "answer": "None",
            "why": "파이썬의 모든 함수는 return이 없거나 return만 있을 경우 '값 없음'을 뜻하는 None을 반환합니다.",
            "hint": "아무것도 없음이라는 뜻의 객체입니다.",
            "trap_points": [
                "C언어의 void와 유사한 개념임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "short_answer",
            "question": "파이썬에서 모듈을 불러온 후 `as` 키워드를 사용하여 짧은 이름으로 별명을 붙이는 행위를 무엇이라 하나요?",
            "answer": "Aliasing (에일리어싱/별칭 지정)",
            "why": "`import pandas as pd` 처럼 긴 이름을 줄여서 코딩 효율을 높입니다.",
            "hint": "별명(Alias)을 지어주는 것입니다.",
            "trap_points": [
                "pd, np 같은 별명은 커뮤니티의 관례임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬의 'Global Interpreter Lock (GIL)'에 대한 설명으로 옳은 것은?",
            "options": [
                "멀티 프로세싱을 방해한다.",
                "하나의 스레드만 인터프리터를 점유하게 하여 멀티 스레딩의 효율을 제한한다.",
                "메모리를 자동으로 해제해준다.",
                "코드를 암호화한다.",
                "인터넷 속도를 제한한다."
            ],
            "answer": "하나의 스레드만 인터프리터를 점유하게 하여 멀티 스레딩의 효율을 제한한다.",
            "why": "GIL은 파이썬 객체에 대한 참조 카운트의 동기화를 위해 한 시점에 하나의 스레드만 실행되도록 보장합니다.",
            "hint": "전역(Global) 인터프리터 잠금(Lock)입니다.",
            "trap_points": [
                "CPU 위주의 멀티 스레드 작업에서 성능 병목의 원인이 됨"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파일 입출력 시, 기존 내용을 지우지 않고 끝에 덧붙여 쓰기 위해 사용하는 모드는?",
            "options": [
                "'r'",
                "'w'",
                "'a'",
                "'x'",
                "'b'"
            ],
            "answer": "'a'",
            "why": "append의 약자인 'a' 모드는 파일 포인터를 끝으로 이동시켜 내용을 추가합니다.",
            "hint": "추가하다(Append)의 첫 글자입니다.",
            "trap_points": [
                "'w' 모드는 기존 내용을 모두 삭제하고 새로 씀"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 문자열 내의 특정 문자를 다른 문자로 치환하는 메서드는?",
            "options": [
                "change()",
                "modify()",
                "replace()",
                "swap()",
                "convert()"
            ],
            "answer": "replace()",
            "why": "replace('기존', '신규')는 모든 발생 지점을 찾아 새 문자열로 바꿉니다.",
            "hint": "교체하다라는 뜻입니다.",
            "trap_points": [
                "원본 문자열은 불변(Immutable)이므로 결과값을 새 변수에 담아야 함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "short_answer",
            "question": "컴퓨터 사양을 넘어서는 큰 정수를 파이썬은 어떻게 처리하나요?",
            "answer": "메모리가 허용하는 한 무제한으로 지원함",
            "why": "파이썬 3의 int 자료형은 임의 정밀도(Arbitrary Precision)를 지원하여 오버플로우가 발생하지 않습니다.",
            "hint": "제약이 거의 없다고 보시면 됩니다.",
            "trap_points": [
                "C언어 등에서 발생하는 오버플로우 걱정이 없음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas에서 데이터프레임의 인덱스를 0부터 시작하는 숫자로 초기화하는 메서드는?",
            "options": [
                "clear_index()",
                "reset_index()",
                "set_index()",
                "reindex()",
                "format_index()"
            ],
            "answer": "reset_index()",
            "why": "기존 인덱스를 제거하고 정수 인덱스를 새로 부여합니다. drop=True 옵션을 주면 기존 인덱스를 삭제합니다.",
            "hint": "다시 설정(Reset)한다.",
            "trap_points": [
                "set_index()는 특정 열을 인덱스로 만들 때 사용함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Numpy에서 행렬 간의 내적(Dot Product)을 수행하는 함수는?",
            "options": [
                "np.multiply()",
                "np.dot()",
                "np.add()",
                "np.sum()",
                "np.prod()"
            ],
            "answer": "np.dot()",
            "why": "np.dot(A, B)는 2차원 배열의 경우 행렬 곱셈을 수행합니다.",
            "hint": "점(Dot) 곱셈입니다.",
            "trap_points": [
                "1차원 벡터끼리는 스칼라 값을 반환함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "정규표현식에서 '0번 이상 반복'됨을 의미하는 기호는?",
            "options": [
                "*",
                "+",
                "?",
                ".",
                "{1,}"
            ],
            "answer": "*",
            "why": "별표(*) 매칭 기호는 앞에 오는 패턴이 없거나(0번) 여러 번 반복됨을 의미합니다.",
            "hint": "0을 포함한 전체 반복입니다.",
            "trap_points": [
                "+ 는 무조건 1번 이상 있어야 함에 주의"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "텍스트 데이터에서 대소문자를 통일하거나 숫자를 특정 기호로 바꾸는 단계를 무엇이라 하나요?",
            "options": [
                "Cleaning",
                "Tokenization",
                "Normalization (정규화)",
                "Stemming",
                "Vectorization"
            ],
            "answer": "Normalization (정규화)",
            "why": "데이터의 다양성을 줄여서 분석 모델이 핵심 특징에 집중하도록 일관된 형태로 만드는 과정입니다.",
            "hint": "정상화, 표준화의 의미입니다.",
            "trap_points": [
                "학습 모델의 사전(Vocabulary) 크기를 줄이는 데 효과적임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas에서 결측치가 포함된 '행'을 아예 삭제해 버리는 메서드는?",
            "options": [
                "fillna()",
                "dropna()",
                "isna()",
                "remove_null()",
                "delete_na()"
            ],
            "answer": "dropna()",
            "why": "dropna()는 NaN이 포함된 행 또는 열을 데이터프레임에서 제거합니다.",
            "hint": "떨어뜨리다(Drop) + NA.",
            "trap_points": [
                "데이터가 너무 많이 삭제될 수 있으므로 주의해서 사용해야 함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "short_answer",
            "question": "텍스트 데이터를 n개의 연속된 단어 묶음으로 표현하여 문맥을 일부 반영하는 기법은?",
            "answer": "N-gram",
            "why": "uni-gram(1개), bi-gram(2개) 등으로 나누어 단어의 앞뒤 결합 정보를 보존합니다.",
            "hint": "N개의 그램(gram)입니다.",
            "trap_points": [
                "n이 커질수록 가능한 조합이 기하급수적으로 늘어남"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Numpy에서 배열의 최소값, 최대값의 차이(Range)를 계산하는 함수는?",
            "options": [
                "np.range()",
                "np.ptp()",
                "np.diff()",
                "np.spread()",
                "np.min_max()"
            ],
            "answer": "np.ptp()",
            "why": "ptp()는 'peak to peak'의 약자로 최대값 - 최소값을 반환합니다.",
            "hint": "P로 시작하는 3글자 함수입니다.",
            "trap_points": [
                "단순히 정렬된 값을 원하면 np.sort()를 써야 함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas에서 데이터프레임의 특정 열 이름을 변경할 때 사용하는 메서드는?",
            "options": [
                "rename()",
                "update()",
                "change()",
                "set_column()",
                "modify()"
            ],
            "answer": "rename()",
            "why": "df.rename(columns={'기존':'변경'}) 형식을 사용하여 이름을 바꿉니다.",
            "hint": "이름을 다시 짓다.",
            "trap_points": [
                "inplace=True를 주지 않으면 원본이 바뀌지 않음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "TF-IDF에서 IDF(역문서 빈도) 값이 크다는 것은 해당 단어가 어떤 특징을 가진다는 뜻인가요?",
            "options": [
                "모든 문서에서 흔하게 등장한다.",
                "특정 문서에만 드물게 등장하므로 정보 가치가 높다.",
                "오타일 확률이 높다.",
                "문장이 매우 길다.",
                "접속사(불용어)일 확률이 높다."
            ],
            "answer": "특정 문서에만 드물게 등장하므로 정보 가치가 높다.",
            "why": "전체 문서 중 적은 수의 문서에만 나타나는 단어일수록 해당 문서를 식별하는 데 유리하여 가중치가 높아집니다.",
            "hint": "희소성(Rareness)과 정보량의 관계를 생각하세요.",
            "trap_points": [
                "'the', 'is' 같은 단어는 모든 문서에 나오므로 IDF가 0에 가까움"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "short_answer",
            "question": "Pandas DataFrame에서 중복된 행을 확인하는(True/False 반환) 메서드는?",
            "answer": "duplicated()",
            "why": "duplicated()는 각 행이 이전에 출현했는지 여부를 불리언 값으로 알려줍니다.",
            "hint": "중복된(Duplicated)의 의미입니다.",
            "trap_points": [
                "제거하려면 drop_duplicates()를 써야 함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "트랜스포머 모델의 셀프 어텐션에서 연산 효율을 위해 Query와 Key의 내적값을 나누어주는 상수는?",
            "options": [
                "배치 크기",
                "시퀀스 길이",
                "헤드 차원의 제곱근 (sqrt(dk))",
                "단어 사전 크기",
                "레이어 수"
            ],
            "answer": "헤드 차원의 제곱근 (sqrt(dk))",
            "why": "내적값이 너무 커지면 소프트맥스 함수의 기울기가 0에 가까워지는 문제를 방지하기 위한 스케일링 과정입니다.",
            "hint": "스케일드 닷 프로덕트 어텐션(Scaled Dot-Product Attention)의 명칭에 이유가 있습니다.",
            "trap_points": [
                "나누지 않으면 학습이 불안정해질 수 있음"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "LLM 성능 측정 시 모델에 '3개 정도의 예시'를 프롬프트로 주고 문제를 풀게 하는 방식을 무엇이라 하나요?",
            "options": [
                "Zero-shot",
                "One-shot",
                "Few-shot",
                "Multi-shot",
                "Full-shot"
            ],
            "answer": "Few-shot",
            "why": "몇 가지(Few) 예시를 통해 모델이 수행할 작업의 규칙을 빠르게 동조화(In-context Learning)시키는 기법입니다.",
            "hint": "수량이 적음을 뜻하는 영어 표현입니다.",
            "trap_points": [
                "예시가 하나면 One-shot이라고 함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "트랜스포머의 FFNN(Feed-Forward Neural Network) 블록이 어텐션 블록 뒤에 위치하여 수행하는 주된 역할은?",
            "options": [
                "단어 간의 관계 파악",
                "위치 정보 부여",
                "비선형 변환을 통한 고차원 특징 학습",
                "데이터 압축",
                "출력 단어 선택"
            ],
            "answer": "비선형 변럼을 통한 고차원 특징 학습",
            "why": "어텐션이 토큰 간 정보를 섞어준다면, FFNN은 각 토큰 벡터의 표현력을 개별적으로 강화하는 역할을 합니다.",
            "hint": "딥러닝의 기본적인 비선형 층을 생각하세요.",
            "trap_points": [
                "각 토큰 위치마다 동일한 가중치가 적용됨(Position-wise)"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "모델의 파라미터가 70B일 때, 'FP16' 정밀도로 순수 가중치를 올리기 위해 필요한 VRAM은 약 몇 GB인가요?",
            "options": [
                "70GB",
                "140GB",
                "280GB",
                "35GB",
                "10GB"
            ],
            "answer": "140GB",
            "why": "FP16은 파라미터당 2바이트(16비트)를 사용하므로 700억 * 2 = 140GB입니다.",
            "hint": "B(십억) * 2바이트 입니다.",
            "trap_points": [
                "4bit 양자화를 하면 이의 1/4 수준으로 줄어듦"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "토크나이저 아키텍처 중 'SentencePiece'의 가장 큰 장점은?",
            "options": [
                "속도가 가장 빠르다.",
                "언어에 상관없이(언어별 형태소 분석 없이) 공백을 포함해 텍스트 조각을 학습할 있다.",
                "오타를 완벽히 수정해준다.",
                "이미지도 토큰화한다.",
                "단어 사전 크기가 무제한이다."
            ],
            "answer": "언어에 상관없이(언어별 형태소 분석 없이) 공백을 포함해 텍스트 조각을 학습할 있다.",
            "why": "사전 지식 없이 데이터로부터 직접 서브워드를 추출하여 다국어 지원에 매우 유리합니다.",
            "hint": "구글에서 만든 다국어 특화 토크나이저입니다.",
            "trap_points": [
                "Llama, T5 등 많은 현대 모델이 채택함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "short_answer",
            "question": "모델이 답변 생성 시 스스로 생성한 문장을 다시 입력으로 사용하여 다음 단어를 예측하는 성질을 무엇이라 하나요?",
            "answer": "Autoregressive (자기회귀)",
            "why": "과거의 출력이 미래의 입력이 되는 순차적 생성 방식을 의미합니다.",
            "hint": "스스로(Auto) 돌아온다(regressive)는 뜻입니다.",
            "trap_points": [
                "이 성질 때문에 생성 속도는 병렬화가 불가능하여 다소 느림"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "LLM이 문장의 문맥을 잃지 않도록 입력 토큰의 위치를 벡터에 회전 방식으로 반영하는 기술은?",
            "options": [
                "Sinusoidal Encoding",
                "RoPE (Rotary Positional Embedding)",
                "ALiBi",
                "Absolute Position",
                "Random Initialization"
            ],
            "answer": "RoPE (Rotary Positional Embedding)",
            "why": "상대적 위치 정보를 회전 행렬로 표현하여 긴 맥락에서도 위치 관계를 잘 유지하게 돕는 기술입니다.",
            "hint": "회전(Rotary)이라는 단어로 시작합니다.",
            "trap_points": [
                "Llama 2, 3 등 최신 모델들의 표준 위치 인코딩 방식임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "OpenAI의 초기 GPT 모델들이 사전학습(Pre-training) 때 주로 사용한 학습 명칭은?",
            "options": [
                "Supervised Learning",
                "Unsupervised Predictive Learning (또는 Self-supervised)",
                "Reinforcement Learning",
                "Meta Learning",
                "Inference Learning"
            ],
            "answer": "Unsupervised Predictive Learning (또는 Self-supervised)",
            "why": "사람의 레이블링 없이 텍스트 뭉치에서 다음 단어를 맞추는 방식으로 스스로 학습하기 때문입니다.",
            "hint": "비지도(Unsupervised) 학습의 일종입니다.",
            "trap_points": [
                "파인튜닝 단계에서는 지도(Supervised) 학습을 병행함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "다음 중 '양자화(Quantization)'를 통해 얻는 이득이 아닌 것은?",
            "options": [
                "모델 가중치 파일 용량 감소",
                "추론 속도 향상 (하드웨어 지원 시)",
                "VRAM 점유율 감소",
                "모델의 정확도(Perplexity) 무조건적 향상",
                "더 큰 모델을 작은 장치에서 실행 가능"
            ],
            "answer": "모델의 정확도(Perplexity) 무조건적 향상",
            "why": "양자화는 정보를 압축하는 과정이므로 약간의 성능 저하가 발생하는 것이 일반적입니다.",
            "hint": "정보를 줄이면 정밀도는 어떻게 될까요?",
            "trap_points": [
                "하지만 최근 기법들은 성능 저하를 극도로 최소화함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "short_answer",
            "question": "신경망이 학습 도중 너무 복잡해져서 훈련 데이터에만 완벽히 적응하고 실전 성능이 나오는 현상은?",
            "answer": "Overfitting (과적합)",
            "why": "데이터의 본질적 패턴이 아닌 노이즈까지 암기해버리는 문제입니다.",
            "hint": "너무 과하게(Over) 맞췄다(Fitting)는 뜻입니다.",
            "trap_points": [
                "파인튜닝 시 너무 많은 에포크를 돌리면 발생함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트 구조화 기법 중 복잡한 작업을 작은 단위 프롬프트 여러 개로 나누어 ‘순서대로 처리’하는 기법은?",
            "options": [
                "Prompt Chaining",
                "Few-shot",
                "Negative Prompting",
                "Zero-shot",
                "Style Transfer"
            ],
            "answer": "Prompt Chaining",
            "why": "한 번에 처리하기 벅찬 일을 여러 프롬프트가 바통을 이어받듯 처리하여 정확도를 높입니다.",
            "hint": "사건들을 사슬(Chain)처럼 연결합니다.",
            "trap_points": [
                "이전 단계의 출력이 다음 단계의 입력이 됨"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "LangChain에서 사용자의 대화 기록을 관리할 때, 마지막 N개의 대화만 유지하는 메모리 기법은?",
            "options": [
                "ConversationBufferMemory",
                "ConversationSummaryMemory",
                "ConversationBufferWindowMemory",
                "ConversationKGMemory",
                "VectorStoreRetrieverMemory"
            ],
            "answer": "ConversationBufferWindowMemory",
            "why": "윈도우(Window) 크기를 지정하여 최근 맥락만 집중적으로 유지함으로써 토큰 소모를 조절합니다.",
            "hint": "지정된 창(Window) 안의 데이터만 봅니다.",
            "trap_points": [
                "너무 과거의 내용은 잊어버리게 됨"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트 엔지니어링에서 'Few-shot' 예시가 모델의 답변을 방해하는 '바이어스(Bias)' 현상이란?",
            "options": [
                "가격이 비싸지는 현상",
                "답변 속도가 느려지는 현상",
                "예시로 든 특정 단어나 형식에 모델이 과도하게 꽂혀서 실제 질문 의도와 다르게 대답하는 것",
                "인터넷이 끊기는 현상",
                "영어로만 답하는 현상"
            ],
            "answer": "예제로 든 특정 단어나 형식에 모델이 과도하게 꽂혀서 실제 질문 의도와 다르게 대답하는 것",
            "why": "모델은 인컨텍스트 패턴을 매우 강력하게 학습하므로, 예시의 특징을 정답 근거보다 중요하게 여길 수 있습니다.",
            "hint": "치우침(Bias)의 문제를 생각하세요.",
            "trap_points": [
                "따라서 예시는 다양하고 중립적이어야 함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트 내에서 '변수'를 중괄호 { } 로 감싸서 나중에 데이터를 채워 넣는 구조를 무엇이라 하나요?",
            "options": [
                "Python Script",
                "Prompt Template",
                "Markdown List",
                "JSON Data",
                "HTML Tag"
            ],
            "answer": "Prompt Template",
            "why": "공통된 프롬프트 뼈대에 사용자별 데이터를 동적으로 삽입하기 위한 표준 방식입니다.",
            "hint": "프롬프트의 틀, 양식입니다.",
            "trap_points": [
                "LangChain 등 프레임워크의 핵심 기능임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "모델에게 '모르는 것은 모른다고 해'라고 지시하여 환각(Hallucination)을 줄이는 것을 프롬프트 요소 중 무엇이라 하나요?",
            "options": [
                "Context",
                "Constraint (제약조건)",
                "Task",
                "Format",
                "Persona"
            ],
            "answer": "Constraint (제약조건)",
            "why": "모델의 자유도를 제한하여 사실에 근거한 답변만 하도록 강제하는 지침입니다.",
            "hint": "하지 말아야 할 일을 규정하는 것입니다.",
            "trap_points": [
                "할루시네이션 방지의 가장 첫 걸음임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "short_answer",
            "question": "모델의 답변을 표나 불릿 리스트 형태로 출력해달라는 프롬프트 요소는?",
            "answer": "Format (형식)",
            "why": "정보 시각화나 후처리를 위해 답변의 물리적 구조를 지정하는 단계입니다.",
            "hint": "포맷팅(Formatting)하다.",
            "trap_points": [
                "마크다운(Markdown) 형식을 쓰면 가독성이 좋아짐"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "LangChain LCEL에서 'Prompt | LLM | StrOutputParser' 처럼 파이프로 연결된 전체 단위를 무엇이라 하나요?",
            "options": [
                "Chain (체인)",
                "Module",
                "Package",
                "Function",
                "Template"
            ],
            "answer": "Chain (체인)",
            "why": "컴포넌트들이 사슬처럼 연결되어 하나의 작업을 완수하므로 체인이라 부릅니다.",
            "hint": "하나의 줄기 혹은 사슬입니다.",
            "trap_points": [
                "실행은 .invoke() 메서드로 수행함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트 내에서 '가장 뒤에 배치한 정보'를 모델이 더 잘 기억하는 현상을 뜻하는 심리학 용어는?",
            "options": [
                "Primacy Effect (초두 효과)",
                "Recency Effect (최신 효과)",
                "Placebo Effect",
                "Anchor Effect",
                "Halo Effect"
            ],
            "answer": "Recency Effect (최신 효과)",
            "why": "긴 프롬프트에서 모델은 가장 마지막에 들어온 지시 사항이나 데이터를 더 강하게 인지하는 경향이 있습니다.",
            "hint": "최신 정보를 잘 기억합니다.",
            "trap_points": [
                "중요한 지시는 맨 뒤에 한 번 더 적어주는 팁이 여기서 나옴"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "short_answer",
            "question": "모델에게 답변의 '길이'를 지정(예: 3줄 이내)하여 정보를 압축하는 프롬프트 테크닉은?",
            "answer": "Length Constraint (길이 제약)",
            "why": "불필요한 미사여구를 줄여 토큰 비용을 아끼고 핵심만 전달하게 합니다.",
            "hint": "길이를 제한하는 것입니다.",
            "trap_points": [
                "너무 짧게 제한하면 정보가 손실될 수 있음"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "복잡한 코딩 태스크를 시킬 때, 'Step-back' 프롬프팅이 하는 역할은?",
            "options": [
                "코드를 대신 써준다.",
                "코드를 짜기 전 필요한 알고리즘의 원리나 목차를 먼저 정리하게 하여 실수를 줄인다.",
                "에러를 무시하게 한다.",
                "코드를 다른 언어로 바꾼다.",
                "속도를 빠르게 한다."
            ],
            "answer": "코드를 짜기 전 필요한 알고리즘의 원리나 목차를 먼저 정리하게 하여 실수를 줄인다.",
            "why": "구현에 집중하기 전 설계도를 먼저 그리게 하여 논리적 완성도를 확보하는 전략입니다.",
            "hint": "한 발 물러나서(Step-back) 전체를 조망합니다.",
            "trap_points": [
                "생성된 구조를 기반으로 실제 답변을 작성하게 함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG의 5단계 중, 사용자의 질문에서 불필요한 단어를 빼거나 더 적합한 검색어로 다듬는 과정은?",
            "options": [
                "Indexing",
                "Searching",
                "Processing (전처리)",
                "Augmenting",
                "Generating"
            ],
            "answer": "Processing (전처리)",
            "why": "질문 정제(Query Refinement)를 통해 벡터 DB 검색의 정밀도를 높이는 기초 단계입니다.",
            "hint": "가공, 처리의 단계를 생각하세요.",
            "trap_points": [
                "질문의 의도 파악(Intent Classification)도 이 단계에서 함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "벡터 DB에서 질문과 '의미적으로' 유사한 문서를 찾기 위해 텍스트를 고차원 숫자로 변환하는 기술은?",
            "options": [
                "Indexing",
                "Tokenizing",
                "Embedding (임베딩)",
                "Scaling",
                "Normalizing"
            ],
            "answer": "Embedding (임베딩)",
            "why": "텍스트의 추상적인 의미를 다차원 공간상의 좌표(벡터)로 변환하는 RAG의 핵심 기술입니다.",
            "hint": "E로 시작하는 용어로, 이미 여러 번 다뤘습니다.",
            "trap_points": [
                "임베딩 모델의 성능이 전체 RAG 품질의 50% 이상을 결정함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "검색된 문서 내용이 너무 길어 LLM의 컨텍스트 한도를 초과할 때, 검색된 결과를 요약해서 붙여주는 기술은?",
            "options": [
                "Refining",
                "Compressing (컨텍스트 압축)",
                "Stretching",
                "Mapping",
                "Reducing"
            ],
            "answer": "Compressing (컨텍스트 압축)",
            "why": "필요한 정보만 엑기스로 추출하여 토큰 비용을 아끼고 모델의 인지 부하를 줄입니다.",
            "hint": "압축한다는 뜻입니다.",
            "trap_points": [
                "압축 과정에서 중요한 소스 인용 정보가 손실되지 않도록 해야 함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG의 '할루시네이션(환각)' 억제 원리에 대해 가장 잘 설명한 것은?",
            "options": [
                "모델이 똑똑해서 거짓말을 안 하게 된다.",
                "검색된 실제 '근거 문서'를 프롬프트에 제공함으로써 모델이 지어낼 필요를 없애준다.",
                "인터넷 속도가 빨라져서",
                "데이터가 압축되어서",
                "모델 가중치가 바뀌어서"
            ],
            "answer": "검색된 실제 '근거 문서'를 프롬프트에 제공함으로써 모델이 지어낼 필요를 없애준다.",
            "why": "지식 컷오프 문제와 잘못된 기억 문제를 외부 데이터 증강을 통해 물리적으로 해결합니다.",
            "hint": "외부의 '근거(Ground truth)'를 제공하는 것에 주목하세요.",
            "trap_points": [
                "문서 내용 자체가 틀려 있으면 모델도 틀린 답을 할 수 있음 (GIGO 원칙)"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "short_answer",
            "question": "벡터 DB에서 유사도 검색의 속도를 높이기 위해, 정확도는 조금 양보하더라도 대략적으로 가장 가까운 것들을 찾아내는 기술은?",
            "answer": "ANN (Approximate Nearest Neighbor)",
            "why": "모든 데이터와 일일이 비교하는 KNN의 한계를 복잡한 인덱싱 알고리즘으로 극복합니다.",
            "hint": "대략적인(Approximate)의 약자입니다.",
            "trap_points": [
                "속도는 수백 배 빠르지만 순위가 100% 정확하지 않을 수 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "AI 에이전트가 실패하거나 도구 사용법이 틀렸을 때, 오류 로그를 보고 스스로 수정하여 다시 시도하는 기법은?",
            "options": [
                "Looping",
                "Self-Correction (또는 Reflection)",
                "Debugging",
                "Rerunning",
                "Augmenting"
            ],
            "answer": "Self-Correction (또는 Reflection)",
            "why": "자신의 행동 결과를 평가(Critic)하고 개선 사항을 도출하여 다음 단계에 반영합니다.",
            "hint": "자기(Self) 수정(Correction)입니다.",
            "trap_points": [
                "복잡한 에이전틱 워크플로우의 정수입니다."
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG 파이프라인 중 검색된 조각들을 질문과 합쳐서 프롬프트를 조립하는 컴포넌트를 무엇이라 하나요?",
            "options": [
                "Retriever",
                "Generator",
                "Augmentor (또는 Orchestrator)",
                "Indexer",
                "Parser"
            ],
            "answer": "Augmentor (또는 Orchestrator)",
            "why": "검색과 생성을 매끄럽게 연결하고 컨텍스트를 증강하는 역할을 수행합니다.",
            "hint": "증강하거나 조율하는 존재를 생각하세요.",
            "trap_points": [
                "LangChain에서는 보통 Chain 객체가 이 역할을 함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "BM25와 같은 알고리즘을 사용하며, 단어의 의미보다는 '철자의 정확한 일치'를 찾는 검색 방식은?",
            "options": [
                "Semantic Search",
                "Lexical Search (키워드 검색)",
                "Visual Search",
                "Deep Search",
                "Neural Search"
            ],
            "answer": "Lexical Search (키워드 검색)",
            "why": "어휘 기반 검색으로 전문 용어나 상품명 등 정확한 매칭이 필요한 경우 효과적입니다.",
            "hint": "어휘, 사전적인 뜻의 단어입니다.",
            "trap_points": [
                "의미가 비슷해도 철자가 다르면 찾아내지 못함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "short_answer",
            "question": "에이전트 구현 시 '현재 내가 무얼 했고, 앞으로 무얼 해야 할지'를 단계별로 기록하고 관리하는 능력을 무엇이라 하나요?",
            "answer": "Reasoning (추론) 또는 Planning (계획)",
            "why": "목표 달성을 위한 전략적 사고의 흐름을 관리하는 핵심 지능입니다.",
            "hint": "P로 시작하는 8글자 단어이기도 합니다.",
            "trap_points": [
                "ReAct 프레임워크의 Thought 단계가 여기에 해당함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "벡터 DB에서 유사도 계산 시 코사인 유사도 대신 '방향은 무시하고 절대적인 거리 차이'만 중요할 때 사용하는 메트릭은?",
            "options": [
                "Cosine Distance",
                "L2 Distance (Euclidean)",
                "Manhattan Distance",
                "Hamming Distance",
                "Dot Product"
            ],
            "answer": "L2 Distance (Euclidean)",
            "why": "유클리드 거리는 임베딩 벡터의 크기(Magnitude) 차이까지 모두 반영하여 거리를 잽니다.",
            "hint": "두 점 사이의 직선 거리입니다.",
            "trap_points": [
                "텍스트 정체성보다 수치적 크기가 중요할 때 유리함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "사전 학습된 베이스 모델의 능력을 그대로 유지하면서, 특정 '도메인(예: 법률, 의료)'의 지식만을 얇게 덧씌우는 PEFT의 이점은?",
            "options": [
                "학습 속도가 느려진다.",
                "모델 파라미터 전체를 학습할 때보다 GPU 메모리를 획기적으로 아끼고 빠른 튜닝이 가능하다.",
                "성능이 무조건 떨어진다.",
                "데이터가 많이 필요하다.",
                "인터넷 연결이 필수다."
            ],
            "answer": "모델 파라미터 전체를 학습할 때보다 GPU 메모리를 획기적으로 아끼고 빠른 튜닝이 가능하다.",
            "why": "가중치의 아주 일부(<1%)만 업데이트하므로 하드웨어 진입 장벽이 낮습니다.",
            "hint": "메모리와 비용의 효율성을 생각하세요.",
            "trap_points": [
                "LoRA가 대표적인 예시임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "RLHF 방식에서 아첨(Sycophancy) 부작용이란 무엇을 의미하나요?",
            "options": [
                "모델이 화를 내는 현상",
                "모델이 사용자에게 무조건 동조하거나 비위를 맞추는 답변만 내놓아 객관성이 떨어지는 현상",
                "답변의 글자 수가 많아지는 현상",
                "영어로만 답하는 현상",
                "인터넷 데이터를 지우는 현상"
            ],
            "answer": "모델이 사용자에게 무조건 동조하거나 비위를 맞추는 답변만 내놓아 객관성이 떨어지는 현상",
            "why": "사람이 매긴 선호도(Reward)가 '듣기 좋은 말'에 편향되어 있을 경우 모델이 이를 학습하게 됩니다.",
            "hint": "남의 비위를 맞춘다는 뜻의 어려운 단어입니다.",
            "trap_points": [
                "모델의 비판적 사고가 저해될 수 있음"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "DeepSeek-R1의 성공 요인 중 하나인 'GRPO'는 무엇의 약자인가요?",
            "options": [
                "Grand Reward Policy Optimization",
                "Group Relative Policy Optimization",
                "General Reason Policy Output",
                "Grid Relation Point Object",
                "Gradient Reset Policy Option"
            ],
            "answer": "Group Relative Policy Optimization",
            "why": "그룹 내의 상대적인 보상을 비교하여 학습하는 강화학습 알고리즘으로 별도의 가치 모델이 필요 없습니다.",
            "hint": "그룹(Group) 상대적(Relative)인 정책 최적화입니다.",
            "trap_points": [
                "DeepSeek에서 제안하여 화제가 됨"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "양자화 기법 중 0을 기준으로 대칭적인 분포를 사용하여 4비트 정밀도에서도 성능을 잘 유지하는 QLoRA의 핵심 포맷은?",
            "options": [
                "float32",
                "int8",
                "NF4 (Normal Float 4)",
                "BF16",
                "FP8"
            ],
            "answer": "NF4 (Normal Float 4)",
            "why": "정보의 손실을 방지하기 위해 가중치의 통계적 분포에 최적화된 비트 할당 방식입니다.",
            "hint": "Normal(정상 분포) + Float 4.",
            "trap_points": [
                "비트 수는 같아도 일반 int4보다 보존력이 높음"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "short_answer",
            "question": "고성능 교사 모델(Teacher)의 출력을 학생 모델(Student)이 따라 하게 하여 지식을 전수하는 기법은?",
            "answer": "Knowledge Distillation (지식 증류)",
            "why": "큰 모델의 확률 분포를 작은 모델이 학습하여 '가벼운 고성능 모델'을 만듭니다.",
            "hint": "지식을 증류(Distillation)함.",
            "trap_points": [
                "sLLM들의 비약적 발전의 숨은 공신임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝 데이터셋 구축 시 '품질이 나쁜 데이터'가 섞여 있을 때 발생하는 가장 고질적인 문제는?",
            "options": [
                "모델의 크기가 커진다.",
                "모델의 출력 품질이 오염되어 횡설수설하거나 틀린 답을 확신 있게 말하게 된다.",
                "학습 속도가 빨라진다.",
                "영어로만 답한다.",
                "UI가 깨진다."
            ],
            "answer": "모델의 출력 품질이 오염되어 횡설수설하거나 틀린 답을 확신 있게 말하게 된다.",
            "why": "쓰레기가 들어가면 쓰레기가 나온다는 GIGO(Garbage In Garbage Out) 원칙은 LLM에서도 매우 강력합니다.",
            "hint": "입력 데이터의 수준이 출력 수준을 결정합니다.",
            "trap_points": [
                "무조건 양이 많은 것보다 소수의 고품질 데이터가 훨씬 나음"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "강화학습에서 모델이 지나치게 변형되는 것을 막기 위해 '원본 모델의 확률 분포'와의 차이를 계산하는 손실 함수는?",
            "options": [
                "MSE Loss",
                "Cross Entropy",
                "KL Divergence (KL 발산)",
                "Huber Loss",
                "L1 Loss"
            ],
            "answer": "KL Divergence (KL 발산)",
            "why": "모델이 보상만 쫓다가 원래의 언어적 기초를 망가뜨리는 것을 방지하는 제약(Constraint) 장치입니다.",
            "hint": "통계적 거리 차이를 재는 용어입니다.",
            "trap_points": [
                "KL 값이 너무 크면 모델이 붕괴(Collapse)될 수 있음"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝 시 학습 데이터에 'Thinking(추론 과정)'을 명시적으로 포함해 교수하는 방식은?",
            "options": [
                "Zero-shot Tuning",
                "Reasoning SFT",
                "Direct Tuning",
                "Style Tuning",
                "Format Tuning"
            ],
            "answer": "Reasoning SFT",
            "why": "단순히 '질문-정답'만 주지 않고 '질문-생각과정-정답'을 함께 학습시켜 논리 구조를 각인시킵니다.",
            "hint": "추론(Reasoning) 과정을 담은 지도 학습(SFT)입니다.",
            "trap_points": [
                "DeepSeek R1-Distill 모델들이 이 방식으로 만들어짐"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "short_answer",
            "question": "파인튜닝 시 특정 데이터를 완전히 잊어버리게 하거나 개인정보를 지우는 기술적 과정은?",
            "answer": "Machine Unlearning (기계 언러닝)",
            "why": "이미 학습된 모델의 가중치에서 특정 지식의 영향력을 제거하는 고도로 어려운 작업입니다.",
            "hint": "배운 것을 잊게 만드는 과정입니다.",
            "trap_points": [
                "단순히 거절 프롬프트를 넣는 것과는 차원이 다른 기술임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "모델 배포 효율을 위해 중복되거나 중요도가 낮은 뉴런(가중치)을 아예 제거해 버리는 최적화 기술은?",
            "options": [
                "Quantization",
                "Pruning (가지치기)",
                "Distillation",
                "Merging",
                "Clipping"
            ],
            "answer": "Pruning (가지치기)",
            "why": "연산 그래프에서 불필요한 연결을 끊어내어 속도를 높이고 용량을 줄이는 기법입니다.",
            "hint": "나뭇가지를 친다는 뜻입니다.",
            "trap_points": [
                "과도하게 하면 성능이 급락할 수 있음"
            ],
            "difficulty": "hard"
        }
    ]
}