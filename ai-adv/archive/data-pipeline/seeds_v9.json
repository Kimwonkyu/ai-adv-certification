{
    "questions": [
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬의 'Itertools' 모듈에서 가용 가능한 모든 조합(Combination)을 생성하는 함수는?",
            "options": [
                "itertools.permutations",
                "itertools.combinations",
                "itertools.product",
                "itertools.cycle",
                "itertools.repeat"
            ],
            "answer": "itertools.combinations",
            "why": "combinations()는 주어 리스트에서 정해진 수만큼의 요소를 순서 상관없이 뽑는 조합을 생성합니다.",
            "hint": "조합이라는 뜻 그대로의 함수입니다.",
            "trap_points": [
                "permutations는 순서가 중요한 '순열'을 생성함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 HTTP 요청을 보내기 위해 가장 널리 쓰이는 외부 라이브러리는?",
            "options": [
                "urllib",
                "requests",
                "http.client",
                "networkx",
                "flask"
            ],
            "answer": "requests",
            "why": "requests 라이브러리는 사람이 읽기 쉬운 API로 HTTP 요청(GET, POST 등)을 처리할 수 있게 해줍니다.",
            "hint": "요청하다라는 뜻의 영어 단어입니다.",
            "trap_points": [
                "표준 라이브러리인 urllib보다 훨씬 사용이 간편함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "FastAPI에서 비동기 프로그래밍을 위해 사용하는 키워드 세트는?",
            "options": [
                "try - except",
                "async - await",
                "yield - next",
                "spawn - join",
                "open - close"
            ],
            "answer": "async - await",
            "why": "async def로 정의된 입출력 대기 시 await를 사용하여 다른 작업을 병렬로 처리할 수 있습니다.",
            "hint": "비동기(Asynchronous)와 기다리다(Await)의 약자입니다.",
            "trap_points": [
                "고성능 백엔드 구축의 핵심 키워드임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬 클래스에서 @staticmethod 와 @classmethod 의 결정적인 차이는?",
            "options": [
                "차이가 없다.",
                "@classmethod는 첫 번째 인자로 클래스 자체(cls)를 받지만, @staticmethod는 아무런 인자를 강제하지 않는다.",
                "@staticmethod만 클래스 변수에 접근 가능하다.",
                "@classmethod는 인스턴스에서 호출이 불가능하다.",
                "@staticmethod는 파일 속도를 빠르게 한다."
            ],
            "answer": "@classmethod는 첫 번째 인자로 클래스 자체(cls)를 받지만, @staticmethod는 아무런 인자를 강제하지 않는다.",
            "why": "클래스 메서드는 클래스의 상태를 수정하거나 팩토리 메서드를 만들 때 유용하며, 정적 메서드는 독립적인 유틸리티에 씁니다.",
            "hint": "클래스(cls) 정보를 전달받는지 여부를 보세요.",
            "trap_points": [
                "두 메서드 모두 인스턴스 생성 없이 클래스 이름으로 호출 가능함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 객체를 텍스트나 바이너리 형태로 직렬화(Serialization)하여 저장하는 내장 모듈은?",
            "options": [
                "json",
                "csv",
                "pickle",
                "marshal",
                "struct"
            ],
            "answer": "pickle",
            "why": "pickle은 파이썬 객체 구조를 바이너리 형태로 저장하고 다시 복원(unpickling)할 수 있게 해줍니다.",
            "hint": "오이 절임(Pickle)처럼 보존한다는 뜻입니다.",
            "trap_points": [
                "신뢰할 수 없는 출처의 피클 파일은 보안 에러(코드 실행)를 일으킬 수 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 리스트 내부 요소들의 합을 구할 때 사용하는 가장 효율적인 내장 함수는?",
            "options": [
                "total()",
                "sum()",
                "add_all()",
                "count()",
                "math.add()"
            ],
            "answer": "sum()",
            "why": "sum() 함수는 이터러블 객체의 모든 수치를 합산하여 반환합니다.",
            "hint": "합계를 뜻하는 영어 단어입니다.",
            "trap_points": [
                "문자열 리스트에는 사용이 불가능함 (join을 써야 함)"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬 3.7부터 딕셔너리에 추가된 중요한 성질은?",
            "options": [
                "값이 자동으로 정렬된다.",
                "항상 모든 키가 영어여야 한다.",
                "요소가 추가된 '순서'가 보장된다.",
                "메모리를 1/10로 줄였다.",
                "중복된 키를 허용한다."
            ],
            "answer": "요소가 추가된 '순서'가 보장된다.",
            "why": "과거에는 OrderDict를 써야 했으나, 현재는 일반 딕셔너리도 삽입 순서를 유지합니다.",
            "hint": "순차적 보관을 생각하세요.",
            "trap_points": [
                "순서가 보장되지만 세트(Set)는 여전히 무작위임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "BeautifulSoup 라이브러리를 사용해 웹 페이지의 HTML 태그를 찾는 기본 메서드는?",
            "options": [
                "soup.get()",
                "soup.find()",
                "soup.search()",
                "soup.match()",
                "soup.lookup()"
            ],
            "answer": "soup.find()",
            "why": "find()는 조건에 맞는 첫 번째 태그를, find_all()은 모든 태그를 리스트로 반환합니다.",
            "hint": "찾다라는 뜻의 4글자 영어입니다.",
            "trap_points": [
                "CSS 선택자를 쓰고 싶다면 soup.select()를 사용함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 문자열이 숫자로만 이루어져 있는지 확인하여 True/False를 반환하는 메서드는?",
            "options": [
                "isdigit()",
                "isnumeric()",
                "isdecimal()",
                "위 셋 모두 유사하지만 미세한 차이가 있으며 보통 isdigit()을 널리 쓴다.",
                "check_num()"
            ],
            "answer": "위 셋 모두 유사하지만 미세한 차이가 있으며 보통 isdigit()을 널리 쓴다.",
            "why": "isdigit은 숫자 형태의 문자 여부를, isdecimal은 0-9의 순수 십진수 여부를 엄격히 따집니다.",
            "hint": "숫자(digit)인가요?(is)",
            "trap_points": [
                "마이너스(-) 기호나 소수점(.)이 포함되면 False가 나옴"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "short_answer",
            "question": "파이썬에서 현재 작업 디렉토리나 환경 변수를 조작하기 위해 사용하는 표준 라이브러리 모듈은?",
            "answer": "os",
            "why": "os.path, os.getenv 등 운영체제(Operating System) 관련 인터페이스를 제공합니다.",
            "hint": "알파벳 두 글자입니다.",
            "trap_points": [
                "최근에는 객체 지향적인 pathlib 사용도 권장됨"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas에서 데이터프레임의 인덱스를 무시하고 단순 수직 결합(Append)할 때 사용하는 함수는?",
            "options": [
                "pd.merge()",
                "pd.concat()",
                "pd.join()",
                "pd.update()",
                "pd.bind()"
            ],
            "answer": "pd.concat()",
            "why": "concat()은 리스트에 담긴 여러 데이터프레임을 축(axis)을 따라 이어 붙입니다.",
            "hint": "연결하다(Concatenate)의 약자입니다.",
            "trap_points": [
                "merge()는 공통 키(Key)를 기준으로 합치는 'JOIN' 연산임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Numpy에서 특정 범위 내의 숫자를 '균등한 간격'으로 지정된 개수만큼 생성하는 함수는?",
            "options": [
                "np.arange()",
                "np.linspace()",
                "np.random.normal()",
                "np.full()",
                "np.eye()"
            ],
            "answer": "np.linspace()",
            "why": "linspace(0, 10, 5)는 0부터 10 사이를 5개로 쪼개어 [0, 2.5, 5, 7.5, 10] 을 만듭니다.",
            "hint": "선형(Linear) 공간(Space)입니다.",
            "trap_points": [
                "arange는 간격을 지정하고, linspace는 개수를 지정함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "데이터의 왜도(Skewness)가 심할 때, 정규분포에 가깝게 만들기 위해 자주 사용하는 변환 기법은?",
            "options": [
                "Linear Scaling",
                "Log Transformation (로그 변환)",
                "Squaring",
                "Rounding",
                "Negative Filter"
            ],
            "answer": "Log Transformation (로그 변환)",
            "why": "로그 변환은 큰 수치들의 차이를 좁혀주어 데이터의 편향을 완화하는 데 매우 효과적입니다.",
            "hint": "로그(log) 함를 적용합니다.",
            "trap_points": [
                "데이터에 0이나 음수가 있으면 바로 적용할 수 없음(Shift 필요)"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Scikit-learn에서 기계학습 모델의 성능을 교차 검증하기 위해 사용하는 클래스는?",
            "options": [
                "LinearRegression",
                "KFold",
                "StandardScaler",
                "PCA",
                "MinMaxScaler"
            ],
            "answer": "KFold",
            "why": "KFold는 데이터를 K개의 그룹으로 나누어 학습과 검증을 번갈아 수행하며 일반화 성능을 높입니다.",
            "hint": "접다(Fold)는 뜻의 단어가 포함됩니다.",
            "trap_points": [
                "검증 데이터셋이 고정되었을 때 발생하는 편향을 방지함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "데이터 분석 시 이상치(Outlier)를 탐지하는 가장 고전적이면서 강력한 기준은?",
            "options": [
                "평균값 기준",
                "IQR (Interquartile Range) 기준",
                "최대값 기준",
                "데이터 개수 기준",
                "알파벳 순서 기준"
            ],
            "answer": "IQR (Interquartile Range) 기준",
            "why": "사분위수 범위(IQR)에서 1.5배 이상 벗어난 값을 이상치로 정의하는 'Whiskers' 방식을 널리 씁니다.",
            "hint": "25% ~ 75%의 범위를 의미합니다.",
            "trap_points": [
                "박스 플롯(Box Plot)의 원리가 되는 수치임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "short_answer",
            "question": "Pandas에서 데이터프레임의 특정 열에서만 유일한(Unique) 값들을 리스트 형태로 가져오는 메서드는?",
            "answer": "unique()",
            "why": "중복을 제거한 고유 값들을 넘파이 배열 형태로 반환합니다.",
            "hint": "유일하다라는 뜻입니다.",
            "trap_points": [
                "Series 객체에서만 바로 사용 가능함 (데이터프레임 전체 X)"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "정규표현식에서 `[a-zA-Z0-9_]` 와 완벽히 동일한 의미를 가진 특수 문자는?",
            "options": [
                "\\d",
                "\\s",
                "\\w",
                "\\b",
                "\\A"
            ],
            "answer": "\\w",
            "why": "\\w는 'word character'의 약자로 영문자, 숫자, 언더바를 포함합니다.",
            "hint": "단어(Word)를 구성하는 문자입니다.",
            "trap_points": [
                "공백은 포함하지 않음에 주의"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Matplotlib에서 차트의 제목을 설정하는 함수는?",
            "options": [
                "plt.name()",
                "plt.title()",
                "plt.header()",
                "plt.label()",
                "plt.write()"
            ],
            "answer": "plt.title()",
            "why": "title() 함수는 차트 상단에 메인 제목을 표기합니다.",
            "hint": "제목을 뜻하는 영어 단어입니다.",
            "trap_points": [
                "한글 폰트 설정이 되어있지 않으면 한글 제목이 깨질 수 있음"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "두 확률 변수 사이의 선형적 관계 강도를 측정하며 -1에서 1 사이의 값을 가지는 지표는?",
            "options": [
                "Mean",
                "Standard Deviation",
                "Pearson Correlation Coefficient (상관계수)",
                "Entropy",
                "Gini Index"
            ],
            "answer": "Pearson Correlation Coefficient (상관계수)",
            "why": "상관계수가 1에 가까우면 강한 양의 상관관계, -1에 가까우면 강한 음의 상관관계를 나타냅니다.",
            "hint": "상관(Correlation) 관계의 정도입니다.",
            "trap_points": [
                "0은 관계가 아예 없음을 뜻함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "short_answer",
            "question": "Numpy에서 행렬 간의 요소별(Element-wise) 나눗셈을 할 때 주의할 점은?",
            "answer": "분모가 0인 경우 (Divide by zero)",
            "why": "분모에 0이 있으면 inf(무한대)나 nan이 발생하여 이후 전체 연산 결과가 오염될 수 있습니다.",
            "hint": "수학적으로 불가능한 나눗셈 상황입니다.",
            "trap_points": [
                "데이터 전처리에서 아주 작은 값(epsilon)을 더해주기도 함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "LLM에서 'Context window expansion' 기술인 Flash Attention이 해결한 물리적 문제는?",
            "options": [
                "GPU 메모리 대역폭 한계와 연산 오버헤드",
                "인터넷 속도 지연",
                "언어 번역 정확도",
                "데이터 셔플링 속도",
                "키보드 입력 지연"
            ],
            "answer": "GPU 메모리 대역폭 한계와 연산 오버헤드",
            "why": "어텐션 행렬 전체를 메모리에 올리지 않고 타일 단위로 계산하여 속도는 수 배 높이고 메모리는 수십 배 절약합니다.",
            "hint": "번개(Flash)처럼 빠른 어텐션입니다.",
            "trap_points": [
                "최신 모델들의 긴 컨텍스트 지원을 가능하게 한 일등공신임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "GPT-4와 같은 거대 모델이 내부적으로 여러 개의 작은 모델(전문가) 조각으로 나뉘어 있는 구조를 무엇이라 하나요?",
            "options": [
                "Multi-tasking",
                "Mixture of Experts (MoE)",
                "Ensemble Learning",
                "Stacked Layers",
                "Parallel Processing"
            ],
            "answer": "Mixture of Experts (MoE)",
            "why": "MoE는 입력된 질문에 가장 적합한 전문가 신경망만 활성하하하여 효율성을 극대화합니다.",
            "hint": "전문가들의 혼합입니다.",
            "trap_points": [
                "파수(Parameter)는 많지만 실제 추론 시 활성화되는 파라미터는 적음"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "모델이 문장의 시작 토큰부터 마지막 토큰까지 한 방향으로만 훑으며 다음 단어를 예측하는 모델 계열은?",
            "options": [
                "BERT (Encoder-only)",
                "GPT (Decoder-only)",
                "T5 (Encoder-Decoder)",
                "YOLO",
                "ResNet"
            ],
            "answer": "GPT (Decoder-only)",
            "why": "GPT는 인과적(Causal) 모델로, 이전까지 나온 정보만을 바탕으로 미래의 단어를 예측합니다.",
            "hint": "생성(Generative)에 특화된 구조입니다.",
            "trap_points": [
                "BERT는 문장 전체를 양방향으로 훑는 인코더 기반임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "LLM에서 답변의 창의성을 높이기 위해 'Temperature' 값을 높이면 나타나는 현상은?",
            "options": [
                "답변이 정확해진다.",
                "확률 분포가 완만해져서 낮은 확률의 단어도 선택될 수 있게 되어 답변이 다양하고 엉뚱해진다.",
                "속도가 빨라진다.",
                "영어로만 답한다.",
                "글자 수가 무조건 길어진다."
            ],
            "answer": "확률 분포가 완만해져서 낮은 확률의 단어도 선택될 수 있게 되어 답변이 다양하고 엉뚱해진다.",
            "why": "온도가 높으면 에너지가 높은 상태처럼 입자(토큰)들이 자유롭게 돌아다니는 것에 비유됩니다.",
            "hint": "분포의 엔트로피가 증가합니다.",
            "trap_points": [
                "너무 높이면 문법이 파괴되거나 아무 말 대잔치가 될 수 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "모델의 파라미터가 4비트 양자화되었을 때, FP16 대비 용량은 어느 정도로 줄어드나요?",
            "options": [
                "1/2",
                "1/4",
                "1/8",
                "1/10",
                "전혀 줄지 않음"
            ],
            "answer": "1/4",
            "why": "16비트에서 4비트로 줄었으므로 수치적으로 4배 압축됩니다.",
            "hint": "16 / 4 를 계산해 보세요.",
            "trap_points": [
                "용량은 줄어도 연산 시에는 16비트로 임시 복원하여 연산하기도 함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "short_answer",
            "question": "LLM이 스스로 이전의 답변을 보고 틀린 부분을 찾아 고치는 능력을 무엇이라 하나요?",
            "answer": "Self-Correction (자기 수정)",
            "why": "모델이 논리적 모순을 인지하고 결과물을 고도화하는 고차원 지능 단계입니다.",
            "hint": "스스로 올바르게(Correction)함.",
            "trap_points": [
                "프롬프트를 통해 '다시 검토해'라고 할 때 발현됨"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "LLM 학습 데이터에서 '중복 데이터'를 제거하는 것이 중요한 이유는?",
            "options": [
                "비용이 아까워서",
                "모델이 특정 문장을 그대로 암기(Memorization)해버리는 부작용을 막기 위해",
                "파일 속도를 빠르게 하려고",
                "영어로만 코딩하게 하려고",
                "데이터 개수가 많으면 에러가 나서"
            ],
            "answer": "모델이 특정 문장을 그대로 암기(Memorization)해버리는 부작용을 막기 위해",
            "why": "반복 학습은 모델이 '이해'하는 대신 '암기'하도록 유도하여 새로운 질문에 대한 응답 능력을 떨어뜨립니다.",
            "hint": "앵무새처럼 따라 하는 현상을 방지합니다.",
            "trap_points": [
                "중복 제거 과정(Deduplication)은 모델 성능 향상의 핵심임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "토큰화 방식 중 하나로, 정해진 단어장(Vocab) 크기 내에서 단어를 효율적으로 쪼개는 방식의 이름은?",
            "options": [
                "BPE (Byte Pair Encoding)",
                "Linear Splitting",
                "Random Cutting",
                "Word Formatting",
                "Sequential Parsing"
            ],
            "answer": "BPE (Byte Pair Encoding)",
            "why": "가장 많이 나오는 문자 쌍을 합쳐가며 사전(Vocabulary)을 구축하는 최신 LLM의 표준 방식입니다.",
            "hint": "바이트 쌍 인코딩의 약자입니다.",
            "trap_points": [
                "한글은 조사나 어미 때문에 영문보다 더 세밀하게 쪼개짐"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "트랜스포머의 'Attention'에서 특정 부분을 안 보이게 가리는 행위(Masking)가 디코더에서 수행되는 이유는?",
            "options": [
                "메모리를 아끼려고",
                "미래의 단어를 미리 보고 정답을 암기하는 것을 방지하기 위해",
                "그냥 관례적으로",
                "영어로만 번역하려고",
                "시스템 에러를 숨기려고"
            ],
            "answer": "미래의 단어를 미리 보고 정답을 암기하는 것을 방지하기 위해",
            "why": "생성 모델은 과거의 정보만 알아야 하므로 다음 단어 이후는 '마스킹' 처리하여 접근을 차단합니다.",
            "hint": "컨닝(Cheating)을 방지하는 가림막입니다.",
            "trap_points": [
                "이를 'Causal Masking' 또는 'Look-ahead Masking'이라 함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "short_answer",
            "question": "모델의 학습 과정에서 인간의 선호도를 직접 학습시켜 '인간다운 답변'을 내놓게 하는 최종 정렬 단계를 무엇이라 하나요?",
            "answer": "RLHF (Reinforcement Learning from Human Feedback)",
            "why": "인간의 교정 데이터를 통해 모델이 어떤 답변이 더 유익하고 안전한지 배우게 합니다.",
            "hint": "인간의 피드백(Human Feedback)을 통한 강화학습입니다.",
            "trap_points": [
                "보상 모델(Reward Model) 학습 단계가 포함됨"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트에 페르소나를 줄 때 '너는 전문가야' 대신 '너는 수십 건의 대형 프로젝트를 성공시킨 10년 차 시니어 아키텍트야'라고 구체적으로 적는 게 유리한 이유는?",
            "options": [
                "모델이 긴 문장을 좋아해서",
                "지식 인출의 세부 범위(Boundary)를 구체적으로 한정하여 관련 지식의 인출 확률을 높이기 때문",
                "타이핑 양이 많으면 정성이 전달되어서",
                "영어로 번역하기 쉬워서",
                "그냥"
            ],
            "answer": "지식 인출의 세부 범위(Boundary)를 구체적으로 한정하여 관련 지식의 인출 확률을 높이기 때문",
            "why": "모델은 확률 분포상에서 지시 사항과 가장 관련 깊은 '공간'의 정보를 가져오려 하기 때문입니다.",
            "hint": "지식의 해상도를 높이는 과정입니다.",
            "trap_points": [
                "구체성이 결여되면 모델은 보편적이고 뻔한 대답을 함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "LangChain에서 사용자의 질문을 검색 엔진에 넣기 전, 검색이 더 잘 되도록 여러 개의 질문으로 확장해 주는 기법은?",
            "options": [
                "RAG",
                "Multi-Query Retriever",
                "Few-shot",
                "OutputParser",
                "Agent"
            ],
            "answer": "Multi-Query Retriever",
            "why": "사용자의 질문을 3~5개의 다른 관점으로 다시 써서 검색 성공률을 획기적으로 높입니다.",
            "hint": "멀티(Multi) + 질의(Query).",
            "trap_points": [
                "한 번의 질문으로 못 찾는 정보를 찾아낼 수 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트에 '출력물 말미에 너의 추론 과정을 요약해'라는 지시를 포함시키는 이유는?",
            "options": [
                "답변 길이를 늘리려고",
                "모델이 한 답변의 논리적 타당성을 스스로 검증하게 하여 품질을 높이기 위해",
                "시스템 로그로 남기려고",
                "영어로만 적게 하려고",
                "그냥"
            ],
            "answer": "모델이 한 답변의 논리적 타당성을 스스로 검증하게 하여 품질을 높이기 위해",
            "why": "스스로 설명하게(Self-explanation) 하는 과정에서 논리적 비약이나 할루시네이션이 자연스럽게 걸러집니다.",
            "hint": "메타 인지(생각에 대한 생각)를 유도합니다.",
            "trap_points": [
                "Chain of Thought와 결합하면 효과가 극대화됨"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트 인젝션(Prompt Injection) 방지를 위해 개발자가 취해야 할 조치는?",
            "options": [
                "사용자 입력을 그대로 모델에 전달한다.",
                "시스템 프롬프트 뒤에 강력한 가이드라인을 배치하고 구분자를 명확히 사용한다.",
                "모델을 끈다.",
                "비밀번호를 바꾼다.",
                "영어로만 입력받는다."
            ],
            "answer": "시스템 프롬프트 뒤에 강력한 가이드라인을 배치하고 구분자를 명확히 사용한다.",
            "why": "사용자 입력 데이터가 '지시 사항'으로 둔갑하는 것을 막기 위해 경계선을 긋고 우선순위를 명시해야 합니다.",
            "hint": "데이터와 명령어를 구분하세요.",
            "trap_points": [
                "최근에는 보안 전용 모델로 입력을 필터링하기도 함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트 엔지니어링 도구 중 여러 프롬프트와 모델 조합의 성능을 정량적으로 비교해 주는 기술을 무엇이라 하나요?",
            "options": [
                "Prompt Testing",
                "Prompt Evaluation (프롬프트 평가)",
                "A/B Testing",
                "Unit Testing",
                "Stress Testing"
            ],
            "answer": "Prompt Evaluation (프롬프트 평가)",
            "why": "다양한 테스트 세트로 모델의 답변을 채점하여 어떤 프롬프트가 가장 좋은지 과학적으로 검증합니다.",
            "hint": "평가(Evaluation)라는 용어를 기억하세요.",
            "trap_points": [
                "RAGAS나 LangSmith 같은 도구가 이 역할을 수행함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "short_answer",
            "question": "프롬프트 내에 마크다운(Markdown)의 '제목(#, ##)' 기능을 사용하는 주된 이유는?",
            "answer": "가독성 및 논리 구조화",
            "why": "모델은 헤더를 통해 문서의 논리적 계층 구조를 인간과 유사하게 파악할 수 있기 때문입니다.",
            "hint": "구조적인 가독성을 생각하세요.",
            "trap_points": [
                "일반 텍스트보다 훨씬 명확한 지침 전달이 가능함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "모델에게 '최종 정답'을 출력하기 전 반드시 수행해야 할 논리 체크리스트를 프롬프트에 넣는 기법은?",
            "options": [
                "Logic Gate",
                "Verification Prompting",
                "Step-by-Step",
                "Few-shot",
                "Persona"
            ],
            "answer": "Verification Prompting",
            "why": "답을 내기 전 스스로 '검증(Verify)' 루틴을 타게 함으로써 어이없는 실수를 방지합니다.",
            "hint": "확인, 검증(Verification)입니다.",
            "trap_points": [
                "추론 모델들의 내부 동작 원리와도 맞닿아 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "LLM이 사용자의 의도를 잘 모르겠을 때, 자의적으로 판단하지 않고 되묻도록 프롬프트를 짜는 전략은?",
            "options": [
                "Implicit prompt",
                "Interactive Clarification (대화형 명확화)",
                "Static prompt",
                "Direct prompt",
                "Fixed prompt"
            ],
            "answer": "Interactive Clarification (대화형 명확화)",
            "why": "정보가 부족할 때 사용자에게 질문(Ask)하게 함으로써 정답의 정확도를 높이는 협력적 전략입니다.",
            "hint": "대화(Interactive)를 통해 명확(Clarification)하게 합니다.",
            "trap_points": [
                "'모르면 물어봐' 라는 한 문장이면 충분함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "short_answer",
            "question": "프롬프트 엔지니어링에서 지시 사항의 '우선순위'를 정할 때, 가장 영향력이 큰 위치는 일반적으로 어디인가요?",
            "answer": "프롬프트의 가장 마지막 부분 (Bottom)",
            "why": "최신 효과(Recency Effect)로 인해 모델은 가장 끝에 배치된 명령을 가장 강하게 수행하는 경향이 있습니다.",
            "hint": "끝부분입니다.",
            "trap_points": [
                "중요한 규칙은 맨 끝에 한 번 더 강조해 주는 것이 팁임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트 내 예시(Few-shot)를 넣을 때 '틀린 답변' 예시도 함께 넣어 무엇이 아닌지를 알려주는 기법은?",
            "options": [
                "Negative Examples",
                "Positive Examples",
                "Neutral Examples",
                "Random Examples",
                "Mix Examples"
            ],
            "answer": "Negative Examples",
            "why": "무엇을 해야 할지뿐만 아니라 '무엇을 하지 말아야 할지'의 경계선을 명확히 긋는 강력한 교수법입니다.",
            "hint": "부정적인(Negative) 사례들입니다.",
            "trap_points": [
                "환각 방지와 스타일 고정에 효과적임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG 시스템 구축 시 텍스트를 고정된 도메인의 숫자인 벡터로 바꾸기 위해 사용하는 기술은?",
            "options": [
                "Indexing",
                "Tokenization",
                "Embedding (임베딩)",
                "Parsing",
                "Formatting"
            ],
            "answer": "Embedding (임베딩)",
            "why": "의미를 수치화하여 벡터 DB에 저장하고 유사도를 계산하기 위함입니다.",
            "hint": "E로 시작하는 단어로, RAG의 핵심입니다.",
            "trap_points": [
                "단어와 문장의 의미적 거리를 계산 가능하게 함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "벡터 DB에서 ‘가장 유사한 문서’ 상위 K개를 찾는 기술 중 하드웨어 리소스를 많이 쓰지만 가장 정확한 것은?",
            "options": [
                "ANN (Approximate)",
                "KNN (K-Nearest Neighbor)",
                "Random Search",
                "Hash Search",
                "Binary Search"
            ],
            "answer": "KNN (K-Nearest Neighbor)",
            "why": "KNN은 모든 데이터와 일일이 비교하여 가장 가까운 이웃을 찾아내므로 100% 정확하지만 속도가 느립니다.",
            "hint": "가장 가까운(Nearest) 이웃(Neighbor)을 직접 찾습니다.",
            "trap_points": [
                "데이터가 많아지면 ANN으로 대체해야 함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "에이전트 구현 시 '반성(Reflection)' 기술이 필요한 결정적인 상황은?",
            "options": [
                "단순한 날씨 묻기",
                "한 단계의 실수로 인해 전체 목표 달성이 불가능한 복잡한 다단계 논리 작업 시",
                "인사말 주고받기",
                "노래 제목 검색하기",
                "오늘의 날짜 묻기"
            ],
            "answer": "한 단계의 실수로 인해 전체 목표 달성이 불가능한 복잡한 다단계 논리 작업 시",
            "why": "스스로의 중간 결과물을 재평가하여 오류를 수정하지 않으면 에러가 누적되어 산으로 가기 때문입니다.",
            "hint": "복잡한 문제 풀이에서 '자기 객관화' 과정을 떠올리세요.",
            "trap_points": [
                "Self-Reflection은 에이전트의 성공률을 수십 % 높여줌"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG의 한계인 ‘컨텍스트 윈도우 한계’를 극복하기 위해 가장 중요한 데이터를 선별하여 다시 배치하는 과정은?",
            "options": [
                "Cleaning",
                "Merging",
                "Re-ranking (리랭킹)",
                "Scaling",
                "Deleting"
            ],
            "answer": "Re-ranking (리랭킹)",
            "why": "검색 결과 수십 개 중 실제 정답과 가장 밀접한 소수만 골라 LLM에 전달하여 비용과 성능을 모두 잡습니다.",
            "hint": "순위(Ranking)를 다시(Re) 매깁니다.",
            "trap_points": [
                "사용자 질문과 문서의 상관 관계를 심층적으로 재계산함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "short_answer",
            "question": "AI 에이전트가 어떤 도구를 언제 사용할지 스스로 계획(Plan)을 수립하는 논리 구조를 무엇이라 하나요?",
            "answer": "Planning (계획)",
            "why": "목표를 달성하기 위한 세부 태스크의 순서와 도구 선택를 설계하는 지능입니다.",
            "hint": "계획이라는 뜻의 영어 단어입니다.",
            "trap_points": [
                "Plan-and-Execute 구조의 핵심임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG 시스템에서 청크(Chunk)를 나눌 때 단어의 중간이 잘리는 것을 막기 위해 사용하는 속성은?",
            "options": [
                "Chunk size",
                "Chunk overlap",
                "Chunk padding",
                "Chunk scaling",
                "Chunk index"
            ],
            "answer": "Chunk overlap",
            "why": "조각 사이를 겹치게(Overlap) 하여 잘려 나간 문맥의 연결 고리를 보존합니다.",
            "hint": "겹침을 뜻하는 단어입니다.",
            "trap_points": [
                "보통 청크 크기의 10~20% 정도를 겹치게 설정함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "벡터 DB에서 질문과 원문 사이의 다리 역할을 하는 ‘가상의 가이드 답변’을 먼저 만들어 검색에 이용하는 기법은?",
            "options": [
                "HyDE",
                "Reranking",
                "Cleaning",
                "Parsing",
                "Indexing"
            ],
            "answer": "HyDE",
            "why": "LLM이 생성한 '가상의 완벽한 정답'을 임베딩하여 원문 저장소에서 유사한 것을 찾는 고급 기법입니다.",
            "hint": "가상(Hypothetical) 문서 임베딩입니다.",
            "trap_points": [
                "실제 질문보다 모델이 만든 답변이 문서 형태와 더 유사할 확률이 높음"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "에이전트가 외부 시스템과 대화하며 자신의 작업 결과를 저장하고 다시 읽는 ‘기억(Memory)’ 중에서, 영구적으로 저장되는 저장소는?",
            "options": [
                "Conversation Buffer",
                "Vector Database (또는 Long-term memory)",
                "RAM",
                "CPU Cache",
                "Internal State"
            ],
            "answer": "Vector Database (또는 Long-term memory)",
            "why": "과거의 수많은 대화나 지식을 벡터 DB에 저장해 뒀다 나중에 필요할 때 찾아 쓰는 방식입니다.",
            "hint": "장기(Long-term) 기억입니다.",
            "trap_points": [
                "에이전트의 페르소나와 과거 이력을 유지하는 핵심임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "short_answer",
            "question": "에이전트가 목표를 달성할 때까지 생각, 행동, 관찰을 무한히 반복하지 않도록 설정하는 안전 장치는?",
            "answer": "Max Iterations (최대 반복 횟수)",
            "why": "무한 루프(Infinite Logic Loop)에 빠져 비용이 폭주하는 것을 막기 위해 횟수 제한을 둡니다.",
            "hint": "최대(Max) 반복(Iteration).",
            "trap_points": [
                "보통 5~10회 정도로 설정함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG 평가 시 '사용자 질문에 대해 검색된 문서가 실제로 정답을 포함하고 있는지'를 평가하는 지표는?",
            "options": [
                "Faithfulness",
                "Context Recall",
                "Context Precision",
                "Answer Relevance",
                "Groundedness"
            ],
            "answer": "Context Recall",
            "why": "실제 정답에 필요한 정보가 검색 결과물 속에 빠짐없이 들어있는지 확인하는 리콜(재현율) 개념입니다.",
            "hint": "정보의 누락 여부를 판단합니다.",
            "trap_points": [
                "정밀도(Precision)는 쓸데없는 게 섞였는지를 봅니다"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "LoRA 파인튜닝 시 'Rank(r)' 파라미터가 가지는 의미는?",
            "options": [
                "모델의 순위",
                "추가되는 어댑터 행렬의 차원 크기 (작을수록 메모리 절약, 클수록 정교함)",
                "데이터의 개수",
                "학습 모델의 가격",
                "인터넷 속도"
            ],
            "answer": "추가되는 어댑터 행렬의 차원 크기 (작을수록 메모리 절약, 클수록 정교함)",
            "why": "랭크는 파인튜닝할 수 있는 '용량'을 결정하며, 보통 8, 16, 32 등이 널리 사용됩니다.",
            "hint": "행렬의 차원 수입니다.",
            "trap_points": [
                "너무 크면 전체 파라미터 학습과 차이가 없어 효율이 떨어짐"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝 학습 중 모델이 원본의 선한 의도나 안전 지침을 무시하고 사용자에게 욕설을 하거나 거칠게 답하는 것을 막는 과정을 무엇이라 하나요?",
            "options": [
                "Normalization",
                "Alignment (정렬)",
                "Scaling",
                "Cleaning",
                "Encryption"
            ],
            "answer": "Alignment (정렬)",
            "why": "모델의 가치관과 인간의 가치관을 일치(Align)시키는 RLHF, DPO 등의 기법이 여기에 포함됩니다.",
            "hint": "인간의 의도에 맞게 조정(Align)합니다.",
            "trap_points": [
                "정렬이 잘 안 된 모델은 자의적인 주장을 펼칠 수 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝된 모델 배포 시 가장 많이 쓰이는 최적화 라이브러리로, 특히 엔비디아 GPU 성능을 100% 끌어내는 것은?",
            "options": [
                "vLLM",
                "TensorRT-LLM",
                "Ollama",
                "Llama.cpp",
                "Auto-GPT"
            ],
            "answer": "TensorRT-LLM",
            "why": "엔비디아 하드웨어에 최적화된 추론 라이브러리로 배치 처리와 지연 시간을 획기적으로 줄여줍니다.",
            "hint": "엔비디아 공식 최적화 툴입니다.",
            "trap_points": [
                "설치는 어렵지만 성능은 압도적임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "사전 학습(Pre-training)과 파인튜닝(Fine-tuning)의 가장 큰 재료 차이는?",
            "options": [
                "재료가 똑같다.",
                "사전 학습은 레이블이 없는 방대한 인터넷 데이터(Next Token Prediction)를 쓰고, 파인튜닝은 질문-답변 쌍과 같은 레이블된 정제 데이터를 쓴다.",
                "사전 학습만 영어다.",
                "파인튜닝은 이미지를 안 쓴다.",
                "차이가 없다."
            ],
            "answer": "사전 학습은 레이블이 없는 방대한 인터넷 데이터(Next Token Prediction)를 쓰고, 파인튜닝은 질문-답변 쌍과 같은 레이블된 정제 데이터를 쓴다.",
            "why": "사전 학습은 세상의 일반적 패턴을 배우는 과정이고, 파인튜닝은 특정 목적으로 ‘길들이는’ 과정입니다.",
            "hint": "데이터의 덩어리(Bulk)와 정제(Curated)의 차이입니다.",
            "trap_points": [
                "최근에는 파인튜닝 단계의 데이터 질이 모델 품질을 결정함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "short_answer",
            "question": "가중치 행렬 중 일부 중요한 값만 남기고 0으로 만들어 모델 용량을 줄이는 최적화 방식은?",
            "answer": "Pruning (가지치기)",
            "why": "신경망 연결망 중 불필요한 가지를 쳐내어 속도와 용량을 개선합니다.",
            "hint": "나뭇가지를 친다는 뜻입니다.",
            "trap_points": [
                "Sparse해진 행렬을 효율적으로 처리하는 전용 커널이 필요함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝 시 'Learning Rate (학습률)'가 너무 높을 때 나타나는 일반적인 증상은?",
            "options": [
                "학습이 너무 완벽하게 된다.",
                "손실 값(Loss)이 발산하거나 요동치며 모델이 아무 기술도 배우지 못하고 망가진다.",
                "속도가 100배 빨라진다.",
                "영어로만 답한다.",
                "글자 수가 길어진다."
            ],
            "answer": "손실 값(Loss)이 발산하거나 요동치며 모델이 아무 기술도 배우지 못하고 망가진다.",
            "why": "보폭(Learning Rate)이 너무 크면 최적의 지점(Minimum)을 지나쳐버리기 때문입니다.",
            "hint": "너무 큰 보폭의 부작용을 생각하세요.",
            "trap_points": [
                "반대로 너무 작으면 학습 진행이 아예 안 될 수도 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝 후 모델의 '할루시네이션(환각)'이 오히려 심해지는 주된 원인은?",
            "options": [
                "컴퓨터가 뜨거워서",
                "데이터셋에 잘못된 정보가 포함되어 있거나, 모델이 데이터를 암기하기 시작해서 (Overfitting)",
                "영어로만 학습해서",
                "파일이 너무 커서",
                "인터넷이 끊겨서"
            ],
            "answer": "데이터셋에 잘못된 정보가 포함되어 있거나, 모델이 데이터를 암기하기 시작해서 (Overfitting)",
            "why": "나쁜 데이터를 배우면 지능 자체가 오염되는 GIGO 법칙의 결과입니다.",
            "hint": "학습 데이터의 품질이 곧 출력의 품질입니다.",
            "trap_points": [
                "데이터 양보다 정제가 훨씬 중요함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "모델의 지능 전수 기법인 'Distillation'에서 교사 모델과 학생 모델의 관계는?",
            "options": [
                "둘은 쌍둥이다.",
                "거대하고 똑똑한 모델(Teacher)의 확률 분포를 작고 가벼운 모델(Student)이 모방하도록 학습한다.",
                "학생이 더 크다.",
                "둘은 싸우는 관계다.",
                "관계가 없다."
            ],
            "answer": "거대하고 똑똑한 모델(Teacher)의 확률 분포를 작고 가벼운 모델(Student)이 모방하도록 학습한다.",
            "why": "효율을 위해 큰 모델의 능력을 작은 모델로 압축하는 강력한 산업적 기술입니다.",
            "hint": "증류(Distillation)의 과정을 생각하세요.",
            "trap_points": [
                "최신 sLLM들이 성능을 비약적으로 올린 비결임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "short_answer",
            "question": "파인튜닝 데이터를 만들 때, 사람이 직접 적는 대신 AI가 AI용 데이터를 자동으로 생성해 주는 기술은?",
            "answer": "Synthetic Data Generation (합성 데이터 생성)",
            "why": "고품질 데이터를 무한히 생성하여 학습 비용을 줄이고 다양성을 확보합니다.",
            "hint": "인공적으로 합성(Synthetic)한 데이터입니다.",
            "trap_points": [
                "최근에는 사람보다 AI가 만든 데이터로 학습한 성능이 더 높기도 함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝된 모델 공유 시 필수적으로 첨부해야 할 'Model Card'에 포함되지 않아도 되는 것은?",
            "options": [
                "모델의 용도와 제한 사항",
                "학습 데이터셋 정보",
                "평가 벤치마크 결과",
                "개발자의 어제 점심 메뉴",
                "저작권 및 라이선스 정보"
            ],
            "answer": "개발자의 어제 점심 메뉴",
            "why": "모델 카드는 기술적/윤리적 명세서이므로 사적인 정보는 필요 없습니다.",
            "hint": "모델의 '명세서'입니다.",
            "trap_points": [
                "투명한 AI 생태계를 위한 표준 약속임"
            ],
            "difficulty": "easy"
        }
    ]
}