{
    "questions": [
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 두 변수가 같은 '객체'를 가리키는지(메모리 주소 비교) 확인하는 연산자는?",
            "options": [
                "==",
                "is",
                "is same",
                "id()",
                "equals"
            ],
            "answer": "is",
            "why": "==는 값(Value)을 비교하고, is는 참조(Identity)를 비교합니다.",
            "hint": "존재 자체를 묻는 단어입니다.",
            "trap_points": [
                "작은 정수나 짧은 문자열은 인턴(Intern)되어 is 결과가 True일 수 있어 주의가 필요함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬의 `copy.deepcopy()` 를 사용해야 하는 상황은?",
            "options": [
                "단순 변수 대입 시",
                "리스트 내부에 리스트나 딕셔너리 같은 가변 객체가 중첩되어 있을 때",
                "영어로만 코딩할 때",
                "파일을 읽을 때",
                "인터넷이 빠를 때"
            ],
            "answer": "리스트 내부에 리스트나 딕셔너리 같은 가변 객체가 중첩되어 있을 때",
            "why": "일반 복사(shallow copy)는 내부 객체의 주소만 복사되어 원본 수정 시 복사본도 함께 바뀌는 문제가 발생하기 때문입니다.",
            "hint": "깊숙한 곳(Deep)까지 복사합니다.",
            "trap_points": [
                "메모리 사용량이 늘어나므로 필요한 경우에만 신중히 써야 함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬 `asyncio`에서 여러 코루틴을 동시에 실행하고 모두 끝날 때까지 기다리는 함수는?",
            "options": [
                "asyncio.run()",
                "asyncio.gather()",
                "asyncio.wait_all()",
                "asyncio.join()",
                "asyncio.start()"
            ],
            "answer": "asyncio.gather()",
            "why": "gather()는 여러 비동기 작업을 묶어서 병렬로 처리하고 결과를 리스트로 반환합니다.",
            "hint": "모으다(Gather)라는 뜻입니다.",
            "trap_points": [
                "하나가 에러 나면 전체가 중단되거나 별도 처리가 필요함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 '익명 함수'를 만들 때 사용하는 키워드는?",
            "options": [
                "def",
                "function",
                "lambda",
                "inline",
                "anon"
            ],
            "answer": "lambda",
            "why": "이름 없이 한 줄로 표현되는 함수로, 일시적인 로직이나 고차 함수의 인자로 쓰입니다.",
            "hint": "그리스 문자 이름입니다.",
            "trap_points": [
                "복잡한 로직은 일반 def 함수를 쓰는 것이 가독성에 좋음"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬 `try-except-else-finally` 문에서 에러 유무와 상관없이 '항상' 실행되는 블록은?",
            "options": [
                "try",
                "except",
                "else",
                "finally",
                "catch"
            ],
            "answer": "finally",
            "why": "주로 파일 닫기나 DB 연결 해제 등 마무리(Clean-up) 작업을 보장하기 위해 사용합니다.",
            "hint": "마지막으로(Finally)라는 뜻입니다.",
            "trap_points": [
                "return 문이 있어도 finally 블록은 실행되고 나감"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "short_answer",
            "question": "파이썬 인터프리터가 자동으로 관리하며 대규모 정수 연산 시 오버플로우를 막아주는 정수 처리 방식은?",
            "answer": "임의 정밀도 (Arbitrary Precision) 산술",
            "why": "사용 가능한 메모리만큼 숫자의 자릿수를 늘려가며 계산합니다.",
            "hint": "정밀도가 가변적입니다.",
            "trap_points": [
                "실수(float)는 IEEE 754 표준에 따라 오차가 발생할 수 있음에 주의"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬 딕셔너리에서 `dict.get('key', 'default')` 방식의 장점은?",
            "options": [
                "값이 더 빨리 나온다.",
                "키가 없어도 에러(KeyError)가 발생하지 않고 기본값을 안전하게 반환한다.",
                "메모리를 아낀다.",
                "영어로만 답한다.",
                "정렬이 잘 된다."
            ],
            "answer": "키가 없어도 에러(KeyError)가 발생하지 않고 기본값을 안전하게 반환한다.",
            "why": "방어적 프로그래밍을 가능하게 하여 코드의 안정성을 높입니다.",
            "hint": "안전한 가져오기(Get)입니다.",
            "trap_points": [
                "d['key'] 방식은 키가 없으면 즉시 에러가 발생함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 객체의 메모리 주소를 정수 형태로 반환하는 함수는?",
            "options": [
                "hex()",
                "id()",
                "addr()",
                "mem()",
                "loc()"
            ],
            "answer": "id()",
            "why": "파이썬 객체마다 부여된 고유한 식별 번호를 반환합니다.",
            "hint": "아이디(Identity)의 약자입니다.",
            "trap_points": [
                "CPython에서는 실제 메모리 주소값을 나타냄"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬 문자열에서 특정 문자가 '포함'되어 있는지 확인할 때 가장 깔끔한 연산자는?",
            "options": [
                "find()",
                "index()",
                "in",
                "contains()",
                "search()"
            ],
            "answer": "in",
            "why": "'char in string' 형태로 직관적으로 포함 여부를 불리언 값으로 반환합니다.",
            "hint": "~안에 있다는 뜻입니다.",
            "trap_points": [
                "단순 확인은 in이 가장 빠르고 가독성이 좋음"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "short_answer",
            "question": "변수의 타입을 런타임이 아닌 '코드 작성 시점'에 명시하여 버그를 줄이는 파이썬 3.5 이상의 기능은?",
            "answer": "Type Hint (타입 힌트)",
            "why": "def add(a: int, b: int) -> int: 처럼 사용하여 IDE의 자동완성과 정적 분석을 돕습니다.",
            "hint": "유형(Type)에 대한 힌트(Hint)입니다.",
            "trap_points": [
                "파이썬은 동적 타이핑 언어이므로, 힌트를 어겨도 런타임 에러가 바로 나지는 않음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas에서 데이터프레임의 특정 조건(예: 가격 > 100)을 만족하는 행들만 필터링하는 관용구는?",
            "options": [
                "df.filter(price > 100)",
                "df[df['price'] > 100]",
                "df.select(price > 100)",
                "df.where(price > 100)",
                "df.get(price > 100)"
            ],
            "answer": "df[df['price'] > 100]",
            "why": "대괄호 안에 불리언 시리즈를 넣어 True인 행만 추출하는 불리언 인덱싱 방식입니다.",
            "hint": "대괄호를 두 번 쓰는 듯한 느낌입니다.",
            "trap_points": [
                "df.query('price > 100')로도 표현 가능함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Numpy에서 행렬 곱셈을 수행할 때 쓰는 공식 연산자(파이썬 3.5+)는?",
            "options": [
                "*",
                "^",
                "@",
                "&",
                "|"
            ],
            "answer": "@",
            "why": "A @ B 는 행렬 곱셈(matrix multiplication)을 수행합니다. *는 요소별 곱셈입니다.",
            "hint": "골뱅이 기호입니다.",
            "trap_points": [
                "np.dot(A, B)와 동일한 결과를 냅니다."
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Scikit-learn에서 여러 전처리 단계와 모델을 하나로 묶어 관리하는 편리한 클래스는?",
            "options": [
                "Bundle",
                "Pipeline (파이프라인)",
                "Group",
                "Chain",
                "Workflow"
            ],
            "answer": "Pipeline (파이프라인)",
            "why": "데이터 스케일링부터 학습까지의 과정을 하나로 묶어 코드 누락을 방지하고 일관된 처리를 돕습니다.",
            "hint": "파이프(Pipe)들이 연결된 라인입니다.",
            "trap_points": [
                "교차 검증(Cross Validation) 시 데이터 누수를 원천 차단해 줌"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas 데이터프레임에서 행과 열의 위치를 기반으로(정수 인덱스) 데이터를 추출하는 속성은?",
            "options": [
                "df.loc",
                "df.iloc",
                "df.at",
                "df.iat",
                "df.get"
            ],
            "answer": "df.iloc",
            "why": "integer location의 약자이며, 정수 번호로 데이터를 인덱싱합니다. loc은 라벨 이름 기준입니다.",
            "hint": "앞글자 i는 정수(Integer)를 뜻합니다.",
            "trap_points": [
                "슬라이싱 시 마지막 인덱스 포함 여부가 loc과 다름에 주의"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "데이터 분석 중 '차원의 저주(Curse of Dimensionality)'를 해결하기 위해 정보를 요약하는 기법은?",
            "options": [
                "Expansion",
                "PCA (주성분 분석)",
                "Clustering",
                "Scaling",
                "Masking"
            ],
            "answer": "PCA (주성분 분석)",
            "why": "고차원 데이터를 가장 특징이 잘 드러나는 저차원 공간으로 투영하여 단순화합니다.",
            "hint": "주(Principal) 성분(Component) 분석.",
            "trap_points": [
                "차원을 줄이는 과정에서 일부 정보 손실은 불가피함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "short_answer",
            "question": "Pandas에서 데이터프레임의 요약 통계량(count, mean, std, min, max 등)을 한눈에 보여주는 메서드는?",
            "answer": "describe()",
            "why": "데이터의 분포를 파악할 때 가장 먼저 사용하는 마법 같은 함수입니다.",
            "hint": "묘사하다, 설명하다라는 영단어입니다.",
            "trap_points": [
                "수치형 데이터에 대해서만 작동하는 것이 기본임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "정규표현식에서 '문장의 맨 시작'을 의미하는 앵커 기호는?",
            "options": [
                "$",
                "^",
                "*",
                "!",
                "@"
            ],
            "answer": "^",
            "why": "문자열의 가장 앞부분이 특정 패턴으로 시작하는지 확인할 때 씁니다.",
            "hint": "삿갓 모양 기호입니다.",
            "trap_points": [
                "대괄호 안[^...]에서 쓰이면 '부정(Not)'의 의미로 바뀜에 주의"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Matplotlib 스타일 중 깔끔하고 현대적인 디자인으로 유명하며, `plt.style.use()` 로 호출 가능한 라이브러리 기반 스타일은?",
            "options": [
                "classic",
                "ggplot",
                "seaborn",
                "dark_background",
                "fivethirtyeight"
            ],
            "answer": "ggplot",
            "why": "R 언어의 유명 시각화 도구 스타일을 가져와서 가독성이 높습니다.",
            "hint": "R 유저들도 많이 쓰는 이름입니다.",
            "trap_points": [
                "seaborn 라이브러리를 직접 쓰면 더 고급 차트가 가능함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas에서 중복된 행을 삭제할 때 쓰는 메서드는?",
            "options": [
                "remove_duplicates()",
                "drop_duplicates()",
                "clear_duplicates()",
                "delete_duplicates()",
                "extract_uniques()"
            ],
            "answer": "drop_duplicates()",
            "why": "완벽히 동일한 내용의 행들을 하나만 남기고 제거합니다.",
            "hint": "중복을 떨어뜨리다(Drop).",
            "trap_points": [
                "특정 열(subset)을 기준으로 중복 판단을 할 수도 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "short_answer",
            "question": "데이터 분석에서 결측치를 단순히 평균값 등으로 채우는 행위를 무엇이라 하나요?",
            "answer": "Imputation (대체/임퓨테이션)",
            "why": "데이터를 버리지 않고 통계적 추정치로 메워 분석을 유지하는 기법입니다.",
            "hint": "I로 시작하는 10글자 영어입니다.",
            "trap_points": [
                "머신러닝 모델(IterativeImputer 등)을 써서 더 정교하게 채울 수도 있음"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "LLM이 문맥을 이해할 때 각 단어가 서로에게 얼마나 집중할지 계산하는 핵심 메커니즘은?",
            "options": [
                "Attention",
                "Reflection",
                "Detection",
                "Correction",
                "Interaction"
            ],
            "answer": "Attention",
            "why": "문장 내 단어 간의 연관성을 가중치로 계산하여 핵심 의미를 추출합니다.",
            "hint": "주의, 집중이라는 뜻입니다.",
            "trap_points": [
                "셀프 어텐션(Self-Attention)이 트랜스포머의 정수임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "트랜스포머 아키텍처에서 데이터의 표현력을 높이기 위해 여러 개의 어텐션을 병렬로 사용하는 것은?",
            "options": [
                "Single-Head Attention",
                "Multi-Head Attention",
                "Cross-Head Attention",
                "Layer-Head Attention",
                "Super-Attention"
            ],
            "answer": "Multi-Head Attention",
            "why": "여러 개의 '머리(Head)'를 두어 단어의 위치, 문법, 감정 등 다양한 측면을 동시에 포착합니다.",
            "hint": "머리가 여러 개입니다.",
            "trap_points": [
                "헤드 개수가 많다고 무조건 똑똑해지는 건 아니지만 풍부한 맥락 이해를 돕음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "LLM의 'Token limit (컨텍스트 길이)'을 결정하는 가장 물리적인 제약 사항은?",
            "options": [
                "컴퓨터 CPU 속도",
                "GPU의 VRAM 용량",
                "네트워크 대역폭",
                "키보드 타자 실력",
                "영문법 지식"
            ],
            "answer": "GPU의 VRAM 용량",
            "why": "어텐션 연산 시 발생하는 행렬 데이터가 메모리에 올라가야 하므로 VRAM이 클수록 긴 문장을 처리할 수 있습니다.",
            "hint": "그래픽 카드의 메모리입니다.",
            "trap_points": [
                "최근에는 메모리를 아끼는 어텐션 기술(Flash Attention 등)로 한계가 늘어남"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "모델이 이미 한 번 했던 실수를 자신의 메모리에서 읽어와 반복하지 않으려 노력하는 능력 수준은?",
            "options": [
                "Level 1 (단순 생성)",
                "Level 2 (추론 및 성찰)",
                "Level 0 (무작위)",
                "Level 5 (인간 초월)",
                "Level 3 (데이터 수집)"
            ],
            "answer": "Level 2 (추론 및 성찰)",
            "why": "자신의 과거 행동을 평가하고 교정하는 고도화된 AI의 특성입니다.",
            "hint": "성찰(Reflection)하는 단계입니다.",
            "trap_points": [
                "최신 추론 모델들이 이 능력을 극대화하고 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "트랜스포머 기반 모델 중 인코더만 사용하여 '문맥 파악'과 '분류'에 최적인 구글의 모델은?",
            "options": [
                "GPT",
                "BERT",
                "T5",
                "Llama",
                "Claude"
            ],
            "answer": "BERT",
            "why": "양방향(Bidirectional)으로 문장을 읽어 단어의 전후 맥락을 완벽히 파악하는 데 특화되어 있습니다.",
            "hint": "Sesame Street 캐릭터 이름과 같습니다.",
            "trap_points": [
                "생성(Generation) 능력은 GPT에 비해 떨어짐"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "short_answer",
            "question": "LLM이 인터넷에 노출되지 않은 최신 정보나 비공개 데이터를 아는 것처럼 답하게 하는 기술은?",
            "answer": "RAG (Retrieval-Augmented Generation)",
            "why": "외부 지식 저장소에서 관련 문서를 검색(Retrieval)하여 모델에 전달하기 때문입니다.",
            "hint": "알파벳 세 글자입니다.",
            "trap_points": [
                "지식 컷오프(Knowledge Cut-off) 문제를 해결하는 표준 해법임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "LLM 답변 생성 시 확률이 가장 높은 단어 하나만 무조건 선택하는 방식은?",
            "options": [
                "Beam search",
                "Greedy search",
                "Random sampling",
                "Top-P sampling",
                "Top-K sampling"
            ],
            "answer": "Greedy search",
            "why": "탐욕(Greedy)적으로 현재 시점에서 가장 높은 확률만 쫓는 방식이며, 답변이 단조로워질 수 있습니다.",
            "hint": "욕심쟁이 검색입니다.",
            "trap_points": [
                "정답이 정해진 코딩이나 수학 문제에 유리할 수 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "모델의 파라미터가 8B일 때, FP16 정밀도 가중치의 용량은 약 몇 GB인가요?",
            "options": [
                "4GB",
                "8GB",
                "16GB",
                "32GB",
                "1GB"
            ],
            "answer": "16GB",
            "why": "FP16은 2바이트를 쓰므로 80억 * 2 = 16GB입니다.",
            "hint": "8억 곱하기 2를 하세요.",
            "trap_points": [
                "운영 시에는 옵티마이저 메모리 등이 추가로 필요하여 더 많은 VRAM이 소요됨"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "LLM이 문장이 끝났음을 인지하고 멈추게 하는 토큰의 정식 명칭은?",
            "options": [
                "STOP token",
                "EOS (End Of Sequence) token",
                "FIN token",
                "EXIT token",
                "LAST token"
            ],
            "answer": "EOS (End Of Sequence) token",
            "why": "Sequence의 끝(End)을 알리는 특수 토큰입니다.",
            "hint": "E-O-S 세 글자 약자입니다.",
            "trap_points": [
                "이 토큰이 생성되기 전까지 모델은 최대 토큰 한도까지 계속 생성함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "short_answer",
            "question": "모델 학습 시 일부러 네트워크의 일부 연결을 무작위로 끊어 과적합을 방지하는 기술은?",
            "answer": "Dropout (드롭아웃)",
            "why": "특정 뉴런에만 의존하지 않도록 강제로 다양성을 확보하는 규제(Regularization) 기법입니다.",
            "hint": "떨어뜨리다(Drop) + 밖으로(Out).",
            "trap_points": [
                "추론(Inference) 단계에서는 드롭아웃을 끄고 모든 뉴런을 사용함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트 엔지니어링 기술 중 모델에게 '예시 없이' 즉석에서 작업을 시키는 방식은?",
            "options": [
                "Zero-shot",
                "One-shot",
                "Few-shot",
                "Multi-shot",
                "Chain-shot"
            ],
            "answer": "Zero-shot",
            "why": "별도의 훈련용 예시(shot)가 0개라는 뜻입니다.",
            "hint": "숫자 0입니다.",
            "trap_points": [
                "모델의 기초 지능이 높을수록 제로샷 성능이 뛰어남"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트에 '너는 초보자에게 친절하게 설명하는 유치원 선생님이야'라고 적는 페르소나 기법의 효과는?",
            "options": [
                "모델이 화를 낸다.",
                "답변의 톤앤매너와 어휘 수준이 지정된 역할에 맞춰 조정된다.",
                "답변 속도가 빨라진다.",
                "영어로만 답한다.",
                "글자 수가 무조건 길어진다."
            ],
            "answer": "답변의 톤앤매너와 어휘 수준이 지정된 역할에 맞춰 조정된다.",
            "why": "모델 내부의 수많은 가능성 중 '유치원 선생님'과 유사한 텍스트 확률 분포 영역을 활성화시킵니다.",
            "hint": "역할 놀이(Role play)의 효과입니다.",
            "trap_points": [
                "정확도보다는 '스타일'을 고정하는 데 유리함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트 내 지시 사항의 '우선순위'를 정할 때, 가장 영향력이 적다고 알려진 위치는?",
            "options": [
                "맨 앞 (Top)",
                "맨 뒤 (Bottom)",
                "중간 (Middle)",
                "따로 적은 주석",
                "제목 부분"
            ],
            "answer": "중간 (Middle)",
            "why": "긴 문맥에서 모델은 양쪽 끝 정보에 집중하며 중간 정보는 희석되는 경향이 있습니다 (Lost in the middle).",
            "hint": "가운데 낀 정보입니다.",
            "trap_points": [
                "중요한 지시는 맨 앞이나 맨 뒤에 재배치해야 함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트 작성 시 '모르는 것은 모른다고 해'라고 제약(Constraint)을 주면 줄어드는 현상은?",
            "options": [
                "Hallucination (환각)",
                "Inference Speed (추론 속도)",
                "Token Cost (비용)",
                "Response Length (길이)",
                "Formatting Error"
            ],
            "answer": "Hallucination (환각)",
            "why": "모델이 억지로 정답을 지어내려는 확률을 억제하여 사실 기반 답변을 유도합니다.",
            "hint": "없는 사실을 지어내는 현상을 막습니다.",
            "trap_points": [
                "과도하게 설정하면 지나치게 답변을 거부할 수 있음"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "LangChain에서 복잡한 프롬프트를 함수화하여 재사용 가능하게 만든 틀의 이름은?",
            "options": [
                "Code Block",
                "Prompt Template",
                "Script Layout",
                "Variable Set",
                "Schema Board"
            ],
            "answer": "Prompt Template",
            "why": "변수(입력값)만 갈아 끼우며 정해진 프롬프트 뼈대를 유지할 수 있게 해줍니다.",
            "hint": "프롬프트 템플릿입니다.",
            "trap_points": [
                "f-string 방식보다 구조적으로 안전하고 관리가 쉬움"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "short_answer",
            "question": "모델의 답변 결과물이 마음에 들지 않을 때, '다시 시도해봐'라고 하기 전 구체적인 수정 방향을 알려주는 행위를 무엇이라 하나요?",
            "answer": "Iterative Refinement (반복적 개선)",
            "why": "피드백을 통해 모델의 결과물을 점진적으로 다듬어 나가는 과정입니다.",
            "hint": "개선(Refinement)을 반복(Iterative)합니다.",
            "trap_points": [
                "한 번에 완벽한 프롬프트를 짜는 것보다 피드백 루프를 도는 게 더 효율적일 때가 많음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트 엔지니어링에서 'Delimiters'로 ###나 --- 같은 특수 기호를 쓰는 이유는?",
            "options": [
                "예쁘게 보여서",
                "모델이 지시 사항(Instruction)과 데이터(Data)의 경계를 명확히 구분하도록 돕기 위해",
                "영어로만 답하기 위해",
                "데이터를 압축하기 위해",
                "이미지 생성을 위해"
            ],
            "answer": "모델이 지시 사항(Instruction)과 데이터(Data)의 경계를 명확히 구분하도록 돕기 위해",
            "why": "경계가 모호하면 입력 데이터를 명령어로 착각하는 실수를 방지할 수 있습니다.",
            "hint": "구분자 역할을 합니다.",
            "trap_points": [
                "일관된 기호 사용이 중요함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "질문을 던지기 전 모델에게 '생각할 시간'을 주는 'Chain of Thought' 기법의 핵심 이점은?",
            "options": [
                "답변 속도가 빨라진다.",
                "중간 추론 단계(Rationale)를 명시적으로 거치면서 최종 정답의 논리적 오류가 줄어든다.",
                "비용이 절감된다.",
                "영어로만 답한다.",
                "글자 수가 짧아진다."
            ],
            "answer": "중간 추론 단계(Rationale)를 명시적으로 거치면서 최종 정답의 논리적 오류가 줄어든다.",
            "why": "어려운 문제를 한 번에 풀지 않고 단계별로 쪼개어 풀게 하여 실수를 방지합니다.",
            "hint": "생각의 사슬입니다.",
            "trap_points": [
                "추론 과정이 길어져서 토큰 소비는 늘어남"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트 내 예시(Few-shot)를 넣을 때 '대표성'이 중요한 이유는?",
            "options": [
                "모델이 지루하면 안 되니까",
                "대표성이 없는 예시는 모델이 엉뚱한 패턴을 일반화하여 오답을 내도록 유도할 수 있기 때문",
                "토큰을 아끼려고",
                "영어로만 답하려고",
                "이미지를 만들려고"
            ],
            "answer": "대표성이 없는 예시는 모델이 엉뚱한 패턴을 일반화하여 오답을 내도록 유도할 수 있기 때문",
            "why": "모델은 인컨텍스트 예시를 매우 강력한 '규칙'으로 여기기 때문입니다.",
            "hint": "예시의 품질이 결과의 품질입니다.",
            "trap_points": [
                "나쁜 예시는 안 주는 것보다 못 할 수도 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "short_answer",
            "question": "프롬프트 엔지니어링 도구 중 사용자의 질문을 가장 유사한 '과거 대화'나 '문서'와 결합해 주는 기술은?",
            "answer": "RAG (Retrieval-Augmented Generation)",
            "why": "검색된 정보를 프롬프트의 '문맥(Context)' 영역에 주입하는 가장 강력한 엔지니어링 기술입니다.",
            "hint": "알파벳 세 글자.",
            "trap_points": [
                "프롬프트에 들어가는 데이터의 '최신성'을 보장하는 핵심 기술임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG 파이프라인에서 텍스트 조각(Chunk)을 수치화된 좌표로 바꾸는 임베딩 모델의 역할은?",
            "options": [
                "글자 수를 센다.",
                "단어의 '의미'를 고차원 공간상의 위치(벡터)로 표현한다.",
                "영어로 번역한다.",
                "데이터를 삭제한다.",
                "파일 이름을 짓는다."
            ],
            "answer": "단어의 '의미'를 고차원 공간상의 위치(벡터)로 표현한다.",
            "why": "비슷한 의미를 가진 텍스트들이 가까운 위치에 있게 하여 검색이 가능하게 만듭니다.",
            "hint": "수치로 박아 넣다(Embed).",
            "trap_points": [
                "임베딩 성능이 RAG 검색 품질의 90%를 결정함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "벡터 DB에서 질문과 '가장 가까운 거리'의 문서를 찾는 기술의 이름은?",
            "options": [
                "Binary Search",
                "Hash View",
                "Similarity Search (유사도 검색)",
                "Sort Scan",
                "List Scan"
            ],
            "answer": "Similarity Search (유사도 검색)",
            "why": "철자가 아닌 '의미의 거리'가 가까운 것을 찾아내는 RAG의 핵심 기술입니다.",
            "hint": "비슷한 정도(Similarity)를 기준으로 찾습니다.",
            "trap_points": [
                "코사인 유사도나 유클리디안 거리 등이 계산 메트릭으로 쓰임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "에이전트가 어떤 문제를 풀기 위해 '인터넷 검색' 도구를 쓸지 '계산기' 도구를 쓸지 결정하는 단계를 무엇이라 하나요?",
            "options": [
                "Thinking",
                "Planning (계획)",
                "Acting",
                "Observing",
                "Reporting"
            ],
            "answer": "Planning (계획)",
            "why": "자신의 목표를 위해 필요한 수단(Tool)을 고르고 일정을 짜는 지능적 단계입니다.",
            "hint": "계획(Plan)을 세웁니다.",
            "trap_points": [
                "복잡한 에이전트는 하위 실행 계획까지 꼼꼼히 세움"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG에서 ‘검색된 문서’가 너무 많을 때 LLM에 넘길 5개만 정밀하게 재배열하는 과정은?",
            "options": [
                "Re-ranking (리랭킹)",
                "Re-scaling",
                "Re-merging",
                "Re-filtering",
                "Re-coding"
            ],
            "answer": "Re-ranking (리랭킹)",
            "why": "단순 벡터 거리보다 훨씬 정교한 모델로 실제 질문과의 연관성을 다시 채점하여 정확도를 높입니다.",
            "hint": "순위(Ranking)를 다시(Re) 매깁니다.",
            "trap_points": [
                "토큰 누수 배제와 답변 품질 향상의 핵심 공정임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "AI 에이전트 워크플로우인 'ReAct'의 의미는?",
            "options": [
                "React 프레임워크 사용",
                "Reasoning (추론)과 Acting (행동)의 결합",
                "빨리 반응하기",
                "다시 행동하기",
                "이미지 처리"
            ],
            "answer": "Reasoning (추론)과 Acting (행동)의 결합",
            "why": "생각(Thought)하고 행동(Action)하고 관찰(Observation)하는 루프를 통해 문제를 해결하는 프레임워크입니다.",
            "hint": "R-e와 A-c-t의 조합입니다.",
            "trap_points": [
                "에이전트 구현의 가장 기본적이고 강력한 패턴임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "short_answer",
            "question": "에이전트가 도구를 사용하여 얻운 중간 결과물(시스템 로그, 검색 결과 등)을 관찰하는 단계의 이름은?",
            "answer": "Observation (관찰)",
            "why": "행동(Action)에 대한 결과를 확인하고 다음 생각을 이어가기 위한 피드백 단계입니다.",
            "hint": "눈으로 보고 확인(Observe)합니다.",
            "trap_points": [
                "관찰 내용이 부실하면 에이전트가 잘못된 판단을 내림"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG 구축 시 한 문서를 ‘어떤 크기(500자, 1000자 등)’로 나눌지가 중요한 이유는?",
            "options": [
                "파일 이름을 지으려고",
                "너무 작으면 문맥이 끊기고, 너무 크면 주제가 섞여 검색 정확도가 떨어지기 때문",
                "영어로만 답하려고",
                "이미지를 만들려고",
                "비용을 늘리려고"
            ],
            "answer": "너무 작으면 문맥이 끊기고, 너무 크면 주제가 섞여 검색 정확도가 떨어지기 때문",
            "why": "RAG 검색의 해상도(Resolution)를 결정하는 핵심 하이퍼파라미터입니다.",
            "hint": "조각(Chunk)의 크기 조절입니다.",
            "trap_points": [
                "보통 문장이나 문단 단위로 겹치도록(Overlap) 나누는 것이 정석임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "벡터 DB에서 질문과 문서 간의 거리를 잴 때 가장 널리 쓰이는 수학적 공식은?",
            "options": [
                "덧셈",
                "뺄셈",
                "Cosine Similarity (코사인 유사도)",
                "피타고라스 정리",
                "미분"
            ],
            "answer": "Cosine Similarity (코사인 유사도)",
            "why": "벡터의 방향 일치도를 0에서 1 사이의 값으로 알려주어 텍스트 의미 비교에 최적입니다.",
            "hint": "코사인(Cosine)입니다.",
            "trap_points": [
                "두 벡터의 길이가 달라도 방향만 같으면 높은 점수가 나옴"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "에이전트가 겪은 실패를 교훈 삼아 다음 단계에서 같은 실수를 반복하지 않게 하는 능력을 무엇이라 비유하나요?",
            "options": [
                "아이큐",
                "성찰(Reflection) 파이프라인",
                "네트워킹",
                "백업",
                "암호화"
            ],
            "answer": "성찰(Reflection) 파이프라인",
            "why": "자신의 중간 답변을 평가(Critic)하고 수정하도록 유도하여 성공률을 높이는 기법입니다.",
            "hint": "거울을 보듯 자기를 돌아보는 과정입니다.",
            "trap_points": [
                "에이전틱 워크플로우의 고도화 단계임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "short_answer",
            "question": "사용자의 모호한 질문을 RAG 검색에 최적화된 형태로 LLM을 통해 다시 쓰는 기법은?",
            "answer": "Query Transformation (질문 변환)",
            "why": "'그게 뭐야' 같은 모호한 지칭을 '파이썬의 GIL이 뭐야' 처럼 구체화하여 검색 효율을 높입니다.",
            "hint": "질문(Query)을 변형(Transformation)합니다.",
            "trap_points": [
                "Multi-query나 HyDE 기법이 여기에 포함됨"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "LoRA 파인튜닝 시 전체 모델 파라미터를 건드리지 않고 일부만 학습시킴으로써 얻는 이득은?",
            "options": [
                "성능이 100배 좋아진다.",
                "GPU 메모리 사용량을 획기적으로 줄여 일반 컴퓨팅 환경에서도 학습이 가능해진다.",
                "영어로만 답한다.",
                "글자 수가 늘어난다.",
                "파일이 깨진다."
            ],
            "answer": "GPU 메모리 사용량을 획기적으로 줄여 일반 컴퓨팅 환경에서도 학습이 가능해진다.",
            "why": "가중치의 아주 일부(<1%)만 업데이트하여 효율을 극대화하는 방식입니다.",
            "hint": "비용과 하드웨어 효율성입니다.",
            "trap_points": [
                "최신 기업용 서드파티 엔진(vLLM 등)에서 LoRA 어댑터를 실시간으로 교체 가능함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝 학습 중 데이터셋의 답변 형식이 일정하지 않(예: JSON이었다가 텍스트였다가)을 때 발생하는 부작용은?",
            "options": [
                "모델이 화를 낸다.",
                "모델이 정해진 형식을 지키지 못하고 답변이 일관성을 잃게 된다.",
                "속도가 빨라진다.",
                "영어로만 답한다.",
                "비용이 줄어든다."
            ],
            "answer": "모델이 정해진 형식을 지키지 못하고 답변이 일관성을 잃게 된다.",
            "why": "모델은 데이터의 '형식적 패턴'도 학습하기 때문에, 오염된 형식 데이터는 결과 품질을 망칩니다.",
            "hint": "일관성(Consistency)의 상실입니다.",
            "trap_points": [
                "데이터 정제(Cleaning) 단계에서 형식을 통일하는 것이 필수임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝 시 모델의 '안전(Safety)'을 위해 부적절한 답변을 거부하도록 훈련하는 기법은?",
            "options": [
                "Safety Alignment (안전 정렬)",
                "Speed Alignment",
                "Color Alignment",
                "File Alignment",
                "Random Alignment"
            ],
            "answer": "Safety Alignment (안전 정렬)",
            "why": "인간의 윤리적 기준에 맞춰 범죄나 차별적 발언을 하지 않도록 모델을 길들이는 과정입니다.",
            "hint": "안전(Safety)을 위한 조율입니다.",
            "trap_points": [
                "RLHF 단계에서 주로 수행됨"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝 시 'Overfitting'을 방지하기 위한 기술 중 하나로, 학습 데이터의 일부를 따로 떼어 '실력 검증'용으로만 쓰는 것은?",
            "options": [
                "Train set",
                "Test set",
                "Validation set (검증셋)",
                "Label set",
                "Index set"
            ],
            "answer": "Validation set (검증셋)",
            "why": "학습에 직접 쓰지 않고 중간중간 평가해봄으로써 모델이 암기 중인지 이해 중인지 확인합니다.",
            "hint": "검증(Validation)용 데이터입니다.",
            "trap_points": [
                "검증 손실이 올라가기 시작하면 학습을 멈춰야 함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "short_answer",
            "question": "파인튜닝할 때 베이스 모델의 능력을 보존하면서 특정 지식만 덧씌울 수 있도록, 고정된 모델 가중치에 덧붙여지는 조각을 무엇이라 하나요?",
            "answer": "Adapter (어댑터)",
            "why": "LoRA 등에서 생성되어 기존 가중치에 병합(Merge)하거나 덧붙여 사용하는 작은 행렬입니다.",
            "hint": "연결 도구(Adapter)를 생각하세요.",
            "trap_points": [
                "이 어댑터 파일만 공유하면 누구나 똑같은 성능을 낼 수 있음"
            ],
            "difficulty": "medium"
        }
    ]
}