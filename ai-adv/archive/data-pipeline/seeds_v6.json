{
    "questions": [
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 두 리스트의 요소를 짝지어 묶어주는 zip() 함수의 반환 객체 타입은?",
            "options": [
                "List",
                "Tuple",
                "Dictionary",
                "Zip object (Iterator)",
                "Array"
            ],
            "answer": "Zip object (Iterator)",
            "why": "zip()은 이터레이터를 반환하며, 실제 리스트로 확인하려면 list(zip(...))과 같이 변환이 필요합니다.",
            "hint": "메모리 효율을 위해 바로 리스트를 만들지 않고 '반복자'를 반환합니다.",
            "trap_points": [
                "반환값이 바로 리스트라고 생각하면 오답임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "다음 중 파일의 모든 내용을 문자열 하나로 읽어오는 메서드는?",
            "options": [
                "f.read()",
                "f.readline()",
                "f.readlines()",
                "f.get_all()",
                "f.fetch()"
            ],
            "answer": "f.read()",
            "why": "read()는 파일 전체 내용을 하나의 문자열로, readlines()는 각 줄을 리스트로 읽어옵니다.",
            "hint": "가장 기본적인 읽기 메서드입니다.",
            "trap_points": [
                "readline()은 한 줄씩만 읽어옴"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬에서 'None'을 확인하기 위해 가장 권장되는 비교 연산자는?",
            "options": [
                "==",
                "!=",
                "is",
                "is not None",
                "in"
            ],
            "answer": "is",
            "why": "None은 싱글턴 객체이므로 값의 동등성(==)보다 객체 동일성(is)을 검사하는 것이 관례이며 안전합니다.",
            "hint": "객체 자체가 동일한지 묻는 키워드입니다.",
            "trap_points": [
                "== None도 작동은 하지만 PEP8에서는 is None을 권장함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "인스턴스 생성 없이 클래스 이름을 통해 바로 호출하며 클래스 상태를 수정하지 않는 메서드 타입은?",
            "options": [
                "Instance method",
                "Class method",
                "Static method",
                "Abstract method",
                "Virtual method"
            ],
            "answer": "Static method",
            "why": "static method는 클래스(@staticmethod)에 속해 있지만 인스턴스나 클래스 인자를 받지 않는 단순 유틸리티용 메서드입니다.",
            "hint": "정적인(Static) 성격의 메서드입니다.",
            "trap_points": [
                "@classmethod는 cls 인자를 받아 클래스 상태에 접근 가능함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬 자료구조 중 내부 데이터가 순서대로 유지되지 않으며 유일한 값만 저장하는 것은?",
            "options": [
                "List",
                "Tuple",
                "Set",
                "Dictionary",
                "Deque"
            ],
            "answer": "Set",
            "why": "셋(Set)은 요소의 순서를 무시하고 중복을 제거하여 저장하는 해시 기반 자료구조입니다.",
            "hint": "수학의 집합과 같습니다.",
            "trap_points": [
                "최근 파이썬의 딕셔너리는 삽입 순서를 유지하지만 셋은 그렇지 않음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "short_answer",
            "question": "파이썬에서 모듈을 불러올 때 사용하는 키워드는?",
            "answer": "import",
            "why": "다른 .py 파일이나 라이브러리의 기능을 현재 파일로 가져올 때 사용합니다.",
            "hint": "수입하다라는 뜻의 영어 단어입니다.",
            "trap_points": [
                "from ... import ... 형식을 쓰면 특정 기능만 가져올 수 있음"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬의 'lambda' 함수에 대한 설명으로 옳은 것은?",
            "options": [
                "여러 줄의 복잡한 로직을 작성할 수 있다.",
                "이름이 없는 한 줄짜리 익명 함수이다.",
                "반드시 return 키워드를 써야 한다.",
                "클래스 내부에서만 정의할 수 있다.",
                "재귀 호출이 불가능하다."
            ],
            "answer": "이름이 없는 한 줄짜리 익명 함수이다.",
            "why": "람다는 이름 없이 식(Expression) 형태로 간단한 연산을 수행하는 함수를 만들 때 씁니다.",
            "hint": "익명을 뜻하는 그리스어 문자를 생각하세요.",
            "trap_points": [
                "복잡한 로직은 def로 정의하는 것이 가독성에 좋음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "파이썬 내장함수 중 모든 요소가 참(True)인지 검사하는 함수는?",
            "options": [
                "any()",
                "all()",
                "every()",
                "check()",
                "sum()"
            ],
            "answer": "all()",
            "why": "all()은 모든 요소가 Truthy할 때만 True를 반환합니다.",
            "hint": "모두를 뜻하는 단어입니다.",
            "trap_points": [
                "any()는 하나라도 참이면 True를 반환함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Python 기초",
            "type": "multiple_choice",
            "question": "문자열을 특정 구분자를 기준으로 리스트로 나누는 메서드는?",
            "options": [
                "join()",
                "split()",
                "partition()",
                "divide()",
                "cut()"
            ],
            "answer": "split()",
            "why": "split()은 공백이나 지정된 문자를 기준으로 문자열을 잘라 리스트로 만듭니다.",
            "hint": "쪼개다라는 뜻입니다.",
            "trap_points": [
                "join()은 리스트를 문자열로 합치는 반대 기능임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "Python 기초",
            "type": "short_answer",
            "question": "파이썬에서 객체의 메모리 주소가 동일한지(동일성) 비교하는 연산자는?",
            "answer": "is",
            "why": "is 연산자는 두 객체가 실제로 메모리상에서 같은 위치를 점유하고 있는지 확인합니다.",
            "hint": "~이다라는 뜻의 영어 단어입니다.",
            "trap_points": [
                "==는 값이 같은지(동등성)를 비교함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas에서 데이터프레임의 특정 열을 인덱스로 설정하는 메서드는?",
            "options": [
                "reset_index()",
                "set_index()",
                "make_index()",
                "update_index()",
                "reindex()"
            ],
            "answer": "set_index()",
            "why": "set_index()는 기존의 일반 열 중 하나를 행의 이름(인덱스)으로 변환합니다.",
            "hint": "인덱스를 '설정'한다.",
            "trap_points": [
                "reset_index()는 인덱스를 다시 일반 열로 보냄"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Numpy에서 행렬 연산이 아닌 요소별(Element-wise) 곱셈을 수행하는 연산자는?",
            "options": [
                "@",
                "dot()",
                "*",
                "matmul()",
                "multiply_all()"
            ],
            "answer": "*",
            "why": "Numpy 배열에 * 연산자를 쓰면 같은 위치의 요소끼리 곱해지며, 행렬곱은 @를 써야 합니다.",
            "hint": "기본 곱셈 기호입니다.",
            "trap_points": [
                "이것이 데이터 분석에서 가장 흔한 실수 포인트 중 하나임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "정규표현식에서 '어떤 문자든 한 글자'를 나타내는 기호는?",
            "options": [
                "*",
                "?",
                ".",
                "+",
                "$"
            ],
            "answer": ".",
            "why": "점(.) 기호는 줄바꿈을 제외한 임의의 문자 하나와 매칭됩니다.",
            "hint": "마침표를 생각하세요.",
            "trap_points": [
                "실제 점 문자 자체를 찾으려면 \\. 으로 써야 함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas 데이터프레임의 정보를 요약해서 보여주는 `df.info()`에서 알 수 없는 정보는?",
            "options": [
                "전체 행/열 개수",
                "열 이름",
                "각 열의 데이터 타입",
                "각 열의 평균값",
                "결측치가 아닌 값의 개수"
            ],
            "answer": "각 열의 평균값",
            "why": "평균값 같은 통계량은 describe()에서 보여주며, info()는 구조적 정보를 보여줍니다.",
            "hint": "데이터의 '형태(Type)'에 집중하세요.",
            "trap_points": [
                "info()는 메모리 사용량도 보여줌"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Numpy에서 0부터 9까지의 숫자를 담은 배열을 만드는 가장 간단한 코드는?",
            "options": [
                "np.array(0, 10)",
                "np.range(10)",
                "np.arange(10)",
                "np.linspace(0, 9, 10)",
                "np.zeros(10)"
            ],
            "answer": "np.arange(10)",
            "why": "arange()는 파이썬의 range()와 유사하게 시퀀스 배열을 생성합니다.",
            "hint": "배열(a) + 범위(range)의 합성어입니다.",
            "trap_points": [
                "파이썬 내장 range()를 np.array()로 감싸도 되지만 arange가 더 직접적임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "short_answer",
            "question": "Pandas에서 시계렬 데이터의 연도 정보만 추출하기 위해 사용하는 속성은?",
            "answer": ".dt.year",
            "why": "시계렬 열에 .dt 접근자를 쓰면 연, 월, 일, 요일 등을 쉽게 추출 가능합니다.",
            "hint": "datetime의 약자와 year의 조합입니다.",
            "trap_points": [
                "열 자체가 datetime 타입이어야 사용 가능함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "정규표현식에서 문자의 시작(^)과 대비되어 '문자열의 끝'을 나타내는 기호는?",
            "options": [
                "#",
                "$",
                "&",
                "!",
                "%"
            ],
            "answer": "$",
            "why": "$ 기호는 패턴이 문자열의 맨 마지막에 위치해야 함을 명시합니다.",
            "hint": "달러 기호입니다.",
            "trap_points": [
                "문서 전체의 끝과 행의 끝 처리가 라이브러리 설정마다 다를 수 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "텍스트 수치화 기법 중 단어 간의 유의미한 관계(예: 왕 - 남자 = 여왕 - 여자)를 잘 보존하는 기법은?",
            "options": [
                "One-hot Encoding",
                "TF-IDF",
                "Word Embedding (예: Word2Vec)",
                "Bag of Words",
                "N-gram"
            ],
            "answer": "Word Embedding (예: Word2Vec)",
            "why": "워드 임베딩은 고차원 공간상에서 단어의 의미적 관계를 벡터 연산이 가능하도록 학습합니다.",
            "hint": "사전적 정의보다 문맥적 의미를 숫자로 표현하는 기술입니다.",
            "trap_points": [
                "TF-IDF는 단순 빈도 기반이라 이런 연산이 불가능함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "multiple_choice",
            "question": "Pandas에서 행과 열을 뒤바꾸는 피벗 테이블을 생성할 때 사용하는 메서드는?",
            "options": [
                "df.swap()",
                "df.pivot()",
                "df.reverse()",
                "df.flip()",
                "df.transpose()"
            ],
            "answer": "df.pivot()",
            "why": "pivot()은 특정 열을 인덱스로, 다른 열을 컬럼으로 재구조화합니다.",
            "hint": "회전축을 뜻하는 단어입니다.",
            "trap_points": [
                "집계 함수까지 쓰려면 pivot_table()을 권장함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "데이터 분석",
            "type": "short_answer",
            "question": "Numpy 배열의 모든 요소의 평균을 구하는 메서드는?",
            "answer": "mean()",
            "why": "mean() 메서드나 np.mean() 함수는 전체 또는 축별 평균을 계산합니다.",
            "hint": "평균을 뜻하는 영어 단어입니다.",
            "trap_points": [
                "매개변수 axis를 주면 행별/열별 평균도 가능함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "트랜스포머 아키텍처에서 여러 개의 어텐션 헤드를 병렬로 사용하는 이유는?",
            "options": [
                "메모리를 아끼기 위해",
                "동시에 여러 관점(문법, 의미, 거리 등)으로 문장을 분석하기 위해",
                "그냥 속도를 높이기 위해 (성능과 무관)",
                "이미지 처리를 위해",
                "답변 길이를 늘리기 위해"
            ],
            "answer": "동시에 여러 관점(문법, 의미, 거리 등)으로 문장을 분석하기 위해",
            "why": "멀티 헤드 어텐션을 통해 모델은 문장의 다각도적 의미를 포착하여 더 풍부한 맥락을 이해합니다.",
            "hint": "머리가 여러 개(Multi-Head)면 여러 생각을 할 수 있겠죠?",
            "trap_points": [
                "헤드 개수가 많을수록 연산량도 늘어남"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "지식을 저장하는 모델의 '파라미터'와 RAG를 통한 '외부 검색'의 조화를 설명하는 비유로 가장 적절한 것은?",
            "options": [
                "지식은 요리사이고 RAG은 레시피이다.",
                "지식은 뇌 속의 상식이고 RAG은 도서관 책이다.",
                "둘은 똑같은 기능을 한다.",
                "지식은 자동차이고 RAG은 기름이다.",
                "지식은 하드웨어이고 RAG은 소프트웨어이다."
            ],
            "answer": "지식은 뇌 속의 상식이고 RAG은 도서관 책이다.",
            "why": "파라미터는 모델이 학습을 통해 내면화한 지식이며, RAG은 필요할 때 외부에서 찾아오는 실시간 정보입니다.",
            "hint": "내재된 능력과 외부 도구의 조화를 생각하세요.",
            "trap_points": [
                "시험 후기에서 'RAG가 해결하고자 하는 LLM의 한계'라는 맥락으로 출제됨"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "LLM이 생성 중 다음에 올 가장 높은 확률의 토큰을 고르는 대신, 상위 K개의 토큰 중 랜덤하게 고르는 기법은?",
            "options": [
                "Top-K Sampling",
                "Greedy Search",
                "Softmax",
                "Beam Search",
                "Normalization"
            ],
            "answer": "Top-K Sampling",
            "why": "Top-K는 후보군을 제한하여 답변의 무작위성을 통제하면서도 어느 정도의 창의성을 확보합니다.",
            "hint": "가장 높은(Top) 순위 K를 선정합니다.",
            "trap_points": [
                "Greedy Search는 무조건 확률 1위만 고름 (지루한 답변 가능성)"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "모델의 학습 데이터에 포함되지 않은 '전혀 새로운 지식'을 물었을 때, 모델이 그럴싸하게 거짓말을 하는 이유는?",
            "options": [
                "사용자를 골탕 먹이려고",
                "모델은 '다음 단어를 맞히는 확률 모델'이지 '사실 확인 엔진'이 아니기 때문에",
                "하드웨어 오류 때문에",
                "인터넷이 끊겨서",
                "데이터가 너무 많아서"
            ],
            "answer": "모델은 '다음 단어를 맞히는 확률 모델'이지 '사실 확인 엔진'이 아니기 때문에",
            "why": "모델은 문장의 자연스러운 흐름을 최우선으로 생성하므로 데이터 공백 영역에서 할루시네이션이 발생합니다.",
            "hint": "모델의 본질인 '확률적 생성'에 집중하세요.",
            "trap_points": [
                "이 현상을 인격적으로 해석하지 않도록 주의해야 함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "마이크로소프트의 'Phi' 모델처럼 크기는 작지만 성능이 뛰어난 모델을 한데 묶어 부르는 용어는?",
            "options": [
                "LLM",
                "sLLM (Small Language Model)",
                "Transformer",
                "Agent",
                "Plugin"
            ],
            "answer": "sLLM (Small Language Model)",
            "why": "작은(Small) 크기로 특정 태스크나 효율적 기기 구동에 최적화된 모델들입니다.",
            "hint": "L 대신 S가 붙습니다.",
            "trap_points": [
                "합성 데이터(Synthetic Data)를 통해 효율을 극대화함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "short_answer",
            "question": "LLM에서 텍스트를 숫자의 나열인 벡터로 바꾸는 과정을 무엇이라 하나요?",
            "answer": "Embedding (임베딩)",
            "why": "단어나 문장의 의미를 수치화하여 컴퓨터가 연산할 수 있게 만드는 기초 기술입니다.",
            "hint": "E로 시작하는 단어입니다.",
            "trap_points": [
                "임베딩 공간 상의 거리가 가까울수록 의미가 유사함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "트랜스포머 설계 시 문장이 아무리 길어져도 단어 간의 거리에 상관없이 관계를 한꺼번에 볼 수 있게 해준 메커니즘은?",
            "options": [
                "Pooling",
                "Convolution",
                "Attention (어텐션)",
                "Relu",
                "Dropout"
            ],
            "answer": "Attention (어텐션)",
            "why": "어텐션은 문장 내의 모든 페어(Pair)를 동시에 연산하여 RNN의 고질적인 '장기 의존성 무시' 문제를 해결했습니다.",
            "hint": "주의, 집중이라는 뜻입니다.",
            "trap_points": [
                "논문 'Attention is all you need'를 기억하세요"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "LLM에서 답변을 생성하기 위해 입력받는 텍스트 덩어리를 흔히 부르는 명칭은?",
            "options": [
                "Command",
                "Query",
                "Prompt (프롬프트)",
                "Note",
                "Code"
            ],
            "answer": "Prompt (프롬프트)",
            "why": "사용자가 모델에게 내리는 지시와 정보를 담은 입력을 프롬프트라고 합니다.",
            "hint": "지체 없이라는 형용사 뜻도 있습니다.",
            "trap_points": [
                "이 입력을 설계하는 것이 프롬프트 엔지니어링임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "multiple_choice",
            "question": "모델의 파라미터를 그대로 둔 채, 프롬프트 내용만으로 새로운 지식을 배우게 하는 효과를 무엇이라 하나요?",
            "options": [
                "Fine-tuning",
                "In-Context Learning",
                "Pre-training",
                "Backpropagation",
                "Weight Decant"
            ],
            "answer": "In-Context Learning",
            "why": "가중치를 바꾸지 않고도 현재 주어진 문맥(Context) 속에서 패턴을 파악하여 수행하는 능력입니다.",
            "hint": "맥락(Context) 안에서(In) 배운다.",
            "trap_points": [
                "Few-shot 예시를 통해 이 능력을 극대화함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "LLM 기본",
            "type": "short_answer",
            "question": "단어와 숫자 사이의 단위로, 모델이 이해하는 가장 작은 언어 입력 단위를 무엇이라 하나요?",
            "answer": "Token (토큰)",
            "why": "최신 모델들은 단어를 더 작게 쪼갠 토큰 단위로 세상을 이해하고 비용을 계산합니다.",
            "hint": "토박이말이 아닌 외래어 그대로 씁니다.",
            "trap_points": [
                "한글은 영어보다 토큰이 더 많이 소모되는 경향이 있음"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트의 4요소 중 '해결에 필요한 배경 지식이나 주변 상황'을 뜻하는 것은?",
            "options": [
                "Persona",
                "Task",
                "Context",
                "Format"
            ],
            "answer": "Context",
            "why": "컨텍스트는 작업의 품질을 높이기 위해 모델에게 전달하는 부가 정보입니다.",
            "hint": "문맥, 배경이라는 뜻입니다.",
            "trap_points": [
                "최근 프롬프트 엔지니어링의 핵심은 'Context Engineering'이라고도 함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "LangChain에서 프롬프트 템플릿의 변수 값을 실제 데이터로 채워 넣는 메서드는?",
            "options": [
                "fill()",
                "format()",
                "inject()",
                "render()",
                "invoke()"
            ],
            "answer": "format()",
            "why": "template.format(name='...') 처럼 사용하여 완성된 문자열을 얻습니다.",
            "hint": "형식을 갖춘다는 뜻의 메서드입니다.",
            "trap_points": [
                "LCEL 환경에서는 invoke()를 통해 체인 흐름 안에서 자동 처리됨"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "모델이 질문을 받았을 때 바로 답하지 않고, '가상의 페르소나들'을 여럿 만들어 토론하게 한 뒤 정답을 고르는 고도화 기법은?",
            "options": [
                "CoT",
                "Self-Consistency",
                "Selection-Inference",
                "Multi-Persona Prompting",
                "Zero-shot"
            ],
            "answer": "Multi-Persona Prompting",
            "why": "다양한 관점을 가진 페르소나를 모델 내부에서 시뮬레이션하여 정답의 객관성을 높이는 전략입니다.",
            "hint": "여러 명의 인격(Persona)을 활용합니다.",
            "trap_points": [
                "토큰 사용량이 많지만 높은 논리적 완성도를 보여줌"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트에 '출력물 마지막에는 반드시 요약을 넣어라'처럼 행동의 제약을 거는 것을 무엇이라 하나요?",
            "options": [
                "Instruction",
                "Constraint (제약조건)",
                "Format",
                "Context",
                "Input"
            ],
            "answer": "Constraint (제약조건)",
            "why": "행동의 범위를 한정 지어 원하는 결과의 일관성을 확보하는 기법입니다.",
            "hint": "억제, 구속이라는 영어 단어입니다.",
            "trap_points": [
                "제약이 너무 많으면 모델의 창의성이 줄어들 수 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트 내에 델리미터(구분자)로 '---' 대신 'xml 태그(<...> </...>)'를 사용할 때 얻는 이점은?",
            "options": [
                "모델이 XML 파서이기 때문에",
                "각 구역의 시작과 끝이 명확하여 복잡한 컨텍스트 내에서도 지시 영역을 헷갈리지 않기 때문",
                "글자 수가 적어서",
                "그냥 보기 좋아서",
                "모델이 인터넷 언어라 좋아해서"
            ],
            "answer": "각 구역의 시작과 끝이 명확하여 복잡한 컨텍스트 내에서도 지시 영역을 헷갈리지 않기 때문",
            "why": "특히 앤스로픽(Claude) 모델 등 최신 LLM은 XML 구조화된 프롬프트를 매우 정확하게 해석합니다.",
            "hint": "컴퓨터가 읽기 좋은 명확한 경계선을 생각하세요.",
            "trap_points": [
                "가장 권장되는 고급 프롬프트 구조화 방식임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "short_answer",
            "question": "모델에게 답을 유도하기 위해 프롬프트 마지막에 '자, 이제 시작하세요:' 처럼 마중물을 넣어주는 기법은?",
            "answer": "Completion Prompting (또는 프리필 Pre-fill)",
            "why": "모델이 정해진 답변 형식을 바로 시작하도록 앞머리를 먼저 떼주는 방식입니다.",
            "hint": "미리 채워둔다는 뜻입니다.",
            "trap_points": [
                "JSON 출력 유도 시 '{' 를 미리 적어주는 것도 여기에 해당함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "LangChain의 LCEL 사용 시 코드 가독성이 올라가는 주된 이유는?",
            "options": [
                "언어가 한글이라서",
                "파이프(|) 기호를 통해 데이터 흐름을 직관적(선언적)으로 표현할 수 있어서",
                "함수 이름이 짧아서",
                "자동으로 오타를 고쳐줘서",
                "코드를 안 써도 돼서"
            ],
            "answer": "파이프(|) 기호를 통해 데이터 흐름을 직관적(선언적)으로 표현할 수 있어서",
            "why": "복잡한 콜백이나 중첩 함수 호출 없이 단계별 파이프라인으로 체인을 구성할 수 있습니다.",
            "hint": "유닉스 쉘의 '파이프라인' 개념을 떠올리세요.",
            "trap_points": [
                "| 연산자가 내부적으로 오버로딩되어 동작함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "질문에 대해 '반대의 상황이나 부정적인 사례'를 먼저 떠올리게 한 뒤 정답을 유도하는 기법은?",
            "options": [
                "Negative Prompting",
                "Contrastive Prompting",
                "Positive Thinking",
                "Reverse Thinking",
                "Self-correction"
            ],
            "answer": "Contrastive Prompting",
            "why": "정답과 오답의 차이를 명확히 인지하게 하여 답변의 변별력을 높이는 기술입니다.",
            "hint": "대조적인이라는 뜻의 단어입니다.",
            "trap_points": [
                "모델의 비판적 사고 능력을 활용하는 방식임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "short_answer",
            "question": "사용자의 질문을 다른 언어(영어 등)로 번역하여 최상의 답변을 얻은 뒤 다시 돌려주는 고급 체인 전략은?",
            "answer": "Translation Chain (또는 영문-한문 브릿지)",
            "why": "한국어 데이터가 부족한 도메인에서 모델의 영어 논리력을 빌려와서 성능을 극대화합니다.",
            "hint": "번역을 거치는 과정입니다.",
            "trap_points": [
                "총 3단계(번역-처리-재번역)가 소요되어 속도는 다소 느려짐"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "프롬프트 엔지니어링",
            "type": "multiple_choice",
            "question": "프롬프트 엔지니어링 시 지시를 '구체적인 계단식(Steps)'으로 나누어 주는 것이 좋은 이유는?",
            "options": [
                "모델이 계단을 좋아해서",
                "복잡한 미션을 한꺼번에 처리할 때의 혼동을 막고 단계별 완성도를 높이기 위해",
                "토큰 비용을 아끼기 위해",
                "답변의 미적 감각을 높이기 위해",
                "그냥 관례적으로 그렇게 한다."
            ],
            "answer": "복잡한 미션을 한꺼번에 처리할 때의 혼동을 막고 단계별 완성도를 높이기 위해",
            "why": "작업을 세분화하면 각 단계의 입력과 출력이 명확해져서 할루시네이션 위험이 줄어듭니다.",
            "hint": "분할 정복(Divide and Conquer)의 원리입니다.",
            "trap_points": [
                "프롬프트 체이닝과 유사한 철학을 가짐"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG의 5단계 중 검색된 내용을 바탕으로 실제 답변을 '출력'하는 마지막 단계는?",
            "options": [
                "Indexing",
                "Searching",
                "Augmenting",
                "Generating",
                "Processing"
            ],
            "answer": "Generating",
            "why": "생성(Generating) 단계에서 LLM은 주어진 컨텍스트를 소화하여 최종 답변을 생성합니다.",
            "hint": "생성하다라는 뜻입니다.",
            "trap_points": [
                "RAG의 최종 마침표를 찍는 단계임"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "벡터 DB에서 질문과 가장 가까운 상위 N개의 조각을 찾아오는 과정을 무엇이라 하나요?",
            "options": [
                "Pulling",
                "Top-K Retrieval",
                "Indexing",
                "Scanning",
                "Parsing"
            ],
            "answer": "Top-K Retrieval",
            "why": "유사도 점수가 가장 높은 K개의 문서를 찾아오는 검색의 기본 과정입니다.",
            "hint": "가장 높은(Top) 순위 K개를 검색함.",
            "trap_points": [
                "최근에는 K를 무조건 크게 잡기보다 품질(Threshold)로 거르기도 함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG 환경에서 답변의 근거를 명시하여 사용자가 직접 원문을 확인할 수 있게 하는 기술은?",
            "options": [
                "Citation (인용)",
                "Shadowing",
                "Masking",
                "Encoding",
                "Mirroring"
            ],
            "answer": "Citation (인용)",
            "why": "답변 중 특정 부분에 [1] 과 같은 표시를 남겨 신뢰도를 높이는 필수적인 UI/UX 요소입니다.",
            "hint": "논문 등에서 출처를 밝히는 것을 무엇이라 하나요?",
            "trap_points": [
                "할루시네이션 방지에 매우 효과적임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG 파이프라인에서 청크 사이즈를 결정할 때, 일반적인 웹 게시물이나 뉴스 기사에 권장되는 초기 설정값(토큰 기준)은?",
            "options": [
                "10 ~ 20 토큰",
                "100 ~ 500 토큰",
                "5000 ~ 10000 토큰",
                "1개 이상의 전체 문서",
                "글자 수 기반 1자"
            ],
            "answer": "100 ~ 500 토큰",
            "why": "너무 작으면 맥락이 없고, 너무 크면 주제가 섞입니다. 500 토큰 내외가 정보의 완결성과 검색 정밀도의 균형이 좋습니다.",
            "hint": "모니터상 대략 대여섯 줄 정도의 분량입니다.",
            "trap_points": [
                "오버랩(Overlap)도 함께 고려해야 완벽해짐"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "short_answer",
            "question": "벡터 DB에 저장하기 전, 긴 문서를 의미 있는 작은 조각으로 나누는 행위를 무엇이라 하나요?",
            "answer": "Chunking (청킹)",
            "why": "모델의 입력 한계와 검색 정밀도를 위해 데이터를 적절한 크기로 분할하는 필수 전처리 과정입니다.",
            "hint": "한 입 크기의 덩어리라는 영어 단어입니다.",
            "trap_points": [
                "의미가 끊기지 않도록 문장이나 단락 단위로 자르는 것이 좋음"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "사용자의 질문 하나로 충분한 정보가 검색되지 않을 때, 질문을 여러 개로 변주하여 검색 확률을 높이는 것은?",
            "options": [
                "Multi-querying",
                "Single-searching",
                "Static-fetching",
                "Binary-matching",
                "Sequential-reading"
            ],
            "answer": "Multi-querying",
            "why": "질문을 다양하게 변형하여 검색 엔진의 사각지대를 없애는 고급 리트리버 전략입니다.",
            "hint": "여러 개(Multi)의 쿼리(Query)입니다.",
            "trap_points": [
                "LangChain에서 MultiQueryRetriever로 쉽게 구현 가능함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "에이전트 구현 시 '메모리'를 관리할 때 대화의 양이 너무 많아지면 어떻게 처리하는 것이 가장 효율적인가요?",
            "options": [
                "그냥 다 보낸다 (비용 상관없음)",
                "과거 내용을 요약하여 전달하거나, 핵심 사실만 추출해 따로 저장한다.",
                "과거를 아예 다 지운다.",
                "영어로만 저장한다.",
                "사용자에게 요약해달라고 시킨다."
            ],
            "answer": "과거 내용을 요약하여 전달하거나, 핵심 사실만 추출해 따로 저장한다.",
            "why": "컨텍스트 윈도우 한계가 있으므로 요약(Summary)이나 벡터 기반 메모리 관리가 필수적입니다.",
            "hint": "줄여서 간직하기(Summarization)를 생각하세요.",
            "trap_points": [
                "중요한 고유 명사가 요약 과정에서 사라지지 않도록 주의해야 함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "벡터 DB에서 두 벡터가 '완전히 같은 방향'일 때 코사인 유사도 값은?",
            "options": [
                "0",
                "-1",
                "1",
                "100",
                "무한대"
            ],
            "answer": "1",
            "why": "코사인 유사도는 1일 때 최대이며(완전 일치), 0은 무관, -1은 정반대를 뜻합니다.",
            "hint": "최댓값은 얼마일까요?",
            "trap_points": [
                "유사도와 거리(Distance)는 반대 개념임에 항상 주의"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "short_answer",
            "question": "AI 에이전트가 외부 웹 검색이나 계산기 등을 사용할 수 있도록 연결된 인터페이스를 보통 무엇이라 부르나요?",
            "answer": "Tool (또는 Function)",
            "why": "에이전트가 텍스트 생성을 넘어 실제 행동을 취하게 해주는 팔과 다리 같은 존재입니다.",
            "hint": "도구라는 뜻입니다.",
            "trap_points": [
                "모델은 이 기능의 '이름과 사용법'만 알고 필요시 호출을 요청함"
            ],
            "difficulty": "easy"
        },
        {
            "chapter_name": "RAG & Agent",
            "type": "multiple_choice",
            "question": "RAG 시스템 성능 개선을 위해 검색된 문서 30개를 가져온 뒤, 가장 정답 확률이 높은 5개만 다시 골라내는 모델 타입은?",
            "options": [
                "Bi-Encoder",
                "Cross-Encoder (리랭커)",
                "Decoder",
                "CNN",
                "Tokenizer"
            ],
            "answer": "Cross-Encoder (리랭커)",
            "why": "느리지만 훨씬 강력한 모델을 사용하여 질문과 문서의 상관관계를 심층 분석해 순위를 재배열합니다.",
            "hint": "두 입력을 교차(Cross)해서 보는 인코더입니다.",
            "trap_points": [
                "대규모 검색에는 부적합하지만 소수 정예 선별에는 탁월함"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "모델의 지능 자체를 높이기보다 '특정한 말투나 업무 포맷(예: 마크다운 보고서 형식)'을 우선적으로 각인시키기 위해 하는 튜닝은?",
            "options": [
                "Pre-training",
                "Style/Instruction Fine-tuning",
                "Quantization",
                "Normalization",
                "Distillation"
            ],
            "answer": "Style/Instruction Fine-tuning",
            "why": "SFT를 통해 답변의 외형적 피처(Feature)를 사용자의 입맛에 맞게 고정합니다.",
            "hint": "스타일과 형식에 집중하는 튜닝입니다.",
            "trap_points": [
                "지식 주입보다 '행동 교정'에 더 큰 효과가 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "DPO 파인튜닝 시 필요한 데이터의 가장 기본적인 최소 단위(Row) 구성은?",
            "options": [
                "질문 하나와 답변 하나",
                "질문 하나와 (좋은 답변, 나쁜 답변) 한 쌍",
                "문서 덩어리 하나",
                "단어 리스트",
                "유저 평점"
            ],
            "answer": "질문 하나와 (좋은 답변, 나쁜 답변) 한 쌍",
            "why": "DPO는 두 가지 답변 중 어느 것을 더 선호하는지 직접 비교하며 확률 분포를 조정하기 때문입니다.",
            "hint": "선호도(Preference)를 알려주기 위해 필요한 최소 비교 대상 수는?",
            "trap_points": [
                "좋은 것만 가르치는 SFT보다 오답의 확률을 직접 낮출 수 있어 강력함"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "추론 모델(DeepSeek R1 등) 학습 시, '풀이 과정이 틀려도 최종 정답만 맞으면 보상을 주는' 강화학습 방식이 가능한 이유는?",
            "options": [
                "모델이 천재라서",
                "정답이 명확한(수학, 코딩 등) 문제의 경우 Rule-based로 자동 검증이 가능하기 때문",
                "사람이 24시간 감시해서",
                "데이터가 윈도우 기반이라서",
                "모델이 스스로 정답을 알기 때문"
            ],
            "answer": "정답이 명확한(수학, 코딩 등) 문제의 경우 Rule-based로 자동 검증이 가능하기 때문",
            "why": "검증 가능한 보상(Verifiable Reward)이 있으면 보상 모델의 주관성 없이도 강력하게 모델을 몰아붙일 수 있습니다.",
            "hint": "채점하기 쉬운 과목(수학/코딩)을 생각하세요.",
            "trap_points": [
                "인문학적 질문에는 이 방식을 적용하기 어려움"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝된 모델을 배포할 때, 메모리 용량을 줄이면서도 성능 저하를 최소화하기 위해 '중요한 파라미터는 덜 자르고 안 중요한 것만 많이 자르는' 방식은?",
            "options": [
                "Uniform Quantization",
                "Importance-based Quantization (예: GPTQ, AWQ)",
                "Linear Pruning",
                "Dropout",
                "Early Stopping"
            ],
            "answer": "Importance-based Quantization (예: GPTQ, AWQ)",
            "why": "각 파라미터의 레이어별 중요도를 고려하여 전략적으로 양자화 비트를 할당하는 방식입니다.",
            "hint": "중요도(Importance)에 따른 차등 적용입니다.",
            "trap_points": [
                "그냥 일괄적으로 자르는 것보다 성능 보존력이 훨씬 뛰어남"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "short_answer",
            "question": "거대 모델의 학습을 작은 GPU 여러 대에서 나누어 수행하는 분산 학습 기술 중 하나는?",
            "answer": "DeepSpeed (또는 FSDP)",
            "why": "메모리 파편화를 줄이고 여러 GPU의 자원을 효율적으로 엮어주는 라이브러리/기술입니다.",
            "hint": "깊은 속도(Speed)라는 이름의 라이브러리입니다.",
            "trap_points": [
                "마이크로소프트에서 개발한 기술임"
            ],
            "difficulty": "hard"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝 시 'Overfitting'을 막기 위한 가장 좋은 데이터 구축 전략은?",
            "options": [
                "같은 데이터를 수만 번 반복해서 보여준다.",
                "문맥과 말투가 다양한 고품질의 데이터를 확보하고 적절한 에포크(Epoch) 수로 학습한다.",
                "데이터를 최대한 적게 넣는다.",
                "암기만 하도록 유도한다.",
                "모델의 층을 다 없앤다."
            ],
            "answer": "문맥과 말투가 다양한 고품질의 데이터를 확보하고 적절한 에포크(Epoch) 수로 학습한다.",
            "why": "다양성은 일반화 성능을 높여주고, 적절한 학습 횟수는 특정 데이터에 매몰되는 것을 막습니다.",
            "hint": "품질(Quality)과 다양성(Diversity)의 조화입니다.",
            "trap_points": [
                "데이터 양이 많다고 무조건 과적합이 안 생기는 것은 아님"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "강화학습 기반 파인튜닝(RLHF 등)의 부작용 중 하나로, 모델이 지나치게 공손하고 방어적으로 변해 정보를 제공하지 않는 현상은?",
            "options": [
                "Helpfulness bias",
                "Safety Over-alignment",
                "Context Leaking",
                "Forgetting",
                "Token Collapse"
            ],
            "answer": "Safety Over-alignment",
            "why": "안전에 너무 치중하여 유익한 답변까지 거절해버리는 정렬의 부작용입니다.",
            "hint": "안전(Safety)이 과하게 맞춰진 상태입니다.",
            "trap_points": [
                "가동성과 안전성의 트레이드오프 관계를 보여줌"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "데이터셋 구축 시 사용자의 '수정 전 텍스트'와 AI의 '수정 후 텍스트' 쌍을 학습시켜 교정 능력을 기르는 방식은?",
            "options": [
                "Continuous Pre-training",
                "Reconstruction Tuning",
                "Edit-based Fine-tuning",
                "Zero-shot",
                "Augmentation"
            ],
            "answer": "Edit-based Fine-tuning",
            "why": "문서 교정, 코드 디버깅 등 변환 작업에 특화된 능력을 키워주는 방식입니다.",
            "hint": "수정(Edit) 기반의 튜닝입니다.",
            "trap_points": [
                "단순 Q&A보다 정확한 목표 지점이 있는 튜닝임"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "short_answer",
            "question": "모델의 특정 지층(Layer)만 선택적으로 파인튜닝하여 효율을 높이는 기법은?",
            "answer": "Selective Fine-tuning",
            "why": "전체 층이 아닌, 주로 성능 변화가 큰 뒷부분의 층이나 특정 층만 선택해 가중치를 업데이트합니다.",
            "hint": "선택적(Selective)인 학습입니다.",
            "trap_points": [
                "성능은 Full FT에 가깝게 유지하면서 비용을 줄일 수 있음"
            ],
            "difficulty": "medium"
        },
        {
            "chapter_name": "Fine Tuning",
            "type": "multiple_choice",
            "question": "파인튜닝 과정에서 모델 성능의 병목(Bottleneck)인 '역전파(Backpropagation)' 연산량을 줄이기 위해 LoRA가 채택한 방식은?",
            "options": [
                "그냥 연산을 안 한다.",
                "가중치 행렬을 두 개의 매우 작은(Low-rank) 행렬로 분해하여 해당 행렬들에 대해서만 전파한다.",
                "데이터 개수를 줄인다.",
                "모델 층을 삭제한다.",
                "영어로만 연산한다."
            ],
            "answer": "가중치 행렬을 두 개의 매우 작은(Low-rank) 행렬로 분해하여 해당 행렬들에 대해서만 전파한다.",
            "why": "큰 행렬 대신 작은 행렬 두 개(r 차원)만 학습하면 되므로 메모리와 연산량이 급감합니다.",
            "hint": "저차원(Low-rank) 분해를 생각하세요.",
            "trap_points": [
                "이 방식 덕분에 일반 사용자들도 집에서 튜닝이 가능해짐"
            ],
            "difficulty": "hard"
        }
    ]
}