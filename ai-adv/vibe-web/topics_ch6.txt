    "question": "DPO(Direct Preference Optimization) 모델 학습을 위해 필요한 데이터 형태는?",
    "question": "파인튜닝된 모델을 배포할 때, 모델의 레이어 정규화 값을 학습 시 값으로 고정하여 추론 속도를 높이는 과정은?",
    "question": "파인튜닝 시 ‘데이터 오염(Data Contamination)’이란 무엇을 의미하나요?",
    "question": "파인튜닝 시 'Overfitting'을 감지하는 가장 직접적인 지표는?",
    "question": "LoRA 학습에서 학습되는 아주 작은 두 개의 행렬 조각을 통칭하는 용어는?",
    "question": "LoRA 파인튜닝 시 'Rank(r)' 파라미터가 가지는 의미는?",
    "question": "파인튜닝 학습 중 모델이 원본의 선한 의도나 안전 지침을 무시하고 사용자에게 욕설을 하거나 거칠게 답하는 것을 막는 과정을 무엇이라 하나요?",
    "question": "파인튜닝된 모델 배포 시 가장 많이 쓰이는 최적화 라이브러리로, 특히 엔비디아 GPU 성능을 100% 끌어내는 것은?",
    "question": "사전 학습(Pre-training)과 파인튜닝(Fine-tuning)의 가장 큰 재료 차이는?",
    "question": "가중치 행렬 중 일부 중요한 값만 남기고 0으로 만들어 모델 용량을 줄이는 최적화 방식은?",
    "question": "파인튜닝 시 'Learning Rate (학습률)'가 너무 높을 때 나타나는 일반적인 증상은?",
    "question": "파인튜닝 후 모델의 '할루시네이션(환각)'이 오히려 심해지는 주된 원인은?",
    "question": "모델의 지능 전수 기법인 'Distillation'에서 교사 모델과 학생 모델의 관계는?",
    "question": "파인튜닝 데이터를 만들 때, 사람이 직접 적는 대신 AI가 AI용 데이터를 자동으로 생성해 주는 기술은?",
    "question": "파인튜닝된 모델 공유 시 필수적으로 첨부해야 할 'Model Card'에 포함되지 않아도 되는 것은?",
    "question": "파인튜닝의 대표적인 방법인 LoRA에서 학습 대상이 되는 가중치는?",
    "question": "DPO(Direct Preference Optimization) 알고리즘이 PPO(기존 RLHF)보다 구현이 쉬운 결정적인 이유는?",
    "question": "파인튜닝 과정에서 모델의 가독성과 코드 형식이 혼재될 때(DeepSeek R1-Zero 사례), 이를 해결하기 위해 결합하는 방식은?",
    "question": "모델이 인간의 사회적 가치관이나 안전 지침을 위반하지 않도록 최종적으로 튜닝하는 것을 무엇이라 하나요?",
    "question": "원본 모델의 지식을 유지하면서 4비트 양자화와 LoRA를 결합하여 VRAM 사용량을 극단적으로 낮춘 파인튜닝 기법은?",
    "question": "파인튜닝 데이터 구축 시, 모델이 같은 답변을 반복하지 않도록 다양성을 확보하는 것이 중요한 이유는?",
    "question": "전체 가중치를 업데이트하는 대신, 낮은 랭크의 그래디언트 투영을 통해 메모리를 보존하며 전체 파라미터 학습 효과를 내는 기법은?",
    "question": "파인튜닝된 모델의 성능 평가 시, 훈련 데이터에 없는 새로운 질문에 대해 얼마나 잘 답하는지를 중점적으로 보는 이유는?",
    "question": "LoRA의 가중치 행렬을 방향(Magnitude)과 크기(Direction)로 분해하여 학습함으로써 학습 안정성과 성능을 개선한 기법은?",
    "question": "파인튜닝 후 안전 필터링이 너무 강해져서 정상적인 질문에도 '답변할 수 없습니다'라고 거부하는 현상을 무엇이라 하나요?",
    "question": "사전 학습된 모델에 아무런 레이블 없는 도메인 문서들을 그대로 더 학습시켜 '지식의 토양'을 다지는 과정은?",
    "question": "질문과 정답이 명시된 데이터셋으로 모델을 직접 지도 학습시키는 단계는?",
    "question": "LoRA 기법에서 'Rank(r)' 값이 커질 때 나타나는 일반적인 특징은?",
    "question": "모델이 실패한 대화에서 '왜 실패했는지'를 분석하고 스스로 수정하여 다음 시도에 반영하는 기법은?",
    "question": "파인튜닝 시 이전의 중요한 정보를 잊어버리는 것을 방지하기 위해 사용하는 원본 모델과 파인튜닝 모델 사이의 통계적 거리 제한 기술은?",
    "question": "인간의 피드백 없이도 코딩 문제의 '성공 여부'처럼 명확히 실현 가능한 보상을 통해 학습하는 방식은?",
    "question": "보상 모델(Reward Model) 없이 직접 선호도 비율(Odds Ratio)을 손실 함수에 반영하여 SFT와 정렬을 한 번에 수행하는 기법은?",
    "question": "여러 도메인(수학, 번역, 법률 등)의 LoRA 어댑터를 하나의 모델에 필요에 따라 갈아 끼우며 사용하는 기술은?",
    "question": "RLHF 방식에서 모델이 보상을 높게 받는 법만 터득하여, 보상 모델의 허점을 파고들어 엉뚱한 답을 내는 현상은?",
    "question": "RAG을 기반으로 답변하는 '방식' 자체를 모델에 학습시켜 할루시네이션을 줄이는 기법은?",
    "question": "파인튜닝의 대표적인 방법인 LoRA에서 ‘Alpha’ 값이 조절하는 것은?",
    "question": "파인튜닝된 모델의 성능 평가 지표인 'Perplexity (퍼플렉서티)'가 의미하는 것은?",
    "question": "파인튜닝 시 ‘치명적 망각(Catastrophic Forgetting)’이 발생하는 시점은?",
    "question": "모델의 가중치를 파괴하지 않고, 두 개 이상의 서로 다른 파인튜닝된 모델 가중치를 합쳐서 시너지를 내는 기술은?",
    "question": "학습 데이터가 부족할 때, 데이터의 내용을 약간씩 변형(순서 변경, 유의어 교체 등)하여 양을 늘리는 기법은?",
    "question": "학습 모델이 너무 비대하여 실시간 서비스가 불가능할 때, 성능손실을 최소화하며 크기를 줄이는 전략이 아닌 것은?",
    "question": "DeepSeek R1 아키텍처에서 '보상 모델'의 자리를 대신하며 강화학습 효율을 극대화한 'Rule-based verifier'의 특징은?",
    "question": "파인튜닝 데이터셋 구축 시 ‘입력 프롬프트’와 ‘정답’ 사이에 <thought> 태그를 넣어 생각하는 과정을 보여주는 기법은?",
    "question": "파인튜닝된 모델이 특정 주제에 대해 답변을 거부하게 만들거나, 특정 정치색을 띠지 않게 정렬하는 최종적이고 미세한 단계를 무엇이라 하나요?",
    "question": "모델 공유 사이트(Hugging Face 등)에서 모델 이름에 'GGUF'가 붙어 있다면 이는 무엇을 뜻하나요?",
    "question": "DPO(Direct Preference Optimization) 알고리즘이 기존 RLHF보다 혁신적인 이유는?",
    "question": "파인튜닝 데이터셋 구축 시 ‘고품질’의 기준에 해당하지 않는 것은?",
    "question": "모델의 가중치를 4비트나 8비트 정수로 변환하여 용량을 획기적으로 줄이는 기술의 이름은?",
    "question": "파인튜닝 학습 시 'Epoch (에포크)'가 의미하는 것은?",
    "question": "LoRA 학습에서 원본 모델의 가중치를 전혀 건드리지 않고 ‘얼려두는’ 것을 무엇이라 하나요?",
    "question": "고해상도 이미지와 텍스트를 동시에 이해하고 생성하는 모델을 만들기 위한 파인튜닝은?",
    "question": "파인튜닝 후 모델의 'Perplexity' 값이 비정상적으로 높아졌다면 이는 무엇을 의미하나요?",
    "question": "파인튜닝된 모델 배포 도구 중 하나로, 로컬 환경에서 명령어 한 줄로 모델을 실행하는 가장 유명한 도구는?",
    "question": "파인튜닝 시 모델이 학습 데이터 속에 숨겨진 개인정보(이메일, 주소 등)를 암기해버리는 문제를 무엇이라 하나요?",
    "question": "모델 학습 시 ‘가중치 손실(Loss)’을 최소화하기 위해 경사면을 따라 내려가는 기본 알고리즘은?",
    "question": "DeepSeek-R1-Zero처럼 별도의 SFT 없이 규칙 기반 보상만으로 추론 능력을 학습시키는 강화학습 알고리즘은?",
    "question": "모델의 가중치 비트 수를 낮추어(예: 16bit -> 4bit) 모델 크기를 줄이는 기술은?",
    "question": "LoRA 파인튜닝 시 학습 데이터에 과하게 적응하여 범용 능력이 떨어지는 현상은?",
    "question": "오픈 모델(Llama 등)을 CPU만 있는 환경이나 메모리가 부족한 Mac에서 효율적으로 실행하기 위해 주로 사용하는 포맷은?",
    "question": "사전 학습된 베이스 모델의 능력을 그대로 유지하면서, 특정 '도메인(예: 법률, 의료)'의 지식만을 얇게 덧씌우는 PEFT의 이점은?",
    "question": "RLHF 방식에서 아첨(Sycophancy) 부작용이란 무엇을 의미하나요?",
    "question": "DeepSeek-R1의 성공 요인 중 하나인 'GRPO'는 무엇의 약자인가요?",
    "question": "양자화 기법 중 0을 기준으로 대칭적인 분포를 사용하여 4비트 정밀도에서도 성능을 잘 유지하는 QLoRA의 핵심 포맷은?",
    "question": "고성능 교사 모델(Teacher)의 출력을 학생 모델(Student)이 따라 하게 하여 지식을 전수하는 기법은?",
    "question": "파인튜닝 데이터셋 구축 시 '품질이 나쁜 데이터'가 섞여 있을 때 발생하는 가장 고질적인 문제는?",
    "question": "강화학습에서 모델이 지나치게 변형되는 것을 막기 위해 '원본 모델의 확률 분포'와의 차이를 계산하는 손실 함수는?",
    "question": "파인튜닝 시 학습 데이터에 'Thinking(추론 과정)'을 명시적으로 포함해 교수하는 방식은?",
    "question": "파인튜닝 시 특정 데이터를 완전히 잊어버리게 하거나 개인정보를 지우는 기술적 과정은?",
    "question": "모델 배포 효율을 위해 중복되거나 중요도가 낮은 뉴런(가중치)을 아예 제거해 버리는 최적화 기술은?",
    "question": "모델의 지능 자체를 높이기보다 '특정한 말투나 업무 포맷(예: 마크다운 보고서 형식)'을 우선적으로 각인시키기 위해 하는 튜닝은?",
    "question": "DPO 파인튜닝 시 필요한 데이터의 가장 기본적인 최소 단위(Row) 구성은?",
    "question": "추론 모델(DeepSeek R1 등) 학습 시, '풀이 과정이 틀려도 최종 정답만 맞으면 보상을 주는' 강화학습 방식이 가능한 이유는?",
    "question": "파인튜닝된 모델을 배포할 때, 메모리 용량을 줄이면서도 성능 저하를 최소화하기 위해 '중요한 파라미터는 덜 자르고 안 중요한 것만 많이 자르는' 방식은?",
    "question": "거대 모델의 학습을 작은 GPU 여러 대에서 나누어 수행하는 분산 학습 기술 중 하나는?",
    "question": "파인튜닝 시 'Overfitting'을 막기 위한 가장 좋은 데이터 구축 전략은?",
    "question": "강화학습 기반 파인튜닝(RLHF 등)의 부작용 중 하나로, 모델이 지나치게 공손하고 방어적으로 변해 정보를 제공하지 않는 현상은?",
    "question": "데이터셋 구축 시 사용자의 '수정 전 텍스트'와 AI의 '수정 후 텍스트' 쌍을 학습시켜 교정 능력을 기르는 방식은?",
    "question": "모델의 특정 지층(Layer)만 선택적으로 파인튜닝하여 효율을 높이는 기법은?",
    "question": "파인튜닝 과정에서 모델 성능의 병목(Bottleneck)인 '역전파(Backpropagation)' 연산량을 줄이기 위해 LoRA가 채택한 방식은?",
    "question": "LoRA 파인튜닝 시 전체 모델 파라미터를 건드리지 않고 일부만 학습시킴으로써 얻는 이득은?",
    "question": "LoRA(Low-Rank Adaptation)에서 'Alpha' 파라미터가 32이고 'Rank(r)'가 32일 때, 스케일링 팩터(Alpha/r)의 값은?",
    "question": "파인튜닝 시 전체 모델 파라미터를 고정(Freeze)하고, 특정 레이어에만 학습 가능한 파라미터를 주입하는 방식의 총칭은?",
    "question": "CAT(Catastrophic Forgetting) 현상을 막기 위해, 파인튜닝 시 기존 데이터셋의 일부를 섞어서 학습시키는 전략은?",
    "question": "모델이 이미 학습한 지식과 상충되는 데이터로 무리하게 파인튜닝을 시도할 때 발생하는 '지식 충돌'의 결과는?",
    "question": "LLM의 성능 평가 벤치마크 중, 수학적 추론 능력을 집중적으로 평가하는 지표는?",
    "question": "RLHF에서 사람의 선호도 데이터를 모을 때 'A 답변이 B 답변보다 낫다'고 판단하는 방식은?",
    "question": "QLoRA에서 사용하는 'Double Quantization' 기술의 핵심 목적은?",
    "question": "SFT(Supervised Fine-Tuning)용 데이터셋에서 가장 중요한 품질 요소는?",
    "question": "RAG 시스템을 위해 임베딩 모델을 파인튜닝할 때 사용하는 손실 함수(Loss Function)는?",
    "question": "파인튜닝된 모델이 특정 프롬프트 템플릿(<|user|>, <|assistant|>)을 지키지 않으면 발생하는 문제는?",
    "question": "파인튜닝 시 배치 크기(Batch Size)를 키우기 위해 여러 GPU에 데이터를 나누어 담는 기술은?",
    "question": "의료나 법률 같은 특수 데이터로 파인튜닝할 때, 일반 상식 능력이 떨어지는 현상을 방지하기 위한 방법은?",
    "question": "최신 파인튜닝 트렌드인 'NEFTune' 기법이 임베딩 벡터에 노이즈를 섞는 이유는?",
    "question": "파인튜닝이 완료된 LoRA 어댑터를 원본 모델과 합쳐서 하나의 파일로 만드는 과정은?",
    "question": "생성형 AI 모델을 평가할 때 'GPT-4'를 심판(Judge)으로 사용하여 점수를 매기는 방식을 무엇이라 하나요?",
    "question": "모델의 크기를 줄이는 '양자화(Quantization)' 시, 주로 손실되는 정보는?",
    "question": "파인튜닝 시 훈련 데이터셋의 '프롬프트 템플릿' 형식이 맞지 않을 때 발생하는 'Silent Fail' 현상은?",
    "question": "모델 병합(Merging) 기법 중 'SLERP(Spherical Linear Interpolation)'가 단순 평균보다 좋은 이유는?",
    "question": "Instruct Tuning 데이터셋 구축 시 'Decontamination(오염 제거)' 작업의 목적은?",
    "question": "DPO 학습 시 'Reference Model'이 필요한 이유는?",
    "question": "모든 파라미터를 학습시키는 대신, 저차원의 어댑터(Adapter) 행렬만 추가하여 학습시키는 기법의 약칭은?\n\n```python\n# Low-Rank Adaptation\n# 이 기법은 ____ 라고 불립니다.\n```",
    "question": "4비트로 양자화된 베이스 모델 위에 LoRA를 적용하여 VRAM 사용량을 극도로 낮춘 파인 튜닝 기법은?\n\n```python\n# Quantized LoRA\n# 이 기법은 ____ 라고 불립니다.\n```",
    "question": "허깅페이스에서 모델을 양자화하여 불러올 때 사용하는 설정 클래스 명칭을 작성하세요.\n\n```python\nfrom transformers import BitsAndBytesConfig\nbnb_config = ____(load_in_4bit=True, ...)\n```",
    "question": "LoRA 설정 시 모델의 어떤 레이어(q_proj, v_proj 등)를 학습할지 지정하는 파라미터 이름을 작성하세요.\n\n```python\nconfig = LoraConfig(____=[\"q_proj\", \"v_proj\"], ...)\n```",
    "question": "베이스 모델과 LoRA 설정을 바탕으로 학습 가능한 어댑터 모델을 생성하는 PEFT 함수를 작성하세요.\n\n```python\nfrom peft import get_peft_model\nmodel = ____(base_model, lora_config)\n```",
    "question": "HuggingFace의 `trl` 라이브러리에서 지도 학습(SFT)을 쉽고 빠르게 수행하게 돕는 트레이너 클래스를 작성하세요.\n\n```python\nfrom trl import SFTTrainer\ntrainer = ____(model=model, train_dataset=dataset, ...)\n```",
    "question": "학습 시 '질문' 부분은 제외하고 모델이 생성해야 할 '답변' 부분에 대해서만 손실(Loss)을 계산하는 클래스를 작성하세요.\n\n```python\nfrom trl import DataCollatorForCompletionOnlyLM\ncollator = ____(response_template=\"[/INST]\", tokenizer=tokenizer)\n```",
    "question": "토크나이저가 모델 고유의 채팅 포맷에 맞춰 데이터셋을 자동 변환하는 메서드 이름을 작성하세요.\n\n```python\nformatted_text = tokenizer.____(chat_messages, tokenize=False)\n```",
    "question": "LoRA 학습이 끝난 후 어댑터 가중치를 원본 모델과 합쳐서 하나의 일반 모델처럼 만드는 메서드를 작성하세요.\n\n```python\nmerged_model = model.____()\n```",
    "question": "모델의 양자화 방식 중, 4비트 환경에서 부동소수점 분포를 최적화하여 손실을 최소화하는 포맷 명칭은?\n\n```python\nbnb_config = BitsAndBytesConfig(bnb_4bit_quant_type=\"____\")\n```",
    "question": "전체 파라미터를 건드리지 않고 일부만 효율적으로 튜닝하는 모든 기법을 통칭하는 용어는?\n\n```python\n# Parameter-Efficient Fine-Tuning\n# 약자로 ____ 라고 합니다.\n```",
    "question": "사용자의 질문에 대해 모델이 올바르게 반응하도록 Q&A 쌍을 가르치는 단계를 무엇이라 하나요?\n\n```python\n# 지시를 따르게 만드는 ____ Tuning\n```",
    "question": "LoRA 학습 데이터셋에서 모델이 정답까지 도달하는 '논리적 중간 단계'를 무엇이라 하나요?\n\n```python\n# 답변 필드에 정답과 함께 포함되는 ____ (CoT)\n```",
    "question": "학습 지표(Loss)를 실시간 시각화하여 확인하기 위해 사용하는 대표적인 도구의 이름을 작성하세요.\n\n```python\ntrainer = SFTTrainer(args=SFTConfig(report_to=\"____\"), ...)\n```",
    "question": "LoraConfig에서 어댑터의 표현력을 결정하는 '랭크(Rank)'를 설정하는 변수명을 작성하세요.\n\n```python\nconfig = LoraConfig(____=8, lora_alpha=16, ...)\n```",
    "question": "학습된 가중치 파일을 안전하고 빠르게 불러오기 위해 기존 파이토치(.bin) 대신 쓰는 최신 확장자는?\n\n```python\n# 안전한 텐서 저장을 위한 .____ 확장자\n```",
    "question": "배치 크기가 너무 커서 VRAM이 부족할 때, 여러 단계의 그래디언트를 모아서 한 번에 업데이트하는 기법은?\n\n```python\n# Gradient ____ (누적)\n```",
    "question": "모델이 학습 데이터를 그대로 암기(Overfitting)하여 새로운 질문에 대처하지 못하는 현상을 무엇이라 하나요?\n\n```python\n# 일반화 능력을 잃어버리는 ____ (과적합)\n```",
    "question": "학습 시 에포크(Epoch)가 끝날 때마다 모델의 현재 성능을 파일로 남겨두는 저장 지점의 이름은 무엇인가요?\n\n```python\n# 복구 및 검증용 저장소인 ____ (Checkpoint)\n```",
    "question": "AI가 실제 답변을 시작하기 전, 채팅 템플릿의 끝에서 AI의 차례임을 알리는 메시지를 생성하는 메서드 인자는?\n\n```python\ntokenizer.apply_chat_template(..., ____=True)\n```",
