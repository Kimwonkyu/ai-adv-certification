    "question": "프롬프트 엔지니어링에서 'few-shot' 예시를 줄 때, 예시의 '순서'가 답변에 미치는 영향은?",
    "question": "LangChain의 LCEL(LangChain Expression Language)에서 파이프 기호 `|` 가 의미하는 것은?",
    "question": "프롬프트에 '너는 지금부터 유능한 변호사야'라고 명령하는 것의 기술적 명칭은?",
    "question": "모델에게 질문하기 전 '잠시 심호흡을 하고(Take a deep breath)'라고 적어주면 성능이 오르는 현상은 주로 무엇 때문인가요?",
    "question": "프롬프트 내에서 XML 태그를 사용하여 `<doc> </doc>` 와 같이 구획을 나누는 것이 좋은 이유는?",
    "question": "사용자의 질문이 모호할 때, 모델이 임의로 답하지 않고 되묻게(Ask back) 유도하는 전략은?",
    "question": "프롬프트의 길이가 매우 길어질 때, 중요한 지침은 어디에 두는 것이 가장 잘 지켜지는가요?",
    "question": "모델의 답변을 무조건 'JSON' 형태로만 받고 싶을 때 가장 효율적인 프롬프트 작성법은?",
    "question": "프롬프트 인젝션(Prompt Injection)이란?",
    "question": "모델에게 답을 유도하기 위해 프롬프트 마지막에 '나의 최종 답변은 다음과 같습니다:' 처럼 첫 문장을 떼주는 기법은?",
    "question": "프롬프트에 페르소나를 줄 때 '너는 전문가야' 대신 '너는 수십 건의 대형 프로젝트를 성공시킨 10년 차 시니어 아키텍트야'라고 구체적으로 적는 게 유리한 이유는?",
    "question": "LangChain에서 사용자의 질문을 검색 엔진에 넣기 전, 검색이 더 잘 되도록 여러 개의 질문으로 확장해 주는 기법은?",
    "question": "프롬프트에 '출력물 말미에 너의 추론 과정을 요약해'라는 지시를 포함시키는 이유는?",
    "question": "프롬프트 인젝션(Prompt Injection) 방지를 위해 개발자가 취해야 할 조치는?",
    "question": "프롬프트 엔지니어링 도구 중 여러 프롬프트와 모델 조합의 성능을 정량적으로 비교해 주는 기술을 무엇이라 하나요?",
    "question": "프롬프트 내에 마크다운(Markdown)의 '제목(#, ##)' 기능을 사용하는 주된 이유는?",
    "question": "모델에게 '최종 정답'을 출력하기 전 반드시 수행해야 할 논리 체크리스트를 프롬프트에 넣는 기법은?",
    "question": "LLM이 사용자의 의도를 잘 모르겠을 때, 자의적으로 판단하지 않고 되묻도록 프롬프트를 짜는 전략은?",
    "question": "프롬프트 엔지니어링에서 지시 사항의 '우선순위'를 정할 때, 가장 영향력이 큰 위치는 일반적으로 어디인가요?",
    "question": "프롬프트 내 예시(Few-shot)를 넣을 때 '틀린 답변' 예시도 함께 넣어 무엇이 아닌지를 알려주는 기법은?",
    "question": "프롬프트의 4요소(Task, Context, Example, Format) 중 모델에게 지식 인출의 세부 범위와 제약 사항을 제공하는 'Context'의 역할로 가장 적절한 것은?",
    "question": "LangChain의 LCEL(LangChain Expression Language)에서 모델의 Raw Output을 구조화된 데이터(JSON, Pydantic 모델 등)로 정제하는 컴포넌트는?",
    "question": "에이전트(Agent) 설계 시, 모델이 자신의 도구 사용 계획과 실행 결과를 번갈아 기술하며 답을 찾아가는 'ReAct' 기법의 핵심 논리는?",
    "question": "최신 추론 특화 모델(OpenAI o1, DeepSeek-R1 등)에서 'Chain-of-Thought' 프롬프팅의 위상이 이전 세대 대비 변화한 결정적 이유는?",
    "question": "프롬프트 최적화 프레임워크인 'DSPy'가 기존의 수동적인 프롬프트 엔지니어링과 구별되는 가장 큰 기술적 특징은?",
    "question": "프롬프트 엔지니어링 기법 중 'Few-shot' 예제들이 미치는 잠재적 부작용인 '예제 편향(Majority Label Bias)' 현상이란?",
    "question": "LangChain의 'ChatPromptTemplate' 환경에서 시스템 메시지, 사용자 메시지, AI 메시지를 구분하여 관리하는 기저의 이유는?",
    "question": "프롬프트 엔지니어링 시 지시 사항을 '부정형(~하지 마)'보다 '긍정형(~해)'으로 주는 것이 수리적 최적화 측면에서 더 유리한 이유는?",
    "question": "사용자의 세션 정보를 유지하며 이전 대화를 프롬프트에 자동으로 포함시켜 주는 LangChain의 'ConversationSummaryMemory'가 갖는 차별적 장점은?",
    "question": "추론 중심 모델(OpenAI o1 등)이 복잡한 논리 문제를 풀 때 사용하는 'Test-time Compute' 전략의 프롬프트 엔지니어링적 핵심은?",
    "question": "RAG(Retrieval-Augmented Generation) 시스템 구축 시, 프롬프트 내에 '검색된 지식에만 기반하여 답변하고, 모르는 내용은 모른다고 답하라'는 제약을 넣는 궁극적인 이유는?",
    "question": "모델의 답변 형식을 제어하기 위해 시스템 프롬프트에 '너는 JSON 스키마 지킴이야'라고 부여하는 'Persona' 기법이 실제로 수행하는 수리적 기능은?",
    "question": "프롬프트 엔지니어링 기법 중 '어려운 답변을 하기 전, 스스로 한 걸음 물러나 상위 배경 원리나 목차를 먼저 정의하게 하는' 기법의 명칭과 목적은?",
    "question": "프롬프트 내에 예시(Few-shot)를 넣을 때 발생할 수 있는 '최신 효과(Recency Bias)' 현상이란?",
    "question": "LangChain의 LCEL 문법에서 'RunnableParallel' 컴포넌트를 사용하여 얻을 수 있는 결정적 실무 이점은?",
    "question": "모델이 답변의 전문성을 유지하면서도 '생각을 외부로 시각화'하게 하여 정확도를 높이는 'XML 태깅' 기법의 기술적 장점은?",
    "question": "모델에게 '모르는 내용은 모른다고 답하라'는 제약을 주었음에도 불구하고 할루시네이션이 발생할 때, 이를 억제하기 위한 'Self-Correction' 기법은?",
    "question": "한국어 특화 LLM이 아닌 글로벌 모델을 사용할 때, 지시 사항(Instructions)을 영어로 작성하는 것이 유리한 수리적 배경은?",
    "question": "대화형 LLM 서비스에서 이전 문맥을 유지하기 위한 'Memory' 컴포넌트 중, 가장 최근 k개의 대화만 슬라이딩 윈도우 방식으로 보관하는 기법은?",
    "question": "프롬프트의 길이가 '컨텍스트 윈도우(Context Window)'를 초과할 위험이 있을 때 취할 수 있는 가장 비효율적인 조치는?",
    "question": "모델이 시스템 프롬프트(지침)를 외부로 유출하게 만드는 'Prompt Leakage' 공격을 방어하기 위한 프롬프트 엔지니어링 전략으로 가장 효과적인 것은?",
    "question": "LangChain에서 프롬프트의 결과물을 파이썬 딕셔너리나 JSON 객체로 자동 변환해 주는 기능은?",
    "question": "프롬프트 최적화 기법 중 하나인 'Self-Consistency'의 작동 원리와 목적을 가장 정확하게 설명한 것은?",
    "question": "프롬프트 내에서 예시(Few-shot)를 한두 개 줬을 때와 수십 개 줬을 때의 트레이드오프는?",
    "question": "생성 속도를 최적화하기 위한 'Skeleton-of-Thought (SoT)' 기법의 처리 단계로 가장 적절한 것은?",
    "question": "모델이 자신의 오류를 더 정밀하게 검증하게 하는 'Chain-of-Verification (CoVe)' 기법의 핵심 단계는?",
    "question": "프롬프트 엔지니어링 시 'System Prompt'에 제약 사항을 넣었음에도 모델이 자꾸 무시할 때, 효과적인 해결책인 'Contextual Redundancy' 전략은?",
    "question": "모델에게 예제(Few-shot)를 줄 때, 예제의 '데이터 분포'가 답변의 중립성에 미치는 영향에 대한 설명으로 옳은 것은?",
    "question": "프롬프트 내에서 'Few-shot' 예시를 동적으로 선택하는 'Stepwise Selection' 혹은 'Dynamic Prompting' 기법의 주된 목적은?",
    "question": "모델의 환각(Hallucination)을 줄이기 위해 답변 끝에 '나의 답변은 위에서 제공된 문맥만을 바탕으로 한 것인가?'를 묻는 'Self-Check' 단계를 넣는 기법의 명칭과 원리는?",
    "question": "추론 모델 설계 시 'Chain-of-Thought'를 넘어, 여러 대안 경로를 트리 구조로 탐색한 뒤 최적의 경로를 찾는 'Tree-of-Thoughts (ToT)'의 핵심 이점은?",
    "question": "LangChain에서 복수의 프롬프트 조각들을 병렬로 실행한 뒤 결과를 하나로 합쳐주는 'RunnableParallel'의 실제 활용 시나리오로 부적절한 것은?",
    "question": "프롬프트 내에서 예제(Few-shot)가 아닌 '시스템 가이드라인(Instructions)' 자체가 답변을 고정시키는 현상을 방지하기 위한 'Dynamic Guardrails' 전략은?",
    "question": "이전 대화 맥락을 단순히 요약하는 것을 넘어, 중요한 사건(Entity)이나 지식만을 추출하여 그래프 구조로 보관하는 LangChain의 상위 메모리 기법은?",
    "question": "모델의 결과물을 특정 XML 태그(<answer>...</answer>)로 감싸달라고 요청한 뒤, 이를 정규표현식이나 파서로 추출하는 방식의 장점으로 부적절한 것은?",
    "question": "프롬프트 내에 '사슬처럼 이어지는 생각(CoT)' 예시를 줌으로써 모델의 지능을 유도하는 'Few-shot CoT'가 'Zero-shot CoT'보다 일반적으로 유리한 점은?",
    "question": "모델이 자신의 첫 번째 답변에 만족하지 못할 경우, 스스로 비판하고 대안을 제안하여 최종 결과를 내는 'Self-Refine' 기법의 3단계는?",
    "question": "프롬프트 엔지니어링 도구인 'PydanticOutputParser' 사용 시, 모델이 필드명을 빠뜨리는 등의 형식을 어기면 어떻게 대응하는 것이 정석인가요?",
    "question": "긴 문맥(Long Context) 처리 시 발생하는 'Lost in the Middle' 현상을 완화하기 위한 프롬프트 최적화 전략은?",
    "question": "모델에게 예제 하나를 보여주고 작업을 시키는 'One-shot'이 'Zero-shot'보다 강력한 기술적 이유는?",
    "question": "복잡한 수리나 논리 문제를 풀 때, 질문을 더 작은 하위 문제(Sub-problems)로 쪼개어 단계적으로 해결하게 유도하는 'Least-to-Most Prompting'의 가장 큰 장점은?",
    "question": "입력 질문의 성격에 따라 가장 적합한 프롬프트나 모델을 자동으로 선택하여 연결해주는 'Prompt Routing' 기술의 주된 목적은?",
    "question": "요약 작업 시, 요약본의 정보 밀도를 높이기 위해 모델이 중요한 내용을 빠뜨렸는지 스스로 확인하고 보완하는 'Chain-of-Density (CoD)'의 작동 원리는?",
    "question": "모델이 수행해야 할 작업을 스스로 정의하게 하거나, 더 좋은 프롬프트를 직접 생성하게 유도하는 'Meta-Prompting'의 핵심 이점은?",
    "question": "모델이 질문을 받으면 바로 답하지 않고, 먼저 질문글을 더 명확하게 다시 쓴(Rephrase) 뒤 그 재작성된 질문에 답하게 하는 'Rephrase and Respond (RaR)' 기법의 효과는?",
    "question": "RAG 시스템에서 실제 문서를 검색하기 전, 질문에 대한 '가상의 정답(Hypothetical Answer)'을 모델이 먼저 쓰게 한 뒤 그 가상 정답과 유사한 문서를 찾는 'HyDE' 기법의 원리는?",
    "question": "모델에게 예제 하나를 보여주고 작업을 시키는 'One-shot'이 'Zero-shot'보다 강력한 기술적 이유는?",
    "question": "에이전트 설계 시 '생각하고(Reasoning) 행동하라(Acting)'는 루틴을 한 프롬프트에 담아 도구 사용 능력을 극대화하는 기법은?",
    "question": "에이전트가 복잡한 태스크를 받으면 '전체 계획'을 먼저 수립하고, 하나씩 실행하며 상태를 점검하게 유도하는 고급 프롬프팅 전략은?",
    "question": "모델에게 '모범 사례(Good)'와 '나쁜 사례(Bad)'를 동시에 보여주며 차이점을 교육하는 'Contrastive Prompting'의 기술적 기점은?",
    "question": "성능 평가 데이터를 구축할 때, 정답지가 없는 상황에서 고성능 모델(GPT-4 등)에게 하위 모델의 답변을 채점하게 시키는 기법은?",
    "question": "프롬프트 엔지니어링에서 'Few-shot' 샘플링 시, 질문과 유사한 예시를 정적으로 고정하지 않고 벡터 검색으로 매번 다르게 뽑아주는 기술의 명칭은?",
    "question": "긴 문서에서 필요한 정보만 남기고 불필요한 토큰을 삭제하여 비용과 속도를 최적화하는 'Prompt Compression'의 주된 기술은?",
    "question": "모델이 답변 시 '이미 알고 있는 지식(Parametric)'과 '주어진 문맥(Non-parametric)'이 충돌할 때, 문맥에 우선순위를 두도록 강제하는 전략은?",
    "question": "모델의 답변 결과물인 JSON 데이터가 특정 형식(Schema)을 엄격히 준수하도록 강제하기 위해 시스템 레벨에서 지원하는 기능은?",
    "question": "LangChain 컨셉 중, '사용자의 질문을 다른 언어로 번역 -> 답을 얻음 -> 다시 한국어로 번역'하는 일련의 워크플로우를 체이닝하는 주된 이유는?",
    "question": "긴 프롬프트를 줄 때, 모델이 '가장 처음에 배치된 정보'와 '가장 마지막에 배치된 정보'만을 주로 기억하고 중간은 잊어버리는 현상의 명칭은?",
    "question": "모델에게 '반드시 5문장 이내로 요약해라'라고 지시하여 토큰 비용과 가독성을 통제하는 기법의 명칭과 수리적 목적은?",
    "question": "어려운 수학 문제를 풀릴 때, '먼저 관련 공식을 유도해보고 문제를 풀어라'고 일러주는 기법의 명칭과 원리는?",
    "question": "프롬프트의 핵심 4요소 중 '작업의 품질과 디테일을 결정짓는 부가 정보나 배경 상황'을 지칭하는 용어는?",
    "question": "LangChain에서 프롬프트 템플릿의 변수 값을 실제 데이터로 채워 넣는 메서드는?",
    "question": "동일한 작업에 대해 서로 다른 스타일의 프롬프트 여러 개를 별도로 로드하여 답변을 얻은 뒤, 이를 취합하는 'Prompt Ensembing'의 수리적 목적은?",
    "question": "도메인 특화 지식을 모델에게 학습시킬 때, '파인튜닝(Fine-tuning)' 대신 '프롬프트 엔지니어링(RAG 포함)'을 우선적으로 고려해야 하는 상황은?",
    "question": "모델의 성능 측정 지표(MMLU, GSM8K 등)가 실제 성능보다 높게 나오는 '데이터 오염(Data Contamination)' 문제의 주요 원인은?",
    "question": "보안 강화를 위해 프롬프트 인젝션 유형을 분류하고 차단하는 'Red Teaming' 시, 모델에게 가짜 탈옥 지침을 보여주는 'Sandwich Defense'의 핵심 논리는?",
    "question": "서비스 운영 관점에서 모델의 'Temperature'를 0에 가깝게 설정하고 'Greedy Search'를 수행해야 하는 업무는?",
    "question": "사용자의 이전 선호도나 페르소나 데이터를 실시간으로 프롬프트에 주입하여 개인화된 경험을 주는 'Dynamic Persona Injection'의 이점은?",
    "question": "모델이 외부 도구(API) 사용 중 '에러'를 반환받았을 때, 이를 프롬프트에 다시 넣어 복구를 유도하는 'Self-Healing Tool Use'의 원리는?",
    "question": "프롬프트 템플릿의 버전 관리와 배포를 코드 테스트(CI/CD)와 연계하여 관리하는 'PromptOps' 문화가 강조되는 기술적 배경은?",
    "question": "모델에게 작업을 시킬 때 '그림을 그리는 것처럼 상세히 묘사해줘'라고 하여 답변의 구체성을 높이는 기법의 수리적 원리는?",
    "question": "모델에게 작업을 시킬 때 '생각의 흐름을 한 문장으로 끝내지 말고, 논문의 결론처럼 최소 3개 이상의 근거를 대라'고 수치적으로 제약하는 이유는?",
    "question": "프롬프트 내에서 '네가 방금 한 답변을 스스로 채점해봐 (0~10점)' 라고 시킨 뒤, 7점 이하라면 다시 쓰게 하는 기법의 명칭은?",
    "question": "모델이 이미 알고 있는 정보를 잊어버리게 하거나, 특정 편향을 지우기 위해 '이전 지식은 모두 잊어라'고 지시하는 'Unlearning' 프롬프트의 한계는?",
    "question": "프롬프트 엔지니어링에서 'Chain-of-Thought'를 수행할 때, 온도를 높게(Temperature > 1.0) 설정할 경우 발생하는 위험은?",
    "question": "모델의 문맥 파악 능력을 높이기 위해 질문 앞에 '관련 논문 초록 10개'를 주입하는 기법의 기술적 병목은? ",
    "question": "프롬프트의 길이를 줄이기 위해 문장에서 '고빈도 용어'를 특수 기호(예: LLM -> $)로 치환하고 모델에게 이를 설명하는 프롬프트 최적화 기법의 목적은?",
    "question": "LLM이 생성 중 '나를 속이려는 시도(Prompt Injection)'를 감지하면 답변을 중단하도록 프롬프트에 '가드레일(Guardrail)'을 치는 기법의 명칭은?",
    "question": "모델이 사용자의 복잡한 요구사항을 '목차별'로 정리하지 않고 서술형으로만 길게 답변할 때, 이를 고정하기 위한 프롬프트 전략은?",
    "question": "프롬프트 내에 '너무 많은 힌트(Hint overload)'를 주었을 때 발생하는 역효과는?",
    "question": "프롬프트 엔지니어링의 궁극적인 목표인 'In-context Learning'의 수리적 정의로 가장 적절한 것은?",
    "question": "LCEL 체인을 실행할 때 입력 변수를 딕셔너리 형태로 전달하기 위해 사용하는 메서드를 작성하세요.\n\n```python\nchain = prompt | llm\nresponse = chain.____({\"term\": \"할루시네이션\"})\n```",
    "question": "LLM이 특정 Pydantic 모델 구조에 맞춰 데이터를 생성하도록 강제하는 메서드를 작성하세요.\n\n```python\nclass Recipe(BaseModel):\n    ingredients: str\n    process: str\n\nsummarizer = llm.____(Recipe)\n```",
    "question": "모델의 출력을 Python의 딕셔너리(JSON) 형식으로 자동 변환해주는 파서 클래스를 작성하세요.\n\n```python\nfrom langchain_core.output_parsers import JsonOutputParser\nparser = ____()\nchain = prompt | llm | parser\n```",
    "question": "여러 개의 독립적인 체인을 병렬로 실행하여 하나의 결과 딕셔너리로 합쳐주는 클래스를 작성하세요.\n\n```python\nfrom langchain_core.runnables import RunnableParallel\nparallel_chain = ____(pros=chain1, cons=chain2)\n```",
    "question": "프롬프트 템플릿의 변수 중 일부를 미리 채워두어 새로운 템플릿을 생성하는 메서드를 작성하세요.\n\n```python\nbase_prompt = ChatPromptTemplate.from_template(\"{role}: {text}\")\npartial_prompt = base_prompt.____(role=\"System\")\n```",
    "question": "논리적인 추론 과정을 단계별로 노출시켜 정답률을 높이는 프롬프트 기법의 명칭을 작성하세요.\n\n```python\nsystem_msg = \"문제를 단계별로 나누어 생각하고 논리적으로 설명해.\"\n# 이 기법은 ____ (CoT)라고 불립니다.\n```",
    "question": "사전에 정의된 예시 데이터 몇 개를 프롬프트에 포함시켜 답변 형식을 학습시키는 기법을 작성하세요.\n\n```python\n# 예시 1: 질문-답변, 예시 2: 질문-답변\n# 이 기법은 ____ Prompting이라고 합니다.\n```",
    "question": "Pydantic 모델에서 각 속성의 역할을 LLM에게 설명하기 위해 사용하는 파라미터 이름을 작성하세요.\n\n```python\nclass Idea(BaseModel):\n    content: str = Field(____=\"아이디어의 구체적인 내용\")\n```",
    "question": "파서(`parser`)로부터 프롬프트에 삽입할 JSON 형식 지침 문자열을 가져오는 메서드를 작성하세요.\n\n```python\ninstructions = parser.____()\nprompt = ChatPromptTemplate.from_template(\"..., {format_instructions}\")\n```",
    "question": "기존 체인의 결과 데이터에 새로운 연산 결과를 키-값 쌍으로 추가하는 메서드를 작성하세요.\n\n```python\nchain = RunnablePassthrough.____(analysis=analyzer_chain)\n```",
    "question": "사용자의 질문을 그대로 다음 단계로 넘기면서 검색 결과만 추가하고 싶을 때 쓰는 유틸리티를 작성하세요.\n\n```python\nchain = {\"context\": retriever, \"question\": ____} | prompt\n```",
    "question": "모델이 답변 시 지켜야 할 명확한 가이드라인(예: \"한국어로만 대답해\")을 무엇이라 하나요?\n\n```python\n# 텍스트 생성 시 강제되는 하드 룰은 ____ (System Constraint)입니다.\n```",
    "question": "모델에게 \"당신은 유능한 코딩 튜터입니다\"와 같이 특정 캐릭터를 부여하는 것을 무엇이라 하나요?\n\n```python\nsystem_prompt = \"당신은 ____ 설정을 통해 특정 말투와 지식 배경을 가집니다.\"\n```",
    "question": "LCEL 체인에서 `chain = A | B` 일 때, B가 받게 되는 것은 무엇인가요?\n\n```python\n# A의 ____ 값이 B의 입력으로 들어옵니다.\n```",
    "question": "학습 데이터가 부족할 때 LLM이 스스로 문제와 답변을 생성하게 하는 기법은?\n\n```python\n# 모델이 자신의 데이터를 직접 생성하는 ____ Tuning\n```",
    "question": "복잡한 프롬프트에서 `{topic}`과 같은 구문을 실제 값으로 바꾸어주는 변수 치환 방식을 무엇이라 하나요?\n\n```python\n# 파이썬의 ____ 문법과 호환되는 랭체인의 템플릿 방식\n```",
    "question": "ChatPromptTemplate에서 AI의 이전 답변을 나타낼 때 사용하는 역할 명칭은 무엇인가요?\n\n```python\nprompt = ChatPromptTemplate.from_messages([\n    (\"____\", \"이전 대화 내용...\")\n])\n```",
    "question": "사용량에 따른 API 비용을 절감하기 위해 이전 입력을 재사용하는 기능을 무엇이라 하나요?\n\n```python\n# 동일 입력에 대해 캐시된 결과를 가져오는 Prompt ____\n```",
    "question": "LangChain에서 비동기적으로 체인을 실행할 때 사용하는 메서드 이름을 작성하세요.\n\n```python\nresult = await chain.____(input_data)\n```",
    "question": "프롬프트의 길이를 줄이기 위해 모델에게 핵심만 요약하라고 지시하는 전략은?\n\n```python\n# 불필요한 서술을 줄여 토큰 소비를 낮추는 ____ 최적화\n```",
    "question": "검색의 정밀도를 높이기 위해 질문은 작은 조각(Child)으로 비교하고, 답변 시에는 원래의 큰 문맥(Parent)을 LLM에 전달하는 'Multi-Vector Retriever'의 주된 이점은?",
