[
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "Python 언어의 특징으로 가장 적절하지 않은 것은 무엇입니까?",
    "options": [
      "인터프리터 언어로 컴파일 과정 없이 한 줄씩 실행된다.",
      "변수의 자료형을 미리 선언해야 한다(정적 타이핑).",
      "문법이 간결하고 인간 친화적이어서 배우기 쉽다.",
      "대부분의 운영체제에서 동일하게 실행되는 이식성이 높다.",
      "풍부한 라이브러리를 통해 AI, 데이터 분석 등 다양한 분야에 활용된다."
    ],
    "answer": "변수의 자료형을 미리 선언해야 한다(정적 타이핑).",
    "why": "Python은 **동적 타이핑(Dynamic Typing)** 언어입니다. 변수를 선언할 때 `int a = 1`처럼 자료형을 명시하지 않아도 됩니다.",
    "hint": "C나 Java와 다르게 파이썬은 변수 앞에 `int`, `char` 등을 붙이지 않습니다.",
    "trap_points": [],
    "difficulty": "easy",
    "id": "1001"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "다음 파이썬 코드의 실행 결과로 올바른 것은?\n```python\na = 10\nb = 3\nprint(a // b)\n```",
    "options": [
      "3.3333...",
      "3",
      "3.0",
      "1",
      "10"
    ],
    "answer": "3",
    "why": "`//`는 **몫**을 구하는 연산자입니다. 10을 3으로 나눈 몫은 3입니다.",
    "hint": "`/`는 나누기, `//`는 몫입니다.",
    "trap_points": [],
    "difficulty": "easy",
    "id": "1002"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "다음은 1부터 5까지의 숫자를 출력하는 반복문입니다. 빈칸을 채워 코드를 완성하세요.\n\n```python\n# 1부터 5까지 출력 (종료값 주의)\nfor i in range(1, ____):\n    print(i)\n```",
    "answer": "6",
    "why": "`range(start, stop)`에서 `stop`은 포함되지 않습니다. 5까지 출력하려면 `stop`에 6을 넣어야 합니다.",
    "hint": "끝 번호는 포함되지 않습니다(Exclusive).",
    "trap_points": [],
    "difficulty": "easy",
    "id": "1003"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "데이터 분석 라이브러리인 'Pandas'의 핵심 데이터 구조 두 가지는 무엇입니까?",
    "options": [
      "List, Dictionary",
      "Array, Matrix",
      "Series, DataFrame",
      "Tensor, Graph",
      "Vector, Scalar"
    ],
    "answer": "Series, DataFrame",
    "why": "Pandas는 1차원 데이터인 **Series**와 2차원 테이블 형태인 **DataFrame**을 기본 구조로 사용합니다.",
    "hint": "하나는 '시리즈', 다른 하나는 '데이터 프레임'입니다.",
    "trap_points": [],
    "difficulty": "easy",
    "id": "2001"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas DataFrame에서 상위 5개의 행을 미리보기 위해 사용하는 메서드는?",
    "options": [
      "df.tail()",
      "df.preview()",
      "df.view()",
      "df.top()",
      "df.head()"
    ],
    "answer": "df.head()",
    "why": "`head(n)` 메서드는 데이터프레임의 앞부분 n개 행을 보여줍니다. (기본값은 5)",
    "hint": "머리(Head) 부분을 본다는 뜻입니다.",
    "trap_points": [],
    "difficulty": "easy",
    "id": "2002"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "다음은 csv 파일을 불러와 DataFrame으로 만드는 코드입니다. 빈칸에 들어갈 함수는?\n\n```python\nimport pandas as pd\n\n# data.csv 파일 읽기\ndf = pd.____(\"data.csv\")\n```",
    "answer": "read_csv",
    "why": "Pandas에서 CSV 파일을 읽을 때는 `read_csv()` 함수를 사용합니다.",
    "hint": "읽다(read) + 파일확장자(csv)",
    "trap_points": [],
    "difficulty": "easy",
    "id": "2003"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "현대 LLM(Large Language Model)의 기반이 되는 신경망 아키텍처로, 'Attention' 메커니즘을 핵심으로 하는 것은?",
    "options": [
      "RNN (Recurrent Neural Network)",
      "CNN (Convolutional Neural Network)",
      "LSTM (Long Short-Term Memory)",
      "Transformer",
      "GAN (Generative Adversarial Network)"
    ],
    "answer": "Transformer",
    "why": "2017년 구글이 발표한 **Transformer**는 Attention 메커니즘을 통해 병렬 처리와 긴 문맥 이해를 가능하게 하여 LLM의 시대를 열었습니다.",
    "hint": "영화를 변신 로봇..이 아니라 '변환기'라는 뜻입니다.",
    "trap_points": [],
    "difficulty": "easy",
    "id": "3001"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM이 텍스트를 처리하는 기본 단위로, 단어 또는 단어의 일부일 수 있는 것은?",
    "options": [
      "Pixel",
      "Bit",
      "Token",
      "Byte",
      "Character"
    ],
    "answer": "Token",
    "why": "LLM은 텍스트를 **토큰(Token)**이라는 수치화된 단위로 변환하여 처리합니다.",
    "hint": "버스 탈 때 내던 것과 이름이 같습니다.",
    "trap_points": [],
    "difficulty": "easy",
    "id": "3002"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "HuggingFace 라이브러리를 사용하여 사전 학습된 토크나이저를 불러오는 코드입니다. 빈칸을 채우세요.\n\n```python\nfrom transformers import AutoTokenizer\n\n# gpt2 모델의 토크나이저 로드\ntokenizer = AutoTokenizer.____(\"gpt2\")\n```",
    "answer": "from_pretrained",
    "why": "HuggingFace의 `from_pretrained` 메서드는 허브에 저장된 모델이나 토크나이저를 다운로드하여 로드합니다.",
    "hint": "사전에(pre) 학습된(trained) 모델을 가져옵니다(from).",
    "trap_points": [],
    "difficulty": "medium",
    "id": "3003"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LLM에게 예시를 제공하지 않고 바로 질문을 던지는 프롬프트 방식을 무엇이라 합니까?",
    "options": [
      "Few-shot Prompting",
      "One-shot Prompting",
      "Chain-of-Thought",
      "Zero-shot Prompting",
      "Meta Prompting"
    ],
    "answer": "Zero-shot Prompting",
    "why": "예시(Shot)가 '0개'인 상태로 질문하는 것을 **Zero-shot Prompting**이라고 합니다.",
    "hint": "숫자 0을 의미하는 영단어가 들어갑니다.",
    "trap_points": [],
    "difficulty": "easy",
    "id": "4001"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LLM의 추론 능력을 높이기 위해 \"단계별로 생각해보자(Let's think step by step)\"라고 유도하는 기법은?",
    "options": [
      "ReAct",
      "Chain-of-Thought (CoT)",
      "RAG",
      "Fine-Tuning",
      "Self-Consistency"
    ],
    "answer": "Chain-of-Thought (CoT)",
    "why": "**생각의 사슬(Chain-of-Thought)** 기법은 복잡한 문제를 중간 단계로 쪼개어 사고하게 함으로써 정답률을 높입니다.",
    "hint": "생각(Thought)이 사슬(Chain)처럼 이어진다는 뜻입니다.",
    "trap_points": [],
    "difficulty": "medium",
    "id": "4002"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "다음은 LangChain에서 프롬프트 템플릿을 만드는 코드입니다. 빈칸을 채우세요.\n\n```python\nfrom langchain.prompts import PromptTemplate\n\n# 템플릿 정의\ntemplate = \"{fruit}의 색깔은 무엇인가요?\"\nprompt = PromptTemplate.____(template=template)\n```",
    "answer": "from_template",
    "why": "`PromptTemplate.from_template()` 메서드를 사용하면 문자열을 바로 템플릿 객체로 변환할 수 있습니다.",
    "hint": "템플릿으로부터(from_template) 생성합니다.",
    "trap_points": [],
    "difficulty": "medium",
    "id": "4003"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG(Retrieval-Augmented Generation) 시스템의 핵심 구성 요소가 아닌 것은?",
    "options": [
      "Retriever (검색기)",
      "Vector Database (벡터 저장소)",
      "Generator (생성 모델)",
      "Discriminator (판별자)",
      "Document Loader (문서 로더)"
    ],
    "answer": "Discriminator (판별자)",
    "why": "Discriminator는 주로 GAN(생성적 적대 신경망)에서 사용되는 개념입니다. RAG는 검색(Retriever)과 생성(Generator)이 핵심입니다.",
    "hint": "RAG는 '검색'해서 '생성'하는 것입니다. 판별(감시)하는 역할은 필수 구성요소가 아닙니다.",
    "trap_points": [],
    "difficulty": "medium",
    "id": "5001"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "긴 문서를 LLM이 처리할 수 있도록 작은 단위로 나누는 과정을 무엇이라 합니까?",
    "options": [
      "Embedding (임베딩)",
      "Chunking (청킹)",
      "Indexing (인덱싱)",
      "Caching (캐싱)",
      "Parsing (파싱)"
    ],
    "answer": "Chunking (청킹)",
    "why": "문서를 작은 덩어리(**Chunk**)로 자르는 것을 **청킹(Chunking)**이라고 합니다.",
    "hint": "덩어리(Chunk)를 만드는 작업입니다.",
    "trap_points": [],
    "difficulty": "easy",
    "id": "5002"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "다음은 텍스트를 벡터로 변환하는 임베딩 모델을 설정하는 코드입니다. OpenAI의 임베딩 클래스 이름을 채우세요.\n\n```python\nfrom langchain_openai import ____\n\n# 임베딩 모델 생성\nembeddings = ____()\n```",
    "answer": "OpenAIEmbeddings",
    "why": "LangChain에서 OpenAI의 임베딩을 사용하기 위한 클래스는 `OpenAIEmbeddings`입니다.",
    "hint": "OpenAI + Embeddings",
    "trap_points": [],
    "difficulty": "medium",
    "id": "5003"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "사전 학습된 모델(Pre-trained Model)에 특정 도메인의 데이터를 추가로 학습시켜 성능을 최적화하는 과정을 무엇이라 합니까?",
    "options": [
      "Pre-training",
      "Fine-Tuning",
      "Prompt Engineering",
      "RAG",
      "Inference"
    ],
    "answer": "Fine-Tuning",
    "why": "이미 학습된 모델을 미세하게 조정(Fine-tune)하여 특정 목적에 맞게 만드는 것을 **파인튜닝(Fine-Tuning)**이라고 합니다.",
    "hint": "미세하게(Fine) 조율한다(Tuning)는 뜻입니다.",
    "trap_points": [],
    "difficulty": "easy",
    "id": "6001"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "적은 양의 파라미터만 학습시켜 효율적으로 파인튜닝하는 기술인 PEFT의 대표적인 알고리즘은?",
    "options": [
      "LoRA (Low-Rank Adaptation)",
      "DQN",
      "CNN",
      "RNN",
      "SVM"
    ],
    "answer": "LoRA (Low-Rank Adaptation)",
    "why": "**LoRA**는 행렬 분해를 이용해 학습해야 할 파라미터 수를 획기적으로 줄인 대표적인 효율적 튜닝 기법입니다.",
    "hint": "로라(LoRA)라고 읽습니다.",
    "trap_points": [],
    "difficulty": "medium",
    "id": "6002"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "HuggingFace의 `peft` 라이브러리에서 LoRA 설정을 위한 클래스는 무엇입니까? 빈칸을 채우세요.\n\n```python\nfrom peft import ____, get_peft_model\n\n# LoRA 설정\nconfig = ____(\n    r=8,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n```",
    "answer": "LoraConfig",
    "why": "LoRA의 하이퍼파라미터를 설정하는 클래스는 `LoraConfig`입니다.",
    "hint": "LoRA + Config",
    "trap_points": [],
    "difficulty": "hard",
    "id": "6003"
  }
]