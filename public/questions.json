[
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬의 'type' 클래스가 자기 자신을 인스턴스로 가지면서도 동시에 모든 클래스의 베이스가 되는 'Metaclass' 메커니즘의 핵심 목적은?",
    "options": [
      "Abstract Base Class",
      "Class Factory",
      "MRO Resolution",
      "Dynamic Dispatch"
    ],
    "answer": "Class Factory",
    "why": "메타클래스는 클래스 자체를 생성하는 엔진(Class Factory) 역할을 하며, 클래스 정의 시점에 속성 검증이나 수정을 동적으로 수행하기 위해 존재합니다.",
    "hint": "클래스를 '찍어내는' 틀의 역할을 생각해보세요.",
    "trap_points": [
      "단순 상속 계층(MRO)과 클래스 생성 시점의 제어는 다른 차원의 문제임"
    ],
    "difficulty": "hard",
    "id": "0001"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 'Descriptor' 프로토콜을 구현할 때, __set__ 메서드만 구현하고 __get__을 생략한 클래스가 가지는 기술적 제약 사항은?",
    "options": [
      "Non-data Descriptor",
      "Read-only Property",
      "Data Descriptor Priority",
      "Attribute Lookup Error"
    ],
    "answer": "Data Descriptor Priority",
    "why": "__set__이나 __delete__ 중 하나라도 구현되면 Data Descriptor가 되며, 이는 인스턴스 딕셔너리(__dict__)의 값보다 우선순위를 가집니다. __get__이 없어도 이 우선순위 법칙은 유지됩니다.",
    "hint": "인스턴스 속성과 디스크립터 속성 간의 네임스페이스 우선순위를 떠올리세요.",
    "trap_points": [
      "__get__만 있으면 Non-data descriptor로 동작하며 우선순위가 낮음"
    ],
    "difficulty": "hard",
    "id": "0002"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "CPython의 GIL(Global Interpreter Lock) 환경에서 I/O Bound 작업이 아닌 CPU Bound 작업 시, multiprocessing이 threading보다 우월한 성능을 내는 구조적 근거는?",
    "options": [
      "Context Switching Avoidance",
      "Shared Memory Access",
      "Independent Address Space",
      "Cooperative Multitasking"
    ],
    "answer": "Independent Address Space",
    "why": "multiprocessing은 각각 독립된 주소 공간과 인터프리터 인스턴스를 가지므로 GIL의 제약 없이 멀티 코어를 병렬로 활용할 수 있습니다.",
    "hint": "프로세스 대 스레드의 자원 독립성을 생각하세요.",
    "trap_points": [
      "Context Switching은 모든 병렬 처리에서 발생하므로 GIL 회피의 근본 이유는 아님"
    ],
    "difficulty": "hard",
    "id": "0003"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 3.10에서 도입된 Structural Pattern Matching(match-case)에서 와일드카드 기호(_)가 다른 식별자와 구별되는 런타임상 특징은?",
    "options": [
      "Binding Avoidance",
      "Shadowing Priority",
      "Scope Extension",
      "Recursive Validation"
    ],
    "answer": "Binding Avoidance",
    "why": "패턴 매칭에서 언더바(_)는 값을 바인딩하지 않는 특수 기호로 처리되어, 메모리 공간을 차지하거나 기존 변수를 덮어쓰지 않습니다.",
    "hint": "변수에 값을 '담지 않는다'는 점에 주목하세요.",
    "trap_points": [
      "일반 변수 할당에서의 _와 match-case에서의 _는 의미론적으로 다름"
    ],
    "difficulty": "hard",
    "id": "0004"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `functools.lru_cache`를 적용할 때, 인자로 전달되는 객체가 'Hashable' 해야만 하는 내부적 설계 이유는?",
    "options": [
      "Binary Search Optimization",
      "Dictionary-based Lookup",
      "Immutability Enforcement",
      "Reference Counter Safety"
    ],
    "answer": "Dictionary-based Lookup",
    "why": "lru_cache는 내부적으로 딕셔너리를 사용하여 인자를 키(Key)로, 결과값을 값(Value)으로 저장하므로 해싱이 불가능한 객체는 키로 사용할 수 없습니다.",
    "hint": "캐시의 저장 구조가 '키-값' 쌍이라는 점을 생각하세요.",
    "trap_points": [
      "불변성(Immutability)은 해시 가능의 조건일 뿐, 캐시의 직접적인 설계 이유는 룩업 구조임"
    ],
    "difficulty": "hard",
    "id": "0005"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬에서 정규표현식 패턴이나 Windows 경로 작성 시 Raw String(r'') 접두사가 권장되는 근거로 가장 타당한 것은?",
    "options": [
      "Unicode Normalization",
      "Backslash Escape Suppression",
      "Regex Engine Optimization",
      "Binary Stream Handling"
    ],
    "answer": "Backslash Escape Suppression",
    "why": "Raw string은 백슬래시(\\)를 특수 문자가 아닌 일반 문자로 취급하여, 인터프리터 수준의 이스케이프 처리를 억제함으로써 정규표현식 엔진에 전달될 패턴의 왜곡을 방지합니다.",
    "hint": "역슬래시의 중복 이스케이프 문제를 생각하세요.",
    "trap_points": [
      "정규표현식 엔진 내부의 최적화와는 별개인 인터프리터 수준의 구문 분석 특징임"
    ],
    "difficulty": "hard",
    "id": "0006"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `weakref` 모듈을 활용하여 '약한 참조'를 구현할 때, 가비지 컬렉션(GC) 메커니즘 관점에서의 이득은?",
    "options": [
      "Reference Counter Skip",
      "Cyclic Dependency Elimination",
      "Memory Fragmentation Reduction",
      "Immediate Object Destruction"
    ],
    "answer": "Reference Counter Skip",
    "why": "약한 참조는 대상 객체의 레퍼런스 카운트를 증가시키지 않으므로, 객체가 더 이상 강한 참조를 갖지 않을 때 GC가 즉시 메모리를 회수할 수 있게 돕습니다.",
    "hint": "카운팅 기반의 메모리 관리 방식을 생각하세요.",
    "trap_points": [
      "순환 참조(Cyclic)는 여전히 존재할 수 있으나 회수를 방해하지 않게 될 뿐임"
    ],
    "difficulty": "hard",
    "id": "0007"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `heapq` 모듈이 유지하는 'Heap Invariant'에 따라 리스트의 0번째 인덱스(`heap[0]`)가 항상 보장하는 값은?",
    "options": [
      "Strict Sorted Order",
      "Minimum Element",
      "Maximum Leaf Node",
      "Median Reference"
    ],
    "answer": "Minimum Element",
    "why": "heapq는 최소 힙(Min-heap) 속성을 유지하며, 부모 노드의 값이 자식 노드의 값보다 작거나 같음을 보장하므로 루트 노드인 0번 인덱스에 항상 최솟값이 위치합니다.",
    "hint": "완전 이진 트리의 루트 노드 성질을 떠올리세요.",
    "trap_points": [
      "나머지 요소들이 완전히 정렬된 상태(Sorted order)를 유지하는 것은 아님"
    ],
    "difficulty": "hard",
    "id": "0008"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 리스트의 `sort()` 메서드 수행 시, 대규모 데이터셋에서 메모리 효율성 측면의 이득은 무엇인가?",
    "options": [
      "In-place Modification",
      "Lazy Evaluation",
      "New Object Allocation",
      "Global Lock Release"
    ],
    "answer": "In-place Modification",
    "why": "sort()는 기존 리스트의 포인터를 수정(In-place)하여 직접 정렬하므로, 정렬된 사본을 만드는 sorted()와 달리 추가적인 리스트 객체 생성 비용이 발생하지 않습니다.",
    "hint": "원본 데이터를 직접 건드리는지 사본을 만드는지의 차이입니다.",
    "trap_points": [
      "속도 측면의 차이보다는 메모리 오버헤드 관점에서의 명분을 요구함"
    ],
    "difficulty": "hard",
    "id": "0009"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 객체의 `__getattribute__`를 명시적으로 호출하는 대신 `getattr(obj, 'name')` 함수를 사용하는 주된 설계적 이점은?",
    "options": [
      "Method MRO Search",
      "Default Value Fallback",
      "Private Member Access",
      "Static Type Checking"
    ],
    "answer": "Default Value Fallback",
    "why": "getattr()은 세 번째 인자로 기본값을 설정할 수 있어, 속성 결여 시 AttributeError 예외를 발생시키지 않고 안전하게 처리할 수 있는 구조를 제공합니다.",
    "hint": "속성이 없을 때의 예외 처리 기능을 떠올리세요.",
    "trap_points": [
      "객체의 매직 메서드를 직접 호출하는 행위는 캡슐화와 안정성 측면에서 권장되지 않음"
    ],
    "difficulty": "hard",
    "id": "0010"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `itertools.combinations`가 대규모 데이터셋의 모든 조합을 생성할 때, 메모리 고갈(OOM)을 방지할 수 있는 내부적 구현 방식은?",
    "options": [
      "Lazy Evaluation",
      "In-place Buffering",
      "Context-free Parsing",
      "Dynamic Programming"
    ],
    "answer": "Lazy Evaluation",
    "why": "combinations는 제너레이터(Generator) 기반의 지연 평가를 활용하여 모든 조합을 메모리에 미리 적재하지 않고, 요청 시점에 순차적으로 생성하여 반환합니다.",
    "hint": "데이터를 한꺼번에 만들지 않고 필요할 때마다 생성하는 방식을 떠올리세요.",
    "trap_points": [
      "메모리 버퍼링과는 다른 개념인 이터레이터 프로토콜의 특성임"
    ],
    "difficulty": "hard",
    "id": "0011"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 표준 라이브러리 `urllib` 대비 `requests` 패키지가 HTTP 요청 성능 최적화를 위해 내부적으로 활용하는 핵심 기술은?",
    "options": [
      "Connection Pooling",
      "Binary Protocol",
      "Kernel Bypass",
      "Header Compression"
    ],
    "answer": "Connection Pooling",
    "why": "requests는 내부적으로 `urllib3`를 사용하여 연결 풀링(Connection Pooling)을 수행하므로, 동일 호스트에 대한 반복 요청 시 TCP 핸드셰이크 비용을 절감합니다.",
    "hint": "이미 연결된 소켓을 재사용하는 방식을 생각하세요.",
    "trap_points": [
      "단순한 API의 편의성이 아닌 하위 수준의 네트워크 자원 관리 방식에 대한 이해가 필요함"
    ],
    "difficulty": "hard",
    "id": "0012"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `asyncio` 기반 비동기 프로그래밍에서 `await` 키워드가 호출되었을 때, 이벤트 루프(Event Loop)에서 발생하는 런타임 제어권의 변화는?",
    "options": [
      "Context Switching",
      "Coroutine Suspension",
      "Thread Spawning",
      "System Call Blocking"
    ],
    "answer": "Coroutine Suspension",
    "why": "await는 현재 코루틴의 실행을 일시 중단(Suspension)하고 제어권을 이벤트 루프에 반환하여, 다른 대기 중인 작업을 처리할 수 있도록 협력적 멀티태스킹을 수행합니다.",
    "hint": "제어권이 루프로 돌아가면서 현재 작업이 어떤 상태가 되는지 생각하세요.",
    "trap_points": [
      "OS 수준의 Context Switching과는 다른 사용자 공간에서의 코루틴 상태 전이임"
    ],
    "difficulty": "hard",
    "id": "0013"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 클래스에서 `@classmethod`를 사용하여 팩토리 메서드를 구현할 때, 상속 구조에서 `@staticmethod` 대비 보장되는 아키텍처적 이득은?",
    "options": [
      "Instance Binding",
      "Subclass Polymorphism",
      "Static Type Safety",
      "Namespace Isolation"
    ],
    "answer": "Subclass Polymorphism",
    "why": "classmethod는 첫 번째 인자로 현재 클래스(cls)를 전달받으므로, 상속받은 자식 클래스에서 호출 시 자식 클래스의 인스턴스를 올바르게 생성하는 다형성을 보장합니다.",
    "hint": "부모 클래스의 메서드가 자식 클래스 정보를 알고 있는지에 집중하세요.",
    "trap_points": [
      "staticmethod는 클래스 정보를 알 수 없으므로 자식 클래스에서의 팩토리 패턴 구현에 제약이 있음"
    ],
    "difficulty": "hard",
    "id": "0014"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `pickle` 모듈을 사용하여 신뢰할 수 없는 출처로부터 바이너리 데이터를 역직렬화(Unpickling)할 때 발생하는 가장 심각한 보안 위험은?",
    "options": [
      "Buffer Overflow",
      "Arbitrary Code Execution",
      "Data Corruption",
      "Memory Leakage"
    ],
    "answer": "Arbitrary Code Execution",
    "why": "pickle 프로토콜은 객체 복원 과정에서 `__reduce__` 등을 통해 임의의 함수 호출을 허용하므로, 악의적으로 조작된 피클 데이터는 시스템 명령어 실행(RCE)으로 이어질 수 있습니다.",
    "hint": "바이러스나 악성 코드가 어떻게 실행될 수 있는지 생각하세요.",
    "trap_points": [
      "단순히 데이터가 깨지는(Corruption) 수준을 넘어선 런타임 제어권 탈취의 위험성임"
    ],
    "difficulty": "hard",
    "id": "0015"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `sum()` 함수가 대규모 숫자 리스트를 합산할 때, 반복문을 통한 수동 합산 대비 성능적 우위를 점하는 주된 기술적 명분은?",
    "options": [
      "C-level Loop Execution",
      "SIMD Instruction Usage",
      "Parallel Thread Dispatch",
      "JIT Compilation"
    ],
    "answer": "C-level Loop Execution",
    "why": "sum() 함수는 내부적으로 C 언어로 구현된 루프(Built-in function)를 사용하므로, 파이썬 인터프리터 수준의 오버헤드 없이 고속으로 연산을 수행합니다.",
    "hint": "파이썬 코드와 내장 함수의 구현 언어 차이를 생각하세요.",
    "trap_points": [
      "단독 스레드에서 동작하며, 기본적으로 멀티스레딩이나 SIMD를 강제하지는 않음"
    ],
    "difficulty": "hard",
    "id": "0016"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 3.7 이후 딕셔너리(dict) 아키텍처가 재설계되면서 얻게 된 '삽입 순서 유지' 특징의 구현상 핵심 변경점은?",
    "options": [
      "Linked List Inclusion",
      "Compact Array Storage",
      "B-Tree Integration",
      "Sorted Bucket Strategy"
    ],
    "answer": "Compact Array Storage",
    "why": "재설계된 딕셔너리는 해시 테이블과 별도로 실제 데이터를 삽입 순서대로 저장하는 조밀한 배열(Compact array)을 유지함으로써 메모리 사용량을 줄이고 순서를 보장합니다.",
    "hint": "데이터가 어떻게 '촘촘하게' 저장되는지 생각해보세요.",
    "trap_points": [
      "기존의 OrderedDict가 사용하던 양방향 연결 리스트(Linked list) 방식과는 다른 구조임"
    ],
    "difficulty": "hard",
    "id": "0017"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "BeautifulSoup HTML 파싱 시, 복잡한 트리 구조에서 특정 패턴의 모든 요소를 가장 효율적으로 추출하기 위해 권장되는 방법은?",
    "options": [
      "Linear Tag Iteration",
      "CSS Selector Mapping",
      "Regex Tag Matching",
      "XPath Query Execution"
    ],
    "answer": "CSS Selector Mapping",
    "why": "soup.select()가 사용하는 CSS 선택자 엔진은 트리 구조를 선형적으로 탐색하는 것보다 복잡한 관계형 조건을 고속으로 처리하는 데 최적화되어 있습니다.",
    "hint": "웹 개발에서 스타일을 정의할 때 쓰는 도구를 떠올리세요.",
    "trap_points": [
      "find_all()은 속도가 빠를 수 있으나 표현력 면에서 select()가 계층 구조 파악에 유리함"
    ],
    "difficulty": "hard",
    "id": "0018"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 문자열 메서드 `isdigit()`이 '①'이나 '²', '³'와 같은 특수 숫자를 구분하는 내부적 기준은?",
    "options": [
      "ASCII Range Filter",
      "Unicode Category Classification",
      "Integer Casting Success",
      "Bitmask Validation"
    ],
    "answer": "Unicode Category Classification",
    "why": "isdigit()은 유니코드 표준의 Numeric Type 범주를 따르므로, 일반 아라비아 숫자뿐만 아니라 유니코드상의 다양한 숫자형 문자들을 True로 판별합니다.",
    "hint": "단순히 0-9 값만 체크하는 것이 아닌 전 세계 문자를 다루는 체계를 생각하세요.",
    "trap_points": [
      "isdecimal()은 0-9의 기본 아라비아 숫자만 엄격하게 검사함"
    ],
    "difficulty": "hard",
    "id": "0019"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `os` 모듈의 절차적 파일 시스템 함수 대신 객체 지향적인 `pathlib` 사용이 권장되는 주된 설계적 명분은?",
    "options": [
      "String-less Path Manipulation",
      "Kernel Thread Safety",
      "Memory Mapping Optimization",
      "Native Binary Parsing"
    ],
    "answer": "String-less Path Manipulation",
    "why": "pathlib은 경로를 단순 문자열이 아닌 추상화된 객체(Path)로 다룸으로써, 운영체제 독립적인 메서드 호출과 코드 가독성을 보장합니다.",
    "hint": "경로가 더 이상 '글자'가 아니라는 점에 주목하세요.",
    "trap_points": [
      "단순히 성능이 빨라지는 것이 아니라 유지보수와 설계의 질적 향상에 초점이 있음"
    ],
    "difficulty": "hard",
    "id": "0020"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `sorted()` 함수가 내부적으로 사용하는 'Timsort' 알고리즘이 Real-world 데이터셋에서 퀵 정렬(Quicksort)보다 유리한 성능을 보이는 수리적 근거는?",
    "options": [
      "Adaptive Merging Strategy",
      "Pivot Selection Stability",
      "In-place Memory Utilization",
      "Divide and Conquer Depth"
    ],
    "answer": "Adaptive Merging Strategy",
    "why": "Timsort는 데이터 내에 이미 존재하는 정렬된 부분(Runs)을 찾아 이를 적응적으로 병합(Adaptive merging)하므로, 부분적으로 정렬된 실제 데이터에서 매우 효율적입니다.",
    "hint": "데이터가 이미 어느 정도 정렬되어 있는 경우를 활용하는 방식을 생각해보세요.",
    "trap_points": [
      "Timsort는 병합 정렬(Merge Sort)과 삽입 정렬(Insertion Sort)의 하이브리드 방식임"
    ],
    "difficulty": "hard",
    "id": "0021"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 딕셔너리에서 `dict[key]` 접근 대신 `dict.get(key, default)`을 사용했을 때의 런타임상 주요 차이점은?",
    "options": [
      "KeyError Suppression",
      "Hash Collision Resolution",
      "Namespace Lookup Speed",
      "Reference Counter Increase"
    ],
    "answer": "KeyError Suppression",
    "why": "get() 메서드는 키가 존재하지 않을 때 KeyError 예외를 발생시키지 않고 지정된 기본값(또는 None)을 반환하여 프로그램의 비정상 종료를 방지합니다.",
    "hint": "예외 처리 구문 없이 안전하게 데이터를 가져오는 법을 생각하세요.",
    "trap_points": [
      "성능상의 유의미한 이득보다는 코드의 안정성과 가독적인 예외 처리에 중점이 있음"
    ],
    "difficulty": "hard",
    "id": "0022"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "대규모 데이터 집합에서 `list` 대신 `set`을 사용하여 특정 요소의 포함 여부(`in` 연산)를 검사할 때 얻게 되는 시간 복잡도(Time Complexity)적 이득은?",
    "options": [
      "O(1) Constant Time",
      "O(log N) Logarithmic",
      "O(N) Linear Scan",
      "O(N log N) Sort-search"
    ],
    "answer": "O(1) Constant Time",
    "why": "set은 해시 테이블(Hash Table) 기반으로 구현되어 있어, 요소의 개수와 상관없이 평균적으로 상수 시간(O(1)) 내에 요소의 존재 여부를 판단할 수 있습니다.",
    "hint": "리스트는 처음부터 끝까지 다 뒤져야 하지만, 집합은 바로 찾아갈 수 있는 지도가 있습니다.",
    "trap_points": [
      "최악의 경우 해시 충돌(Collision)로 인해 성능이 저하될 수 있으나 일반적으로 O(1)로 간주함"
    ],
    "difficulty": "hard",
    "id": "0023"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "다중 상속 구조에서 `super()`를 통해 부모 클래스의 메서드를 호출할 때, 파이썬이 호출 대상의 우선순위를 결정하는 정교한 알고리즘은?",
    "options": [
      "Depth-First Search",
      "C3 Linearization (MRO)",
      "Breadth-First Search",
      "Alphabetical Resolution"
    ],
    "answer": "C3 Linearization (MRO)",
    "why": "파이썬은 C3 선형화(Linearization) 알고리즘을 사용하여 결정된 메서드 결정 순서(MRO)를 따르며, 이를 통해 다이아몬드 상속 문제 등을 논리적으로 해결합니다.",
    "hint": "클래스의 계층 구조를 일직선으로 펴는 방식을 생각하세요.",
    "trap_points": [
      "단순한 깊이 우선 탐색(DFS)은 과거 파이썬에서 사용되었으나 현재는 C3를 표준으로 함"
    ],
    "difficulty": "hard",
    "id": "0024"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 문자열 `strip()` 메서드에 인자를 전달하여 특정 문자군을 제거할 때, 내부적으로 수행되는 처리 방식의 특징으로 옳은 것은?",
    "options": [
      "Exact Substring Match",
      "Set-based Character Stripping",
      "Sequential Pattern Removal",
      "Regex-engine Evaluation"
    ],
    "answer": "Set-based Character Stripping",
    "why": "strip()의 인자는 부분 문자열이 아닌 개별 문자들의 집합(Set)으로 취급되어, 양 끝단에서 해당 집합에 포함된 문자가 나타나지 않을 때까지 모두 제거합니다.",
    "hint": "인자로 준 글자들이 '팀'으로 움직이는지 아니면 '낱개'로 움직이는지 생각하세요.",
    "trap_points": [
      "인자로 'abc'를 주면 'abc'라는 단어 자체를 찾는 것이 아니라 a, b, c 중 하나라도 있으면 지움"
    ],
    "difficulty": "hard",
    "id": "0025"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `@property` 데코레이터가 내부적으로 구현하는 디자인 패턴이자, 메서드를 클래스 속성처럼 접근하게 만드는 핵심 프로토콜은?",
    "options": [
      "Strategy Pattern",
      "Descriptor Protocol",
      "Observer Pattern",
      "Single Responsibility"
    ],
    "answer": "Descriptor Protocol",
    "why": "property는 내부적으로 `__get__`, `__set__` 등을 구현한 디스크립터(Descriptor) 클래스를 생성하여, 단순 함수 호출을 속성 접근 인터페이스로 추상화합니다.",
    "hint": "객체의 속성 접근 방식을 제어하는 저수준 프로토콜을 떠올리세요.",
    "trap_points": [
      "단순히 'Setter' 기능을 제공하는 것을 넘어선 파이썬 데이터 모델의 핵심 메커니즘임"
    ],
    "difficulty": "hard",
    "id": "0026"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `enumerate()` 함수가 반환하는 객체의 런타임상 주요 특징으로 가장 적절한 것은?",
    "options": [
      "List of Tuples",
      "Generator-based Iterator",
      "Ordered Dictionary View",
      "Static Array Indexing"
    ],
    "answer": "Generator-based Iterator",
    "why": "enumerate()는 모든 인덱스-값 쌍을 즉시 생성하지 않고, 이터레이터 포괄(Iterator protocol)을 통해 호출 시점에만 하나씩 생성하여 반환하므로 메모리 효율적입니다.",
    "hint": "루프를 돌 때마다 하나씩 '뽑아주는' 도구의 속성을 생각하세요.",
    "trap_points": [
      "결과를 리스트로 변환하기 전까지는 실제 데이터를 메모리에 적재하지 않음"
    ],
    "difficulty": "hard",
    "id": "0027"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `list.extend()`와 `list + list`를 통한 리스트 병합 시, 메모리 할당 관점에서의 근본적인 차이는?",
    "options": [
      "In-place Mutation vs New Allocation",
      "Shallow Copy vs Deep Copy",
      "Lazy Evaluation vs Eager Execution",
      "Reference Counter vs Bitwise Copy"
    ],
    "answer": "In-place Mutation vs New Allocation",
    "why": "extend()는 기존 리스트 객체의 메모리를 확장하여 값을 추가(In-place)하지만, 더하기 연산(+)은 두 리스트를 합친 완전히 새로운 리스트 객체를 할당합니다.",
    "hint": "기존 바구니를 늘리는 것인지, 새 바구니를 사는 것인지의 차이입니다.",
    "trap_points": [
      "메모리 효율성 측면에서 대규모 리스트 병합 시 extend()가 훨씬 유리함"
    ],
    "difficulty": "hard",
    "id": "0028"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "함수 내부에서 외부 스코프의 변수를 참조(Read)하는 것은 가능하나, `global` 선언 없이 수정(Write)하려 할 때 발생하는 현상의 근본 원인은?",
    "options": [
      "Shadowing of Local Scope",
      "Immutability of Global Table",
      "Stack Overflow Exception",
      "Closure Reference Error"
    ],
    "answer": "Shadowing of Local Scope",
    "why": "함수 내부에서 값을 할당하려 하면 파이썬은 이를 로컬 변수로 간주(Shadowing)하며, 전역 변수와 동일한 이름의 로컬 변수를 새로 생성하기 때문에 외부 전역 변수가 수정되지 않습니다.",
    "hint": "파이썬이 이름표(Name)를 어디서 먼저 찾는지(LEGB 규칙)를 생각하세요.",
    "trap_points": [
      "단순한 권한 문제가 아니라 컴파일 시점의 변수 바인딩 규칙에 의한 것임"
    ],
    "difficulty": "hard",
    "id": "0029"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 3에서 `dict.keys()`가 반환하는 객체의 주요 기술적 특징으로 옳은 것은?",
    "options": [
      "Dynamic Dictionary View",
      "Static Snapshot List",
      "Immutable Tuple Copy",
      "Hash-ordered Array"
    ],
    "answer": "Dynamic Dictionary View",
    "why": "반환된 뷰(View) 객체는 원본 딕셔너리와 연결되어 있어, 딕셔너리의 내용이 변경되면 뷰 객체의 내용도 실시간으로 반영됩니다.",
    "hint": "복사본이 아니라 '거울'처럼 원본을 비춰준다는 점을 생각하세요.",
    "trap_points": [
      "파이썬 2에서는 리스트 복사본을 반환했으나 3에서는 메모리 절약을 위해 뷰 방식을 사용함"
    ],
    "difficulty": "hard",
    "id": "0030"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬의 '동적 타이핑(Dynamic Typing)' 환경에서 코드의 유연성을 극대화하기 위해 채택하는 'Duck Typing' 철학의 핵심 메커니즘은?",
    "options": [
      "Explicit Interface Inheritance",
      "Attribute presence validation at Runtime",
      "Static Type Inference",
      "Nominal Type Matching"
    ],
    "answer": "Attribute presence validation at Runtime",
    "why": "파이썬은 객체의 특정 타입(Class)을 상속받았는지 검사하기보다, 실행 시점(Runtime)에 해당 객체가 필요한 속성이나 메서드를 가지고 있는지(Duck typing)에 집중하여 유연성을 확보합니다.",
    "hint": "객체가 '무엇인가'보다 '무엇을 할 수 있는가'에 집중하는 방식을 생각하세요.",
    "trap_points": [
      "전통적인 상속(Inheritance) 구조 없이도 다형성(Polymorphism)을 구현할 수 있게 함"
    ],
    "difficulty": "hard",
    "id": "0031"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 리스트(list)와 달리 튜플(tuple)이 불변성(Immutability)을 가짐으로써 얻게 되는 기술적 이점과 활용 제약은?",
    "options": [
      "Hashability for Dictionary Keys",
      "Dynamic Size Expansion",
      "In-place Append Efficiency",
      "Reference Memory Reduction"
    ],
    "answer": "Hashability for Dictionary Keys",
    "why": "튜플은 내용이 변경되지 않음이 보장되므로 해시 값을 생성할 수 있으며(Hashable), 이를 통해 딕셔너리의 키나 세트의 요소로 사용될 수 있습니다.",
    "hint": "변경이 불가능한 객체만이 '고유함'을 증명하는 해시 값을 가질 수 있다는 원리를 떠올리세요.",
    "trap_points": [
      "튜플 내부의 가변 객체(리스트 등)가 포함된 경우 전체 튜플은 Hashable하지 않게 됨"
    ],
    "difficulty": "hard",
    "id": "0032"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "함수 정의 시 가변 인자 `*args`를 사용하여 인수를 전달받을 때, 파이썬 인터프리터 수준에서 일어나는 데이터 구조의 변화는?",
    "options": [
      "Positional Argument Tuple Packing",
      "Keyword Argument Dictionary Mapping",
      "Generator Object Encapsulation",
      "Immutable Buffer Allocation"
    ],
    "answer": "Positional Argument Tuple Packing",
    "why": "*args는 정해지지 않은 수의 위치 기반 인수(Positional arguments)들을 하나의 튜플(Tuple)로 묶어서(Packing) 함수 내부로 전달합니다.",
    "hint": "여러 개의 낱개 인자들이 함수 안으로 들어올 때 어떤 '주머니'에 담기는지 생각하세요.",
    "trap_points": [
      "**kwargs는 딕셔너리 형태로 패킹되므로 *args와는 다른 차원에서 동작함"
    ],
    "difficulty": "hard",
    "id": "0033"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `with` 문에서 활용하는 컨텍스트 매니저(Context Manager) 프로토콜이 보장하는 결정적인 자원 관리 전략은?",
    "options": [
      "RAII (Resource Acquisition Is Initialization)",
      "Lazy Loading Optimization",
      "Immediate Garbage Collection",
      "Deterministic Deadlock Prevention"
    ],
    "answer": "RAII (Resource Acquisition Is Initialization)",
    "why": "컨텍스트 매니저는 `__enter__`에서 자원을 획득하고 `__exit__`에서 자원을 확정적으로 해제함으로써, 예외 발생 여부와 상관없이 자원 누수를 방지하는 RAII 패턴을 구현합니다.",
    "hint": "객체의 생성과 소멸에 맞춰 자원을 자동으로 관리하는 C++의 고전적 기법을 떠올리세요.",
    "trap_points": [
      "단순히 코드를 줄이는 문법적 설탕(Syntactic sugar)을 넘어선 자원 수명 주기 관리 기법임"
    ],
    "difficulty": "hard",
    "id": "0034"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 클래스 내에서 인스턴스 메서드를 통해 클래스 변수를 수정하려 할 때, `self.variable = value` 구문이 야기하는 예기치 못한 부작용은?",
    "options": [
      "Creation of Shadowing Instance Attribute",
      "Global Namespace Corruption",
      "Thread Competency Deadlock",
      "MRO Pointer Invalidation"
    ],
    "answer": "Creation of Shadowing Instance Attribute",
    "why": "self를 통해 할당 연산을 수행하면 클래스 변수를 수정하는 대신, 해당 인스턴스 전용의 새로운 속성을 생성하여 클래스 변수를 가리는(Shadowing) 현상이 발생합니다.",
    "hint": "클래스 전체가 공유하던 주머니 대신, 나만의 작은 주머니를 새로 만들게 된다는 점에 주목하세요.",
    "trap_points": [
      "클래스 변수를 공통으로 수정하려면 `ClassName.variable` 형식을 사용해야 함"
    ],
    "difficulty": "hard",
    "id": "0035"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬의 설계 철학 중 'LBYL(Look Before You Leap)' 대비 `try-except`를 선호하는 'EAFP' 방식의 핵심 논거는?",
    "options": [
      "Condition Atomicity and Performance",
      "Compile-time Type Safety",
      "Memory Footprint Optimization",
      "Linear Execution Predictability"
    ],
    "answer": "Condition Atomicity and Performance",
    "why": "가정(Assumption) 하에 코드를 실행하고 예외 시에만 처리하는 방식은, 매번 조건(if)을 체크하는 오버헤드를 줄이고 경쟁 상태(Race condition)에서의 원자성을 보장하기 유리합니다.",
    "hint": "이미 일어날 확률이 높은 상황을 굳이 매번 '검사'할 필요가 있는지 생각해보세요.",
    "trap_points": [
      "EAFP(Easier to Ask Forgiveness than Permission)는 파이썬에서 매우 권장되는 코딩 스타일임"
    ],
    "difficulty": "hard",
    "id": "0036"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 루프 제어에서 `continue`가 호출되었을 때, 인터프리터 수준에서 스킵(Skip)되는 실행 단위는?",
    "options": [
      "Remaining Lines of Current Iteration",
      "Entire Loop Block Execution",
      "Internal Pointer Increment",
      "Exception Handler Registration"
    ],
    "answer": "Remaining Lines of Current Iteration",
    "why": "continue는 현재 반복(Iteration)의 아래에 남은 코드들을 무시하고, 즉시 루프의 다음 회차 평가 단계로 제어권을 넘깁니다.",
    "hint": "한 '바퀴'를 다 돌지 않고 바로 다음 '바퀴'로 건너뛰는 상황을 떠올리세요.",
    "trap_points": [
      "루프 자체를 끝내는 break와 루프의 코드 일부만 건너뛰는 continue를 정확히 구분해야 함"
    ],
    "difficulty": "hard",
    "id": "0037"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 PEP 8 스타일 가이드에서 상수를 ALL_CAPS로 명명할 것을 권장함에도 불구하고, 이것이 실제 런타임상에서 상수의 불변성(Immutability)을 보장하지 못하는 근거는?",
    "options": [
      "Lack of Lexical Constness",
      "Dynamic Attribute Binding",
      "Global Namespace Flexibility",
      "Interpreter Soft-link System"
    ],
    "answer": "Lack of Lexical Constness",
    "why": "파이썬 언어 자체에는 C++나 Java의 `const`, `final`처럼 변수의 재할당을 문법적으로 금지하는 기능이 없으므로, 대문자 표기는 개발자 간의 규약(Convention)일 뿐입니다.",
    "hint": "문법적인 장치가 아닌, 사람끼리의 '약속'이라는 점에 주목하세요.",
    "trap_points": [
      "상수처럼 쓰고 싶다면 별도의 커스텀 클래스나 래퍼를 만들어야 강제성이 생김"
    ],
    "difficulty": "hard",
    "id": "0038"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "상속 구조에서 부모 클래스의 메서드를 자식 클래스에서 재정의(Overriding)할 때, 객체 지향의 'Open-Closed Principle'을 준수하기 위해 지켜야 할 부모-자식 간의 규칙은?",
    "options": [
      "Signature Compatibility",
      "Private Member Shadowing",
      "Static Bound Resolution",
      "Memory Address Alignment"
    ],
    "answer": "Signature Compatibility",
    "why": "오버라이딩 시 메서드의 시그니처(인자의 수와 타입)를 호환 가능하게 유지해야, 부모 타입을 사용하는 코드에서 자식 인스턴스를 원활하게 사용하는 리스코프 치환 원칙을 지킬 수 있습니다.",
    "hint": "겉모양(인터페이스)은 그대로 둔 채 내용물만 바꾸는 상황을 생각하세요.",
    "trap_points": [
      "단순히 덮어쓰는 것 이상의 설계적 정합성이 요구됨"
    ],
    "difficulty": "hard",
    "id": "0039"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 패키지 관리자 `pip`가 패키지 설치 시 `setup.py`를 직접 실행하는 방식 대비 'Wheel(.whl)' 바이너리를 우선적으로 설치함으로써 얻는 이점은?",
    "options": [
      "Avoidance of Local Compilation",
      "Global Variable Registry Protection",
      "Deterministic Conflict Resolution",
      "Source Code Encryption"
    ],
    "answer": "Avoidance of Local Compilation",
    "why": "Wheel은 이미 빌드된 바이너리 아티팩트이므로, 설치 시점에 컴파일러나 빌드 도구가 필요하지 않아 설치 속도가 빠르고 환경 의존성을 최소화합니다.",
    "hint": "이미 요리된(Build) 음식을 가져오는 것과 재료를 사서 집에서 요리하는 것의 차이를 생각하세요.",
    "trap_points": [
      "Python 3 패키징 표준으로 정착된 효율적인 배포 방식임"
    ],
    "difficulty": "hard",
    "id": "0040"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `copy.deepcopy()`가 중첩된 가변 객체를 복제할 때, 일반적인 얕은 복사(Shallow Copy)와 차별화되는 메모리 관리적 특징은?",
    "options": [
      "Recursive Object Reference Creation",
      "Linear Address Pointer Copy",
      "Global Interpreter Lock Release",
      "Immediate Reference Count Incrementation"
    ],
    "answer": "Recursive Object Reference Creation",
    "why": "deepcopy()는 객체 내부에 포함된 모든 자식 객체들까지 재귀적으로(Recursive) 추적하여 완전히 새로운 독립적인 메모리 주소에 복제본을 생성합니다.",
    "hint": "복사가 객체의 '겉모습'만 하는지, 아니면 '속 깊숙이'까지 들어가는지를 생각하세요.",
    "trap_points": [
      "단순 리스트 복사는 내부 리스트의 참조 주소까지는 보호하지 못함을 간과해서는 안 됨"
    ],
    "difficulty": "hard",
    "id": "0041"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 제너레이터(Generator)가 대용량 스트리밍 데이터 처리에서 메모리 효율성을 보장하는 핵심 런타임 메커니즘은?",
    "options": [
      "Lazy Evaluation via yield",
      "Batch Processing Buffer",
      "Immediate Stack Unrolling",
      "Static Memory Pre-allocation"
    ],
    "answer": "Lazy Evaluation via yield",
    "why": "제너레이터는 `yield` 키워드를 통해 한 번에 하나의 요소만 실행 시점(Runtime)에 생성하여 반환(Lazy evaluation)함으로써, 데이터 전체를 물리 메모리에 적재하지 않습니다.",
    "hint": "데이터를 한 줄씩 '그때그때' 읽어오는 도서관 사서의 역할을 떠올리세요.",
    "trap_points": [
      "제너레이터는 상태(State)를 보존하지만, 데이터 자체를 리스트처럼 미리 점유하지는 않음"
    ],
    "difficulty": "hard",
    "id": "0042"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 데코레이터(Decorator)가 기존 함수에 추가 기능을 주입할 때 활용하는 하위 수준의 프로그래밍 개념은?",
    "options": [
      "Closure and High-order functions",
      "Global Variable Shadowing",
      "Binary Opcode Modification",
      "Dynamic Library Linkage"
    ],
    "answer": "Closure and High-order functions",
    "why": "데코레이터는 함수를 인자로 받아 내부에서 새로운 함수(Closure)를 정의하고 반환하는 고차 함수(High-order function)의 특성을 이용하여 런타임에 동적으로 기능을 확장합니다.",
    "hint": "함수 안에 함수가 숨어 있고, 그 함수가 외부 변수를 기억하는 방식을 떠올리세요.",
    "trap_points": [
      "단순한 문법적 설탕(Syntactic sugar)이 아닌, 파이썬의 일급 객체(First-class object) 성질을 극대화한 것임"
    ],
    "difficulty": "hard",
    "id": "0043"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "검색 성격의 작업에서 `list` 대신 `set`을 사용했을 때, 대규모 데이터셋(N이 매우 큼)에서 압도적인 성능 우위를 보이는 기술적 근거는?",
    "options": [
      "Hashing and Bucket Direct Access",
      "Binary Search Progression",
      "Sequential Pointer Traversal",
      "Dynamic List Resizing"
    ],
    "answer": "Hashing and Bucket Direct Access",
    "why": "세트는 해싱(Hashing)을 통해 데이터를 특정 버킷(Bucket)에 매핑하므로, 연산 횟수가 요소 개수(N)와 무관하게 평균적으로 일정하게 유지되는 O(1) 성능을 제공합니다.",
    "hint": "처음부터 끝까지 하나씩 맞춰보는 것과 번호를 알면 바로 찾아가는 것의 차이를 생각하세요.",
    "trap_points": [
      "리스트 역시 인덱스 접근은 빠르지만, 특정 '값'을 찾는 행위는 선형 탐색(O(N))을 피할 수 없음"
    ],
    "difficulty": "hard",
    "id": "0044"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 객체의 문자열 표현을 정의할 때 `__str__` 대비 `__repr__`이 갖는 기술적 엄격함과 지향점은?",
    "options": [
      "Unambiguous Object Reconstruction",
      "Human-Friendly Natural Language",
      "Internationalization Formatting",
      "Memory Address Alignment"
    ],
    "answer": "Unambiguous Object Reconstruction",
    "why": "repr()은 개발자가 해당 객체를 다시 생성할 수 있을 정도의 명확하고 모호함 없는(Unambiguous) 정보 출력을 목적으로 하며, 디버깅 도구 등에서 기본적으로 활용됩니다.",
    "hint": "객체의 '인상'을 보여주는 것과 객체의 '설계 정보'를 보여주는 것의 차이를 떠올리세요.",
    "trap_points": [
      "__str__이 정의되지 않았을 때 파이썬은 대체제로 __repr__을 호출하지만, 그 반대는 성립하지 않음"
    ],
    "difficulty": "hard",
    "id": "0045"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 3.10의 'Structural Pattern Matching'이 기존의 단순 C-style switch 문과 차별화되는 강력한 기능적 명분은?",
    "options": [
      "Destructuring of Complex Objects",
      "Linear Branching Optimization",
      "Static Global Entry Check",
      "Namespace Collision Prevention"
    ],
    "answer": "Destructuring of Complex Objects",
    "why": "match-case 문은 값을 비교할 뿐만 아니라 리스트, 딕셔너리, 클래스 인스턴스 등의 내부 구조를 해체(Destructuring)하고 변수에 바로 바인딩할 수 있는 패러다임을 제공합니다.",
    "hint": "데이터의 '모양'을 보고 해당 모양 안의 속성값들을 바로 꺼낼 수 있는지 생각해보세요.",
    "trap_points": [
      "가독성 향상을 넘어 데이터 구조 분해와 결합된 조건 처리가 핵심임"
    ],
    "difficulty": "hard",
    "id": "0046"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "문자열 곱셈 연산(`'S' * 100`)을 통해 대규모 버퍼를 생성할 때, 인터프리터 수준에서 발생할 수 있는 잠재적 리스크는?",
    "options": [
      "Memory Allocation Fragmentation",
      "Type Casting Overhead",
      "Global Variable Shadowing",
      "Bytecode Compilation Error"
    ],
    "answer": "Memory Allocation Fragmentation",
    "why": "반복적인 문자열 생성이 아닌 단일 곱셈 연산이라도, 결과값이 물리 메모리 한계를 넘어서거나 빈번하게 발생할 경우 힙(Heap) 영역의 메모리 파편화(Fragmentation)를 유발할 수 있습니다.",
    "hint": "메모리가 '찢어지고 흩어지는' 현상을 떠올리세요.",
    "trap_points": [
      "사소한 곱하기 연산이라도 데이터 규모에 따라 시스템 전체 자원에 영향을 줄 수 있음을 간과하면 안 됨"
    ],
    "difficulty": "hard",
    "id": "0047"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `pip` 환경에서 `requirements.txt` 정의 시 오픈소스 취약점 대응 및 예측 가능한 빌드(Reproducible Build)를 위한 최선의 버전 명시 전략은?",
    "options": [
      "Strict Equality (==)",
      "Compatibility Release (~=)",
      "Greater-than constraint (>=)",
      "Latest Wildcard (*)"
    ],
    "answer": "Strict Equality (==)",
    "why": "정확한 버전(==)을 명시해야만 배포 환경 간의 라이브러리 차이로 인한 예기치 못한 동작이나 보안 패치 누락, 종속성 충돌을 완벽하게 통제할 수 있습니다.",
    "hint": "어디서든 '똑같이' 동작해야 한다는 점을 가장 우선하세요.",
    "trap_points": [
      ">= 와 같은 표현은 새 버전 릴리스 시 예기치 못한 하위 호환성 파괴가 발생할 위험이 큼"
    ],
    "difficulty": "hard",
    "id": "0048"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `collections.defaultdict`이 빈도 계산(Counting) 등의 알고리즘 구현 시 일반 `dict` 대비 코드의 원자성(Atomicity)을 높여주는 설계적 명분은?",
    "options": [
      "In-place Key Initialization",
      "Lock-free Mutability",
      "Global Variable Registry",
      "Automatic Garbage Flushing"
    ],
    "answer": "In-place Key Initialization",
    "why": "defaultdict은 키 존재 여부를 확인(Check)하고 생성(Creation)하는 두 단계를 내부적으로 통합(In-place)하여 처리함으로써 예외 상황을 원천 차단하고 논리를 간결하게 만듭니다.",
    "hint": "방에 손님이 있는지 물어보고 열쇠를 주는 대신, 그냥 들어가면 알아서 침대가 생겨 있는 상황을 떠올리세요.",
    "trap_points": [
      "단순히 코드가 짧아지는 것에 그치지 않고 KeyError를 핸들링하는 부가 로직을 제거함"
    ],
    "difficulty": "hard",
    "id": "0049"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "다중 상속 구조에서 파이썬의 'C3 Linearization' 알고리즘이 MRO를 결정할 때 가장 우선적으로 지키고자 하는 논리적 원칙은?",
    "options": [
      "Monotonicity and Local Precedence",
      "Depth-First Stack Unwinding",
      "Alphabetical Name Resolution",
      "Instance Reference Count"
    ],
    "answer": "Monotonicity and Local Precedence",
    "why": "C3 알고리즘은 단조성(Monotonicity)을 유지하여 부모 클래스의 상속 순서를 보존하고, 지역 우선순위(Local Precedence)를 통해 다이아몬드 상속의 모순을 해결합니다.",
    "hint": "부모님이 정해준 순서가 바귀지 않으면서도 나랑 가장 가까운 쪽을 먼저 본다는 원리입니다.",
    "trap_points": [
      "오래된 DFS 방식의 MRO가 가진 모호성을 해결하기 위해 도입된 현대적 명세임"
    ],
    "difficulty": "hard",
    "id": "0050"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 리스트 슬라이싱 `list[::-1]`이 역순 정렬 메서드 `list.reverse()`와 차별화되는 근본적인 런타임 결과는 무엇인가?",
    "options": [
      "New Object Allocation",
      "In-place Reordering",
      "Iterator-only Generation",
      "Reference Counter Reduction"
    ],
    "answer": "New Object Allocation",
    "why": "슬라이싱은 원본 리스트를 건드리지 않고 요소를 역순으로 담은 완전히 새로운 리스트 객체를 생성(Allocation)하여 반환합니다.",
    "hint": "원본이 바뀌는지, 아니면 새 결과물이 나오는지에 집중하세요.",
    "trap_points": [
      "reverse()는 반환값이 None이며 원본을 직접 수정하므로 메모리 사용 면에서 더 효율적일 수 있음"
    ],
    "difficulty": "hard",
    "id": "0051"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 'Iterable Unpacking' (예: `a, *b, c = [1, 2, 3, 4]`) 구문에서 별표(`*`) 연산자가 수행하는 핵심적인 데이터 구조화 동작은?",
    "options": [
      "Intermediate List Collection",
      "Lazy Generator Binding",
      "Strict Tuple Packing",
      "Binary Stream Buffer"
    ],
    "answer": "Intermediate List Collection",
    "why": "가변 인자 언패킹 시 별표가 붙은 변수는 할당되지 않은 나머지 모든 요소들을 하나의 리스트(List) 객체로 수집하여 담습니다.",
    "hint": "남은 것들이 어떤 '자료형'으로 묶이는지 생각해보세요.",
    "trap_points": [
      "개수가 하나도 없더라도 빈 리스트([])가 생성되어 할당됨"
    ],
    "difficulty": "hard",
    "id": "0052"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬의 'Generational Garbage Collection'이 레퍼런스 카운팅만으로 해결할 수 없는 'Circular Reference' 문제를 처리하는 주요 방식은?",
    "options": [
      "Threshold-based Generation Promotion",
      "Mark-and-Sweep Isolation",
      "Immediate Reference Count Clearing",
      "Lazy Object Identification"
    ],
    "answer": "Threshold-based Generation Promotion",
    "why": "GC는 객체를 세대별로 관리하며, 일정 횟수의 검사에서 살아남은 객체를 다음 세대로 승격(Promotion)시키고 세대별 임계값(Threshold)에 따라 검사 주기를 조절하여 순환 참조를 감지합니다.",
    "hint": "오래 살아남은 객체일수록 검사 횟수를 줄이는 효율적인 관리 체계를 생각하세요.",
    "trap_points": [
      "레퍼런스 카운팅은 주된 GC 기법이지만, 순환 참조 해결을 위해서는 세대별 GC 알고리즘이 필수적으로 병행됨"
    ],
    "difficulty": "hard",
    "id": "0053"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `assert` 문이 프로덕션 환경에서 `-O` (Optimization) 옵션과 함께 실행될 때 발생하는 런타임상 주요 변화는?",
    "options": [
      "Elimination of Statement Code",
      "Silent Suppression of Errors",
      "Logging of Failed Assertions",
      "Immediate Program Termination"
    ],
    "answer": "Elimination of Statement Code",
    "why": "최적화 옵션 사용 시 파이썬은 모든 assert 문을 바이트코드 수준에서 제거(Elimination)하므로, 프로덕션 환경에서는 assert를 통한 비즈니스 로직 유효성 검증을 신뢰할 수 없습니다.",
    "hint": "디버깅 도구가 상업용 버전에 포함되지 않고 '사라지는' 현상을 떠올리세요.",
    "trap_points": [
      "에러를 숨기는 것이 아니라 전제 조건 검증 코드 자체가 사라지므로 성능은 올라가지만 안전망이 제거됨"
    ],
    "difficulty": "hard",
    "id": "0054"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 클래스에서 `__slots__`를 정의하여 `__dict__` 생성을 억제했을 때 얻게 되는 메모리 구조상의 이점은?",
    "options": [
      "Fixed-size Pointer Array Usage",
      "Dynamic Attribute Binding",
      "Global Variable Registry Isolation",
      "Lazy Member Initialization"
    ],
    "answer": "Fixed-size Pointer Array Usage",
    "why": "slots를 사용하면 가변적인 해시 테이블 대신 고정 크기의 포인터 배열을 사용하여 속성 정보를 저장하므로, 객체마다 발생하는 해시 테이블 오버헤드를 줄여 메모리를 극적으로 절약합니다.",
    "hint": "유연한 가방 대신, 칸이 딱딱 나누어진 수납장을 사용한다고 생각하세요.",
    "trap_points": [
      "다만 slots에 명시되지 않은 새로운 속성을 실행 중에 추가하는 유연성은 상실됨"
    ],
    "difficulty": "hard",
    "id": "0055"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 3.8부터 도입된 'Walrus Operator'(:=)가 표현식 내부에서 변수를 할당할 때 갖는 스코프(Scope)적 특징으로 옳은 것은?",
    "options": [
      "Value persistence beyond Expression",
      "Immediate Memory Eviction",
      "Recursive Function Call Protection",
      "Static Type Binding Constraint"
    ],
    "answer": "Value persistence beyond Expression",
    "why": "바다표범 연산자로 할당된 변수는 해당 표현식이 끝난 후에도 현재 스코프 내에서 유지(Persistence)되어 후속 로직에서 재사용될 수 있습니다.",
    "hint": "한 번 정해진 이름표가 그 문장이 끝나도 살아남아 있는지 생각해보세요.",
    "trap_points": [
      "단순히 코드 길이를 줄이는 용도를 넘어, 조건문 검사와 변수 활용을 동시에 수행하기 위해 고안됨"
    ],
    "difficulty": "hard",
    "id": "0056"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 패키지 내부의 `__init__.py` 파일이 수행하는 핵심적인 아키텍처적 가이드 역할은?",
    "options": [
      "Namespace Initialization and API Exposure",
      "Binary Instruction Preloading",
      "Module Search Path Modification",
      "Source Code Obfuscation"
    ],
    "answer": "Namespace Initialization and API Exposure",
    "why": "__init__.py는 해당 디렉토리를 패키지로 인식하게 할 뿐만 아니라, 패키지 수준에서 공개하고 싶은 API들을 임포트하여 네임스페이스를 관리(Exposure)하는 진입점 역할을 합니다.",
    "hint": "외국 손님이 왔을 때 우리 집의 어떤 방을 먼저 보여줄지 결정하는 로비의 역할과 같습니다.",
    "trap_points": [
      "파이썬 3.3 이후 네임스페이스 패키지 도입으로 이 파일이 없어도 임포트는 가능하나, 초기화 로직을 위해서는 여전히 중요함"
    ],
    "difficulty": "hard",
    "id": "0057"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 3.12의 'type alias' (예: `type Point = tuple[float, float]`) 구문이 대입 연산자를 사용한 기존 방식 대비 갖는 주요 이점은?",
    "options": [
      "Lazy Evaluation and Structural Clarity",
      "Strict Dynamic Type Enforcement",
      "Execution Speed Boost",
      "Binary Size Minimization"
    ],
    "answer": "Lazy Evaluation and Structural Clarity",
    "why": "새로운 `type` 구문은 타입 정보를 즉시 평가하지 않고 지연 평가(Lazy evaluation)하여 순환 참조 문제 등을 해결하기 용이하며, 타입임을 더 명확히 명시하는 가독성을 제공합니다.",
    "hint": "단순히 별명을 붙이는 것을 넘어, 복잡한 타입들 간의 관계를 정리하는 정교한 방법을 생각하세요.",
    "trap_points": [
      "런타임 효율성보다는 타입 힌팅 시스템의 견고함과 설계의 명확성에 기여함"
    ],
    "difficulty": "hard",
    "id": "0058"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬에서 리스트 중복 제거 시 `list(dict.fromkeys(data))` 트릭이 `list(set(data))` 방식보다 아키텍처적으로 우수하다고 평가받는 결정적 이유는?",
    "options": [
      "Maintenance of Insertion Order",
      "Hash Collision Suppression",
      "Memory Allocation Efficiency",
      "Parallel Execution Support"
    ],
    "answer": "Maintenance of Insertion Order",
    "why": "딕셔너리는 삽입된 키의 순서를 유지하므로(Insertion order), 순서를 지키면서 중복만 제거하는 작업을 가장 효율적으로 수행할 수 있는 파이썬의 표준 수단입니다.",
    "hint": "불러온 책들을 정리할 때, 원래 꽂혀 있던 순서가 뒤죽박죽되지 않는 상황을 생각하세요.",
    "trap_points": [
      "set()은 집합의 정의상 순서 개념이 없으므로 중복 제거 후 데이터가 무작위로 섞임"
    ],
    "difficulty": "hard",
    "id": "0059"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 컨텍스트 매니저의 `__exit__` 메서드에서 예외가 발생했을 때, 이를 프로그램 상위로 전파하지 않고 '억제(Suppression)'하고 싶을 때 취해야 할 반환값 전략은?",
    "options": [
      "Return True (Truthy value)",
      "Raise StopIteration",
      "Return None (Default)",
      "Yield Exception Context"
    ],
    "answer": "Return True (Truthy value)",
    "why": "__exit__ 메서드가 True를 반환하면, 발생한 예외가 처리된 것으로 간주되어 바깥쪽 스코프로 전파되지 않고 조용히 억제(Suppression)됩니다.",
    "hint": "에러가 났지만 '내가 해결했으니 괜찮다'는 신호를 루프나 블록에 어떻게 줄 수 있는지 생각하세요.",
    "trap_points": [
      "False나 None을 반환하면 발생했던 예외가 그대로 바깥으로 던져짐"
    ],
    "difficulty": "hard",
    "id": "0060"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 f-string이 `str.format()`이나 `%` 방식보다 런타임 속도 면에서 압도적으로 빠른 기술적 명분은?",
    "options": [
      "Compile-time Bytecode Inlining",
      "Dynamic Runtime Dictionary Lookup",
      "Lazy String Template Caching",
      "Global String Interning"
    ],
    "answer": "Compile-time Bytecode Inlining",
    "why": "f-string은 런타임에 해석되는 대신 컴파일 시점에 리터럴과 변수 참조가 바이트코드(BUILD_STRING)로 직접 인라이닝되어 호출 오버헤드를 극적으로 줄입니다.",
    "hint": "코드 실행 '전'에 이미 문자열이 어떻게 합쳐질지 바이트코드 수준에서 결정된다는 점을 생각하세요.",
    "trap_points": [
      "단순히 문법이 간결한 것을 넘어, 파이썬 인터프리터 수준의 최적화가 적용된 결과임"
    ],
    "difficulty": "hard",
    "id": "0061"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `collections.Counter` 객체 간의 합집합(`|`) 연산이 단순 덧셈(`+`) 연산과 차별화되는 결과적 특징은?",
    "options": [
      "Maximum Frequency Selection",
      "Cumulative Score Summation",
      "Binary Bitwise Masking",
      "Lexicographical Key Merging"
    ],
    "answer": "Maximum Frequency Selection",
    "why": "Counter 객체의 합집합(`|`) 연산은 동일한 키에 대해 두 객체 중 더 큰 빈도수(Maximum)를 선택하는 반면, 덧셈(`+`)은 빈도수를 합산합니다.",
    "hint": "집합론에서 합집합이 '공통된 것 중 큰 쪽'을 포함하는 원리와 유사함을 생각하세요.",
    "trap_points": [
      "덧셈 연산은 결과가 0이나 음수가 될 경우 카운터에서 해당 키를 자동으로 제거하지만, 합집합은 양수 중 최대치만 남김"
    ],
    "difficulty": "hard",
    "id": "0062"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 내장 함수 `dir()`이 인자 없이 호출될 때, 현재 로컬 네임스페이스(Local Namespace)에서 탐색하지 않는 영역은?",
    "options": [
      "Built-in Exception Hierarchy",
      "Currently Assigned Variables",
      "Imported Module Names",
      "Locally Defined Functions"
    ],
    "answer": "Built-in Exception Hierarchy",
    "why": "인자 없는 dir()은 현재 로컬 스코프에 정의된 변수, 함수, 임포트된 모듈 이름 등을 반환하지만, `builtins` 모듈에 속한 내장 예외나 함수들은 직접적으로 포함하지 않습니다.",
    "hint": "내가 '지금 여기서' 직접 만든 것들이나 가져온 것들에 주목하세요.",
    "trap_points": [
      "내장 함수(print 등)가 dir() 출력에 나오지 않는 이유는 그것들이 로컬이 아닌 빌트인 스코프에 존재하기 때문임"
    ],
    "difficulty": "hard",
    "id": "0063"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `abc` 모듈의 'Virtual Subclassing' 기능을 통해 명시적 상속 없이도 특정 클래스를 추상 베이스 클래스의 자식으로 인정받게 만드는 매커니즘은?",
    "options": [
      "ABC.register() method",
      "Dynamic Bytecode Patching",
      "Global Variable Shadowing",
      "Static Type Inspection"
    ],
    "answer": "ABC.register() method",
    "why": "register()를 사용하면 클래스 계층 구조를 직접 수정하지 않고도, 특정 클래스가 해당 추상 클래스의 인터페이스를 준수함을 런타임에 등록(Virtual subclass)할 수 있습니다.",
    "hint": "가족 관계 증명서에 입양된 자녀를 등록하는 절차와 비슷함을 생각하세요.",
    "trap_points": [
      "가상 서브클래스는 isinstance() 체크는 통과하지만, 추상 메서드 구현 여부를 인터프리터가 강제로 검증하지는 않음"
    ],
    "difficulty": "hard",
    "id": "0064"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `enumerate()`가 반환하는 이터레이터가 소비(Consume)될 때, 메모리 관리 측면에서 주의해야 할 '일회성' 특징은?",
    "options": [
      "Exhaustion of Iterator State",
      "Recursive Memory Swapping",
      "Binary Stream Buffer Flush",
      "Dynamic Object Re-indexing"
    ],
    "answer": "Exhaustion of Iterator State",
    "why": "enumerate 객체는 이터레이터이므로 한 번 순회를 마치면 상태가 소진(Exhaustion)되어 재사용이 불가능하며, 다시 사용하려면 객체를 새로 생성해야 합니다.",
    "hint": "한 번 다 읽어버린 카세트테이프를 되감지 않으면 소리가 나지 않는 상황을 떠올리세요.",
    "trap_points": [
      "리스트처럼 여러 번 for 문에 넣어도 매번 동작할 것이라 기대하면 논리 오류가 발생함"
    ],
    "difficulty": "hard",
    "id": "0065"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 문자열 메서드 `title()`을 사용할 때, 아포스트로피(`'`)가 포함된 영단어(예: `they're`)에서 발생하는 예기치 못한 유니코드 케이싱 동작은?",
    "options": [
      "Capitalization after Punctuation",
      "Lowercase String Normalization",
      "Immediate Character Stripping",
      "Binary Encoding Conversion"
    ],
    "answer": "Capitalization after Punctuation",
    "why": "title()은 공백뿐만 아니라 문장 부호 뒤의 첫 글자도 대문자로 변환하는 단순 알고리즘을 사용하므로, `they're`를 `They'Re`로 변환하는 등의 의도치 않은 결과가 발생할 수 있습니다.",
    "hint": "단어 중간에 들어간 점이나 따옴표를 파이썬이 새로운 단어의 시작으로 오해하는 상황을 생각하세요.",
    "trap_points": [
      "단순히 제목 형식으로 바꿀 때는 `string.capwords()`를 사용하는 것이 더 안전할 수 있음"
    ],
    "difficulty": "hard",
    "id": "0066"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 클로저(Closure) 구현 중, `nonlocal` 키워드를 생략한 채 외부 변수를 수정하려 할 때 발생하는 런타임 오류나 예기치 못한 동작은?",
    "options": [
      "UnboundLocalError due to Shadowing",
      "Global Variable Overwrite",
      "Static Bound Reference Error",
      "Memory Address Overflow"
    ],
    "answer": "UnboundLocalError due to Shadowing",
    "why": "함수 내부에서 외부 스코프 변수에 값을 대입하면, 파이썬은 이를 새로운 로컬 변수 선언으로 간주(Shadowing)하며, nonlocal이 없으면 대입 전 참조 시 UnboundLocalError를 발생시킵니다.",
    "hint": "이름이 같아서 내 것인 줄 알았는데, 사실은 바깥쪽 주인의 물건이었다는 것을 나중에 알게 되는 상황을 생각하세요.",
    "trap_points": [
      "변수 값을 '읽기'만 할 때는 nonlocal이 없어도 되지만, '수정(Re-binding)'할 때는 반드시 필요함"
    ],
    "difficulty": "hard",
    "id": "0067"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 3.10 이상 `zip()` 함수에서 `strict=True` 인자를 전달했을 때, 입력된 이터러블들의 길이가 다를 경우 발생하는 동작은?",
    "options": [
      "Raise ValueError",
      "Truncate to Longest",
      "Fill Missing with None",
      "Ignore Length Mismatch"
    ],
    "answer": "Raise ValueError",
    "why": "strict 모듈이 활성화되면 zip()은 모든 인자의 길이가 동일함을 강제하며, 하나라도 다를 경우 즉시 ValueError를 발생시켜 데이터 누락을 방지합니다.",
    "hint": "엄격하게(Strict) 규칙을 지키지 않으면 혼을 내주는 상황을 떠올리세요.",
    "trap_points": [
      "기본(False) 설정에서는 가장 짧은 이터러블에 맞춰 데이터를 조용히 잘라버림(Truncate)"
    ],
    "difficulty": "hard",
    "id": "0068"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 3의 리스트 컴프리헨션(List Comprehension)이 반복 변수의 '스코프 누수(Scope Leakage)' 문제를 해결하기 위해 취한 설계적 변화는?",
    "options": [
      "Implicit Function Scope Isolation",
      "Global Variable Shadowing",
      "Static Memory Mapping",
      "Immediate Variable Eviction"
    ],
    "answer": "Implicit Function Scope Isolation",
    "why": "파이썬 3의 컴프리헨션은 내부적으로 별도의 함수 스코프와 유사한 격리된 공간에서 실행되므로, 루프 변수가 외부 네임스페이스를 오염시키는 문제를 원천 차단했습니다.",
    "hint": "리스트를 만드는 '공장' 안에서 쓰던 도구가 공장 문 바깥으로 흘러나오지 않는다고 생각하세요.",
    "trap_points": [
      "파이썬 2에서는 컴프리헨션의 루프 변수가 외부 스코프에 그대로 남았으나, 3에서는 접근이 불가능함"
    ],
    "difficulty": "hard",
    "id": "0069"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 클래스의 메서드 정의 시 첫 번째 인자로 `self`를 명시적으로 선언해야 하는 언어 설계적 명분과 바인딩(Binding) 원리는?",
    "options": [
      "Explicit Object Reference Passing",
      "Static Method Dispatching",
      "Global Variable Registry Lookup",
      "Automatic Context Injection"
    ],
    "answer": "Explicit Object Reference Passing",
    "why": "파이썬은 '명시적인 것이 암시적인 것보다 낫다(Explicit is better than implicit)'는 철학에 따라, 인스턴스 메서드가 호출될 때 해당 객체 자신을 첫 번째 인자로 전달함을 명시적으로 구현합니다.",
    "hint": "함수가 누구의 것인지 '나 자신(self)'을 통해 확실히 밝히는 절차를 생각해보세요.",
    "trap_points": [
      "실행 시 인스턴스를 통해 호출하면 첫 번째 인자는 인터프리터에 의해 자동으로 채워지지만, 정의 시에는 반드시 적어주어야 함"
    ],
    "difficulty": "hard",
    "id": "0070"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `__getitem__` 매직 메서드가 슬라이싱 연산(`obj[1:5:2]`)을 처리할 때, 인터프리터가 메서드 인자로 전달하는 내장 객체의 명칭과 속성은?",
    "options": [
      "slice(start, stop, step) object",
      "RangeGenerator sequence",
      "SubscriptMap dictionary",
      "MemoryView pointer"
    ],
    "answer": "slice(start, stop, step) object",
    "why": "`obj[a:b:c]` 형식의 접근은 내부적으로 `slice(a, b, c)` 객체를 생성하여 `__getitem__`에 전달하므로, 개발자는 해당 객체의 start/stop/step 속성을 분석하여 부분 데이터를 반환해야 합니다.",
    "hint": "데이터의 '시작, 끝, 간격'을 하나의 덩어리로 묶어서 함수에 전달하는 전용 객체를 떠올리세요.",
    "trap_points": [
      "단순 인덱스 접근 시에는 정수(int)가 오지만, 슬라이싱 시에는 slice 객체가 오므로 타입 체크가 필수적임"
    ],
    "difficulty": "hard",
    "id": "0071"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 세트(Set) 연산에서 비트 단위 OR 기호(`|`)를 사용한 합집합 연산이 `set.union()` 메서드 호출과 차별화되는 입력 타입의 엄격함은?",
    "options": [
      "Operator requires Set-to-Set operands",
      "Method prohibits non-hashable inputs",
      "Operator supports generator expressions",
      "Method results in in-place modification"
    ],
    "answer": "Operator requires Set-to-Set operands",
    "why": "`|` 연산자는 양쪽 피연산자가 모두 세트(Set) 타입이어야 하지만, `union()` 메서드는 리스트나 튜플 등 순회 가능한 모든 객체(Iterable)를 인자로 받아 합집합을 수행할 수 있습니다.",
    "hint": "기호(`|`)는 끼리끼리 엄격하게 따지고, 메서드(`union`)는 좀 더 포용력이 넓다는 점을 생각하세요.",
    "trap_points": [
      "s | [1, 2] 는 TypeError를 발생시키지만, s.union([1, 2]) 는 정상적으로 합집합을 생성함"
    ],
    "difficulty": "hard",
    "id": "0072"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 스크립트 실행 시 `sys.argv[0]` 값이 운영체제 수준의 프로세스 인자와 다르게 해석될 수 있는 특수 실행 환경과 그 조건은?",
    "options": [
      "Package execution via `-m` flag",
      "Recursive subprocess spawning",
      "Direct Bytecode injection",
      "Virtual Environment Isolation"
    ],
    "answer": "Package execution via `-m` flag",
    "why": "파이썬을 `python -m pkg.mod` 명령으로 실행할 경우, `sys.argv[0]`에는 실행된 파일의 경로가 아닌 해당 모듈의 전체 경로(Full path)가 담기게 됩니다.",
    "hint": "파일을 직접 실행하는 것과 '모듈'로서 실행하는 것의 차이를 생각해보세요.",
    "trap_points": [
      "일반적인 실행 환경에서는 스크립트 파일명이 오지만, 실행 방식에 따라 절대경로가 오거나 모듈명이 올 수 있어 파일 시스템 접근 시 주의가 필요함"
    ],
    "difficulty": "hard",
    "id": "0073"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 'Timsort' 알고리즘이 리스트 정렬 시 '안정성(Stability)'을 유지하기 위해 활용하는 핵심적인 내부 전략은?",
    "options": [
      "Preservation of relative order for identical keys",
      "In-place Bit-swap optimization",
      "Recursive Merge-Depth Limitation",
      "Global Heap Invariant Maintenance"
    ],
    "answer": "Preservation of relative order for identical keys",
    "why": "Timsort는 값이 같은 요소들이 나타난 원래의 상대적 순서를 보존(Stability)하도록 설계되어 있어, 여러 번의 정렬 수행 시에도 논리적 일관성을 유지합니다.",
    "hint": "줄을 세울 때 성적이 같은 사람들은 처음 서 있던 순서대로 세워주는 친절함을 생각하세요.",
    "trap_points": [
      "단순한 퀵 정렬 기반 알고리즘(일부 구현체)은 안정성을 보장하지 않아 데이터 순서가 뒤섞일 수 있음을 유의해야 함"
    ],
    "difficulty": "hard",
    "id": "0074"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `importlib.reload()`를 통해 런타임에 모듈을 다시 불러올 때, 구버전 객체(Instance)들이 겪게 되는 아키텍처적 일관성 결여 현상은?",
    "options": [
      "Retention of old class references",
      "Immediate memory address reclaim",
      "Binary Opcode synchronization",
      "Global Variable Registry Purge"
    ],
    "answer": "Retention of old class references",
    "why": "reload()는 모듈의 전역 심볼은 업데이트하지만, 이미 생성된 기존 객체들은 여전히 reload '이전'의 클래스 정의를 참조하므로 런타임에 타입 일치 오류가 발생할 수 있습니다.",
    "hint": "설계도(Class)가 바뀌었지만, 이미 지어진 집(Instance)들은 옛날 설계도를 붙잡고 있는 난감한 상황을 생각하세요.",
    "trap_points": [
      "reload()가 만능이 아니며, 클래스 변수를 사용하는 싱글톤 패턴 등에서는 심각한 부작용을 초래할 수 있음"
    ],
    "difficulty": "hard",
    "id": "0075"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 리스트 `pop(index)` 메서드가 인덱스 인자를 받을 때, 리스트의 크기(N)에 비례하여 성능 저하(O(N))가 발생하는 결정적 구현 배경은?",
    "options": [
      "Sequential Memory Shift for remaining elements",
      "Hashing Collision Resolution delay",
      "Recursive Pointer Re-assignment",
      "Immediate Garbage Flushing overhead"
    ],
    "answer": "Sequential Memory Shift for remaining elements",
    "why": "리스트는 동적 배열 구조이므로 중간이나 앞쪽 요소를 삭제(pop)하면, 삭제된 자리 이후의 모든 요소들을 앞으로 한 칸씩 물리적으로 이동(Shift)시켜야 하는 비용이 발생합니다.",
    "hint": "의자에 앉아 있는 사람들의 줄에서 중간 사람이 빠졌을 때, 뒤에 있는 모든 사람이 한 칸씩 당겨 앉아야 하는 수고로움을 생각하세요.",
    "trap_points": [
      "마지막 요소를 꺼내는 pop()은 이동이 필요 없어 O(1)이지만, pop(0)은 데이터가 많을수록 최악의 효율을 보임"
    ],
    "difficulty": "hard",
    "id": "0076"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 3의 나눗셈 연산(`5 / 2`) 결과가 항상 실수형(Float)을 반환하게 됨으로써, 대규모 수치 계산에서 발생할 수 있는 잠재적 위험 요소는?",
    "options": [
      "Precision loss in Binary Floating-Point",
      "Static Integer Overflow",
      "Register Overflow in 32-bit CPU",
      "Global Interpreter Lock Conflict"
    ],
    "answer": "Precision loss in Binary Floating-Point",
    "why": "실수형은 IEEE 754 표준을 따르므로 무한 소수 등의 표현 시 미세한 정밀도 손실(Precision loss)이 발생하며, 이는 긴 연산 체인에서 오차를 누적시킬 위험이 있습니다.",
    "hint": "정확한 정수의 세계에서 소수점이 있는 '근사치'의 세계로 넘어갔을 때 생기는 불안정성을 생각하세요.",
    "trap_points": [
      "파이썬 2에서는 정수 간 나눗셈 결과가 정수였으나, 3에서는 실수로 강제 전환됨에 따른 정밀도 이슈를 간과하지 말아야 함"
    ],
    "difficulty": "hard",
    "id": "0077"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 클래스에서 속성 이름 앞에 언더바 두 개를 붙이는 'Name Mangling' 현상이 상속 구조에서 갖는 실제적인 보호 원리는?",
    "options": [
      "Storage under `_ClassName__AttributeName`",
      "Immediate Memory Encryption",
      "Bytecode Exclusion for external access",
      "Global Variable Namespace Isolation"
    ],
    "answer": "Storage under `_ClassName__AttributeName`",
    "why": "언더바 두 개로 시작하는 이름은 인터프리터에 의해 `_클래스명__속성명`으로 물리적으로 변환되어 저장되므로, 자식 클래스에서 동일한 이름을 사용하더라도 부모의 속성을 실수로 덮어쓰는(Overriding) 것을 방지합니다.",
    "hint": "나만의 도구함에 내 이름을 적어두어, 나중에 들어올 가족이 자기 물건으로 착각하지 않게 하는 장치와 같습니다.",
    "trap_points": [
      "자바의 private처럼 접근을 완전히 차단하는 것이 아니라, 이름을 복잡하게 뒤섞어 혼란을 막는 것뿐임"
    ],
    "difficulty": "hard",
    "id": "0078"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 3에서 `dict.values()`가 반환하는 'Dynamic View' 객체의 런타임 특징으로 옳은 것은?",
    "options": [
      "Reflects original dictionary changes in real-time",
      "Static Snapshots of values at call time",
      "Lexicographical ordering guaranteed",
      "Immediate conversion to immutable list"
    ],
    "answer": "Reflects original dictionary changes in real-time",
    "why": "values(), keys(), items() 메서드가 반환하는 뷰 객체는 원본 딕셔너리와 연결되어 있어, 딕셔너리 내용이 변경되면 별도의 재호출 없이도 해당 변화가 즉시 반영(Reflect)됩니다.",
    "hint": "사본을 찍어두는 사진기가 아니라, 실시간 현장을 보여주는 CCTV와 같다는 점을 생각하세요.",
    "trap_points": [
      "파이썬 2에서는 리스트로 반환되어 정적이었으나, 3에서는 뷰 객체로 변경되어 동적으로 동작함"
    ],
    "difficulty": "hard",
    "id": "0079"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 가상 머신(PVM) 수준에서 함수가 `return` 문 없이 종료될 때 호출 스택(Call Stack)에 푸시되는 기본 싱글톤 객체는?",
    "options": [
      "None (NoneType instance)",
      "Zero (Integer literal)",
      "False (Boolean literal)",
      "Null (C-level pointer)"
    ],
    "answer": "None (NoneType instance)",
    "why": "파이썬의 모든 함수는 명시적인 리턴값이 없을 경우, 객체의 부재를 나타내는 싱글톤 객체인 `None`을 암시적으로 반환(Implicit return)하도록 설계되어 있습니다.",
    "hint": "함수가 일을 마쳤지만 아무런 성적표를 주지 않을 때, 인터프리터가 대신 적어주는 '비어있음'의 증표를 떠올리세요.",
    "trap_points": [
      "단순히 값이 없는 상태가 아니라, 'None'이라는 실제 객체가 반환되는 것임을 인식해야 함"
    ],
    "difficulty": "hard",
    "id": "0080"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `import module as alias` 문법을 통한 에일리어싱(Aliasing)이 단순히 코드 타이핑을 줄이는 목적 외에, 런타임 네임스페이스 관리 측면에서 갖는 실제 기능적 영향은?",
    "options": [
      "Binding the module object to a local name",
      "Dynamic Bytecode Re-compilation",
      "Memory Address Relocation",
      "Automatic Symbol Exporting"
    ],
    "answer": "Binding the module object to a local name",
    "why": "`as` 키워드는 임포트된 모듈 객체를 현재 스코프의 지정된 이름(Local name)에 바인딩할 뿐이며, 모듈의 실제 물리적 위치나 바이트코드를 수정하지 않습니다.",
    "hint": "이미 로드된 '물건'에 '다른 이름표'를 붙여서 내 옆에 두는 행위와 같습니다.",
    "trap_points": [
      "에일리어싱을 한다고 해서 모듈이 중복 로드되거나 메모리가 추가로 소모되는 것이 아님을 유의해야 함"
    ],
    "difficulty": "hard",
    "id": "0081"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "CPython의 GIL(Global Interpreter Lock) 매커니즘 하에서, 멀티스레드가 CPU 연산 중 인터프리터의 제어권을 강제로 내려놓게 되는(Preemptive context switch) 결정적 기준은?",
    "options": [
      "Instruction-based Bytecode Interval",
      "Wall-clock Time Milliseconds",
      "Memory Usage Threshold",
      "Recursive Depth Limit"
    ],
    "answer": "Instruction-based Bytecode Interval",
    "why": "파이썬 3.2 이전에는 명령 횟수 기준이었으나, 최신 버전에서는 일정 시간(기본 5ms) 동안 바이트코드를 실행한 후 GIL을 해제하여 다른 스레드에게 기회를 주는 '체크 간격(sys.setswitchinterval)' 방식을 사용합니다.",
    "hint": "스레드가 쉬고 싶어서 쉬는 게 아니라, 정해진 '업무 시간'이 끝나면 교대해야 하는 시스템을 생각하세요.",
    "trap_points": [
      "GIL은 I/O 작업 시에는 자동으로 해제되지만, 수치 계산 같은 CPU 작업에서는 병목의 핵심 원인이 됨"
    ],
    "difficulty": "hard",
    "id": "0082"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 파일 입출력 시 'a' 모드(Append)가 운영체제 수준에서 보장하려 노력하는 원자적(Atomic) 동작의 특징은?",
    "options": [
      "Always write to current EOF",
      "Exclusive Dynamic Lock acquisition",
      "Binary Stream Buffer Flush",
      "Incremental Metadata Update"
    ],
    "answer": "Always write to current EOF",
    "why": "'a' 모드로 파일을 열면 쓰기 작업 직전에 파일 포인터가 항상 파일의 끝(End Of File)으로 강제 이동하므로, 여러 프로세스가 동시에 기록하더라도 기존 데이터를 덮어쓰지 않고 뒤에 덧붙여집니다.",
    "hint": "펜을 들 때마다 항상 종이의 맨 마지막 빈 줄을 찾아가는 자동 추적 기능을 떠올리세요.",
    "trap_points": [
      "seek()으로 위치를 옮겨도 쓰기 시점에는 다시 끝으로 돌아가기 때문에 중간 수정이 불가능함"
    ],
    "difficulty": "hard",
    "id": "0083"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 문자열 `replace()` 메서드가 대용량 텍스트 처리 시 `re.sub()`(정규표현식)보다 성능상 유리한 기술적 명분은?",
    "options": [
      "Specific fixed-pattern algorithm without Regex engine overhead",
      "Direct Memory Mapping of input string",
      "Asynchronous Buffer Streaming",
      "Global String Interning Cache"
    ],
    "answer": "Specific fixed-pattern algorithm without Regex engine overhead",
    "why": "`replace()`는 단순 문자열 매칭을 위해 최적화된 C 수준의 알고리즘을 사용하므로, 복잡한 패턴 분석이 필요한 정규표현식 엔진을 거치는 것보다 훨씬 빠릅니다.",
    "hint": "단순한 글자 찾기는 정교한 탐정(정규식)보다 성실한 작업자(내장 메서드)가 더 빠른 법입니다.",
    "trap_points": [
      "패턴이 복잡하지 않다면 무조건 내장 문자열 메서드를 쓰는 것이 성능과 가독성 면에서 유리함"
    ],
    "difficulty": "hard",
    "id": "0084"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 3에서 `int` 타입이 물리적 메모리 한계까지 정수를 표현할 수 있게 만드는 '임의 정밀도(Arbitrary Precision)'의 내부 구현 방식은?",
    "options": [
      "Storing digits in an array of 30-bit integers",
      "Automatic conversion to Floating-Point precision",
      "Stack-based recursion for big number arithmetic",
      "Exclusive 128-bit register allocation"
    ],
    "answer": "Storing digits in an array of 30-bit integers",
    "why": "파이썬의 정수는 내부적으로 숫자들을 일정한 단위(보통 30비트)씩 끊어서 배열에 저장하는 방식을 사용하여, 고정된 비트(64비트 등)를 넘어서는 초거대 정수를 연산할 수 있습니다.",
    "hint": "긴 숫자를 한 번에 못 읽어서 여러 조각으로 나누어 적어두고 계산하는 방식을 생각하세요.",
    "trap_points": [
      "숫자가 커질수록 연산 속도가 기하급수적으로 느려지며, 문자열 변환 시 `sys.set_int_max_str_digits` 제한에 걸릴 수 있음"
    ],
    "difficulty": "hard",
    "id": "0085"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `zip()` 함수가 반환하는 객체가 소비(Iteration)된 직후의 상태와 재사용 가능 여부는?",
    "options": [
      "Exhausted and non-reusable state",
      "Auto-reset and multi-pass support",
      "Immutable static caching in memory",
      "Persistent pointers to original iterables"
    ],
    "answer": "Exhausted and non-reusable state",
    "why": "zip 객체는 제너레이터와 유사하게 동작하는 이터레이터이므로, 한 번 끝까지 순회하면 모든 값을 소진(Exhausted)하여 다시 순회할 때 빈 결과를 반환합니다.",
    "hint": "한 번 쏟아버린 모래시계는 뒤집지 않는 한 다시 흐르지 않는 원리와 같습니다.",
    "trap_points": [
      "두 번 이상 사용해야 한다면 `list(zip(...))`를 통해 데이터를 실체화(Materialize)해두어야 함"
    ],
    "difficulty": "hard",
    "id": "0086"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "수십 기가바이트(GB) 크기의 로그 파일을 처리할 때, `f.read()` 대신 `for line in f:` 방식을 사용하는 메모리 관리적 결정타는?",
    "options": [
      "Lazy loading per line with constant memory footprint",
      "Multi-threaded buffer lookahead",
      "Direct memory mapping of binary offset",
      "Automatic garbage collection of read strings"
    ],
    "answer": "Lazy loading per line with constant memory footprint",
    "why": "파일 객체에 대해 바로 iteration을 수행하면 내장 버퍼를 통해 한 줄씩 필요할 때만 메모리에 로드(Lazy loading)하므로, 파일 크기와 상관없이 메모리 사용량을 일정하게 유지할 수 있습니다.",
    "hint": "책 전체 내용을 한 번에 외우려 하지 말고, 한 문장씩 읽고 넘기는 지혜를 생각하세요.",
    "trap_points": [
      "read()나 readlines()는 파일 전체를 메모리에 한꺼번에 올리려 시도하여 MemoryError를 유발할 수 있음"
    ],
    "difficulty": "hard",
    "id": "0087"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬에서 `None` 확인 시 `==` 대신 `is` 연산자를 사용하는 것이 논리적으로 더 안전한(Robust) 이유는?",
    "options": [
      "Protects against `__eq__` operator overloading in objects",
      "Improves floating-point precision comparisons",
      "Supports bitwise identity masking",
      "Prevents global namespace pollution"
    ],
    "answer": "Protects against `__eq__` operator overloading in objects",
    "why": "`is`는 객체의 고유한 ID(메모리 주소)를 비교하는 반면, `==`는 `__eq__` 메서드가 재정의된 객체에서 예기치 않은(항상 True를 반환하는 등) 결과를 초래할 수 있기 때문입니다.",
    "hint": "누군가 '같다'는 기준(`==`)을 자기 마음대로 바꿔놓았을 수도 있으니, '진짜 그 사람 본인인지(`is`)'를 직접 보는 것이 확실합니다.",
    "trap_points": [
      "None은 파이썬 인터프리터 전체에서 유일한 싱글톤 객체이므로 ID 비교가 가장 빠르고 확실함"
    ],
    "difficulty": "hard",
    "id": "0088"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 클래스에서 `@staticmethod`를 사용하여 메서드를 정의했을 때, 인스턴스 메서드와 구별되는 바인딩(Binding) 매커니즘은?",
    "options": [
      "No implicit bound reference to instance or class",
      "Static binding to private class dictionary",
      "Automatic dependency injection of self",
      "Compile-time symbol resolution only"
    ],
    "answer": "No implicit bound reference to instance or class",
    "why": "정적 메서드는 호출 시 `self`나 `cls` 같은 첫 번째 인자를 암시적으로 받지 않으며, 단순히 클래스 네임스페이스에 할당된 일반 함수처럼 동작합니다.",
    "hint": "클래스라는 지붕 아래 살긴 하지만, 가족 관계(`self`, `cls`)에 얽매이지 않고 고독하게 일하는 독립적인 일꾼을 생각하세요.",
    "trap_points": [
      "상속 시 부모의 정적 메서드를 호출하더라도 자식 클래스 정보를 알 수 없으므로, 클래스 정보가 필요하면 classmethod를 써야 함"
    ],
    "difficulty": "hard",
    "id": "0089"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 세트(Set) 자료구조가 멤버십 확인(`item in collection`) 테스트에서 리스트(List)보다 압도적인 속도(O(1))를 보이는 기술적 배경은?",
    "options": [
      "Hash-based indexing for direct key lookup",
      "Binary search tree optimization",
      "Sequential memory scanning with SIMD",
      "LIFO based reference tracking"
    ],
    "answer": "Hash-based indexing for direct key lookup",
    "why": "세트는 해시 테이블을 기반으로 구현되어 있어, 항목의 해시값을 계산하여 물리적 위치를 즉시 찾아낼 수 있으므로 전체를 훑어야 하는 리스트와 달리 데이터 규모에 관계없이 일정한 시간이 걸립니다.",
    "hint": "번번호표를 들고 자기 자리를 바로 찾아가는 시스템(Set)과, 처음부터 끝까지 직접 물어보며 찾는 시스템(List)의 차이를 생각하세요.",
    "trap_points": [
      "이 속도를 누리기 위해서는 세트에 넣으려는 객체가 반드시 '해시 가능(Hashable)'해야 함"
    ],
    "difficulty": "hard",
    "id": "0090"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `import` 과정에서 발생하는 'Circular Import(순환 참조)' 문제를 해결하기 위해 활용할 수 있는 스코프 기반 우회 전략은?",
    "options": [
      "Local import within function/method body",
      "Global symbol aliasing with `as`",
      "Static type hinting exclusion",
      "Dynamic bytecode injection at runtime"
    ],
    "answer": "Local import within function/method body",
    "why": "임포트 문을 모듈 최상단이 아닌 함수 내부에 배치(Local import)하면, 해당 함수가 실제로 실행되는 시점까지 임포트가 지연되어 서로가 서로를 참조하는 무한 루프를 막을 수 있습니다.",
    "hint": "처음부터 서로 마주 보려 하지 말고, 실제 일이 생겼을 때만 문을 열고 확인하는 방식을 취해보세요.",
    "trap_points": [
      "근본적인 해결책은 코드 구조를 리팩토링하여 순환 관계를 끊는 것이지만, 단기적으로는 지연 임포트가 효과적임"
    ],
    "difficulty": "hard",
    "id": "0091"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `lambda` 함수를 루프 내에서 정의하여 클로저로 생성할 때 발생하는 'Late Binding' 관련 논리 오류와 그 원인은?",
    "options": [
      "Capturing variables by reference at execution time",
      "Immediate memory address deallocation",
      "Stack-based recursion overflow",
      "Static variable shadowing at compile time"
    ],
    "answer": "Capturing variables by reference at execution time",
    "why": "람다는 변수 값을 생성 시점에 복사하지 않고 실행 시점에 참조(Late binding)하므로, 루프 변수를 그대로 쓰면 모든 람다가 루프의 마지막 값만 참조하게 되는 흔한 함정이 있습니다.",
    "hint": "다 만들어진 결과물들이 나중에 확인해보니 모두 줄의 맨 마지막 사람만 쳐다보고 있는 상황을 생각하세요.",
    "trap_points": [
      "이 문제를 해결하려면 `lambda x=i: ...` 처럼 기본 인자(Default argument)를 사용해 값을 즉시 고정해야 함"
    ],
    "difficulty": "hard",
    "id": "0092"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 내장함수 `all()`에 빈 이터러블(예: `[]`)이 전달되었을 때의 논리적 반환값(Vacuous Truth)과 그 근거는?",
    "options": [
      "True (No elements violate the condition)",
      "False (No elements to confirm truthiness)",
      "None (Undefined logical state)",
      "Raise StopIteration error"
    ],
    "answer": "True (No elements violate the condition)",
    "why": "all()은 '거짓인 요소가 하나라도 있으면 False'라고 동작하므로, 검사할 요소가 아예 없는 빈 시퀀스는 논리적으로 거짓인 사례가 없기 때문에 True를 반환(공허한 참)합니다.",
    "hint": "잘못한 사람이 아무도 없다면 전체가 무죄라고 선언하는 판결 방식을 생각해보세요.",
    "trap_points": [
      "반면 any()는 빈 시퀀스에서 참인 사례를 찾을 수 없으므로 False를 반환함에 유의해야 함"
    ],
    "difficulty": "hard",
    "id": "0093"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 문자열 `split()` 메서드를 구분자 인자 없이(`s.split()`) 호출했을 때, 공백 문자를 처리하는 '특별한' 동작 방식은?",
    "options": [
      "Consecutive whitespaces are treated as a single delimiter",
      "Only the first single space character is replaced",
      "Empty strings are inserted between spaces",
      "Binary null characters are automatically stripped"
    ],
    "answer": "Consecutive whitespaces are treated as a single delimiter",
    "why": "인자 없이 split()을 호출하면 하나 이상의 연속된 공백(Space, Tab, Newline 등)을 하나의 구분자로 합쳐서 처리하며, 결과 리스트에 빈 문자열이 포함되지 않도록 자동으로 제거합니다.",
    "hint": "공백이 아무리 많아도 '빈 공간'이라는 하나의 덩어리로 묶어서 쪼개는 관대함을 생각하세요.",
    "trap_points": [
      "반면 `split(' ')`처럼 명시적으로 공백 한 칸을 지정하면, 연속된 공백 사이의 빈 문자열(`''`)을 결과에 포함하게 되므로 주의해야 함"
    ],
    "difficulty": "hard",
    "id": "0094"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬의 'Integer Interning' 캐싱 정책으로 인해, 서로 다른 두 변수 A, B에 할당된 정수값이 항상 동일한 메모리 주소(`is`)를 보장하는 범위는?",
    "options": [
      "Integers from -5 to 256",
      "Powers of 2 up to 1024",
      "All positive integers under 65535",
      "Prime numbers under 1000"
    ],
    "answer": "Integers from -5 to 256",
    "why": "CPython은 성능 최적화를 위해 작고 자주 사용되는 정수 범위(-5 ~ 256)를 미리 메모리에 할당해두고 재사용하므로, 이 범위 내의 숫자는 어디서 할당하든 객체 동일성(is)이 성립합니다.",
    "hint": "자주 쓰는 도구들을 상자에 미리 넣어두고 필요할 때마다 같은 도구를 꺼내 쓰는 시스템을 생각하세요.",
    "trap_points": [
      "이 범위를 벗어나는 숫자는 값이 같더라도(==) 메모리 주소가 다를 수 있어 `is` 연산 시 False가 나올 위험이 큼"
    ],
    "difficulty": "hard",
    "id": "0095"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 `@classmethod`가 상속 구조에서 `@staticmethod`보다 팩토리 패턴(Factory Pattern) 구현에 더 유리한 결정적 이유는?",
    "options": [
      "Access to the calling class through `cls` argument",
      "Immediate instantiation bypassing `__init__`",
      "Automatic synchronization of class variables",
      "Lower memory footprint per invocation"
    ],
    "answer": "Access to the calling class through `cls` argument",
    "why": "`@classmethod`는 호출된 클래스 자체를 첫 번째 인자(`cls`)로 받으므로, 자식 클래스에서 호출했을 때 부모 클래스가 아닌 자식 클래스의 인스턴스를 동적으로 생성하여 반환할 수 있습니다.",
    "hint": "누가 불렀는지(`cls`)를 알고 그 사람의 입맛에 맞춰서 객체를 만들어줄 수 있는 유연함을 생각하세요.",
    "trap_points": [
      "@staticmethod는 클래스 정보를 알지 못하므로 하드코딩된 특정 클래스의 인스턴스만 만들 수 있어 확장성이 떨어짐"
    ],
    "difficulty": "hard",
    "id": "0901"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "CPython의 GIL(Global Interpreter Lock)이 네트워크 통신이나 파일 읽기 같은 I/O 작업 중에도 멀티스레드 성능 저하를 일으키지 않는 시스템적 배경은?",
    "options": [
      "Implicit GIL release during blocking system calls",
      "Zero-copy buffer sharing between threads",
      "Asynchronous context switching at kernel level",
      "Global Virtual Memory isolation"
    ],
    "answer": "Implicit GIL release during blocking system calls",
    "why": "파이썬은 I/O 작업이나 외부 C 라이브러리(numpy 등) 호출 시 호출 직전에 GIL을 명시적으로 해제하며, 대기 시간이 끝난 후에 다시 획득하므로 I/O 대기 중에 다른 스레드가 실행될 수 있습니다.",
    "hint": "은행원이 서류 확인을 위해 자리를 비울 때, 창구 키(`Lock`)를 동료에게 넘겨주고 가는 상황을 생각하세요.",
    "trap_points": [
      "I/O 작업은 효율적이지만, 대규모 데이터 가공 같은 CPU 작업에서는 여전히 GIL이 병목을 일으키므로 멀티프로세싱을 써야 함"
    ],
    "difficulty": "hard",
    "id": "0902"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 제너레이터(Generator) 내의 `yield` 키워드가 일반적인 `return`과 차별화되는 호출 스택(Call Stack) 관리 측면의 특징은?",
    "options": [
      "Preservation of local state and execution pointer",
      "Recursive frame allocation per iteration",
      "Immediate memory flush upon value emission",
      "Global variable registry synchronization"
    ],
    "answer": "Preservation of local state and execution pointer",
    "why": "`yield`는 값을 반환한 후 함수의 코드 실행 위치와 지역 변수 상태를 정지(Suspend)된 상태로 보존하며, 다음 호출 시 중단된 지점부터 즉각 재개(Resume)됩니다.",
    "hint": "영화 플레이를 잠시 멈췄다가(`yield`), 나중에 다시 누르면 멈춘 곳부터 이어지는 상황을 생각하세요.",
    "trap_points": [
      "리스트를 반환하는 함수는 매번 처음부터 다시 실행되어야 하며 전체 메모리를 점유하지만, 제너레이터는 상태만 유지하며 하나씩 생성함"
    ],
    "difficulty": "hard",
    "id": "0903"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 '컨텍스트 매니저'의 `__exit__` 메서드에서 예외를 억제(Suppress)하고 `with` 문 외부로 전파되지 않게 만드는 구체적인 반환 전략은?",
    "options": [
      "Return a Truthy value (e.g. True)",
      "Raise a StopIteration exception",
      "Return None explicitly",
      "Delete the local exception reference"
    ],
    "answer": "Return a Truthy value (e.g. True)",
    "why": "`__exit__`가 `True`를 반환하면 발생한 예외가 처리된 것으로 간주되어 소멸하지만, `False`나 `None`을 반환하면 예외가 상위 스코프로 다시 위로 던져집니다.",
    "hint": "사고가 났을 때 '내가 해결했어!'라고 `True`를 외치면 조용히 넘어가지만, 입을 꾹 다물면 소문이 퍼지는 상황을 생각하세요.",
    "trap_points": [
      "단순히 예외 인자를 받는 것만으로는 예외가 사라지지 않으며, 반드시 `True`를 리턴해야 함을 잊지 말아야 함"
    ],
    "difficulty": "hard",
    "id": "0904"
  },
  {
    "chapter_name": "Python 기초",
    "type": "객관식",
    "question": "파이썬 3.10+ `match / case` 문에서 언더바(`_`) 와일드카드 패턴이 갖는 '계층적' 매칭 우선순위의 특징은?",
    "options": [
      "Matches anything as a last resort (fallback)",
      "Overrides specify group patterns",
      "Forces immediate syntax evaluation",
      "Prevents variable scoping in cases"
    ],
    "answer": "Matches anything as a last resort (fallback)",
    "why": "`_` 패턴은 모든 값과 매칭되므로 가장 마지막에 배치하여 어떤 상위 패턴에도 걸리지 않은 경우를 처리하는 '기본값(Default)' 역할을 수행합니다.",
    "hint": "여러 그물망을 통과한 뒤 맨 바닥에 깔려있는 마지막 안전망과 같은 역할을 한다고 생각하세요.",
    "trap_points": [
      "`_` 패턴을 `case`문의 중간에 배치하면 그 아래에 있는 더 구체적인 패턴들이 영영 실행되지 않게 되므로 주의해야 함"
    ],
    "difficulty": "hard",
    "id": "0905"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "f-string을 사용하여 소수점 둘레 데이터 `val = 12.3456`을 총 10자리의 너비 내에서 별표(`*`)로 패딩하고 우측 정렬하며, 소수점 둘째 자리까지 반환하는 코드를 완성하세요.\n\n```python\nval = 12.3456\nformatted = f\"{val:____}\"\n# 결과 예: \"*****12.35\"\n```",
    "options": [],
    "answer": "*>10.2f",
    "why": "f-string의 포맷 서식 `{value:char>width.precisionf}` 형식을 사용하면 공백 대신 특정 문자로 패딩하고 정밀도를 제어할 수 있습니다.",
    "hint": "채움 문자(`*`), 정렬 방향(`>`), 전체 너비(`10`), 정밀도(`.2f`) 순서로 작성하세요.",
    "difficulty": "hard",
    "id": "0101"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "리스트 `fruits` 뒤에 또 다른 리스트 `extras`의 모든 요소를 대문자로 변환하여 한꺼번에 추가(평탄화 확장)하는 코드를 완성하세요.\n\n```python\nfruits = ['apple', 'banana']\nextras = ['orange', 'grape']\nfruits.____(map(str.upper, extras))\n# 결과: ['apple', 'banana', 'ORANGE', 'GRAPE']\n```",
    "options": [],
    "answer": "extend",
    "why": "`extend()` 메서드는 리스트뿐만 아니라 `map` 같은 이터러블 객체를 인자로 받아 그 안의 모든 요소를 순차적으로 현재 리스트 뒤에 추가합니다.",
    "hint": "단순 추가(append)가 아닌 '확장'하는 메서드입니다.",
    "difficulty": "hard",
    "id": "0102"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "리스트 `data = [10, 20, 30, 40, 50]`에서 첫 번째 요소는 `head`에, 마지막 요소는 `tail`에 담고 나머지는 `body` 리스트에 몰아서 담는 'Extended Iterable Unpacking' 코드를 완성하세요.\n\n```python\ndata = [10, 20, 30, 40, 50]\nhead, ____, tail = data\n```",
    "options": [],
    "answer": "*body",
    "why": "파이썬 3에서 `*` 기호를 변수 앞에 사용하면, 언패킹 시 남는 모든 요소를 리스트 형태로 해당 변수에 할당할 수 있습니다.",
    "hint": "여러 개를 한꺼번에 모으는 '별' 기호를 기억하세요.",
    "difficulty": "hard",
    "id": "0103"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "중첩된 딕셔너리 구조에서 키가 없을 경우 발생하는 `KeyError`를 방지하며, 안전하게 하위 키 'points'의 값을 가져오는 코드를 완성하세요. (없을 시 기본값 0 반환)\n\n```python\nplayer = {'info': {'name': 'Player1'}}\nscore = player.get('info', {}).____('points', 0)\n```",
    "options": [],
    "answer": "get",
    "why": "딕셔너리 체이닝 시 첫 번째 `get`이 빈 딕셔너리(`{}`)를 반환하게 유도하면, 연쇄적으로 두 번째 `get`을 안전하게 호출할 수 있는 패턴입니다.",
    "hint": "데이터를 '가져오는(Get)' 메서드를 연속으로 사용하세요.",
    "difficulty": "hard",
    "id": "0104"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "문자열 `text = \"  !!Clean Up!!  \"`에서 양쪽 가의 공백과 느낌표(`!`)를 한꺼번에 제거하는 코드를 완성하세요.\n\n```python\ntext = \"  !!Clean Up!!  \"\nresult = text.____(\" !\")\n# 결과: \"Clean Up\"\n```",
    "options": [],
    "answer": "strip",
    "why": "`strip()` 메서드에 인자로 문자열을 주면, 해당 문자열에 포함된 각 문자들(여기서는 공백과 '!')이 양 끝에 있다면 모두 제거합니다.",
    "hint": "양쪽 끝의 불필요한 것들을 '벗겨내는' 메서드입니다.",
    "difficulty": "hard",
    "id": "0105"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "정수 리스트 `nums = [1, 2, 3]`를 하이픈(`-`)으로 연결된 문자열 \"1-2-3\"으로 변환하는 코드를 완성하세요. (타입 캐스팅 유의)\n\n```python\nnums = [1, 2, 3]\nresult = \"-\".join(____(str, nums))\n```",
    "options": [],
    "answer": "map",
    "why": "`join()` 메서드는 문자열 리스트만 받을 수 있으므로, 정수 리스트를 `map(str, nums)`를 통해 문자열 이터러블로 먼저 변환해야 합니다.",
    "hint": "리스트의 각 요소에 특정 함수(str)를 '지도 그리듯 한꺼번에 적용'하는 함수입니다.",
    "difficulty": "hard",
    "id": "0106"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "리스트 컴프리헨션 내에서 조건부 표현식(If-Else)을 사용하여 `numbers`의 요소가 5보다 크면 'High', 작거나 같으면 'Low'로 분류하는 리스트를 완성하세요.\n\n```python\nnumbers = [3, 7, 5, 9]\nresult = [\"High\" ____ n > 5 else \"Low\" for n in numbers]\n```",
    "options": [],
    "answer": "if",
    "why": "리스트 컴프리헨션에서 `if-else`가 모두 쓰일 때는 루프 변수 뒤가 아닌, 루프(`for`) 앞쪽에서 '삼항 연산자'의 형태로 위치해야 합니다.",
    "hint": "이것(`if`) 참이면 앞을, 아니면 뒤(`else`)를 선택하는 삼항 연산 구조입니다.",
    "difficulty": "hard",
    "id": "0107"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "리스트 `data = [0, 1, 2, 3, 4]`를 역순으로 뒤집으면서 동시에 2칸씩 건너뛰어 `[4, 2, 0]`을 만드는 슬라이싱 코드를 완성하세요.\n\n```python\ndata = [0, 1, 2, 3, 4]\nresult = data[____]\n```",
    "options": [],
    "answer": "::-2",
    "why": "슬라이싱 `[start:stop:step]`에서 step을 `-2`로 설정하면 끝에서부터 시작하여 2의 간격으로 역순 순회합니다.",
    "hint": "처음부터 끝까지(`::`)를 '보폭 -2'로 걷는다고 생각하세요.",
    "difficulty": "hard",
    "id": "0108"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "딕셔너리 컴프리헨션을 사용하여 리스트 `names = ['a', 'b']`의 요소를 키로, 그 인덱스를 값으로 갖는 `{ 'a': 0, 'b': 1 }`을 생성하는 코드를 완성하세요.\n\n```python\nnames = ['a', 'b']\nd = {name: i for i, name in ____(names)}\n```",
    "options": [],
    "answer": "enumerate",
    "why": "`enumerate()` 함수는 이터러블의 요소와 인덱스를 동시에 튜플(index, value)로 반환하므로 컴프리헨션과 결합하여 효율적으로 맵을 생성할 수 있습니다.",
    "hint": "순번과 데이터를 한 번에 열거(Enum)해주는 함수입니다.",
    "difficulty": "hard",
    "id": "0109"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "임베디드 객체인 `datetime`을 JSON으로 직렬화할 때 발생하는 에러를 방지하기 위해, 직렬화 불가능한 타입을 문자열로 변환하여 처리하는 파라미터를 완성하세요.\n\n```python\nimport json\nfrom datetime import datetime\ndata = {\"time\": datetime.now()}\njson_str = json.dumps(data, ____=str)\n```",
    "options": [],
    "answer": "default",
    "why": "`json.dumps`의 `default` 파라미터에 함수를 지정하면, 기본 직렬화가 불가능한 객체를 만났을 때 해당 함수를 호출하여 변환을 시도합니다.",
    "hint": "기본적으로 처리 못 하는 것을 대비한 '기본(Default)' 처리기입니다.",
    "difficulty": "hard",
    "id": "0110"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "특정 예외(`FileNotFoundError`)가 발생하더라도 이를 무시하고 조용히 넘어가기 위해 `contextlib` 라이브러리를 사용한 컨텍스트 매니저 코드를 완성하세요.\n\n```python\nfrom contextlib import ____\nwith suppress(FileNotFoundError):\n    os.remove(\"temp.txt\")\n```",
    "options": [],
    "answer": "suppress",
    "why": "`contextlib.suppress`는 지정된 예외가 발생했을 때 이를 가로채어 정상적으로 종료시키는 유틸리티 컨텍스트 매니저입니다.",
    "hint": "예외를 '억제하다'라는 뜻의 영어 단어입니다.",
    "difficulty": "hard",
    "id": "0111"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "한 번의 `except` 블록에서 두 개 이상의 예외(`ValueError`, `TypeError`)를 동시에 처리하기 위한 괄호 문법을 완성하세요.\n\n```python\ntry:\n    # some code\nexcept (____) as e:\n    print(f\"Captured: {e}\")\n```",
    "options": [],
    "answer": "ValueError, TypeError",
    "why": "여러 예외를 한꺼번에 잡으려면 `except` 뒤에 튜플 형태로 예외 클래스들을 나열해야 합니다.",
    "hint": "두 클래스를 쉼표(,)로 구분하여 나열하세요.",
    "difficulty": "hard",
    "id": "0112"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "파이썬 3.10 이상의 'Union Type' 문법을 사용하여, 매개변수 `n`이 정수(`int`) 또는 `None`일 수 있음을 나타내는 타입 힌트를 완성하세요.\n\n```python\ndef process_data(n: ____ = None):\n    print(n)\n```",
    "options": [],
    "answer": "int | None",
    "why": "파이썬 3.10부터는 `Union[int, None]` 대신 파이프(`|`) 기호를 사용하여 간결하게 여러 타입을 지정할 수 있습니다.",
    "hint": "수직 바(`|`) 기호를 사용하여 '인자 또는(or) None'을 표현하세요.",
    "difficulty": "hard",
    "id": "0113"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "가변 인자 리스트 `args`를 다른 함수 `target_func`에 그대로 '풀어서(Unpacking)' 전달하기 위한 코드를 완성하세요.\n\n```python\ndef wrapper(*args):\n    target_func(____)\n```",
    "options": [],
    "answer": "*args",
    "why": "함수 호출 시 `*`를 사용하면 튜플이나 리스트의 요소들을 각각의 독립된 위치 인자로 분리하여 전달합니다.",
    "hint": "묶여 있는 보따리를 푸는 '별' 기호를 사용하세요.",
    "difficulty": "hard",
    "id": "0114"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "딕셔너리 `scores = {'A': 90, 'B': 80}`을 점수(Value)를 기준으로 내림차순 정렬하기 위해 `sorted()`의 `key` 인자에 전달할 람다 함수를 완성하세요.\n\n```python\nscores = {'A': 90, 'B': 100}\nresult = sorted(scores.items(), key=____, reverse=True)\n```",
    "options": [],
    "answer": "lambda x: x[1]",
    "why": "`items()`는 (key, value) 형태의 튜플 이터러블을 반환하므로, 인덱스 `1`을 추출하는 람다를 통해 값을 기준으로 정렬할 수 있습니다.",
    "hint": "튜플의 두 번째 요소(index 1)를 지목하세요.",
    "difficulty": "hard",
    "id": "0115"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "문자열 리스트를 먼저 '길이'순으로 정렬하고, 길이가 같을 경우 '알파벳' 순으로 정렬하기 위해 `key` 인자에 전달할 튜플 기반 람다식을 완성하세요.\n\n```python\nwords = [\"apple\", \"bat\", \"cat\", \"ant\"]\nwords.sort(key=____)\n```",
    "options": [],
    "answer": "lambda x: (len(x), x)",
    "why": "파이썬의 정렬 키에 튜플을 반환하는 함수를 주면, 튜플의 첫 번째 요소로 먼저 비교하고 같으면 두 번째 요소로 넘어가는 계층적 정렬을 수행합니다.",
    "hint": "길이(`len(x)`)와 자기 자신(`x`)을 튜플로 묶으세요.",
    "difficulty": "hard",
    "id": "0116"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "현재 시각을 밀리초(Microseconds)까지 포함하여 ISO 8601 형식인 \"2023-10-27T10:20:30.123456\" 형태로 출력하는 포맷 문자열을 완성하세요.\n\n```python\nfrom datetime import datetime\nnow = datetime(2023, 10, 27, 10, 20, 30, 123456)\nformatted = now.____(\"%Y-%m-%dT%H:%M:%S.%f\")\n```",
    "options": [],
    "answer": "strftime",
    "why": "`%f`는 마이크로초를 나타내는 포맷 지시자로, 정밀한 시간 기록이 필요한 로그 시스템 등에서 자주 쓰입니다.",
    "hint": "날짜 객체를 문자열로 '포맷'하여 출력하는 메서드입니다.",
    "difficulty": "hard",
    "id": "0117"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "정규표현식에서 도메인 주소만 추출하기 위해 'Non-capturing Group' 문법인 `(?:...)`를 활용하여 `https://` 부분은 결과에서 제외하는 패턴을 완성하세요.\n\n```python\nimport re\nurl = \"https://google.com\"\ndomains = re.findall(r\"____google.com\", url)\n```",
    "options": [],
    "answer": "(?:https?://)",
    "why": "`(?:...)` 문법은 그룹으로 묶어 패턴 매칭에는 사용하지만, 최종 결과물(`findall` 등)에 해당 부분은 포함시키지 않는 '비캡처 그룹' 역할을 합니다.",
    "hint": "물음표와 콜론(`?:`)을 조합한 비캡처 그룹 문법을 사용하세요.",
    "difficulty": "hard",
    "id": "0118"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "정수 리스트 `nums = [-5, 1, -10, 3]`을 '절댓값' 기준으로 내림차순 정렬하기 위해 필요한 인자들을 완성하세요.\n\n```python\nnums = [-5, 1, -10, 3]\nnums.sort(____=abs, reverse=True)\n```",
    "options": [],
    "answer": "key",
    "why": "`sort()`의 `key` 인자에 함수를 넘기면 정렬 기준값을 커스텀할 수 있으며, `reverse=True`와 조합하여 내림차순을 구현합니다.",
    "hint": "정렬의 핵심 '기준'이 되는 인자 명칭입니다.",
    "difficulty": "hard",
    "id": "0119"
  },
  {
    "chapter_name": "Python 기초",
    "type": "코드 완성형",
    "question": "딕셔너리 컴프리헨션을 사용하여 기존 `user = {'a': 1, 'b': 2}`의 값을 모두 2배로 증가시킨 새 딕셔너리를 생성하는 코드를 완성하세요.\n\n```python\nuser = {'a': 1, 'b': 2}\nnew_user = {k: v * 2 for k, v in user.____()}\n```",
    "options": [],
    "answer": "items",
    "why": "`items()` 메서드는 (key, value)의 뷰를 제공하므로, 컴프리헨션에서 k와 v 두 변수로 즉시 언패킹하여 가공할 수 있습니다.",
    "hint": "키와 값을 모두 가져오는 메서드입니다.",
    "difficulty": "hard",
    "id": "0120"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas의 `resample()` 메서드를 사용하여 상향 샘플링(Up-sampling)을 수행할 때, 레이블과 간격의 경계 조건(`closed`, `label`)을 설정하는 논리가 시계렬 분석의 무결성에 미치는 영향은?",
    "options": [
      "Determines which boundary is inclusive and how points are labeled",
      "Automatically interpolates missing values via Spline",
      "Shifts the entire index by a fixed UTC offset",
      "Converts the frequency to a business-day offset only"
    ],
    "answer": "Determines which boundary is inclusive and how points are labeled",
    "why": "`resample`은 구간의 왼쪽 혹은 오른쪽 중 어디를 닫을지(`closed`), 그리고 결과 레이블을 어느 쪽 경계값으로 정할지(`label`)에 따라 데이터 전달(Look-ahead bias) 문제가 발생할 수 있으므로 주의해야 합니다.",
    "hint": "데이터가 특정 시간에 기록되었을 때, 이를 '앞의 시간대'에 넣을지 '뒤의 시간대'에 넣을지 정하는 기준을 생각하세요.",
    "trap_points": [
      "단순히 주기를 바꾸는 것을 넘어, 실제 데이터가 어느 주기에 포함될지 결정하는 통계적 근거가 됨"
    ],
    "difficulty": "hard",
    "id": "0121"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Numpy 배열을 1차원으로 펼치는 `flatten()`과 `ravel()` 메서드의 결정적인 성능 및 메모리 관리적 차이점은?",
    "options": [
      "flatten() creates a copy, while ravel() attempts to return a view",
      "ravel() is limited to 2D arrays, whereas flatten() supports nD",
      "flatten() performs an in-place modification on the original",
      "ravel() sorts elements while reshaping to 1D"
    ],
    "answer": "flatten() creates a copy, while ravel() attempts to return a view",
    "why": "`flatten()`은 항상 새로운 메모리를 할당하여 복사본을 만드는 반면, `ravel()`은 가능한 경우 원본 데이터를 참조하는 뷰(View)를 반환하여 더 빠르고 메모리 효율적입니다.",
    "hint": "원본 데이터를 건드렸을 때 '같이 변하는지' 아니면 '독립적인지'의 메모리 구조 차이를 생각하세요.",
    "trap_points": [
      "원본 데이터의 손상을 방지해야 한다면 반드시 복사본을 만드는 flatten()을 써야 함"
    ],
    "difficulty": "hard",
    "id": "0122"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "파이썬 정규표현식 엔진에서 수량자 뒤에 붙는 `?`(예: `*?`, `+?`)가 백트래킹(Backtracking) 성능에 미치는 영향과 그 명칭은?",
    "options": [
      "Non-greedy (Lazy) matching: Matches the minimum necessary characters",
      "Atomic matching: Prevents any backtracking after a match",
      "Possessive quantifier: Consumes everything but fails immediately",
      "Forward looking assertion: Validates pattern without consuming"
    ],
    "answer": "Non-greedy (Lazy) matching: Matches the minimum necessary characters",
    "why": "기본 수량자는 최대치를 찾으려 하지만(Greedy), `?`가 붙으면 최소 조건을 충족하는 즉시 멈춤으로써 복잡한 텍스트에서 불필요한 탐색을 줄입니다.",
    "hint": "욕심을 부리지 않고 '조건만 맞으면 바로 퇴근'하는 성실한 일꾼을 생각하세요.",
    "trap_points": [
      "남용할 경우 탐색 횟수가 오히려 증가할 수 있으므로 패턴 설계 시 유의해야 함"
    ],
    "difficulty": "hard",
    "id": "0123"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas의 `applymap()`(또는 최신 버전의 `map()`)이 대규모 데이터프레임에서 벡터화 연산(NumPy ufunc)보다 느린 기술적 이유는?",
    "options": [
      "Iterative Python-level function call per element",
      "Automatic data type casting to Object",
      "Global Interpreter Lock during memory allocation",
      "Lack of support for GPU acceleration"
    ],
    "answer": "Iterative Python-level function call per element",
    "why": "`applymap`은 모든 요소에 대해 파이썬 함수를 호출하므로 루프 오버헤드가 크지만, 넘파이 벡터화 연산은 C 수준에서 병렬 처리되므로 훨씬 빠릅니다.",
    "hint": "수백만 명에게 한 명씩 일일이 서명해주는 것(`applymap`)과, 도장으로 한꺼번에 찍어내는 것(Vectorization)의 차이를 생각하세요.",
    "trap_points": [
      "최신 판다스 버전에서는 `applymap`이 폐기 예정(Deprecated)이며 `DataFrame.map`으로 대체됨"
    ],
    "difficulty": "hard",
    "id": "0124"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "범주형 데이터를 '원-핫 인코딩(One-hot Encoding)'으로 처리할 때, 선형 회귀 모델에서 '더미 변수의 함정(Dummy Variable Trap)'을 피하기 위한 핵심 조치는?",
    "options": [
      "Dropping one category column to prevent multicollinearity",
      "Scaling the dummy values to unit variance",
      "Applying PCA before encoding the labels",
      "Interpolating missing category levels"
    ],
    "answer": "Dropping one category column to prevent multicollinearity",
    "why": "인코딩된 모든 열의 합이 1이 되어버리면 열끼리 완벽한 선형 관계(다중공선성)를 가지게 되어 모델 학습을 방해하므로, 보통 하나(First)의 열을 삭제하여 정보를 보존하면서 독립성을 확보합니다.",
    "hint": "N개의 방 중에서 N-1개의 방이 비어있다면, 나머지 1개는 당연히 차 있다는 사실을 역으로 이용하세요.",
    "trap_points": [
      "카테고리 수가 너무 많을 때는 원-핫 인코딩 대신 임베딩이나 해싱 트릭을 고려해야 함"
    ],
    "difficulty": "hard",
    "id": "0125"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "수백만 건의 데이터를 2차원 산점도(Scatter Plot)에 시각화할 때, '오버플로팅(Overplotting)'으로 인해 데이터 분포가 왜곡되어 보이는 현상을 해결하기 위한 효과적인 대안 차트는?",
    "options": [
      "Hexbin plot with color density gradient",
      "3D Mesh surface reconstruction",
      "Radar chart with normalization",
      "Stacked area graph for each point"
    ],
    "answer": "Hexbin plot with color density gradient",
    "why": "점들이 겹쳐서 구분이 안 될 때는 평면을 육각형 격자로 나누고 해당 격자 내 데이터 개수를 색상 농도로 표현하는 헥스빈(Hexbin) 차트가 밀도를 파인하는 데 훨씬 유리합니다.",
    "hint": "수많은 개미들이 한곳에 뭉쳐있을 때, 개미를 한 마리씩 세지 말고 '얼마나 시커멓게 뭉쳐있는지' 구역별로 보는 방식입니다.",
    "trap_points": [
      "알파(투명도)를 조절하는 것도 방법이지만, 데이터가 극단적으로 많으면 헥스빈이나 커널 밀도 추정(KDE)이 필수적임"
    ],
    "difficulty": "hard",
    "id": "0126"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas의 `to_datetime()` 수행 시 `errors='coerce'` 옵션이 데이터 전처리 파이프라인에서 갖는 실제 기능적 영향은?",
    "options": [
      "Replaces unparseable strings with NaT (Not a Time)",
      "Throws a Fatal Exception for any format mismatch",
      "Automatically skips the index containing errors",
      "Forcibly converts strings using local timezone"
    ],
    "answer": "Replaces unparseable strings with NaT (Not a Time)",
    "why": "`coerce` 옵션을 사용하면 형식이 잘못된 데이터를 에러로 멈추는 대신 `NaT`(시계렬용 결측치)로 강제 변환하여, 분석이 중단되지 않고 결측치 처리 단계로 넘어갈 수 있게 해줍니다.",
    "hint": "이해할 수 없는 암호를 만났을 때, 포기하고 멈추기보다 일단 '빈 칸'으로 표시해두고 다음 줄을 읽는 지혜를 생각하세요.",
    "trap_points": [
      "에러를 발견하지 못하고 넘어갈 수 있으므로, 변환 후 반드시 `isna()`로 깨진 데이터 양을 체크해야 함"
    ],
    "difficulty": "hard",
    "id": "0127"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Numpy의 `np.diag()` 함수가 입력 배열의 차원(Rank)에 따라 수행하는 상이한 두 가지 동작은?",
    "options": [
      "Extract diagonal from 2D / Create diagonal matrix from 1D",
      "Calculate matrix determinant / Solve linear equations",
      "Transpose the rows / Invert the column order",
      "Normalize elements / Standardize column variance"
    ],
    "answer": "Extract diagonal from 2D / Create diagonal matrix from 1D",
    "why": "2차원 행렬을 넣으면 대각선 성분만 뽑아내어 1차원으로 반환하고, 1차원 배열을 넣으면 이를 대각선으로 하는 2차원 대각행렬을 생성하는 '이중 기능'을 수행합니다.",
    "hint": "목걸이에서 알맹이만 빼는 작업과, 알맹이를 꿰어 목걸이를 만드는 작업 두 가지를 동시에 할 줄 아는 함수입니다.",
    "trap_points": [
      "k 인자를 통해 주대각선 외의 대각선(Upper/Lower)으로 위치를 옮길 수 있음"
    ],
    "difficulty": "hard",
    "id": "0128"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "시계렬 데이터에서 결측치를 `ffill`(Forward Fill)로 처리할 때, 머신러닝 모델 학습 시 주의해야 하는 '기술적 편향(Data Leakage)'의 원인은?",
    "options": [
      "Using future values to fill previous timestamps (Look-ahead)",
      "Decreasing target variance due to repeated samples",
      "Invalidating the strict temporal order of cross-validation",
      "Global scaling mismatch across feature windows"
    ],
    "answer": "Using future values to fill previous timestamps (Look-ahead)",
    "why": "`bfill`은 미래의 데이터를 과거로 끌어오기에 명백한 금기이지만, `ffill` 역시 실시간 서비스 중 아직 발생하지 않은 이벤트의 이전 값을 무분별하게 참조할 수 있어 검증 전략 설계 시 주의해야 합니다.",
    "hint": "미래의 시험 정답지를 정답 처리용으로 미리 과거에 가져와 사용하는 커닝 행위를 생각하세요.",
    "trap_points": [
      "데이터 분석 시점에서는 편리하지만, 실제 배포된 모델이 결측치를 실시간으로 만났을 때 ffill이 불가능한 상황이 생길 수 있음"
    ],
    "difficulty": "hard",
    "id": "0129"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas의 `reset_index(drop=True)` 연산이 대규모 데이터프레임에서 메모리 및 탐색 성능에 기여하는 정성적인 이유는?",
    "options": [
      "Normalizes the index to RangeIndex for O(1) integer access",
      "Compresses the underlying column data into a sparse format",
      "Automatically triggers a garbage collection of unused levels",
      "Re-hashes the index keys for faster string lookup"
    ],
    "answer": "Normalizes the index to RangeIndex for O(1) integer access",
    "why": "기존의 복잡하거나 불연속적인 인덱스를 정적 패턴의 `RangeIndex`로 초기화하면, 별도의 인덱스 맵 저장 공간을 줄이고 정수 기반의 즉각적인 메모리 오프셋 계산이 가능해져 효율적입니다.",
    "hint": "뒤죽박죽인 번호표를 버리고, 0번부터 순서대로 다시 매기는 것이 왜 찾기 쉬운지 생각해보세요.",
    "trap_points": [
      "`drop=False`인 경우 기존 인덱스가 일반 컬럼으로 편입되어 메모리 사용량이 일시적으로 늘어날 수 있음"
    ],
    "difficulty": "hard",
    "id": "0130"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas의 `pd.concat()` 수행 시 `join='outer'`(기본값)와 `join='inner'`가 중복되지 않는 열(Column)들을 처리하는 방식의 차이는?",
    "options": [
      "Outer keeps all columns with NaNs / Inner keeps only shared columns",
      "Outer automatically merges columns / Inner creates a MultiIndex",
      "Outer requires unique indices / Inner allows duplicate keys",
      "Outer renames overlapping columns / Inner drops them"
    ],
    "answer": "Outer keeps all columns with NaNs / Inner keeps only shared columns",
    "why": "`outer` 조인은 합집합을 구하여 없는 자리에 NaN을 채우지만, `inner` 조인은 교집합을 구하여 모든 데이터프레임이 공통으로 가진 열만 남깁니다.",
    "hint": "두 집단의 '전체 합친 양'과 '공통된 부분' 중 무엇을 보고 싶은지의 차이를 생각하세요.",
    "trap_points": [
      "행(axis=0) 결합 시 열 이름이 하나하나 다르면 inner join의 결과가 빈 데이터프레임이 될 수 있음에 주의해야 함"
    ],
    "difficulty": "hard",
    "id": "0131"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Numpy의 `np.linspace()`가 `np.arange()`보다 수치 계산 실습(예: 그래프 그리기)에서 선호되는 결정적인 수치적 명분은?",
    "options": [
      "Guaranteed inclusion of the endpoint without floating-point offset errors",
      "Native support for complex number interpolation",
      "Automatic detection of logarithmic stepping",
      "Lower memory overhead for large integer ranges"
    ],
    "answer": "Guaranteed inclusion of the endpoint without floating-point offset errors",
    "why": "`arange`는 부동소수점 누적 오차로 인해 마지막 값이 포함되지 않을 위험이 있으나, `linspace`는 등분할 개수를 기반으로 좌표를 계산하여 마지막 경계값을 확실히 고정합니다.",
    "hint": "0부터 1까지 10칸을 나눌 때, 정확히 1에 도착하는 것이 보장되는 시스템을 생각하세요.",
    "trap_points": [
      "endpoint=False 옵션을 주면 arange처럼 마지막 값을 제외할 수도 있음"
    ],
    "difficulty": "hard",
    "id": "0132"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Scikit-learn의 `StandardScaler` 적용 시 `fit()`을 학습 데이터(Train)에만 수행하고, 테스트 데이터(Test)에는 `transform()`만 수행해야 하는 통계적 명분은?",
    "options": [
      "To prevent 'Data Leakage' by hiding test distribution from categories",
      "To reduce the computational complexity of inverse transforms",
      "Because test data is implicitly assumed to have zero variance",
      "To ensure the model weights remain strictly orthogonal"
    ],
    "answer": "To prevent 'Data Leakage' by hiding test distribution from categories",
    "why": "테스트 데이터의 평균과 표준편차를 직접 사용하면 모델이 미래의 정보를 미리 엿듣게 되는(Leakage) 꼴이 되어 실무 성능이 과대평가될 위험이 크기 때문입니다.",
    "hint": "시험을 보기 전에 시험지의 평균 점수를 미리 알려주고 공부시키는 행위가 왜 공정하지 못한지 생각하세요.",
    "trap_points": [
      "실제 서비스(Inference) 단계에서도 학습 시 사용된 평균/표준편차 값을 그대로 고정하여 치환해야 함"
    ],
    "difficulty": "hard",
    "id": "0133"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "PCA(주성분 분석)를 수행하기 전 데이터에 대해 반드시 평균 센터링(Mean Centering)을 수행해야 하는 기하학적 이유는?",
    "options": [
      "To ensure the first PC points in the direction of maximum variance",
      "To force all eigenvalues to be strictly positive",
      "To eliminate the need for calculating the covariance matrix",
      "To reduce the dimensionality of the feature space linearly"
    ],
    "answer": "To ensure the first PC points in the direction of maximum variance",
    "why": "데이터가 원점에 중심이 있지 않으면 주성분이 분산이 아닌 원점과의 거리를 기준으로 탐색되어 엉뚱한 방향이 주성분으로 잡히게 될 위험이 있기 때문입니다.",
    "hint": "그림을 그릴 때 종이 한가운데에서 시작하지 않고 구석에서 시작하면, 전체 균형(분산)이 틀어지는 원리를 생각하세요.",
    "trap_points": [
      "대부분의 라이브러리(Scikit-learn 등)는 내부적으로 센터링을 수행하지만, 원리를 모르면 수동 구현 시 큰 오류를 범함"
    ],
    "difficulty": "hard",
    "id": "0134"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas의 `groupby().transform()`이 일반적인 `aggregate()`와 구별되는 출력 데이터의 구조적 특징은?",
    "options": [
      "Propagates the result to match the original index length",
      "Returns a single scalar value per entire group list",
      "Automatically drops categorical columns after fusion",
      "Sorts the final results purely by timestamp order"
    ],
    "answer": "Propagates the result to match the original index length",
    "why": "`aggregate`는 그룹당 하나의 요약 값을 내놓아 데이터 크기가 줄어들지만, `transform`은 그룹별 통계량을 계산한 뒤 다시 원본 행의 개수에 맞춰 분산(Broadcast) 시키므로 데이터프레임 구조를 그대로 유지합니다.",
    "hint": "각 반의 평균을 낸 뒤, 그 평균 점수를 모든 학생의 성적표 옆에 한 줄씩 적어주는 상황을 생각하세요.",
    "trap_points": [
      "결측치를 그룹 평균으로 채우는 등의 전처리 작업 시에 `transform`이 매우 강력한 도구가 됨"
    ],
    "difficulty": "hard",
    "id": "0135"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "피어슨 상관계수(Pearson)와 달리 스피어먼 상관계수(Spearman)가 비선형(Non-linear) 관계인 변수 쌍에서도 높은 값을 보장받을 수 있는 기술적 명분은?",
    "options": [
      "Calculation based on Rank-order instead of raw scale values",
      "Application of quadratic kernel mapping on inputs",
      "Elimination of covariance normalization factors",
      "Focus on Euclidean distance between feature vectors"
    ],
    "answer": "Calculation based on Rank-order instead of raw scale values",
    "why": "스피어먼은 데이터의 실제 크기가 아니라 '등수(Rank)'를 기반으로 상관성을 계산하므로, 두 변수가 단순히 선형이 아니더라도 동시에 증가하거나 감소하는 양상(단조성)만 뚜렷하면 높은 상관성을 보입니다.",
    "hint": "실제 점수가 아니라 '반에서 누가 몇 등인지' 순위표만 보고 두 과목의 실력이 비슷한지 판단하는 방식을 생각하세요.",
    "trap_points": [
      "이상치에 매우 민감한 피어슨과 달리 등수 기반인 스피어먼은 이상치의 영향을 훨씬 적게 받음"
    ],
    "difficulty": "hard",
    "id": "0136"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas `fillna()` 메서드의 `limit` 파라미터가 시계렬 데이터 보간(Interpolation) 연산에서 하는 역할은?",
    "options": [
      "Specifies the maximum number of consecutive NaNs to fill",
      "Sets the cumulative threshold for memory usage",
      "Defines the minimum group size for categorical mean",
      "Forcibly stops the broadcast after a certain row count"
    ],
    "answer": "Specifies the maximum number of consecutive NaNs to fill",
    "why": "공백이 너무 길게 비어있는 경우(예: 센서 고장 10시간), 이를 이전 값으로 너무 길게 채우면 현실 왜곡이 발생하므로 이를 방지하기 위해 최대 연속 전파 횟수를 제한합니다.",
    "hint": "옆 사람의 의견을 따라가되(`ffill`), 최대 3명까지만 전달하고 그 뒤로는 '모름'으로 남겨두는 보험 같은 설정을 생각하세요.",
    "trap_points": [
      "limit을 넘어서는 결석 구간은 그대로 NaN으로 남으므로 후속 처리 전략이 필요함"
    ],
    "difficulty": "hard",
    "id": "0137"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas 문자열 접근자 `.str.contains()` 사용 시, 결측치(`NaN`)가 포함된 행에 매칭 결과가 아닌 `NaN`이 그대로 전파되지 않도록 설정하는 파라미터는?",
    "options": [
      "na=False (or True)",
      "fill_value='skip'",
      "errors='ignore'",
      "strict=False"
    ],
    "answer": "na=False (or True)",
    "why": "문자열 여부를 판단할 때 원본에 NaN이 있으면 결과도 NaN이 되어 불리언 인덱싱(Filtering) 시 에러가 발생할 수 있는데, `na=False`를 주면 해당 행을 '포함하지 않음'으로 깔끔하게 처리해줍니다.",
    "hint": "데이터가 아예 없는 칸(NaN)에 대해 '너는 검색 결과가 아니라고 치자'라고 미리 정해주는 스위치를 생각하세요.",
    "trap_points": [
      "na를 설정하지 않으면 필터링 조건문(`df[df['col'].str.contains(...)]`)에서 ValueError를 유발할 수 있음"
    ],
    "difficulty": "hard",
    "id": "0138"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "중복된 값이 매우 많은 문자열 열을 `astype('category')`로 변환했을 때 얻을 수 있는 대표적인 '메모리 효율적' 데이터 표현 방식의 특징은?",
    "options": [
      "Dictionary-based mapping with integer indices",
      "LZW based lossless compression of bytes",
      "Binary quantization of floating points",
      "Global interning of non-hashable buffers"
    ],
    "answer": "Dictionary-based mapping with integer indices",
    "why": "카테고리 타입은 같은 문자열을 반복 저장하지 않고, 고유한 문자열 리스트(Codes)를 한 번만 저장한 뒤 원본 데이터는 이를 가리키는 '작은 정수 인덱스'로만 채워 메모리를 획기적으로 절약합니다.",
    "hint": "이름표를 일일이 적지 않고, 번호표만 나눠준 뒤 '1번은 사과, 2번은 포도'라고 장부에 한 번만 적어두는 효율성을 생각하세요.",
    "trap_points": [
      "고유값(Unique)이 전체의 50%를 넘을 정도로 많다면 오히려 인덱스 관리에 메모리가 더 쓰일 수 있음"
    ],
    "difficulty": "hard",
    "id": "0139"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "가로로 넓은 데이터(Wide format)를 세로로 긴 데이터(Long format)인 'Tidy Data' 구조로 변환하기 위해 사용하는 Pandas의 메서드는?",
    "options": [
      "melt()",
      "pivot()",
      "stack()",
      "unstack()",
      "reshape()"
    ],
    "answer": "melt()",
    "why": "`melt`는 고정할 칼럼과 변환할 칼럼을 지정하여 데이터를 녹여내듯이 세로로 길게 재구조화하며, 이는 데이터베이스 입력이나 시계렬 시각화에 최적화된 형태입니다.",
    "hint": "단단하게 굳어있는 넓은 판을 '녹여서(Melt)' 길게 늘어트리는 상황을 떠올리세요.",
    "trap_points": [
      "pivot() 메서드는 melt()의 정확히 반대 동작을 수행하여 다시 가로로 넓게 펼칩니다."
    ],
    "difficulty": "hard",
    "id": "0140"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas의 `groupby()` 연산 시 `as_index=False` 파라미터를 설정했을 때 발생하는 구조적 변화와 그 성능상의 이점은?",
    "options": [
      "Returns a flat DataFrame with columns instead of a MultiIndex",
      "Disables automatic sorting for faster execution speed",
      "Calculates only global aggregates while skipping group-wise loops",
      "Converts the resulting object into a NumPy recarray directly"
    ],
    "answer": "Returns a flat DataFrame with columns instead of a MultiIndex",
    "why": "기본적으로 `groupby`는 그룹 기준 열을 인덱스로 만드는데, `as_index=False`를 주면 연산 결과를 일반 컬럼이 있는 평면 데이터프레임으로 유지하여 후속 병합(Merge) 작업 시 인덱스 재설정 오버헤드를 줄여줍니다.",
    "hint": "결과물에서 '이름'이 왼쪽 인덱스 칸에 들어가는지, 아니면 일반 데이터 칸에 그대로 남아있는지의 차이입니다.",
    "trap_points": [
      "인덱스가 계층적(MultiIndex)으로 쌓이는 것을 방지하여 코드가 더 직관적이게 됨"
    ],
    "difficulty": "hard",
    "id": "0141"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Numpy `reshape()` 연산 시 `-1` 파라미터를 사용하는 기술적 명분과 메모리 구조에 미치는 영향은?",
    "options": [
      "Automatically infers one dimension based on total size",
      "Forcibly stops any memory view sharing and creates a copy",
      "Rotates the memory layout from Row-major to Column-major",
      "Initializes the new shape with random Gaussian noise"
    ],
    "answer": "Automatically infers one dimension based on total size",
    "why": "배열의 전체 요소 개수는 고정되어 있으므로, 나머지 차원 크기가 정해졌을 때 `-1`을 쓰면 넘파이가 자동으로 정확한 값을 계산해주어 유연한 코드 작성을 돕습니다.",
    "hint": "총 12개의 공을 3줄로 세우면, 한 줄에 몇 개씩 들어갈지는 계산하지 않아도 이미 정해져 있다는 논리입니다.",
    "trap_points": [
      "두 개 이상의 차원에 -1을 사용할 수는 없음에 주의해야 함"
    ],
    "difficulty": "hard",
    "id": "0142"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "자연어 전처리에서 'Lemmatization'이 단순히 어미를 자르는 'Stemming'보다 문맥적으로 우월한 기술적 근거는?",
    "options": [
      "Morphological analysis using dictionary and Part-of-Speech",
      "Linear interpolation of character frequencies",
      "Compression of sparse vector space into latent dimensions",
      "Hash-based mapping of character tri-grams"
    ],
    "answer": "Morphological analysis using dictionary and Part-of-Speech",
    "why": "표제어 추출(Lemmatization)은 단어의 품사와 문법 정보를 고려하여 'am/is/are'를 'be'로 변환하는 등 실제 사전적 원형을 찾기에 훨씬 정교합니다.",
    "hint": "단순히 꼬리만 자르는 것과, 족보(사전)를 뒤져서 원래 이름이 무엇인지 찾아내는 정성의 차이입니다.",
    "trap_points": [
      "정교한 만큼 Stemming보다 연산 시간이 더 소요되므로 실시간 처리 시 고려해야 함"
    ],
    "difficulty": "hard",
    "id": "0143"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "정규표현식에서 `^` 기호가 `MULTILINE` 플래그 활성화 여부에 따라 다르게 동작하는 기술적 구체성은?",
    "options": [
      "Matches start of each line vs. only start of entire string",
      "Forces case-insensitive matching in the first word",
      "Ignores comment lines starting with hash characters",
      "Automatically escapes special meta-characters at the start"
    ],
    "answer": "Matches start of each line vs. only start of entire string",
    "why": "기본적으로 `^`는 전체 텍스트의 맨 처음만 찾지만, `MULTILINE` 옵션을 주면 개행 문자(`\\n`) 뒤를 새로운 시작으로 인식하여 각 행의 첫 부분을 모두 찾아냅니다.",
    "hint": "책 전체의 첫 페이지 첫 글자만 볼 것인지, 매 장(Line)마다 첫 글자를 볼 것인지의 설정 차이입니다.",
    "trap_points": [
      "전체 텍스트의 진짜 시작만 고정하고 싶다면 `^` 대신 `\\A`를 사용하는 것이 안전함"
    ],
    "difficulty": "hard",
    "id": "0144"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas의 `df.describe()` 메서드가 범주형(Object/Categorical) 데이터에 대해 호출되었을 때, 수치형 연산 대신 제공하는 유일한 통계 지표 정보는?",
    "options": [
      "Unique count, top value, and its frequency",
      "Median and interquartile range of string lengths",
      "Levenshtein distance distribution between labels",
      "Missing value percentage per category level"
    ],
    "answer": "Unique count, top value, and its frequency",
    "why": "범주형 데이터는 평균을 낼 수 없으므로, 대신 얼마나 고유한 값이 있는지(`unique`), 가장 많이 나온 값은 무엇인지(`top`), 그 빈도(`freq`)는 얼마인지를 요약해 보여줍니다.",
    "hint": "숫자가 아닌 데이터에서 '가장 인기 있는 주인공'과 '그 주인공의 출연 횟수'를 알려주는 방식입니다.",
    "trap_points": [
      "데이터프레임에 수치형과 범주형이 섞여 있을 때 `include='all'`을 주어야 두 정보를 모두 볼 수 있음"
    ],
    "difficulty": "hard",
    "id": "0145"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Numpy에서 `*` 연산자와 `@` 연산자가 2차원 정사각 행렬 연산에서 보여주는 결정적인 수치적 차이는?",
    "options": [
      "Element-wise multiplication vs. True Matrix Multiplication",
      "Floating point scaling vs. Integer modular arithmetic",
      "Sparse matrix compression vs. Dense array extension",
      "Row-wise horizontal sum vs. Column-wise vertical mean"
    ],
    "answer": "Element-wise multiplication vs. True Matrix Multiplication",
    "why": "`*`는 같은 위치의 요소끼리 곱하지만, `@`(또는 `np.matmul`)은 수학적 정의에 따른 행렬 곱셈(Dot product)을 수행하므로 연산 결과의 차원이 완전히 달라질 수 있습니다.",
    "hint": "가로줄과 세로줄의 만남(`@`)인지, 아니면 그냥 똑같은 칸끼리 마주 보고 곱하는 것(`*`)인지의 차이입니다.",
    "trap_points": [
      "1차원 벡터에 대해서는 두 연산자가 내적(Dot product)으로 동일하게 동작할 수 있어 중급자들이 가장 많이 헷갈려 함"
    ],
    "difficulty": "hard",
    "id": "0146"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas 슬라이싱 작업 시 `.loc[a:b]`와 일반 파이썬 리스트 슬라이싱 `list[a:b]`가 마지막 경계값 `b`를 처리하는 근본적 차이는?",
    "options": [
      ".loc is inclusive of 'b' vs. list is exclusive of 'b'",
      ".loc requires integer offsets while list allows labels",
      ".loc creates a deep copy while list creates a shallow view",
      ".loc automatically flips the order if a > b"
    ],
    "answer": ".loc is inclusive of 'b' vs. list is exclusive of 'b'",
    "why": "파이썬의 기본 문법은 마지막 값을 포함하지 않지만, `.loc`은 레이블 기반이기에 '어디서부터 어디까지'라는 의미를 명확히 하고자 마지막 레이블 `b`를 결과에 포함시킵니다.",
    "hint": "1번부터 5번까지 오라고 했을 때, 5번 학생이 포함되는지 안 되는지의 차이를 생각하세요.",
    "trap_points": [
      "숫자 기반인 `.iloc`은 다시 파이썬 기본 관례를 따라 마지막 값을 제외하며, 이 차이로 인한 인덱스 에러가 빈번함"
    ],
    "difficulty": "hard",
    "id": "0147"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "단어의 등장 빈도를 가방에 담듯 수치화하는 'Bag of Words(BOW)' 기법이 '희소 행렬(Sparse Matrix)'을 유발하여 메모리를 낭비하게 되는 구조적 한계는?",
    "options": [
      "Massive zero-filled dimensions for rarely occurring words",
      "Recursive branching of nested n-gram probability tables",
      "Byte-level padding for non-unicode character segments",
      "Exponential growth of floating-point precision indices"
    ],
    "answer": "Massive zero-filled dimensions for rarely occurring words",
    "why": "전체 사전의 단어는 수만 개인데 각 문서에는 몇 단어만 쓰이므로, 대부분의 칸이 0으로 채워지는 비효율적인 거대 행렬이 만들어지기 때문입니다.",
    "hint": "수만 명의 이름표를 준비했는데, 정작 파티에는 5명만 왔을 때 비어있는 수만 개의 의자를 생각하세요.",
    "trap_points": [
      "이를 극복하기 위해 0이 아닌 값만 저장하는 특수한 메모리 포맷(CSR, CSC)을 주로 사용함"
    ],
    "difficulty": "hard",
    "id": "0148"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Numpy의 '벡터화(Vectorization)' 연산이 파이썬의 명시적 `for` 루프보다 압도적으로 빠른 하드웨어 수준의 기술적 명분은?",
    "options": [
      "SIMD (Single Instruction Multiple Data) at CPU level",
      "Dynamic allocation of context-free register buffers",
      "Recursive pre-fetching of asynchronous memory blocks",
      "Automatic offloading to integrated GPU pipelines"
    ],
    "answer": "SIMD (Single Instruction Multiple Data) at CPU level",
    "why": "파이썬은 한 번에 하나씩 처리하는 '인터프리터 오버헤드'가 크지만, 벡터화 연산은 CPU의 특수 명령어를 통해 한 번의 호출로 여러 데이터를 병렬 처리하기 때문입니다.",
    "hint": "계단을 한 칸씩 올라가는 것과, 엘리베이터에 모두 태워서 한꺼번에 옥상으로 이동하는 속도의 차이를 생각하세요.",
    "trap_points": [
      "단순히 속도가 빠른 것을 넘어, 복잡한 연산을 간결한 수식으로 표현할 수 있게 해줌"
    ],
    "difficulty": "hard",
    "id": "0149"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "정규표현식의 `\\s` 수량자가 매칭하는 대상에 포함되지 않는 '화이트스페이스' 예외 상황은?",
    "options": [
      "Zero-width non-breaking space (Unicode dependent)",
      "Standard horizontal tab character (\\t)",
      "Vertical form-feed character (\\f)",
      "Explicit carriage return (\\r)"
    ],
    "answer": "Zero-width non-breaking space (Unicode dependent)",
    "why": "`\\s`는 보편적인 공백(Space, Tab, CR, LF, FF)을 처리하지만, 유니코드의 특수한 보이지 않는 문자나 제로-폭 공백 등은 환경이나 엔진 설정에 따라 매칭되지 않을 수 있습니다.",
    "hint": "눈에는 보이지 않지만, 컴퓨터 입장에서는 '공간을 차지하지 않는 투명한 벽'과 같아 일반적인 공백 청소기로는 걸러지지 않는 먼지를 생각하세요.",
    "trap_points": [
      "단순한 ` `(스페이스)만 생각하다가는 탭이나 줄바꿈 문자로 인한 파싱 에러를 놓치기 십상임"
    ],
    "difficulty": "hard",
    "id": "0150"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Numpy의 `np.zeros()`로 배열을 초기화할 때, 명시적으로 `dtype`을 지정하지 않았을 때 발생하는 기본 데이터 타입(Default)과 그로 인한 정밀도 영향은?",
    "options": [
      "float64: 8-byte double precision floating point",
      "int32: 4-byte signed integer for discrete counts",
      "object: Variable size pointer to Python numbers",
      "float32: 4-byte single precision for memory saving"
    ],
    "answer": "float64: 8-byte double precision floating point",
    "why": "넘파이는 수치 계산의 정밀도를 위해 기본적으로 64비트 부동소수점(`float64`)을 사용하지만, 대규모 정수 데이터 처리 시에는 메모리 절약을 위해 `int` 계열로 명시적 변환이 권장됩니다.",
    "hint": "기본적으로 '실수' 형태로 만들어지며, 꽤 많은 메모리를 차지하는 정밀한 칸이라고 생각하세요.",
    "trap_points": [
      "0으로 채웠다고 해서 정수 타입일 것이라고 오해하면 형 변환 시 예기치 못한 에러를 겪을 수 있음"
    ],
    "difficulty": "hard",
    "id": "0151"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas의 `df.head()`를 사용하여 대규모 로그 데이터를 전처리할 때 발생할 수 있는 '선택 편향(Selection Bias)'의 위험성은?",
    "options": [
      "Early data may not represent later temporal shifts",
      "Subsequent head calls always trigger a full re-sort",
      "Head returns an immutable view that cannot be scaled",
      "First rows are strictly limited to character-type columns"
    ],
    "answer": "Early data may not represent later temporal shifts",
    "why": "데이터가 시간순으로 쌓여있을 경우 `head`만 보면 최근의 트렌드나 이상치를 놓칠 수 있으므로, 전체 분포 확인을 위해 `sample()`이나 `tail()`을 병행 사용해야 합니다.",
    "hint": "출근길 지하철 1번 칸만 보고 '오늘 서울 시민들은 모두 파란 옷을 입었군'이라고 판단하는 상황을 생각하세요.",
    "trap_points": [
      "데이터가 셔플(Shuffle)되지 않았다면 head는 매우 위험한 통계적 근거가 될 수 있음"
    ],
    "difficulty": "hard",
    "id": "0152"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "정규표현식에서 `.+` 패턴이 '탐욕적 매칭(Greedy Matching)'을 수행함으로써 의도치 않게 너무 긴 문자열을 잡아내는 현상에 대한 설명은?",
    "options": [
      "Matches as much as possible until the very last delimiter",
      "Fails immediately if more than one newline is encountered",
      "Recursively expands the capture group back to the start",
      "Automatically inserts a look-ahead anchor at each step"
    ],
    "answer": "Matches as much as possible until the very last delimiter",
    "why": "기본 수량자(`+`)는 조건을 만족하는 한 가장 멀리 있는 끝점까지 먹어 치우려 하므로, 짧은 매칭을 원한다면 `.+?`와 같이 논그리디(Non-greedy) 수량자를 써야 합니다.",
    "hint": "뷔페에 가서 접시에 음식을 산더미처럼 쌓으려다가, 정작 먹고 싶었던 뒤쪽 음식을 놓치는 상황을 생각하세요.",
    "trap_points": [
      "이 현상은 HTML 태그 추출 등 특정 구분자가 여러 번 등장할 때 대형 참사를 유발함"
    ],
    "difficulty": "hard",
    "id": "0153"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "자연어 처리 파이프라인에서 '불용어(Stopwords) 제거'가 문맥 이해(예: 변신, 생성 모델) 작업에서 역효과를 낼 수 있는 위험 요인은?",
    "options": [
      "Loss of subtle nuances implied by functional particles",
      "Incompatibility with TF-IDF weighting schemes",
      "Forced normalization of distinct lexical entities",
      "Asynchronous alignment of multi-token bi-grams"
    ],
    "answer": "Loss of subtle nuances implied by functional particles",
    "why": "단순 빈도가 높다고 'The', 'not' 등을 무분별하게 지우면, 부정문의 의미가 바뀌거나 단어 사이의 유기적인 관계 정보가 유실되어 복잡한 문맥 파악이 어려워집니다.",
    "hint": "요리에서 소금이 짜다고 해서 소금을 다 빼버리면, 다른 재료들의 맛까지 살리지 못하게 되는 이치를 생각하세요.",
    "trap_points": [
      "최근의 트랜스포머 기반 모델(BERT 등)은 불용어를 지우지 않고 문맥의 일부로 학습함"
    ],
    "difficulty": "hard",
    "id": "0154"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "유클리드 거리(Euclidean Distance)와 비교했을 때, '코사인 유사도(Cosine Similarity)'가 텍스트 벡터 비교에서 갖는 절대적 강점은?",
    "options": [
      "Scale invariance: Robust to difference in document lengths",
      "Linear separability: Forces all vectors into a unit sphere",
      "Computational speed: Uses integer bitwise shift kernels",
      "Global convergence: Prevents local minima in clustering"
    ],
    "answer": "Scale invariance: Robust to difference in document lengths",
    "why": "코사인 유사도는 두 벡터의 '방향'만 보기 때문에, 같은 내용을 담고 있지만 길이가 매우 긴 문서와 짧은 문서를 비교할 때 거리 기반 방식보다 훨씬 정확한 유사도를 산출합니다.",
    "hint": "키가 큰 사람과 작은 사람이 같은 방향을 가리키고 있다면, 두 사람의 '키 차이(거리)'를 무시하고 '방향'만 보겠다는 논리입니다.",
    "trap_points": [
      "두 벡터의 크기가 다르더라도 방향이 같으면 유사도는 1이 됨"
    ],
    "difficulty": "hard",
    "id": "0155"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas의 `merge()` 연산 시 기본값인 'inner join'이 데이터 유실을 발생시킬 수 있는 기술적 전제 조건은?",
    "options": [
      "Presence of keys that do not exist in both DataFrames",
      "Existence of duplicated rows in the left DataFrame only",
      "Mismatched data types between index and column labels",
      "Global scaling differences across float-based keys"
    ],
    "answer": "Presence of keys that do not exist in both DataFrames",
    "why": "`inner` 조인은 두 데이터프레임 모두에 존재하는 공통 키만 남기므로, 한쪽에만 있는 소중한 데이터가 결과물에서 조용히 사라질 수 있어 분석 전 결합 전략(Left/Outer 등)을 잘 세워야 합니다.",
    "hint": "두 파티에 모두 참석한 '인싸'들만 초대 명단에 남기기로 했을 때, 한 군데만 참석한 친구들이 소외되는 상황을 생각하세요.",
    "trap_points": [
      "데이터가 사라지는 것을 방지하려면 기준이 되는 쪽을 유지하는 `how='left'`를 주로 사용함"
    ],
    "difficulty": "hard",
    "id": "0156"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas의 `isna()` 메서드가 반환하는 '불리언 마스크(Boolean Mask)'가 메모리 내부에서 실제로 효율적으로 처리되는 방식은?",
    "options": [
      "Element-wise bit-array that mirrors the original shape",
      "Dictionary-based lookup of row-column coordinates",
      "Sparse vector allocation of non-null indices only",
      "Compressed B-tree storage of valid memory offsets"
    ],
    "answer": "Element-wise bit-array that mirrors the original shape",
    "why": "`isna()`는 원본 데이터와 똑같은 모양의 `True/False` 배열을 생성하며, 넘파이의 불리언 인덱싱을 통해 해당 마스크가 1인 데이터만 즉각 추출하는 백터화 연산에 최적화되어 있습니다.",
    "hint": "원본 사진 위에 투명하지만 '빈 칸'만 빨간색으로 칠해진 필름을 한 장 더 겹쳐서 보는 방식을 생각하세요.",
    "trap_points": [
      "isnull()과 isna()는 판다스 내부적으로 완전히 동일한 기능을 수행하는 얼라이어스(Alias)임"
    ],
    "difficulty": "hard",
    "id": "0157"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Numpy의 `.T` 속성을 사용하여 행렬 전치(Transpose)를 수행할 때, 실제 메모리 내부에서 데이터의 복사가 일어나지 않는 기술적 근거는?",
    "options": [
      "Modifying the metadata (strides) of the existing buffer",
      "Recursive bit-shuffling of categorical row-segments",
      "Asynchronous caching of inverted memory offsets",
      "Dynamic allocation of mirrored virtual address space"
    ],
    "answer": "Modifying the metadata (strides) of the existing buffer",
    "why": "전치는 데이터를 실제로 옮기는 것이 아니라, 메모리에서 데이터를 읽는 보폭(Strides) 정보만 행과 열을 서로 맞바꿔서 보여주는 '뷰(View)' 연산이기에 거의 즉각적으로 완료됩니다.",
    "hint": "책장은 그대로 두고, 책을 읽는 순서만 '왼쪽에서 오른쪽'이 아니라 '위에서 아래'로 바꾸는 것과 같습니다.",
    "trap_points": [
      "1차원 배열에 .T를 적용하면 아무 일도 일어나지 않음(여전히 1차원)에 주의해야 함"
    ],
    "difficulty": "hard",
    "id": "0158"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "범주형 데이터를 수치로 바꾸는 원-핫 인코딩(One-hot Encoding)이 딥러닝 임베딩(Embedding) 레이어보다 비효율적이라고 평가받는 메모리적 이유는?",
    "options": [
      "High-dimensionality and sparsity of the feature space",
      "Lack of support for floating-point gradient updates",
      "Inability to handle non-integer categorical labels",
      "Global synchronization overhead during backpropagation"
    ],
    "answer": "High-dimensionality and sparsity of the feature space",
    "why": "원-핫 인코딩은 단어 수가 10만 개면 10만 차원의 거대한 0 행렬을 만들어야 하지만, 임베딩은 이를 수백 차원의 밀집 벡터로 압축하여 효율성과 의미론적 유사도를 정밀하게 담아냅니다.",
    "hint": "수만 개의 서랍장을 준비해서 양말 한 켤레씩 넣는 것보다, 큰 배낭에 차곡차곡 의미 있는 물건들만 챙기는 것이 효율적인 것과 같습니다.",
    "trap_points": [
      "단순한 선형 회귀에서는 원-핫 인코딩이 명료하지만, 데이터가 복잡해질수록 임베딩이 압도적으로 유리함"
    ],
    "difficulty": "hard",
    "id": "0159"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas의 `drop_duplicates()` 메서드 사용 시, 특정 기준 열만을 검사하여 중복을 제거하고자 할 때 사용하는 파라미터는?",
    "options": [
      "subset=['column_name']",
      "keep='first_unique'",
      "inplace=True_duplicates",
      "ignore_index=False_only"
    ],
    "answer": "subset=['column_name']",
    "why": "`subset` 옵션을 주면 전체 행이 아닌 지정된 열들의 값만 비교하여 중복을 판단하므로, 더 유연한 데이터 정제 작업이 가능해집니다.",
    "hint": "전체 신상정보를 다 대조하지 않고, '이름'만 같으면 동일 인물로 간주하겠다는 '부분 집합' 설정을 생각하세요.",
    "trap_points": [
      "subset을 지정하지 않으면 모든 열의 값이 완벽히 일치해야 중복으로 처리됨"
    ],
    "difficulty": "hard",
    "id": "0160"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "멀티 인덱스(MultiIndex)를 가진 데이터프레임에서 최하위 행 인덱스를 열 인덱스로 피벗하여 데이터를 가로로 펼치는 Pandas 메서드는?",
    "options": [
      "unstack()",
      "stack()",
      "melt()",
      "pivot()",
      "reset_index()"
    ],
    "answer": "unstack()",
    "why": "`unstack()`은 행 인덱스의 마지막 레벨을 열 인덱스로 올려주어 'Long format'에서 'Wide format'으로 계층을 재배치할 때 사용합니다.",
    "hint": "쌓여있던(stack) 것을 반대로 펼치는(un-) 작업입니다.",
    "trap_points": [
      "melt()는 컬럼을 행으로 녹여 내리는 정반대의 논리 구조를 가짐"
    ],
    "difficulty": "hard",
    "id": "0161"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas Series에 불리언 인덱싱을 적용할 때, 파이썬의 `and` 대신 비트와이즈 연산자 `&`를 사용해야 하는 기술적 명분은?",
    "options": [
      "Element-wise evaluation vs. Single truth value evaluation",
      "Automatic handling of multi-threaded memory locks",
      "Support for recursive backtracking in filter conditions",
      "Literal matching of binary pointer representations"
    ],
    "answer": "Element-wise evaluation vs. Single truth value evaluation",
    "why": "파이썬의 `and`는 전체 리스트의 진실성(Truthiness) 하나만 판단하려 하여 에러를 내지만, `&`는 각 요소별로 개별적인 논리 연산을 수행하기 때문입니다.",
    "hint": "모두가 같이 판단을 내릴 것인지, 아니면 각자가 번호표대로 하나씩 판단할 것인지의 차이입니다.",
    "trap_points": [
      "이때 연산자 우선순위 문제로 각 조건을 반드시 소괄호 `()`로 묶어줘야 함에 유의해야 함"
    ],
    "difficulty": "hard",
    "id": "0162"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "정규표현식에서 `\\B` 메타 문자가 매칭을 시도하는 기술적 지점은?",
    "options": [
      "Non-word boundary (middle of a word segment)",
      "Start of a binary encoded sequence",
      "End of a bracketed character range",
      "Backreference to the previous capture group"
    ],
    "answer": "Non-word boundary (middle of a word segment)",
    "why": "`\\b`가 단어의 끝(경계)을 찾는다면, `\\B`는 반대로 단어의 중간이나 문자들 사이 등 경계가 아닌 곳을 타겟팅합니다.",
    "hint": "소문자는 '경계', 대문자는 '경계가 아님'을 뜻하는 규칙을 생각하세요.",
    "trap_points": [
      "단어 'python'에서 'yth'를 감싸는 빈 공간들이 바로 `\\B`가 찾는 지점임"
    ],
    "difficulty": "hard",
    "id": "0163"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas의 `Timedelta` 객체를 사용하여 '특정 시간 기간'을 수치적으로 조작할 때 권장되는 기술적 접근은?",
    "options": [
      "Arithmetic operations between Timestamp and Timedelta",
      "Bitwise shifting of nano-second epoch integers",
      "Normalization of categorical date-stamps via log-scale",
      "Explicit recursion over day-of-week frequency buckets"
    ],
    "answer": "Arithmetic operations between Timestamp and Timedelta",
    "why": "`Timestamp`에서 `Timedelta`를 더하거나 빼면 정확한 날짜 연산이 가능하며, 이는 윤년이나 월별 일수 차이 등을 내부적으로 고려하여 수행됩니다.",
    "hint": "현재 시각(`Timestamp`)에 '10일 뒤'(`Timedelta`)라는 기간을 더하는 직관적인 수식을 생각하세요.",
    "trap_points": [
      "단순한 정수를 날짜에 더하려고 하면 에러가 발생하므로 반드시 Timedelta 객체로 변환해야 함"
    ],
    "difficulty": "hard",
    "id": "0164"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Numpy의 `np.random.shuffle()` 메서드와 `np.random.permutation()` 메서드의 근본적 동작 차이는?",
    "options": [
      "In-place shuffling vs. Returning a shuffled copy",
      "Floating point seed range vs. Integer-based hashing",
      "Recursive sorting stability vs. Unstable swapping",
      "Single-threaded pointer swap vs. Multi-threaded batching"
    ],
    "answer": "In-place shuffling vs. Returning a shuffled copy",
    "why": "`shuffle`은 원본 배열을 직접 뒤섞어 메모리를 아끼지만, `permutation`은 원본은 그대로 두고 섞인 새로운 배열을 복사하여 반환합니다.",
    "hint": "내 주머니의 사탕을 직접 섞을 것인지, 사탕을 복사해서 다른 주머니에서 섞을 것인지의 차이입니다.",
    "trap_points": [
      "shuffle()은 반환값이 None이므로 다른 변수에 저장하려고 하면 데이터를 잃을 수 있음"
    ],
    "difficulty": "hard",
    "id": "0165"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas의 `stack()` 메서드가 데이터프레임의 차원을 압축하는 기술적 과정은?",
    "options": [
      "Compressing columns into rows to create a MultiIndex",
      "Reducing floating-point precision of index labels",
      "Pruning zero-valued segments from sparse matrices",
      "Linearizing the memory layout for vectorized access"
    ],
    "answer": "Compressing columns into rows to create a MultiIndex",
    "why": "`stack()`은 컬럼 레이블을 인덱스의 가장 안쪽 레벨로 '회전(Pivot)'시켜 내려놓음으로써, 행이 더 길고 계층적인 구조로 변환합니다.",
    "hint": "가로로 늘어선 사람들을 세로 줄무늬 뒤로 숨겨서 세로로 긴 줄을 만드는 것과 같습니다.",
    "trap_points": [
      "stack()을 수행하면 결측치(NaN)가 있는 위치는 결과물에서 아예 사라지는 것이 기본 동작임"
    ],
    "difficulty": "hard",
    "id": "0166"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "자연어 데이터에서 Zipf의 법칙(Zipf's Law)이 불용어(Stopwords) 제거의 통계적 정당성을 부여하는 근거는?",
    "options": [
      "Dominance of highly frequent but low-informative particles",
      "Normal distribution of word lengths in academic corpora",
      "Constant ratio between unique tokens and total vocabulary size",
      "Exponential decay of document frequency for proper nouns"
    ],
    "answer": "Dominance of highly frequent but low-informative particles",
    "why": "가장 많이 나오는 단어들은 의미가 희박한 조사나 관사인 경우가 많으므로, 이 '롱테일'의 앞부분을 제거해야 모델이 실질적인 핵심 단어에 집중할 수 있기 때문입니다.",
    "hint": "너무 흔해서 아무도 신경 쓰지 않는 공기 같은 단어들(the, is 등)을 걸러내는 통계적 명분입니다.",
    "trap_points": [
      "반대로 너무 적게 등장하는(1~2회) 단어들 또한 노이즈로 보고 제거하는 것이 일반적임"
    ],
    "difficulty": "hard",
    "id": "0167"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas `read_csv()` 호출 시 한국어 환경에서 `cp949`와 `utf-8-sig` 인코딩 설정의 결정적 차이는?",
    "options": [
      "Presence of a hidden BOM (Byte Order Mark) for Excel compatibility",
      "Automatic decompression of character-byte offset indices",
      "Literal translation of non-ascii integer code points",
      "Recursive normalization of decomposed hangul jamo segments"
    ],
    "answer": "Presence of a hidden BOM (Byte Order Mark) for Excel compatibility",
    "why": "엑셀에서 저장된 UTF-8 파일은 가끔 맨 앞에 보이지 않는 기호(BOM)를 붙이는데, 이를 인식하려면 `utf-8`이 아닌 `utf-8-sig`로 열어야 한글 깨짐 없이 데이터를 읽을 수 있습니다.",
    "hint": "파일의 첫머리에 '이건 한글 파일이야'라고 속삭이는 비밀 사인이 들어있는지 확인하는 과정입니다.",
    "trap_points": [
      "대부분의 현대적 시스템은 UTF-8을 기본으로 하지만, 윈도우 기반 엑셀 파일은 여전히 인코딩 전쟁터임"
    ],
    "difficulty": "hard",
    "id": "0168"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "선형대수학에서 '직교 행렬(Orthogonal Matrix)' $Q$가 역행렬을 구할 때 갖는 극강의 연산 효율적 특징은?",
    "options": [
      "$Q^{-1} = Q^T$ (Inverse is equal to Transpose)",
      "$Q^2$ is always equal to the Identity Matrix",
      "Determinant is guaranteed to be zero",
      "All non-diagonal elements are prime numbers"
    ],
    "answer": "$Q^{-1} = Q^T$ (Inverse is equal to Transpose)",
    "why": "직교 행렬은 역행렬을 복잡하게 계산할 필요 없이 그냥 행과 열을 뒤집은 전치 행렬을 구하기만 하면 되어, 수치 해석에서 매우 중요한 역할을 합니다.",
    "hint": "행렬의 거울을 봤을 때, 그 모습이 바로 반대 방향으로 되돌아가는 열쇠가 되는 신기한 구조를 생각하세요.",
    "trap_points": [
      "이 성질 덕분에 PCA 등에서 차원을 변환하거나 되돌릴 때 속도가 매우 빠름"
    ],
    "difficulty": "hard",
    "id": "0169"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "정규표현식 엔진에서 메타 캐릭터 `.`를 리터럴 마침표 문자로 정확히 인식시키기 위한 '이스케이프(Escape)' 기법과 파이썬 문자열에서의 권장 표기법은?",
    "options": [
      "Using backslash `\\.` with raw string literal `r'...'` ",
      "Enclosing the character with triple hash signs `###.###`",
      "Doubling the character in a square bracket group `[..]`",
      "Suffixing the pattern with an explicit stop-anchor `.$`"
    ],
    "answer": "Using backslash `\\.` with raw string literal `r'...'` ",
    "why": "파이썬 문자열 자체의 이스케이프와 정규표현식의 이스케이프가 충돌할 수 있으므로, `r`을 붙여 '날것의 문자열'임을 명시하여 `\\.`를 그대로 엔진에 전달해야 합니다.",
    "hint": "컴퓨터에게 '이 백슬래시는 내가 치는 타자 그대로를 전달하라는 뜻이야'라고 선언하는 방법입니다.",
    "trap_points": [
      "raw string을 쓰지 않으면 `\\` 하나를 표현하기 위해 `\\\\`를 써야 하는 등 가독성이 급격히 떨어짐"
    ],
    "difficulty": "hard",
    "id": "0170"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "판다스의 `df['col'].nunique()` 연산이 대규모 문자열 데이터셋에서 `len(df['col'].unique())`보다 권장되는 메모리 관리적 유효성은?",
    "options": [
      "Avoids materializing the full list of unique values in memory",
      "Performs automatic categorical downcasting during count",
      "Utilizes SIMD instructions for parallel string hashing",
      "Skips the evaluation of globally interned Python strings"
    ],
    "answer": "Avoids materializing the full list of unique values in memory",
    "why": "`nunique`는 고유 값의 리스트를 실제로 생성하지 않고 카운트만 수행할 수 있도록 최적화되어 있어, 메모리 사용량을 줄이면서도 빠르게 고유값 개수를 산출합니다.",
    "hint": "전체 리스트라는 '실체'를 만들어서 세는 것과, 지나가는 것을 눈으로 체크하며 숫자만 올리는 것의 차이입니다.",
    "trap_points": [
      "dropna=True 가 기본값이며, 결측치를 포함해 세고 싶다면 False로 명시해야 함"
    ],
    "difficulty": "hard",
    "id": "0171"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "영어 불용어 전처리 중 정교한 형태소 분석이 필요한 'Lemmatization' 대신 'Stemming'을 선택하는 가장 현실적인 엔지니어링 명분은?",
    "options": [
      "Extreme computational speed for real-time indexing",
      "Preservation of semantic context in deep learning models",
      "Accurate mapping of irregular verbs to their base forms",
      "Support for multi-lingual character decomposition"
    ],
    "answer": "Extreme computational speed for real-time indexing",
    "why": "Stemming은 사전을 찾지 않고 단순히 규칙(Porter, Snowball 등)에 따라 어미를 자르기 때문에 속도가 압도적으로 빨라, 대규모 실시간 검색 엔진 등에 유리합니다.",
    "hint": "언어적 정교함보다는 '빠르게 대충 쳐내기'가 필요한 상황을 생각하세요.",
    "trap_points": [
      "속도는 빠르지만 'flies'가 'fli'로 변하는 등 단어의 원형이 훼손될 수 있음에 주의"
    ],
    "difficulty": "hard",
    "id": "0172"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "데이터의 중심 경향성을 파악할 때, 평균(Mean)이 아닌 중앙값(Median)이 강력한 통계적 대안(Robust)으로 기능하는 기술적 상황은?",
    "options": [
      "When the distribution has extreme outliers or heavy tails",
      "When the sample size is prime and needs factorial scaling",
      "When evaluating binary outcomes with a logit linker",
      "When sorting is computationally impossible on large buffers"
    ],
    "answer": "When the distribution has extreme outliers or heavy tails",
    "why": "평균은 극단값(Outlier) 하나에 의해 전체 지표가 왜곡되기 쉽지만, 중앙값은 상위 50%의 위치만 보므로 데이터의 오염에 훨씬 강력한 저항성을 가집니다.",
    "hint": "전체 평균 연봉을 계산할 때, 억만장자 한 명이 포함되어 평균이 왜곡되는 상황을 생각하세요.",
    "trap_points": [
      "이상치가 없다면 평균이 더 많은 정보를 담고 있지만, 현실 데이터에서는 중앙값이 더 정직할 때가 많음"
    ],
    "difficulty": "hard",
    "id": "0173"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas 데이터프레임을 `to_excel()`로 저장할 때, 대량의 행 데이터를 처리하면서 발생하는 주요 성능 병목 지점과 해결책은?",
    "options": [
      "XML formatting overhead; use `to_parquet` or `to_csv` for speed",
      "Automatic encryption of integer columns by default",
      "Recursive recursion of the index pointer tree",
      "Linear scanning of cell-style metadata buffers"
    ],
    "answer": "XML formatting overhead; use `to_parquet` or `to_csv` for speed",
    "why": "Excel(.xlsx) 파일은 내부적으로 복잡한 XML 구조를 가지므로 쓰기 속도가 매우 느립니다. 대용량 데이터는 CSV나 Parquet 형식을 쓰는 것이 훨씬 효율적입니다.",
    "hint": "화려한 포장을 하는 시간(`to_excel`)과 그냥 물건만 담는 시간(`to_csv`)의 차이를 생각하세요.",
    "trap_points": [
      "to_excel()은 별도의 엔진(openpyxl, xlsxwriter)이 설치되어 있어야 동작함"
    ],
    "difficulty": "hard",
    "id": "0174"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Numpy 브로드캐스팅(Broadcasting) 시, 실제 배열 데이터를 복제하지 않고 가상으로 확장하여 연산 효율을 높이는 하드웨어적 원리는?",
    "options": [
      "Using zero-valued strides for the expanded dimension",
      "Parallel duplication of memory buffers in the L3 cache",
      "Recursive pointer jumping across disjoint memory segments",
      "Dynamic allocation of virtual shadow arrays"
    ],
    "answer": "Using zero-valued strides for the expanded dimension",
    "why": "넘파이는 실제 데이터를 복사하는 대신, 특정 차원의 보폭(Stride)을 0으로 설정하여 물리적으로는 하나인 데이터를 여러 개인 것처럼 읽어 메모리를 획기적으로 아낍니다.",
    "hint": "종이 한 장을 복사하지 않고, 거울 여러 개를 비춰서 여러 장이 있는 것처럼 사기(?)를 치는 아주 효율적인 방법입니다.",
    "trap_points": [
      "이 기법 덕분에 메모리가 부족한 환경에서도 대규모 행렬 연산이 가능함"
    ],
    "difficulty": "hard",
    "id": "0175"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "판다스의 `.T` 속성을 통해 행렬을 전치(Transpose)했을 때, 생성된 객체가 원본 데이터와 메모리를 공유하는 '뷰(View)' 형태인지 검증하는 중요성은?",
    "options": [
      "Modifying the transpose affects the original dataframe",
      "Implicit conversion to a sparse matrix format occurs",
      "Forced alignment of categorical index labels",
      "Global locking of the internal buffer during read"
    ],
    "answer": "Modifying the transpose affects the original dataframe",
    "why": "전치는 데이터의 메타데이터(보폭)만 바꾸는 뷰 연산이므로, 전치된 데이터프레임의 값을 수정하면 원본 데이터도 함께 수정될 수 있어 주의가 필요합니다.",
    "hint": "종이를 뒤집어서 글자를 썼는데, 그 글자가 원래 종이 뒷면에도 그대로 적히는 현상을 생각하세요.",
    "trap_points": [
      "데이터 타입이 섞여 있는 경우(Mixed dtypes) 전치 시 복제본이 만들어질 수 있는 예외 케이스도 존재함"
    ],
    "difficulty": "hard",
    "id": "0176"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "시계렬 데이터 분석 시 `resample()` 연산에서 '업샘플링(Up-sampling)' 수행 시 반드시 수반되어야 하는 후속 처리는?",
    "options": [
      "Interpolation or filling to handle newly created NaNs",
      "Dropping duplicated timestamps at the lower bound",
      "Recursive normalization of the datetime freq indicator",
      "Bitwise compression of the sub-second resolution"
    ],
    "answer": "Interpolation or filling to handle newly created NaNs",
    "why": "1일 단위를 1시간 단위로 잘게 쪼개면 중간에 빈 시간대(NaN)가 생기므로, `ffill`이나 `linear interpolation` 등을 통해 적절한 값을 채워 넣어야 합니다.",
    "hint": "영상을 슬로우 모션으로 만들 때, 중간에 비어버린 프레임을 자연스럽게 채워 넣는 작업을 생각하세요.",
    "trap_points": [
      "단순히 resample만 하면 비어있는 구간은 모두 NaN으로 출력됨"
    ],
    "difficulty": "hard",
    "id": "0177"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "판다스의 `sort_values()`가 내부적으로 사용하는 '안정 정렬(Stable Sort)' 알고리즘인 Timsort의 동작 이점은?",
    "options": [
      "Preserves original order of rows with equal values",
      "Guarantees O(1) space complexity on sparse datasets",
      "Automatically parallelizes sort across multiple GPUs",
      "Ignores case-sensitivity for unicode character strings"
    ],
    "answer": "Preserves original order of rows with equal values",
    "why": "안정 정렬은 값이 같을 경우 기존의 순서를 유지하므로, 여러 기준 열로 순차적 정렬을 할 때 이전 정렬 결과가 망가지지 않고 유지되게 합니다.",
    "hint": "1등이 두 명일 때, 앞에서 기다리던 사람을 여전히 앞에 세워주는 '예의 바른' 정렬 방식을 생각하세요.",
    "trap_points": [
      "성능뿐만 아니라 '다계층 정렬'의 예측 가능성을 위해 매우 중요한 설계적 선택임"
    ],
    "difficulty": "hard",
    "id": "0178"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "대규모 행렬 연산에서 파이썬의 `for` 루프 반복(Iteration)이 넘파이의 벡터화(Vectorization)보다 비효율적인 결정적 이유는?",
    "options": [
      "Overhead of Python interpreter and dynamic type checking",
      "Forced flushing of the CPU pipeline at each list access",
      "Lack of memory view caching in the L1 instruction buffer",
      "Recursive locking of the Global Interpreter Lock (GIL)"
    ],
    "answer": "Overhead of Python interpreter and dynamic type checking",
    "why": "파이썬의 루프는 매 단계마다 객체의 타입을 확인하고 인터프리터가 한 줄씩 해석해야 하지만, 벡터화는 미리 최적화된 C 코드를 통해 반복 없이 직접 처리하기 때문입니다.",
    "hint": "한 단어마다 사전(타입)을 찾아보며 읽는 초보자와, 이미 내용을 다 알고 눈으로 쓱 훑는 전문가의 속도 차이를 생각하세요.",
    "trap_points": [
      "루프를 없애고 수식으로 표현하는 것만으로도 수백 배 이상의 속도 향상을 얻을 수 있음"
    ],
    "difficulty": "hard",
    "id": "0179"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "정규표현식의 문자 클래스 `\\W` 가 매칭 대상으로 삼는 문자의 정체와 `\\w`와의 관계는?",
    "options": [
      "Total opposite of [a-zA-Z0-9_] (Non-alphanumeric)",
      "Whitespace characters excluding hard tabs and form-feeds",
      "Unicode decomposed hangul syllables and punctuation",
      "Control characters within the first 32 ASCII slots"
    ],
    "answer": "Total opposite of [a-zA-Z0-9_] (Non-alphanumeric)",
    "why": "`\\w`가 영문자, 숫자, 언더바(_)를 포함한다면, `\\W`는 이를 제외한 공백, 특수문자, 문장부호 등을 타겟팅합니다.",
    "hint": "대문자 지시어는 보통 소문자 지시어가 찾는 것들의 '안티테제(반대)'임을 기억하세요.",
    "trap_points": [
      "언더바(_)는 `\\w`에 포함되므로, 순수 영문자만 찾고 싶다면 `[a-zA-Z]`를 따로 써야 함"
    ],
    "difficulty": "hard",
    "id": "0180"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Pandas의 `df.head()`를 사용하여 시계렬 로그의 '전체적인 경향성'을 파악하려 할 때 발생할 수 있는 데이터 공학적 리스크는?",
    "options": [
      "Temporal sampling bias (Chronological skew)",
      "Inversion of floating-point index precision",
      "Loss of global categorical mapping pointers",
      "Asynchronous buffer-spill during metadata read"
    ],
    "answer": "Temporal sampling bias (Chronological skew)",
    "why": "로그는 보통 시간순으로 적재되므로, `head`만 보면 가장 과거 혹은 가장 최신의 데이터만 보게 되어 전체적인 패턴(예: 주기성)을 오판할 위험이 큽니다.",
    "hint": "책의 첫 페이지만 읽고 '이 책 전체는 평화로운 이야기야'라고 결론 내리는 편견을 생각하세요.",
    "trap_points": [
      "전체 분포를 고르게 보고 싶다면 sample(n, random_state)을 사용하는 것이 통계적으로 더 안전함"
    ],
    "difficulty": "hard",
    "id": "0181"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "상관계수(Correlation Coefficient)가 -0.9로 매우 높게 산출되었음에도 불구하고, 두 변수 사이의 인과관계(Causality)를 단정 지을 수 없는 근본적인 통계적 이유는?",
    "options": [
      "Possibility of a confounding variable (Lurking variable)",
      "Strict linearity requirement of the Pearson algorithm",
      "Violation of the Central Limit Theorem in small samples",
      "Inevitability of floating-point rounding errors in OLS"
    ],
    "answer": "Possibility of a confounding variable (Lurking variable)",
    "why": "두 변수가 강하게 연결되어 보여도, 실제로는 제3의 변수(예: 기온)가 두 변수(예: 아이스크림 판매, 익사 사고) 모두에 영향을 미치고 있을 가능성이 있기 때문입니다.",
    "hint": "두 사람이 항상 같이 다닌다고 해서, 한 사람이 다른 사람을 조종하고 있다고 확신할 수 없는 것과 같습니다.",
    "trap_points": [
      "상관관계는 연관성만 보여줄 뿐, 'A 때문에 B가 일어났다'는 원인과 결과를 설명하지 못함"
    ],
    "difficulty": "hard",
    "id": "0182"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Numpy 배열의 `.shape` 속성을 호출했을 때, 실제 메모리 레이아웃(Contiguity)을 스캔하지 않고도 즉각적인 결과를 반환할 수 있는 하위 기술 구조는?",
    "options": [
      "Accessing pre-stored metadata in the C-array wrapper",
      "Recursive bit-counting of the element pointers",
      "Parallel scanning of the L2 instruction cache",
      "Dynamic computation of floating-point byte offsets"
    ],
    "answer": "Accessing pre-stored metadata in the C-array wrapper",
    "why": "넘파이 배열은 내부에 이미 자신의 모양, 차원, 보폭(Strides) 정보를 메타데이터로 가지고 있으므로, 전체 데이터를 읽을 필요 없이 해당 값만 읽어 즉시 반환합니다.",
    "hint": "상자의 내용물을 다 세보지 않고, 상자 겉면에 적힌 '가로x세로' 스티커만 보고 판단하는 것과 같습니다.",
    "trap_points": [
      "속성(Property)이기 때문에 연산 오버헤드가 거의 없으며 괄호()를 붙이지 않음"
    ],
    "difficulty": "hard",
    "id": "0183"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "영어 자연어 정제 시 'Stopword removal'을 무분별하게 적용했을 때, 감성 분석(Sentiment Analysis) 모델에서 발생할 수 있는 치명적 정보 유실 사례는?",
    "options": [
      "Deletion of words like 'not' affecting negation logic",
      "Loss of high-frequency character casing pointers",
      "Inversion of Unicode character decomposition indices",
      "Forced normalization of distinct morphological roots"
    ],
    "answer": "Deletion of words like 'not' affecting negation logic",
    "why": "'not'과 같은 단어는 전체 문장의 의미를 180도 바꾸는 불용어(Stopword) 리스트에 포함되는 경우가 많아, 이를 지우면 긍정과 부정을 완전히 반대로 판단하게 될 수 있습니다.",
    "hint": "양념이 강하다고 해서 '소금'을 아예 빼버리면, 음식의 근본적인 맛을 잃게 되는 것과 같습니다.",
    "trap_points": [
      "최근의 LLM들은 불용어를 직접 지우지 않고 문맥의 일부로 학습시켜 이 문제를 해결함"
    ],
    "difficulty": "hard",
    "id": "0184"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Matplotlib의 `plt.subplot()`을 사용하여 여러 차트를 배치할 때, 객체지향 API 방식인 `plt.subplots()`(복수형)가 권장되는 설계적 이유는?",
    "options": [
      "Provides explicit handles for Figure and Axes objects",
      "Enables automatic GPU acceleration for 2D rendering",
      "Supports recursive nesting of invisible plot layers",
      "Forces mandatory inclusion of a global colorbar"
    ],
    "answer": "Provides explicit handles for Figure and Axes objects",
    "why": "`subplots()`는 전역 상태에 의존하지 않고 각 그래프 조각(`Axes`)을 객체로 직접 제어할 수 있게 해주어, 복잡한 시각화 레이아웃을 훨씬 정교하고 안전하게 관리할 수 있게 합니다.",
    "hint": "리모컨 하나로 모든 TV를 조종하는 것이 아니라, 각 TV마다 전용 리모컨(`Axes`)을 부여받는 방식입니다.",
    "trap_points": [
      "plt.subplot(211) 식의 호출은 '상태 기반'이라 코드가 길어질수록 어떤 차트를 그리는지 헷갈리기 쉬움"
    ],
    "difficulty": "hard",
    "id": "0185"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "데이터 스케일링(Scaling) 적용 시 학문적으로 가장 주의해야 할 '데이터 누수(Data Leakage)' 시점은?",
    "options": [
      "Fitting the scaler on the entire dataset instead of train set only",
      "Using integers for standard deviation calculation buffers",
      "Normalizing categorical labels before one-hot encoding",
      "Scaling the target variable after the model training is done"
    ],
    "answer": "Fitting the scaler on the entire dataset instead of train set only",
    "why": "테스트 데이터의 정보(평균, 분산 등)가 미리 스케일러에 반영되면 모델이 미래의 정답을 미리 엿보는 꼴이 되어, 성능이 과하게 좋게 측정되는 치명적 오류를 범하게 됩니다.",
    "hint": "시험 문제를 풀기 전에, 이미 전교생의 평균 점수(테스트셋 정보)를 알고 시험장에 들어가는 부정행위와 같습니다.",
    "trap_points": [
      "반드시 Train 셋에만 `fit`을 하고, 그 기준을 그대로 Test 셋에 `transform`만 해야 함"
    ],
    "difficulty": "hard",
    "id": "0186"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "정규표현식의 메타 캐릭터 `.` 가 기본적으로 줄바꿈 문자(`\\n`)를 매칭하지 못하는 한계를 극복하기 위해 사용하는 엔진 플래그는?",
    "options": [
      "re.DOTALL (or re.S)",
      "re.MULTILINE (or re.M)",
      "re.IGNORECASE (or re.I)",
      "re.VERBOSE (or re.X)"
    ],
    "answer": "re.DOTALL (or re.S)",
    "why": "기본적으로 `.`는 한 줄 내에서만 임의의 문자를 찾지만, `DOTALL` 옵션을 활성화하면 줄바꿈까지 포함하여 텍스트 전체를 하나의 긴 흐름으로 인식합니다.",
    "hint": "마침표(Dot)가 모든 것(All)을 다 아우를 수 있게 허락해주는 강력한 마법 주문을 생각하세요.",
    "trap_points": [
      "여러 줄에 걸친 HTML 코드나 긴 문장을 통째로 추출할 때 이 플래그가 없으면 매칭이 중간에 끊김"
    ],
    "difficulty": "hard",
    "id": "0187"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "정규표현식의 `\\d` 클래스가 유니코드(Unicode) 모드로 동작할 때, 단순 ASCII 숫자 `[0-9]`를 넘어 매칭할 수 있는 대상의 범위는?",
    "options": [
      "Numbers from various languages like Arabic or Devanagari numerals",
      "Floating point notation with explicit scientific exponents",
      "Hexadecimal encoded memory offset identifiers",
      "Fractional representations including half-width segments"
    ],
    "answer": "Numbers from various languages like Arabic or Devanagari numerals",
    "why": "파이썬 3의 정규표현식 엔진은 기본적으로 유니코드를 지원하므로, 다른 언어에서 사용하는 숫자 체계까지도 `\\d`로 잡아낼 수 있어 글로벌 데이터 처리 시 주의가 필요합니다.",
    "hint": "우리가 흔히 쓰는 아라비아 숫자 말고도, 지구상에는 '숫자'로 분류되는 수많은 다른 글자들이 있다는 점을 생각하세요.",
    "trap_points": [
      "순수하게 서구권 숫자 0-9만 정확히 뽑고 싶다면 `[0-9]`를 명시하거나 `re.ASCII` 플래그를 써야 안전함"
    ],
    "difficulty": "hard",
    "id": "0188"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "판다스의 `fillna()` 메서드를 사용하여 결측치를 보간할 때, 시계렬 데이터 분석에서 '데이터 누수(Data Leakage)'를 방지하기 위해 금기시되는 방식은?",
    "options": [
      "Filling early missing values using future mean/median",
      "Recursive application of back-fill (bfill) on training set",
      "Implicit padding of nulls via linear bit-interpolation",
      "Explicit replacement of NaN with the global mode value"
    ],
    "answer": "Filling early missing values using future mean/median",
    "why": "과거의 빈칸을 채우기 위해 '미래의 평균값'을 끌어다 쓰면, 모델이 미래의 정보를 미리 알고 과거를 판단하게 되어 실제 예측 환경에서는 동작하지 않는 가짜 성능이 나오게 됩니다.",
    "hint": "어제의 가계부 빈칸을 채우기 위해, 한 달 뒤의 총수입 평균 점수를 미리 보고 적어 넣는 부정행위를 생각하세요.",
    "trap_points": [
      "시계렬에서는 반드시 직전의 데이터만 참고하는 `ffill`(Forward fill) 방식이 통계적으로 정당함"
    ],
    "difficulty": "hard",
    "id": "0189"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "판다스의 `value_counts()` 메서드를 사용하여 클래스 불균형(Class Imbalance)을 조사할 때, 절대 빈도가 아닌 '상대적 비율'을 즉시 산출하기 위한 파라미터는?",
    "options": [
      "normalize=True",
      "ascending=False_relative",
      "bins=Categorical_only",
      "dropna=False_scaling"
    ],
    "answer": "normalize=True",
    "why": "`normalize=True`를 설정하면 단순히 개수가 아닌 0~1 사이의 비율로 값을 환산해주어, 특정 클래스가 전체의 몇 %를 차지하는지 한눈에 파악할 수 있게 합니다.",
    "hint": "개별 숫자로 보는 것이 아니라, 전체를 100%로 두고 '정규화(Normalize)' 해서 보겠다는 선언입니다.",
    "trap_points": [
      "결측치(NaN) 비중까지 보고 싶다면 `dropna=False` 옵션을 함께 사용하는 것이 국룰임"
    ],
    "difficulty": "hard",
    "id": "0190"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "자연어 수치화 기법인 TF-IDF에서 IDF(Inverse Document Frequency) 가 특정 단어에 부여하는 통계적 의미는?",
    "options": [
      "Penalty for globally frequent words to emphasize domain specifics",
      "Bonus for lengthier documents to normalize term density",
      "Recursive smoothing of rare tokens via Laplace estimate",
      "Linear scaling of sentiment polarity markers"
    ],
    "answer": "Penalty for globally frequent words to emphasize domain specifics",
    "why": "IDF는 모든 문서에서 흔히 나타나는 단어(the, a 등)에 페널티를 주어 점수를 낮추고, 특정 문서에서만 의미 있게 등장하는 단어의 중요도를 상대적으로 높여줍니다.",
    "hint": "너무 흔해서 가치가 없는 단어들을 걸러내고, 진짜 알짜배기 단어를 찾아내는 수학적 필터입니다.",
    "trap_points": [
      "TF는 빈도가 높을수록 점수가 올라가지만, IDF는 반대로 흔할수록 점수가 내려가는 반비례 구조임"
    ],
    "difficulty": "hard",
    "id": "0191"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "판다스 인덱스 조작 시 `reset_index()`에서 `drop=True` 옵션을 누락했을 때 대규모 데이터프레임에서 발생하는 오버헤드는?",
    "options": [
      "Memory bloat due to duplication of index into a new column",
      "Forced recalculation of floating-point hash buckets",
      "Recursive sorting of the secondary pointer buffer",
      "Automatic conversion to a sparse matrix representation"
    ],
    "answer": "Memory bloat due to duplication of index into a new column",
    "why": "기본적으로 `reset_index`는 기존 인덱스를 새로운 일반 열로 복사하여 살려두기 때문에, 데이터가 클 경우 메모리 점유율이 두 배 가까이 늘어날 수 있어 주의가 필요합니다.",
    "hint": "과거의 이름표를 버리지 않고 가방 속에 꾸역꾸역 넣어두는 상황을 생각하세요.",
    "trap_points": [
      "인덱스의 정보가 더 이상 필요 없다면 반드시 drop=True를 써서 메모리를 아껴야 함"
    ],
    "difficulty": "hard",
    "id": "0192"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Numpy 배열의 전치 `.T` 작업 후 `reshape()` 연산 시 '메모리 연속성(Contiguity)' 이슈로 인해 발생할 수 있는 에러와 해결책은?",
    "options": [
      "AttributeError (non-contiguous array); use `.copy()` or `.reshape(-1)` ",
      "OverflowError (pointer wrap-around); use 64-bit indices",
      "RecursionError (cyclic access); set max_depth to zero",
      "SegmentationFault (invalid stride jump); use vector alignment"
    ],
    "answer": "AttributeError (non-contiguous array); use `.copy()` or `.reshape(-1)` ",
    "why": "전치된 배열은 메모리 상에서 데이터의 순서와 인덱스가 일치하지 않는 비연속적 상태이므로, 일부 형태 변환 시 원본 복사본을 만들어 메모리를 재정렬해야 합니다.",
    "hint": "책장은 그대로 두고 책의 위치만 바꿔놨는데, 갑자기 책장의 칸막이를 다시 짜려고 하면 발생하는 충돌 같은 것입니다.",
    "trap_points": [
      "데이터가 엄청나게 클 경우 .copy()를 하면 메모리를 추가로 점유하게 되므로 주의해야 함"
    ],
    "difficulty": "hard",
    "id": "0193"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "전체 데이터셋에서 스케일링(Scaling)이나 이상치 제거를 수행한 '후'에 Train/Test 셋을 나누는 행위가 초래하는 통계적 참사는?",
    "options": [
      "Information leakage (Model glimpses future test statistics)",
      "Inversion of the binary loss gradient pointers",
      "Reduction of the global categorical hashing space",
      "Recursive duplication of floating-point noise fragments"
    ],
    "answer": "Information leakage (Model glimpses future test statistics)",
    "why": "테스트 데이터의 정보가 스케일링 기준(평균 등)에 미리 섞여 들어가면, 모델이 정답지의 힌트를 미리 본 채로 학습하는 꼴이 되어 성능이 허위로 높게 측정됩니다.",
    "hint": "시험을 보기도 전에 전교 1등의 점수를 평균에 미리 넣어두고 내 등수를 가늠하는 '부정행위'를 생각하세요.",
    "trap_points": [
      "반드시 Train 셋으로만 fitting을 하고 그 기준을 바탕으로 Test 셋을 변환해야 함"
    ],
    "difficulty": "hard",
    "id": "0194"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Matplotlib 스타일 설정 중 `r--` 와 같은 포맷 스트링이 유니코드(Unicode) 처리가 안 된 환경에서 일으킬 수 있는 구문적 모호성은?",
    "options": [
      "Collision with raw-string literal interpretation in regex-heavy scripts",
      "Missing color alignment in high-DPI display buffers",
      "Forced normalization of sequential dash character pointers",
      "Recursive fallback to the underlying Tkinter canvas engine"
    ],
    "answer": "Collision with raw-string literal interpretation in regex-heavy scripts",
    "why": "포맷 스트링의 `-`나 `.` 등이 정규표현식이나 복잡한 파이썬 패턴과 함께 쓰일 때, 이스케이프 처리가 제대로 되지 않으면 예기치 못한 차트 렌더링 오류를 낼 수 있습니다.",
    "hint": "컴퓨터에게 '이 글자는 색깔을 뜻하는 거지 수식이 아니야'라고 명확하게 말해줘야 하는 상황을 생각하세요.",
    "trap_points": [
      "가독성과 안전성을 위해 `color='red', linestyle='--'` 처럼 명시적 파라미터를 쓰는 것이 더 권장됨"
    ],
    "difficulty": "hard",
    "id": "0195"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "판다스의 `dropna()`를 시계렬 데이터에 적용했을 때, 임의로 행을 삭제하는 행위가 초래하는 시계열 특성(Periodicity)의 파괴 효과는?",
    "options": [
      "Violation of constant-step assumption for FFT/ACF analysis",
      "Inversion of the binary epoch datetime markers",
      "Recursive realignment of the global categorical frequency",
      "Forced bit-shuffling of sub-second interval buffers"
    ],
    "answer": "Violation of constant-step assumption for FFT/ACF analysis",
    "why": "시계렬 분석은 데이터가 일정한 시간 간격으로 존재한다고 가정하는 경우가 많은데, 중간에 행을 지워버리면 그 간격이 깨져 계절성이나 주기를 찾는 수식이 망가지게 됩니다.",
    "hint": "노래 테이프가 중간중간 끊겨서 재생되면 박자를 맞출 수 없게 되는 상황과 같습니다.",
    "trap_points": [
      "삭제보다는 `interpolate`(보간)를 통해 시간의 흐름을 유지하는 것이 시계렬 분석의 정석임"
    ],
    "difficulty": "hard",
    "id": "0196"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "판다스에서 `set_index()` 연산을 수행하여 특정 열을 인덱스로 활용할 때 얻을 수 있는 결정적 성능 이점은?",
    "options": [
      "O(1) average time complexity for data retrieval via Hashing",
      "Linear scanning acceleration via SIMD string parsing",
      "Recursive bit-compression of the primary pointer buffer",
      "Automatic parallelization of categorical mapping indices"
    ],
    "answer": "O(1) average time complexity for data retrieval via Hashing",
    "why": "인덱스는 내부적으로 해시 테이블 등으로 관리되므로, 특정 값을 찾을 때 데이터를 처음부터 끝까지 훑는 대신 즉시 정답 지점으로 점프할 수 있어 검색 속도가 비약적으로 빨라집니다.",
    "hint": "수만 명의 이름표를 뒤져서 찾는 대신, 가나다순으로 정리된 '색인'을 보고 바로 페이지를 넘기는 무기를 얻는 것입니다.",
    "trap_points": [
      "자주 검색하는 열을 인덱스로 설정하면 데이터프레임이 훨씬 가벼워지고 빨라짐"
    ],
    "difficulty": "hard",
    "id": "0197"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Numpy의 `np.dot()` 연산이 대규모 데이터셋에서 단순 `*` 연산 루프보다 수백 배 빠른 하드웨어적 명분은?",
    "options": [
      "Utilization of BLAS/LAPACK optimized low-level libraries",
      "Implicit recursive pre-computation of floating-point noise",
      "Parallel bit-shuffling of non-contiguous memory segments",
      "Literal translation of Python syntax into GPU shaders"
    ],
    "answer": "Utilization of BLAS/LAPACK optimized low-level libraries",
    "why": "넘파이 내부는 전문적인 수치 해석 라이브러리(BLAS 등)에 연결되어 있어, CPU의 여러 코어를 동시에 쓰고 벡터 연산 기능을 최대로 끌어내어 처리하기 때문입니다.",
    "hint": "암산으로 하나씩 더하는 것이 아니라, 수백 대의 계산기(CPU 코어)를 가진 공장을 풀가동하는 원리입니다.",
    "trap_points": [
      "2차원 행렬 곱셈을 할 때는 `dot`이나 `@` 연산자를 반드시 써야 하며, `*`는 위치별 단순 곱셈임을 구별해야 함"
    ],
    "difficulty": "hard",
    "id": "0198"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "정규표현식에서 메타 캐릭터 `*` (Greedy) 사용 시, 대규모 문서에서 발생할 수 있는 '파괴적 백트래킹(Catastrophic Backtracking)'의 원인은?",
    "options": [
      "Exponential growth of matching permutations on failed matches",
      "Sequential inversion of the UTF-8 character buffer",
      "Forced normalization of invisible whitespace segments",
      "Recursive stack overflow during floating-point pointer jump"
    ],
    "answer": "Exponential growth of matching permutations on failed matches",
    "why": "욕심쟁이(`*`) 매칭이 실패할 경우, 엔진은 모든 가능한 경우의 수를 다시 되돌아가며 검사하는데, 패턴이 복잡하면 이 과정이 기하급수적으로 늘어나 CPU를 얼려버릴 수 있습니다.",
    "hint": "뷔페에서 모든 음식을 다 한 번씩 맛보려다가, 하나라도 맛이 없으면 처음부터 다른 순서로 다시 다 먹어보는 엄청난 비효율을 생각하세요.",
    "trap_points": [
      "이를 방지하기 위해 `+?`나 `*?` 같은 '비욕심(Lazy)' 매칭을 적절히 혼합하여 범위를 좁혀야 함"
    ],
    "difficulty": "hard",
    "id": "0199"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "데이터 정규화(Normalization) 과정에서 `Min-Max Scaling`이 `Standard Scaling`이나 `Robust Scaling`보다 아웃라이어(Outlier)에 극도로 취약한 이유는?",
    "options": [
      "Squashing effect: outliers condense normal values into a tight range",
      "Inversion of the binary floating-point mantissa bucket",
      "Automatic deletion of zero-valued feature segments",
      "Recursive re-centering of the global population mean"
    ],
    "answer": "Squashing effect: outliers condense normal values into a tight range",
    "why": "0~1 사이로 무조건 압축하다 보니, 말도 안 되게 큰 값이 하나 있으면 나머지 정상적인 데이터들이 전부 0.0001 같은 좁은 구역에 다닥다닥 붙게 되어 모델이 구분하기 힘들어집니다.",
    "hint": "초대형 농구 선수가 한 명 섞인 반에서 키를 0~1로 맞추면, 나머지 친구들은 전부 0.1 이하의 '난쟁이'처럼 보이게 되는 왜곡 현상입니다.",
    "trap_points": [
      "이상치가 많은 현실 데이터에서는 평균/표준편차를 쓰는 StandardScaler나 중앙값을 쓰는 RobustScaler가 훨씬 안전함"
    ],
    "difficulty": "hard",
    "id": "0200"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "판다스의 `dropna()` 사용 시, '행의 모든 값이 NaN인 경우에만' 해당 행을 삭제하기 위해 설정해야 하는 `how` 파라미터 옵션은?",
    "options": [
      "how='all'",
      "how='any'",
      "how='strict'",
      "how='full'"
    ],
    "answer": "how='all'",
    "why": "`how='any'`(기본값)는 하나만 NaN이어도 지우지만, `how='all'`은 행 전체가 비어있을 때만 삭제하므로 데이터 소실을 최소화할 수 있습니다.",
    "hint": "전부(All) 다 비어있을 때만 지우겠다는 '관대한' 기준을 생각하세요.",
    "trap_points": [
      "데이터 정제 시 실수로 중요한 정보가 담긴 행을 통째로 날리지 않기 위해 반드시 체크해야 할 옵션임"
    ],
    "difficulty": "hard",
    "id": "0201"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "자연어 처리에서 `N-gram`의 'N' 수치를 과도하게 높게 설정했을 때 직면하게 되는 통계적 데이터 '희소성(Sparsity)' 이슈는?",
    "options": [
      "Exponential decrease in overlapping patterns across documents",
      "Inversion of the binary word-vector distance markers",
      "Recursive normalization of invisible sub-word segments",
      "Linear scaling of the vocabulary-to-corpus ratio"
    ],
    "answer": "Exponential decrease in overlapping patterns across documents",
    "why": "단어를 너무 길게 묶으면(`4~5-gram` 등) 해당 표현이 전체 문서에서 딱 한 번만 등장할 확률이 높아져, 모델이 패턴을 학습하지 못하고 단순 암기하게 됩니다.",
    "hint": "너무 긴 문장을 토씨 하나 안 틀리고 똑같이 말하는 사람을 찾기가 매우 힘든 것과 같습니다.",
    "trap_points": [
      "일반적으로 성능과 일반화 사이의 균형을 위해 2(bi-gram)나 3(tri-gram)이 가장 많이 쓰임"
    ],
    "difficulty": "hard",
    "id": "0202"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Numpy에서 배열의 최대값과 최소값의 차이(Range)를 계산할 때, `max() - min()` 보다 연산 성능 루프가 최적화된 전문 함수는?",
    "options": [
      "np.ptp()",
      "np.diff_range()",
      "np.peak()",
      "np.span()"
    ],
    "answer": "np.ptp()",
    "why": "`ptp`(Peak To Peak)는 내부적으로 한 번의 순회로 최대/최소를 동시에 찾아 차이를 계산하므로, 대규모 배열에서 조금 더 효율적입니다.",
    "hint": "산의 꼭대기(Peak)에서 다음 꼭대기(Peak)까지의 거리를 잰다는 영어 약자를 생각하세요.",
    "trap_points": [
      "단순한 이름이지만 실제 연산 속도 최적화가 필요한 임베디드나 대규모 시뮬레이션에서 유용함"
    ],
    "difficulty": "hard",
    "id": "0203"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "판다스의 `rename()` 메서드를 사용하여 열 이름을 바꿀 때, `columns` 파라미터의 값으로 딕셔너리(`{}`) 형태를 전달해야 하는 기술적 이유는?",
    "options": [
      "Explicit mapping of 'old_label' to 'new_label' via key-value pairing",
      "Automatic hashing of the column layout to prevent memory leaks",
      "Forced alignment of multi-lingual character decomposition",
      "Recursive sorting of the internal column pointer buffer"
    ],
    "answer": "Explicit mapping of 'old_label' to 'new_label' via key-value pairing",
    "why": "딕셔너리를 쓰면 바꾸고 싶은 특정 열만 골라서 바꿀 수 있고, 실수로 다른 열의 순서를 망가뜨릴 위험도 없기 때문에 가장 안전한 방식입니다.",
    "hint": "'기존 이름'을 열쇠(Key)로 넣으면 '새 이름'이라는 보상(Value)을 돌려주는 구조를 생각하세요.",
    "trap_points": [
      "리스트로 전체 열 이름을 덮어쓰는 것보다 훨씬 유연하고 유지보수에 유리함"
    ],
    "difficulty": "hard",
    "id": "0204"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "TF-IDF 수식에서 IDF(역문서 빈도)를 계산할 때, 분모인 문서 빈도(`df`)에 로그(log)를 취하는 결정적 수학적 의도는?",
    "options": [
      "To dampen the impact of extremely high frequencies (Damping)",
      "To convert binary frequency into a probability distribution",
      "To normalize the character-byte length of the word segment",
      "To eliminate zero-valued elements from the sparse matrix"
    ],
    "answer": "To dampen the impact of extremely high frequencies (Damping)",
    "why": "문서 빈도가 10배 많아진다고 해서 그 단어의 중요도가 10배나 낮아지는 것은 아니므로, 로그를 취해 완만하게 변화하도록 충격을 흡수(Damping)해주는 것입니다.",
    "hint": "1,000만 원 차이가 날 때보다 10억 원 차이가 날 때 '체감하는 차이'가 무뎌지는 것과 비슷한 원리입니다.",
    "trap_points": [
      "로그를 취하지 않으면 흔한 단어들의 페널티가 너무 커져서 정보가 왜곡될 수 있음"
    ],
    "difficulty": "hard",
    "id": "0205"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "판다스의 `duplicated()` 메서드 실행 시, 중복된 행 중 '가장 나중에 나타난 것만' 중복이 아닌 것으로 인정(중복 체크에서 제외)하려면 어떤 파라미터를 써야 하는가?",
    "options": [
      "keep='last'",
      "keep='first'",
      "keep=False",
      "keep='unique'"
    ],
    "answer": "keep='last'",
    "why": "`keep='last'`를 쓰면 마지막 행을 중복이 아닌 것으로 간주하고 그 앞의 데이터들을 True(중복)로 처리합니다. 기본값은 `first`입니다.",
    "hint": "최신 데이터를 살리고 과거의 중복 기록들을 지우고 싶을 때 사용하는 옵션입니다.",
    "trap_points": [
      "keep=False 로 설정하면 중복된 모든 행을 True로 반환하여 아예 '중복 그룹' 자체를 찾아낼 수도 있음"
    ],
    "difficulty": "hard",
    "id": "0206"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "판다스에서 `set_index()` 연산을 수행하여 특정 열을 인덱스로 활용할 때 얻을 수 있는 결정적 성능 이점은?",
    "options": [
      "O(1) average time complexity for data retrieval via Hashing",
      "Linear scanning acceleration via SIMD string parsing",
      "Recursive bit-compression of the primary pointer buffer",
      "Automatic parallelization of categorical mapping indices"
    ],
    "answer": "O(1) average time complexity for data retrieval via Hashing",
    "why": "인덱스는 내부적으로 해시 테이블 등으로 관리되므로, 특정 값을 찾을 때 데이터를 처음부터 끝까지 훑는 대신 즉시 정답 지점으로 점프할 수 있어 검색 속도가 비약적으로 빨라집니다.",
    "hint": "수만 명의 이름표를 뒤져서 찾는 대신, 가나다순으로 정리된 '색인'을 보고 바로 페이지를 넘기는 무기를 얻는 것입니다.",
    "trap_points": [
      "자주 검색하는 열을 인덱스로 설정하면 데이터프레임이 훨씬 가벼워지고 빨라짐"
    ],
    "difficulty": "hard",
    "id": "0207"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Numpy 배열 [1, 2]와 [3, 4]에 대해 `*` 연산자와 `@` 연산자를 각각 적용했을 때의 결과적 차이는?",
    "options": [
      "Element-wise multiplication ([3, 8]) vs. Dot product (11)",
      "Vector addition ([4, 6]) vs. Cross product calculation",
      "Iterative summation vs. Parallel batch normalization",
      "Literal string mapping vs. Binary shift operations"
    ],
    "answer": "Element-wise multiplication ([3, 8]) vs. Dot product (11)",
    "why": "`*`는 같은 위치의 숫자끼리 곱하는 직관적인 연산이고, `@`는 내적(Dot product)을 구하여 하나의 숫자로 합쳐내는 선형대수적 연산입니다.",
    "hint": "그냥 곱하기와, '곱해서 더하기(내적)'의 차이를 생각하세요.",
    "trap_points": [
      "@ 연산자는 파이썬 3.5부터 행렬 곱셉 전용으로 도입되었으며 `np.matmul()`과 동일하게 동작함"
    ],
    "difficulty": "hard",
    "id": "0208"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "정규표현식의 앵커(Anchor) 캐릭터인 `^`와 `$`가 결합된 `^...$` 패턴이 강제하는 매칭의 엄격성은?",
    "options": [
      "Full string matching (from start to end) instead of partial search",
      "Literal translation of non-ascii unicode code points",
      "Recursive backtracking over multiline character buffers",
      "Forced normalization of zero-width space segments"
    ],
    "answer": "Full string matching (from start to end) instead of partial search",
    "why": "`^`는 시작, `$`는 끝을 못 박아버리기 때문에, 문장 중간에 포함된 단어가 아니라 문장 자체가 해당 패턴과 정확히 일치해야만 매칭이 성공합니다.",
    "hint": "울타리를 앞뒤로 쳐서 도망가지 못하게 가둬놓는 것과 같습니다.",
    "trap_points": [
      "비밀번호 유효성 검사 등 '정확히 이 형식이어야만 함'을 선언할 때 필수적인 기법임"
    ],
    "difficulty": "hard",
    "id": "0209"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "판다스의 `df.info()` 출력 결과에서 'Dtype' 정보가 데이터 분석가의 ETL(추출-변환-적재) 초기 단계에서 갖는 기술적 가치는?",
    "options": [
      "Identifying implicit data corruption and memory overhead",
      "Calculating the Pearson correlation of categorical features",
      "Normalization of floating-point precision in the L3 cache",
      "Recursive sorting of the internal column indexing buffer"
    ],
    "answer": "Identifying implicit data corruption and memory overhead",
    "why": "숫자여야 할 열이 `object`로 나온다면 숫자가 아닌 문자가 섞여 있다는 뜻이고, `float64`가 너무 많으면 메모리가 낭비되고 있다는 것을 즉시 알 수 있게 해줍니다.",
    "hint": "공사장에 들어갈 때, 자재(Data)들의 종류(Type)가 제대로 들어왔는지 송장을 체크하는 것과 같습니다.",
    "trap_points": [
      "특히 수백만 행의 데이터를 다룰 때, object 타입을 category로만 바꿔도 메모리가 80% 이상 줄어들 수 있음"
    ],
    "difficulty": "hard",
    "id": "0210"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "Numpy에서 부동소수점 간격(Step)을 가진 배열을 생성할 때, `np.arange()`가 아닌 `np.linspace()` 사용이 권장되는 정밀도적 이유는?",
    "options": [
      "Avoidance of floating-point error accumulation in the stop value",
      "Implicit recursive alignment of sub-normal bit fragments",
      "Support for multi-threaded memory allocation via SIMD",
      "Literal matching of binary-coded decimal representations"
    ],
    "answer": "Avoidance of floating-point error accumulation in the stop value",
    "why": "`arange`는 간격을 더해나가는 방식이라 미세한 오차가 쌓여 마지막 숫자가 포함되거나 생략되는 불안정함이 있지만, `linspace`는 등간격을 나누는 방식이라 정확한 개수를 보장합니다.",
    "hint": "계단을 오르는 방식과, 밧줄을 정확히 같은 길이로 자르는 방식의 안정성 차이를 생각하세요.",
    "trap_points": [
      "부동소수점(0.1 등)을 간격으로 쓸 때는 무조건 `linspace`를 쓰는 것이 안전함"
    ],
    "difficulty": "hard",
    "id": "0211"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "판다스의 시계렬 열에서 특정 요일만 필터링하거나 연도별로 그룹화할 때, 연산 성능 최적화를 위해 활용해야 하는 접근자는?",
    "options": [
      ".dt accessor (Vectorized datetime properties)",
      ".st accessor (Sparse temporal alignment)",
      ".ts accessor (Thread-safe sequence indexing)",
      ".df accessor (Dimensionally folded access)"
    ],
    "answer": ".dt accessor (Vectorized datetime properties)",
    "why": "`.dt`를 쓰면 파이썬 루프 없이 내부적으로 최적화된 C 코드로 한꺼번에 날짜 정보를 처리하므로, `apply` 함수를 쓰는 것보다 수십 배 이상 빠릅니다.",
    "hint": "이미 판다스가 날짜 전용으로 '날카롭게 깎아놓은 도구(DT)'를 꺼내 쓴다고 생각하세요.",
    "trap_points": [
      "이 접근자는 Series가 datetime64 타입일 때만 활성화됨에 유의"
    ],
    "difficulty": "hard",
    "id": "0212"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "정규표현식에서 특정 문자열을 매칭에 포함시키지 않고 '그 앞에 이 패턴이 있는지'만 확인하는 `(?=...)` 문법의 기술적 명칭과 특징은?",
    "options": [
      "Positive Lookahead (Zero-width assertion)",
      "Reverse Backreference (Recursive matching)",
      "Strict Prefix Mapping (Pointer alignment)",
      "Greedy Buffer Clipping (State-based search)"
    ],
    "answer": "Positive Lookahead (Zero-width assertion)",
    "why": "전방 탐색은 실제로 문자를 '소비'하지 않고 위치만 체크하는 'Zero-width' 방식이어서, 조건을 확인한 후에도 다음 매칭을 바로 그 자리에서 이어갈 수 있게 해줍니다.",
    "hint": "범인을 잡기 전에, '저 사람이 마스크를 썼는지'만 멀리서 슬쩍 확인하고 내 위치는 그대로 유지하는 것과 같습니다.",
    "trap_points": [
      "복잡한 비밀번호 규칙(숫자와 영문 포함 등)을 한 번에 검증할 때 필수적인 고급 기법임"
    ],
    "difficulty": "hard",
    "id": "0213"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "워드 임베딩(Word2Vec) 기법에서 'Skip-gram' 모델이 'CBOW' 대비 소규모 말뭉치(Corpus)에서 희귀 단어에 대해 더 높은 복원력을 가지는 이유는?",
    "options": [
      "One target predicts multiple contexts (Increases rare word training signals)",
      "Recursive averaging of context buckets to reduce gradient noise",
      "Automatic elimination of low-frequency stopword pointers",
      "Forced normalization of the cosine similarity distance matrix"
    ],
    "answer": "One target predicts multiple contexts (Increases rare word training signals)",
    "why": "하나의 중심 단어로 주변 여러 단어를 예측하는 구조 덕분에, 가끔 등장하는 단어도 주변 정보와 엮이는 기회가 더 많아져서 그 의미를 더 정교하게 학습할 수 있습니다.",
    "hint": "주변 사람들이 말하는 걸 듣고 나를 추측하는 것보다, 내가 여러 사람에게 말을 걸며 나를 알리는 것이 훨씬 더 깊은 인상을 남기는 원리입니다.",
    "trap_points": [
      "반대로 데이터가 엄청나게 많을 때는 CBOW가 훨씬 간결하고 빠르게 학습된다는 장점이 있음"
    ],
    "difficulty": "hard",
    "id": "0214"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "판다스의 `melt()` 연산이 데이터를 'Wide format'에서 'Long format'으로 녹여낼 때, `id_vars` 파라미터가 수행하는 기술적 역할은?",
    "options": [
      "Anchor columns that remain fixed as identifiers",
      "Forced recalculation of row-major sorting buffers",
      "Implicit recursive hashing of categorical column labels",
      "Automatic deletion of zero-valued numeric segments"
    ],
    "answer": "Anchor columns that remain fixed as identifiers",
    "why": "`id_vars`에 지정된 열은 움직이지 않는 기준점이 되고, 나머지 열들만 행으로 녹아내려 '변수'와 '값'의 형태로 재구성됩니다.",
    "hint": "회전목마의 중심 기둥(ID)은 그대로 있고, 주변의 말들(다른 열들)만 빙글빙글 돌아 제자리로 정렬되는 모습을 생각하세요.",
    "trap_points": [
      "반대 방향인 Long to Wide는 `pivot`이나 `unstack`을 사용하여 수행함"
    ],
    "difficulty": "hard",
    "id": "0215"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "대규모 데이터셋에서 특정 문자열 열의 중복도가 높을 때, `object` 타입을 `category` 타입으로 변환함으로써 얻는 메모리 상의 이득은?",
    "options": [
      "Integer mapping of labels (Reduces redundant string storage)",
      "Bit-level compression of UTF-8 character buffers",
      "Parallelized indexing via SIMD categorical hashing",
      "Forced alignment of pointer-based memory segments"
    ],
    "answer": "Integer mapping of labels (Reduces redundant string storage)",
    "why": "동일한 문자열이 수백만 번 나와도 메모리에는 딱 한 번만 저장하고 숫자로 링크만 걸어두기 때문에, 특히 중복이 많은 성별, 지역명 등의 데이터에서 메모리를 최대 90% 이상 아낄 수 있습니다.",
    "hint": "수천 개의 책 이름을 일일이 적는 대신, 번호가 적힌 도서 카드를 나눠주고 실제 책은 창고에 한 권씩만 두는 '중앙 관리 방식'입니다.",
    "trap_points": [
      "하지만 모든 값이 제각각인 고유한 문자열(예: ID)에 카테고리를 쓰면 오히려 메모리가 더 늘어날 수 있음에 주의"
    ],
    "difficulty": "hard",
    "id": "0216"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "두 변수 간의 선형적 인과관계가 아닌 '단순 방향성'을 측정하는 '피어슨 상관계수'가 선형 변환(Scaling)에 독립적인 기술적 명분은?",
    "options": [
      "Normalization via standardized covariance dividing by sigma product",
      "Recursive inversion of the binary loss gradient pointers",
      "Implicit bit-shuffling of zero-width feature buckets",
      "Automatic elimination of non-convex statistical artifacts"
    ],
    "answer": "Normalization via standardized covariance dividing by sigma product",
    "why": "분산의 곱으로 공분산을 나눠주어 단위를 없애버렸기 때문에, 키를 cm로 재든 m로 재든 상관계수 값은 변하지 않고 두 변수의 순수하게 닮은 꼴만 추출됩니다.",
    "hint": "지도에서 크기(Scale)가 커지거나 작아져도, 산맥의 모양(Direction)은 그대로 유지되는 원리와 같습니다.",
    "trap_points": [
      "단, 두 변수가 비선형(곡선) 관계를 가질 때는 피어슨 계수가 0에 가깝게 나와 함정에 빠질 수 있음"
    ],
    "difficulty": "hard",
    "id": "0217"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "데이터의 정규성(Normality)이 파괴된 환경에서 '평균' 대신 '순위(Rank)'를 활용하여 두 집단의 차이를 검증하는 비모수 검정의 기술적 타당성은?",
    "options": [
      "Robustness against extreme outliers and skewed distributions",
      "Linear scaling of the logarithmic population intercept",
      "Recursive alignment of the floating-point mantissa bucket",
      "Forced bit-compression of the primary categorical pointers"
    ],
    "answer": "Robustness against extreme outliers and skewed distributions",
    "why": "실제 수치가 아닌 '누가 더 앞서나' 하는 순서만 보기 때문에, 말도 안 되게 큰 값이 툭 튀어나와서 평균을 왜곡시키는 이상치 공격에 매우 강한 저항력을 가집니다.",
    "hint": "점수 자체로 줄을 세우는 것이 아니라, 전교 1등부터 꼴찌까지 '등수'만 보고 실력 차이를 판단하는 공정한 심판법입니다.",
    "trap_points": [
      "Mann-Whitney U 검정이나 Kruskal-Wallis 검정 등이 대표적인 비모수 검정 기법임"
    ],
    "difficulty": "hard",
    "id": "0218"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "결측치 처리에서 '단순 평균 대치'가 데이터의 '분산(Variance)'을 과소평가(Underestimate)하게 만드는 통계적 결함은?",
    "options": [
      "Artificially reduces the spread by clustering values at the mean",
      "Inverts the binary log-loss derivative pointers",
      "Recursive normalization of invisible noise fragments",
      "Literal matching of binary-coded decimal representations"
    ],
    "answer": "Artificially reduces the spread by clustering values at the mean",
    "why": "모르는 부분을 전부 평균으로 채워버리면, 데이터가 중간에만 몰리게 되어 실제보다 훨씬 '예측 가능하고 균일한' 데이터처럼 보이는 왜곡이 발생합니다.",
    "hint": "안개 낀 부분을 전부 회색 평지로 칠해버리면, 그 아래에 숨겨진 굴곡과 계곡들을 전혀 알 수 없게 되는 상황과 같습니다.",
    "trap_points": [
      "이를 극복하기 위해 MICE(다중 대치)나 모델 기반 대치를 통해 데이터의 굴곡을 살려줘야 함"
    ],
    "difficulty": "hard",
    "id": "0219"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "객관식",
    "question": "시계열 데이터 분석의 STL 분해(Decomposition)에서 '잔차(Residual)' 항목이 가지는 통계적 가치는?",
    "options": [
      "Capturing irregular fluctuations after removing Trend and Seasonality",
      "Recursive sorting of the primary datetime epoch buffer",
      "Linear scaling of the logarithmic population intercept",
      "Support for multi-threaded memory allocation via SIMD"
    ],
    "answer": "Capturing irregular fluctuations after removing Trend and Seasonality",
    "why": "추세나 계절성으로 설명 안 되는 '진짜 노이즈'이자 '특이 사항'이 잔차에 남으므로, 이상치 탐지나 예측 불가능한 돌발 변수를 찾을 때 핵심적인 단서가 됩니다.",
    "hint": "명절 대목(계절성)이나 꾸준한 매출 상승(추세)을 다 걷어내고 남은, 정말 '그날따라 이상했던' 흔적을 찾는 돋보기입니다.",
    "trap_points": [
      "잔차가 일정한 패턴 없이 화이트 노이즈(White Noise) 형태라면 모델이 학습을 아주 잘했다는 증거임"
    ],
    "difficulty": "hard",
    "id": "0220"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "판다스 시리즈에서 데이터 타입을 확인하여 부동소수점 오차나 메모리 점유율을 가늠하기 위해 사용하는 속성을 작성하세요.\n\n```python\nimport pandas as pd\ndf = pd.DataFrame({'val': [3.14, 2.71]})\nprint(df['val'].____)\n```",
    "options": [],
    "answer": "dtype",
    "why": "dtype 속성은 해당 열의 물리적 데이터 타입(float64, int64 등)을 반환하여 수치 정밀도를 확인할 수 있게 합니다.",
    "difficulty": "easy",
    "id": "0221"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "판다스에서 단일 열 선택 시 Series가 아닌 DataFrame 형태로 결과(Shadow Copy)를 얻기 위해 사용해야 하는 인덱싱 문법을 완성하세요.\n\n```python\n# 'name' 컬럼을 데이터프레임 구조로 가져오기\nsubset_df = df[____]\n```",
    "options": [],
    "answer": "['name']",
    "why": "대괄호 안에 리스트(Double Bracket)를 넣으면 단일 열이라도 데이터프레임 형식을 유지하여 반환됩니다.",
    "difficulty": "medium",
    "id": "0222"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "판다스에서 '점수가 80점 이상'이면서 '출석률이 90% 이상'인 행들만 복합적으로 필터링하기 위한 논리 연산자를 작성하세요.\n\n```python\n# 비트와이즈 AND 연산자 사용\nresult = df[(df['score'] >= 80) ____ (df['attendance'] >= 90)]\n```",
    "options": [],
    "answer": "&",
    "why": "판다스의 불리언 마스킹에서는 요소별(Element-wise) 연산을 수행하는 비트와이즈 연산자(&)를 써야 하며, 각 조건은 반드시 소괄호로 감싸야 합니다.",
    "difficulty": "medium",
    "id": "0223"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "시리즈의 각 요소에 파이썬 함수를 개별적으로 적용하여 데이터를 가공할 때 사용하는 핵심 매핑 메서드를 작성하세요.\n\n```python\n# experience 컬럼의 각 값에 10을 더함\ndf['exp_plus'] = df['experience'].____(lambda x: x + 10)\n```",
    "options": [],
    "answer": "map",
    "why": "단일 시리즈(열)의 값 대 값 변환에는 apply보다 map이 더 가볍고 명확한 의도를 전달합니다.",
    "difficulty": "medium",
    "id": "0224"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "문자열 열에서 정규표현식을 사용하여 특정 단어가 포함되어 있는지 벡터 연산으로 대량 검사하기 위한 접근자를 완성하세요.\n\n```python\n# 'Python' 포함 여부 확인\nhas_py = df['skills'].str.____('Python')\n```",
    "options": [],
    "answer": "contains",
    "why": "str.contains()를 통해 특정 문자열 포함 여부를 벡터 연산으로 빠르게 검사할 수 있습니다.",
    "difficulty": "medium",
    "id": "0225"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "특정 기준열로 데이터를 묶은 뒤, `agg` 함수를 통해 여러 개의 통계량(평균, 합계 등)을 한꺼번에 산출하기 위한 전제 메서드를 작성하세요.\n\n```python\n# 부서별 급여 평균과 합계 동시 산출\nres = df.____('dept')['salary'].agg(['mean', 'sum'])\n```",
    "options": [],
    "answer": "groupby",
    "why": "groupby()는 특정 기준에 따라 데이터를 그룹으로 나누어 복합적인 집계 작업을 수행하게 해줍니다.",
    "difficulty": "medium",
    "id": "0226"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "데이터를 CSV 파일로 저장할 때, 무의미한 행 번호(0, 1, 2...)가 열로 추가되어 저장되는 것을 방지하기 위한 옵션을 완성하세요.\n\n```python\ndf.to_csv('out.csv', ____=False)\n```",
    "options": [],
    "answer": "index",
    "why": "index=False 옵션을 주면 인덱스가 별도의 데이터 컬럼으로 출력되는 것을 막아 용량을 줄이고 깔끔한 파일을 만듭니다.",
    "difficulty": "easy",
    "id": "0227"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "넘파이 배열의 차원 정보(행과 열의 개수)를 메타데이터 수준에서 즉시 확인하기 위해 사용하는 속성을 작성하세요.\n\n```python\nimport numpy as np\narr = np.array([[1, 2], [3, 4]])\nprint(arr.____)\n```",
    "options": [],
    "answer": "shape",
    "why": "shape 속성은 실제 데이터를 스캔하지 않고 행렬의 구조 정보를 튜플 형태로 즉시 반환합니다.",
    "difficulty": "easy",
    "id": "0228"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "넘파이에서 부동소수점 오차를 최소화하며 0부터 10까지 2의 간격으로 숫자를 등차 생성하기 위해 `range` 대신 사용하는 함수를 작성하세요.\n\n```python\n# [0, 2, 4, 6, 8]\narr = np.____(0, 10, 2)\n```",
    "options": [],
    "answer": "arange",
    "why": "arange()는 넘파이에서 수치 범위를 가진 벡터를 생성하는 표준적인 함수입니다.",
    "difficulty": "medium",
    "id": "0229"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "파이썬 3.5 이후 버전에서 `np.dot()` 연산을 대체하여 직관적이고 가독성 높게 '행렬 곱셉'을 수행하기 위해 도입된 연산자 기호는?\n\n```python\n# C = A . B 와 같은 의미\nC = A ____ B\n```",
    "options": [],
    "answer": "@",
    "why": "@ 연산자는 행렬 곱셉(Matmul) 전용으로 도입되어 선형 대수 코드를 더욱 수학적으로 표현하게 해줍니다.",
    "difficulty": "medium",
    "id": "0230"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "벡터의 크기를 1로 맞추는 정규화(Normalization) 과정에서 필연적으로 사용되는 L2 노름(Norm) 산출 함수를 완성하세요.\n\n```python\n# 벡터의 길이 계산\nv_len = np.linalg.____(v)\n```",
    "options": [],
    "answer": "norm",
    "why": "linalg.norm()은 유클리드 거리를 계산하여 벡터의 실제 물리적 크기나 거리를 구할 때 사용합니다.",
    "difficulty": "hard",
    "id": "0231"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "데이터프레임의 '전체 열 중 단 하나라도' 결측치(NaN)가 있는 행을 가차 없이 삭제하기 위한 파라미터가 적용된 메서드를 작성하세요.\n\n```python\n# 행 전체가 아닌, 일부라도 비어있으면 삭제\nclean = df.____(how='any')\n```",
    "options": [],
    "answer": "dropna",
    "why": "dropna()의 how='any'는 데이터의 완전성을 보장하기 위해 조금이라도 비어있는 샘플을 모두 제거합니다.",
    "difficulty": "easy",
    "id": "0232"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "수치형 데이터의 평균, 사분위수, 최대최소를 요약하여 데이터의 분포와 이상치 존재 여부를 파악하는 기술 통계 메서드를 작성하세요.\n\n```python\nsummary = df['score'].____()\n```",
    "options": [],
    "answer": "describe",
    "why": "describe()는 기본적인 통계 지표를 한눈에 보여주어 데이터의 '중심'과 '퍼짐'을 이해하게 해줍니다.",
    "difficulty": "easy",
    "id": "0233"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "넘파이 배열의 전치(Transpose) 작업 시, 메모리 복사 없이 뷰(View)만 반환하여 물리적 연산 부하를 최소화하는 단축 속성을 작성하세요.\n\n```python\n# 행과 열 뒤바꾸기\nB = A.____\n```",
    "options": [],
    "answer": "T",
    "why": ".T 속성은 실제 메모리 상의 순서를 건드리지 않고 인덱싱 방식만 바꿔 전치를 수행합니다.",
    "difficulty": "easy",
    "id": "0234"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "판다스의 인덱스 레이블명이 숫자로 구성되어 있을 때, 이름이 아닌 '물리적인 정수 순서'만으로 데이터를 추출하기 위해 사용하는 접근자를 완성하세요.\n\n```python\n# 파일의 맨 마지막 행 가져오기\nlast = df.____[-1]\n```",
    "options": [],
    "answer": "iloc",
    "why": "iloc는 레이블 명칭에 관계없이 무조건 0부터 시작하는 '위치 번호'로 데이터를 찾습니다.",
    "difficulty": "medium",
    "id": "0235"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "판다스 시계렬 데이터에서 요일을 '0(월) ~ 6(일)' 사이의 정수 인덱스로 추출하여 주말 여부 등을 판별할 때 사용하는 속성을 완성하세요.\n\n```python\n# 요일 정보 추출\nday_idx = df['date'].dt.____\n```",
    "options": [],
    "answer": "dayofweek",
    "why": "dayofweek은 날짜 정보를 한꺼번에 요일 숫자로 변환하여 시계렬 패턴 분석을 가능하게 합니다.",
    "difficulty": "hard",
    "id": "0236"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "넘파이 배열에서 '값이 0인 요소들만' 찾아내어 인덱스 정보를 활용할 수 있도록 결과(True/False)를 반환하는 마스크 생성 코드를 완성하세요.\n\n```python\n# 0인 위치를 불리언으로 표시\nmask = (arr ____ 0)\n```",
    "options": [],
    "answer": "==",
    "why": "비교 연산자를 활용한 브로드캐스팅은 반복문 없이 대규모 행렬의 특정 값을 즉시 찾아내게 합니다.",
    "difficulty": "hard",
    "id": "0237"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "특정 열에 존재하는 고유한 값들의 빈도를 '비율(Ratio)'로 환산하여 상대적 비중을 즉시 파악하기 위해 사용하는 메서드를 완성하세요.\n\n```python\nratio = df['type'].____(normalize=True)\n```",
    "options": [],
    "answer": "value_counts",
    "why": "value_counts(normalize=True)는 단순 카운트가 아닌 가중치를 한눈에 보여주는 도구입니다.",
    "difficulty": "medium",
    "id": "0238"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "연산 레이어의 가중치 초기화 등에서 모든 요소를 1로 가득 채운 특정 형상의 배열을 만들 때 사용하는 함수를 작성하세요.\n\n```python\n# 3행 3열을 1로 채움\narr = np.____((3, 3))\n```",
    "options": [],
    "answer": "ones",
    "why": "ones() 함수는 연산의 항등원인 1.0으로 배열을 초기화하여 수치 시뮬레이션 등에 활용됩니다.",
    "difficulty": "easy",
    "id": "0239"
  },
  {
    "chapter_name": "데이터 분석",
    "type": "코드 완성형",
    "question": "여러 개의 데이터프레임을 수직 또는 수평으로 단순 연결(Concat)할 때, 원래의 인덱스를 무시하고 새로 번호를 매기는 옵션과 결합 함수를 작성하세요.\n\n```python\n# 인덱스 재설정하며 병합\nres = pd.____([df1, df2], ignore_index=True)\n```",
    "options": [],
    "answer": "concat",
    "why": "concat()은 복수의 데이터를 축을 따라 효율적으로 이어 붙이는 물리적 병합 도구입니다.",
    "difficulty": "medium",
    "id": "0240"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "Transformer 아키텍처에서 Self-Attention 연산이 RNN의 순차적(sequential) 계산 대비 병렬화 성능을 비약적으로 높일 수 있는 수리적 근거는?",
    "options": [
      "Time Complexity Reduction",
      "Constant Path Length",
      "Linear Matrix Multiplicaton",
      "Global Context Window"
    ],
    "answer": "Constant Path Length",
    "why": "Self-attention은 문장 내 임의의 두 토큰 사이의 거리에 관계없이 한 번의 연산으로 관계를 파악(Constant path length)할 수 있어, 이전 상태에 의존하는 재귀적 구조가 불필요합니다.",
    "hint": "토큰 간의 '의존성 거리'를 생각해보세요.",
    "trap_points": [
      "행렬 곱셈 자체는 병렬화의 결과물이지 근본적인 탈-재귀의 원인은 아님"
    ],
    "difficulty": "hard",
    "id": "0241"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 추론 시 'KV Caching'이 생성 토큰당 레이턴시(Latency)를 줄이는 핵심 원리임에도 불구하고, 대규모 서빙 시 발생하는 주요 트레이드오프는?",
    "options": [
      "Arithmetic Intensity Decrease",
      "Memory Bandwidth Bottleneck",
      "Parallel Processing Stall",
      "Attention Map Distortion"
    ],
    "answer": "Memory Bandwidth Bottleneck",
    "why": "KV 캐싱은 연산(Compute)을 줄이는 대신 거대한 KV 텐서를 매번 메모리에서 읽어와야 하므로, 추론 속도가 연산 속도가 아닌 메모리 대역폭에 의해 결정되는 병목 현상을 야기합니다.",
    "hint": "데이터를 매번 '가져오는' 비용을 생각하세요.",
    "trap_points": [
      "연산 집약도는 오히려 낮아지며, 이는 연산 유닛의 유효 활용률을 떨어뜨림"
    ],
    "difficulty": "hard",
    "id": "0242"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "Speculative Decoding에서 'Target Model'이 'Draft Model'의 출력을 검토할 때, 왜 전체 시퀀스를 한 번의 Forward Pass로 검증할 수 있는가?",
    "options": [
      "Rejection Sampling",
      "Autoregressive Bypass",
      "Parallel Validation",
      "Recursive Verification"
    ],
    "answer": "Parallel Validation",
    "why": "드래프트 모델이 이미 토큰들을 생성해두었으므로, 타겟 모델은 이를 '입력'으로 간주하여 학습 시와 마찬가지로 모든 토큰을 병렬로(Parallel) 한 번에 처리하고 어텐션 맵을 계산할 수 있습니다.",
    "hint": "생성(Generation)과 검증(Verification)의 차이를 생각하세요.",
    "trap_points": [
      "모델 자체가 비-자기회귀로 바뀌는 것이 아니라, 제공된 초안 덕분에 병렬 처리가 가능해지는 것임"
    ],
    "difficulty": "hard",
    "id": "0243"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM에서 'Context Window'의 한계인 잃어버린 중간(Lost in the Middle) 현상이란?",
    "options": [
      "중간 줄이 안 나오는 현상",
      "문장이 너무 길 때, 모델이 앞부분과 뒷부분은 잘 기억하나 중간에 위치한 정보를 놓치는 현상",
      "답변 속도가 느려지는 현상",
      "영어가 서툰 현상",
      "파일이 깨지는 현상"
    ],
    "answer": "문장이 너무 길 때, 모델이 앞부분과 뒷부분은 잘 기억하나 중간에 위치한 정보를 놓치는 현상",
    "why": "어텐션 메커니즘의 특성상 정보 밀도가 양끝단에 쏠리는 경향이 있어 발생하는 한계입니다.",
    "hint": "가운데(Middle)를 잃어버립니다.",
    "trap_points": [
      "중요한 지시나 근거는 문장의 맨 앞이나 맨 뒤에 두는 것이 유리함"
    ],
    "difficulty": "medium",
    "id": "0244"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머 레이어 중 'Multi-Query Attention (MQA)'과 'Grouped-Query Attention (GQA)'이 추론 최적화에서 해결하고자 하는 공통적인 수리적 병목은 무엇인가?",
    "options": [
      "Query 연산의 부동소수점 오차",
      "KV 캐시의 메모리 대역폭(Memory Bandwidth) 소모와 VRAM 점유",
      "어텐션 맵의 제곱 배수(N^2) 연산량",
      "Feed-Forward 층의 파라미터 과잉"
    ],
    "answer": "KV 캐시의 메모리 대역폭(Memory Bandwidth) 소모와 VRAM 점유",
    "why": "MQA와 GQA는 Key와 Value 헤드 수를 줄여 KV 캐시 크기를 압축함으로써, 추론 시 메모리 대역폭 병목을 완화하고 더 긴 컨텍스트를 지원하게 합니다.",
    "hint": "KV 캐싱 시 메모리에서 데이터를 '읽어오는' 비용에 집중하세요.",
    "trap_points": [
      "연산 성능(TFLOPS)보다는 메모리 읽기 성능이 병목인 LLM 서빙의 특성을 반영함"
    ],
    "difficulty": "hard",
    "id": "0245"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM이 특정 페르소나를 유지하거나 '나는 도움을 주는 AI'라는 정체성을 가지게 되는 것은 주로 어떤 데이터를 통한 훈련 결과인가?",
    "options": [
      "System Prompt 및 페르소나가 투영된 SFT 데이터",
      "수조 개의 대규모 사전 학습(Pre-training) 원시 텍스트",
      "토크나이저의 어휘 집합(Vocab)",
      "추론 엔진의 하드웨어 정밀도(Quantization)"
    ],
    "answer": "System Prompt 및 페르소나가 투영된 SFT 데이터",
    "why": "지도 미세 조정(SFT) 단계에서 특정 역할극 데이터를 학습하거나, 시스템 프롬프트를 통해 모델이 출력해야 할 가이드라인과 세계관을 주입하기 때문입니다.",
    "hint": "모델의 '행동 양식'과 '정체성'을 강제하는 단계를 생각하세요.",
    "trap_points": [
      "사전 학습 데이터에도 정체성 암시가 있으나, 결정적인 '정렬'은 SFT와 이후 과정에서 일어남"
    ],
    "difficulty": "medium",
    "id": "0246"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM의 'Emergent Abilities (발현 능력)'가 특정 파라미터 규모 및 학습량(Compute) 이상에서 갑갑이 나타나는 현상에 대한 가장 유력한 가설은?",
    "options": [
      "모델이 인터넷에 연결되어 답을 찾아오기 때문",
      "복합적 추론을 위한 논리적 고리들이 모두 연결되는 임계점(Threshold) 통과",
      "하드웨어 온도가 높아져서 연산 속도가 빨라지기 때문",
      "이미지 데이터가 텍스트 데이터보다 압도적으로 많아질 때"
    ],
    "answer": "복합적 추론을 위한 논리적 고리들이 모두 연결되는 임계점(Threshold) 통과",
    "why": "작은 모델에서는 부분적인 논리만 수행하던 모델이, 특정 규모 이상에서 여러 논리 단계를 한꺼번에 수행할 수 있는 수준으로 통합되면서 능력이 비약적으로 향상됩니다.",
    "hint": "양질의 변화가 질질의 변화로 이어지는 문턱 값을 생각하세요.",
    "trap_points": [
      "최근에는 학습 데이터 단계를 미세하게 측정하면 사실 선형적으로 점진 향상 중이라는 견해도 있음"
    ],
    "difficulty": "medium",
    "id": "0247"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "현대 토크나이저가 'OOV (Out Of Vocabulary)' 현상을 해결하기 위해 글자(Char)와 단어(Word)의 중간 지점에서 채택하는 전략은?",
    "options": [
      "사전에 없는 단어는 모두 지운다.",
      "의미를 보존하는 최소 단위인 서브워드(Subword)로 분할하여 표현한다.",
      "단어를 무시하고 한글 자모음 단위로만 쪼갠다.",
      "모든 단어를 무조건 해시(Hash)값으로 변환한다."
    ],
    "answer": "의미를 보존하는 최소 단위인 서브워드(Subword)로 분할하여 표현한다.",
    "why": "단어 사전의 크기를 관리하면서도, 생소한 단어를 'un' + 'believable' 처럼 쪼개어 조합함으로써 모든 표현이 가능하게 합니다.",
    "hint": "쪼개진 조각(Subword)들이 모여 거대한 의미를 만듭니다.",
    "trap_points": [
      "BPE나 WordPiece 등이 이 전략의 하위 알고리즘에 해당함"
    ],
    "difficulty": "medium",
    "id": "0248"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머의 인코더와 디코더 아키텍처에서 '미래 정보 접근(Information Leakage)'을 차단하기 위해 디코더에만 존재하는 수리적 장치는?",
    "options": [
      "Residual Connection",
      "Causal (Masked) Self-Attention",
      "Feed-Forward Expansion",
      "Sinusoidal Positional Encoding"
    ],
    "answer": "Causal (Masked) Self-Attention",
    "why": "디코더는 생성 모델이므로 현재 토큰을 예측할 때 미래 시점의 토큰 가중치를 강제로 -inf로 처리(Masking)하여 정보 유출을 막아야 합니다.",
    "hint": "앞을 보지 못하게 가리는 'Mask'의 역할에 집중하세요.",
    "trap_points": [
      "인코더는 문장 전체를 한꺼번에 보고 맥락을 뽑는 '양방향'이 기본임"
    ],
    "difficulty": "hard",
    "id": "0249"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 학습 시 단일 GPU 메모리를 초과하는 거대 모델을 학습하기 위해, 가중치와 그래디언트를 여러 GPU에 효과적으로 쪼개어 분산하는 DeepSpeed의 핵심 기술은?",
    "options": [
      "ZeRO (Zero Redundancy Optimizer)",
      "Flash Attention 3.0",
      "Speculative Pushing",
      "Quantized Gradient Descent"
    ],
    "answer": "ZeRO (Zero Redundancy Optimizer)",
    "why": "ZeRO는 모델 상태(Optimizer States, Gradients, Parameters)를 GPU들 사이에서 분할 저장하여 중복 메모리 사용을 0으로 만들어 수천억 모델의 학습을 가능하게 합니다.",
    "hint": "중복(Redundancy)을 없앤다(Zero)는 뜻의 약자를 찾으세요.",
    "trap_points": [
      "모델 병렬화(Model Parallelism)와는 또 다른 차원의 최적화 기술임"
    ],
    "difficulty": "hard",
    "id": "0250"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "현대 LLM의 긴 컨텍스트(Context Window) 지원을 혁명적으로 가능하게 한 Flash Attention이 해결한 HBM(고대역폭 메모리) 차원의 병목은?",
    "options": [
      "GPU 클럭 속도 부족",
      "어텐션 행렬 연산의 입출력(IO) 병목 및 메모리 점유율 급증",
      "데이터 세트의 텍스트 노이즈",
      "전기 에너지 효율성 저하"
    ],
    "answer": "어텐션 행렬 연산의 입출력(IO) 병목 및 메모리 점유율 급증",
    "why": "거대한 어텐션 행렬 전체를 VRAM에 쓰지 않고 타일링 기법으로 계산하여 메모리 읽기/쓰기 횟수를 극적으로 줄임으로써 속도와 컨텍스트 길이를 모두 잡았습니다.",
    "hint": "IO-aware 어텐션 알고리즘임을 기억하세요.",
    "trap_points": [
      "실제 연산 횟수(FLOPS)를 대폭 줄이는 것이 아니라, 데이터 전송 효율을 극대화한 것임"
    ],
    "difficulty": "hard",
    "id": "0251"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "Mixture of Experts(MoE) 구조가 '거대한 조밀 모델(Dense Model)' 대비 가지는 결정적인 추론 성능 상의 이점은 무엇인가?",
    "options": [
      "모든 파라미터가 매번 연산되어 정확도가 높음",
      "동일한 파라미터 규모에서 실제 추론에는 일부(Active) 파라미터만 사용되어 연산 비용(FLOPs) 절감",
      "데이터 암기 능력이 무조건적으로 상승",
      "학습 데이터 양을 1/10로 줄여도 됨"
    ],
    "answer": "동일한 파라미터 규모에서 실제 추론에는 일부(Active) 파라미터만 사용되어 연산 비용(FLOPs) 절감",
    "why": "1조 파라미터 모델이라도 추론 시에는 수십 개의 전문가 중 2개 정도만 활성화하여 계산하기 때문에 속도가 압도적으로 빠릅니다.",
    "hint": "모든 파라미터를 사용하지 않는 'Sparse' 연산의 특징을 생각하세요.",
    "trap_points": [
      "학습 시에는 모든 전문가가 골고루 최적화되어야 하므로 VRAM 요구량은 여전히 큼"
    ],
    "difficulty": "hard",
    "id": "0252"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "GPT 계열의 'Decoder-only' 모델이 BERT 계열의 'Encoder-only' 모델 대비 '생성(Generation)'에 더 유리한 수리적 근거는?",
    "options": [
      "가중치가 무조건 더 많기 때문",
      "인과적 어텐션(Causal Attention)을 통해 이전 단어에만 의존하며 순차적 출력을 생성하기에 최적화됨",
      "이미지 데이터를 섞어서 쓰기 때문",
      "영어를 더 잘하기 때문"
    ],
    "answer": "인과적 어텐션(Causal Attention)을 통해 이전 단어에만 의존하며 순차적 출력을 생성하기에 최적화됨",
    "why": "디코더는 다음 단어를 하나씩 붙여 나가는 '자기회귀적' 방식이 구조에 내재되어 있어, 긴 문장 생성 시 일관성을 유지하는 능력이 탁월합니다.",
    "hint": "인과성(Causality)과 미래 정보 가리기에 집중하세요.",
    "trap_points": [
      "최근에는 인코더-디코더 통합형인 T5도 쓰이지만, 압도적인 생성 성능은 여전히 디코더 모델들이 주도함"
    ],
    "difficulty": "medium",
    "id": "0253"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM의 'Temperature' 파라미터가 0에서 멀어질수록(높아질수록) 모델 출력의 확률 분포에는 어떤 변화가 일어나는가?",
    "options": [
      "가장 높은 확률의 토큰만 극단적으로 강조됨",
      "전체 토큰의 확률 분포가 평탄(Flatten)해지며 샘플링의 다양성이 증가",
      "동일한 문장만 반복해서 생성하게 됨",
      "문법적으로 완벽한 문장만 생성하게 됨"
    ],
    "answer": "전체 토큰의 확률 분포가 평탄(Flatten)해지며 샘플링의 다양성이 증가",
    "why": "온오를 높이면 소프트맥스 출력값들이 서로 비슷해지면서 낮은 확률의 단어도 선택될 여지가 커지기 때문입니다.",
    "hint": "열역학의 엔트로피가 증가하는 이미지를 떠올려 보세요.",
    "trap_points": [
      "온도를 너무 높이면 문맥과 상관없는 '아무 말'이 섞일 확률도 함께 올라감"
    ],
    "difficulty": "medium",
    "id": "0254"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM을 4비트 양자화(Int4)하여 실행할 때, FP16 대비 VRAM 사용량을 1/4로 줄이면서도 연산의 높은 정밀도를 유지하기 위해 사용하는 기술적 우회법은?",
    "options": [
      "이미지를 같이 인쇄함",
      "연산 시에만 일시적으로 FP16으로 복원(De-quantization)하여 커널 연산을 수행",
      "데이터를 절반만 처리함",
      "네트워크 속도를 높임"
    ],
    "answer": "연산 시에만 일시적으로 FP16으로 복원(De-quantization)하여 커널 연산을 수행",
    "why": "저장은 4비트로 하여 메모리를 아끼지만, 행렬 곱샘 등의 연산은 정밀도가 필요하므로 즉석에서 복원하여 연산 유닛에 보냅니다.",
    "hint": "저장 정밀도와 연산 정밀도의 차이를 생각하세요.",
    "trap_points": [
      "최근의 NF4(NormalFloat4) 방식은 QLoRA 등에서 표준으로 쓰임"
    ],
    "difficulty": "hard",
    "id": "0255"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "모델이 답변 후 자신의 오류를 스스로 인지하고 수정하는 'Self-Correction' 능력을 극대화하기 위해 권장되는 프롬프트 설계 전략은?",
    "options": [
      "질문을 무조건 짧게 하기",
      "비판적 사고를 지시하는 별도의 검토 단계(Verifier)를 프롬프트 체인에 포함",
      "데이터를 다 영어로 바꾸기",
      "모델 버전을 계속 낮추기"
    ],
    "answer": "비판적 사고를 지시하는 별도의 검토 단계(Verifier)를 프롬프트 체인에 포함",
    "why": "모델은 한 번에 정답을 내기보다, 답변 결과를 다시 입력으로 넣어 '틀린 점이 없는지 검토해달라'고 요청할 때 추론 능력이 더 잘 발휘됩니다.",
    "hint": "생각의 과정을 한 번 더 거치게 하는 구조입니다.",
    "trap_points": [
      "자기 수정은 모델 내부 지식의 고도화된 연상 능력에 기반함"
    ],
    "difficulty": "medium",
    "id": "0256"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 학습 데이터에서 중복(Duplicate) 데이터를 완벽하게 제거(Deduplication)하지 않았을 때 발생하는 가장 치명적인 부작용은?",
    "options": [
      "연산 비용의 절감",
      "특정 문장에 대한 '암기(Memorization)' 편향으로 인한 일반화 성능 하락 및 개인정보 유출 위험",
      "단어 사전 파일의 크기 감소",
      "답변 속도의 무조건적 향상"
    ],
    "answer": "특정 문장에 대한 '암기(Memorization)' 편향으로 인한 일반화 성능 하락 및 개인정보 유출 위험",
    "why": "데이터가 중복되어 여러 번 학습되면 모델은 이를 패턴이 아닌 '고정값'으로 암기하여, 유사한 질문에 유연하게 대처하지 못하고 학습 데이터를 그대로 뱉어냅니다.",
    "hint": "지능적인 추론과 앵무새 같은 암기의 차이를 생각하세요.",
    "trap_points": [
      "중복 제거는 학습 효율을 높이는 동시에 모델의 안전성을 확보하는 필수 단계임"
    ],
    "difficulty": "hard",
    "id": "0257"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "BPE(Byte Pair Encoding) 토크나이저가 '희귀 단어(Rare words)'를 처리할 때 다른 방식보다 효율적인 이유는 무엇인가?",
    "options": [
      "희귀 단어를 무시하기 때문",
      "단어를 더 작은 단위인 서브워드로 분해하여 사전에 있는 조합으로 모두 표현 가능하기 때문",
      "모든 단어를 숫자로 변환하기 때문",
      "이미지 토큰과 결합하기 때문"
    ],
    "answer": "단어를 더 작은 단위인 서브워드로 분해하여 사전에 있는 조합으로 모두 표현 가능하기 때문",
    "why": "자주 쓰이는 단어는 하나의 토큰으로, 드문 단어는 '조각'들로 표현하여 알 수 없는 단어(Unknown)를 0에 가깝게 줄입니다.",
    "hint": "레고 블록처럼 단어를 조립하는 원리를 생각하세요.",
    "trap_points": [
      "한글과 같은 교착어에서 조사나 어미를 분리하는 데 매우 강력함"
    ],
    "difficulty": "medium",
    "id": "0258"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머 디코더에서 'Look-ahead Masking'이 실제 소프트맥스 연산 전에 주의(Attention) 점수 행렬에 적용되는 값은?",
    "options": [
      "0으로 채움",
      "-inf (음의 무한대)",
      "1로 채움",
      "랜덤한 난수"
    ],
    "answer": "-inf (음의 무한대)",
    "why": "소프트맥스를 취했을 때 미래 토큰의 확률값이 0이 되게 하려면, 지수 함수(exp)의 특성상 입력값이 음의 무한대여야 합니다.",
    "hint": "소프트맥스 함수의 수리적 특성을 생각하세요.",
    "trap_points": [
      "0을 넣으면 exp(0)=1이 되어 확률이 남게 되므로 오답임"
    ],
    "difficulty": "hard",
    "id": "0259"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "RLHF(Reinforcement Learning from Human Feedback) 과정 중, 'PPO' 알고리즘이 모델을 업데이트할 때 기준점으로 삼는 지표는 무엇인가?",
    "options": [
      "손실 함수의 미분값만 사용",
      "이전 단계 모델(Reference Model)과의 KL-Divergence를 통한 정책 변화 억제 및 보상 최대화",
      "이미지 픽셀 단위의 유사도",
      "학습 데이터 파일의 용량"
    ],
    "answer": "이전 단계 모델(Reference Model)과의 KL-Divergence를 통한 정책 변화 억제 및 보상 최대화",
    "why": "모델이 인간의 선호를 배우면서도 기존의 언어적 기초를 파괴하지 않도록(Catastrophic Forgetting 방지) 제약을 걸면서 보상을 높여야 하기 때문입니다.",
    "hint": "너무 멀리 가지 않게(Divergence) 잡으면서 상(Reward)을 줍니다.",
    "trap_points": [
      "최근에는 DPO가 이 복잡한 보상 모델 학습 과정을 수리적으로 단축하여 인기를 끄는 중임"
    ],
    "difficulty": "medium",
    "id": "0260"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머 아키텍처에서 인코더와 디코더 사이의 연결을 담당하며 인코더의 정보를 디코더로 넘겨주는 어텐션은?",
    "options": [
      "Self-Attention",
      "Masked Self-Attention",
      "Cross-Attention",
      "Multi-Head Attention"
    ],
    "answer": "Cross-Attention",
    "why": "크로스 어텐션은 디코더가 생성 시 인코더가 뽑아낸 입력 문장의 맥락 벡터를 참조하게 해줍니다.",
    "hint": "서로 교차(Cross)한다는 뜻입니다.",
    "trap_points": [
      "디코더 전용 모델(GPT)에는 이 과정이 없음"
    ],
    "difficulty": "hard",
    "id": "0261"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머의 Self-Attention 연산 시, 입력 문장의 길이(L)가 늘어남에 따라 계산 복잡도와 필요한 메모리가 급격히 증가하는 수리적 관계는?",
    "options": [
      "선형 비례 (O(L))",
      "로그 비례 (O(log L))",
      "제곱 비례 (O(L^2))",
      "상수 시간 (O(1))"
    ],
    "answer": "제곱 비례 (O(L^2))",
    "why": "어텐션 메커니즘은 문장의 모든 토큰끼리 한 번씩 서로를 참조해야 하므로 NxN 행렬 연산이 필수적이며, 길이가 2배가 되면 연산량은 4배가 됩니다.",
    "hint": "모든 단어쌍(Pairwise)을 검사하는 비용을 생각하세요.",
    "trap_points": [
      "BERT 모델의 경우 인코더 블록이 이 제곱 복잡도의 영향을 크게 받음"
    ],
    "difficulty": "medium",
    "id": "0262"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM이 실제 사실이 아닌 내용을 그럴듯하게 답하는 'Hallucination(환각)' 현상을 억제하기 위해, 외부 신뢰 소스에서 정보를 실시간으로 검색하여 제공하는 기술적 명칭은?",
    "options": [
      "RLHF",
      "RAG (Retrieval-Augmented Generation)",
      "MMLU Evaluation",
      "Prompt Injecting"
    ],
    "answer": "RAG (Retrieval-Augmented Generation)",
    "why": "모델의 고정된 내부 지식에만 의존하지 않고, 최신 뉴스나 전문 문서를 DB에서 찾아 프롬프트에 동적으로 삽입하여 답변의 근거를 보강하는 방식입니다.",
    "hint": "검색(Retrieval)하여 보강(Augmented)하는 생성 방식입니다.",
    "trap_points": [
      "RAG는 모델 자체를 재학습시키지 않고도 지식 업데이트와 환각 억제가 가능함"
    ],
    "difficulty": "easy",
    "id": "0263"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "BERT 모델이 GPT와 달리 문장 중간의 단어를 예측하는 'Masked Language Modeling (MLM)'을 통해 얻는 아키텍처적 강점은 무엇인가?",
    "options": [
      "더 긴 문장을 생성할 수 있음",
      "문맥을 양방향(Bidirectional)으로 훑어 단어의 의미를 더 정확하게 파악함",
      "이미지 분류를 더 잘함",
      "추론 속도가 10배 빠름"
    ],
    "answer": "문맥을 양방향(Bidirectional)으로 훑어 단어의 의미를 더 정확하게 파악함",
    "why": "BERT는 앞뒤 맥락을 모두 사용하여 빈칸을 맞추도록 학습되므로, 감성 분석이나 분류 등 '문장 이해' 작업에 최적화되어 있습니다.",
    "hint": "BPE와 달리 문장 전체의 의미 표현(Representation)에 집중합니다.",
    "trap_points": [
      "생성(Generation)보다는 이해와 분류(NLU) 작업에 훨씬 더 강력한 구조임"
    ],
    "difficulty": "medium",
    "id": "0264"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "70억 파라미터(7B) 모델을 FP16 정밀도로 GPU에 로드하려고 할 때, 순수 가중치용으로만 필요한 최소 VRAM 용량은 약 얼마인가?",
    "options": [
      "7GB",
      "14GB",
      "21GB",
      "28GB"
    ],
    "answer": "14GB",
    "why": "FP16은 파라미터당 2바이트를 사용하므로 70억 * 2 = 14GB가 순수 가중치 용량입니다.",
    "hint": "70억 개 가중치 * 2바이트(16비트)를 계산해 보세요.",
    "trap_points": [
      "실제 실행 시에는 KV 캐시 등으로 더 많은 메모리가 필요함"
    ],
    "difficulty": "medium",
    "id": "0265"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM의 'Pre-training' 단계와 'Fine-tuning' 단계의 가장 근본적인 수리적 목표 차이는 무엇인가?",
    "options": [
      "Pre-training은 이미지 학습이고 Fine-tuning은 텍스트 학습이다.",
      "Pre-training은 일반적인 다음 단어 예측(Next token prediction)을, Fine-tuning은 특정 지시나 레이블에 대한 최적화(Instruction following)를 목표로 함",
      "Pre-training은 정답을 암기하고 Fine-tuning은 질문을 이해하는 과정이다.",
      "두 단계 모두 손실 함수 최적화 방식이 100% 동일하여 차이가 없다."
    ],
    "answer": "Pre-training은 일반적인 다음 단어 예측(Next token prediction)을, Fine-tuning은 특정 지시나 레이블에 대한 최적화(Instruction following)를 목표로 함",
    "why": "사전 학습은 레이블 없는 원시 텍스트(Raw Text)를 통해 모델의 기초 지능을 구축하는 단계이며, 파인튜닝은 대화 형식이나 특정 작업의 형식을 가르치는 단계입니다.",
    "hint": "먼저(Pre) 학습시키는 거대한 지식 기반과 나중에 다듬는(Fine) 능력의 차이를 생각하세요.",
    "trap_points": [
      "파인튜닝 단계에서도 '다음 단어 예측' 메커니즘은 유지되지만, 데이터셋의 정렬(Alignment) 목적이 다름"
    ],
    "difficulty": "medium",
    "id": "0266"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "모델이 복잡한 질문에 대해 답변하기 전, 내부적으로 논리적인 추론 단계를 거치는 'Chain of Thought (CoT)'를 명시적으로 출력하는 최신 모델의 전용 태그는?",
    "options": [
      "<answer>",
      "<think>",
      "<logic>",
      "<step>"
    ],
    "answer": "<think>",
    "why": "최신 모델(DeepSeek R1 등)은 생각하는 과정(Thinking Process)을 별도의 태그 안에 출력하여 논리력을 보강하며, 이는 추론 성능 향상의 핵심입니다.",
    "hint": "생각하다라는 영어 단어입니다.",
    "trap_points": [
      "사용자에게는 이 구간을 숨기고 최종 답변만 보여주어 간결함을 유지하기도 함"
    ],
    "difficulty": "medium",
    "id": "0267"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "Meta가 공개한 오픈 소스 LLM인 Llama 시리즈가 채택하여 추론 효율을 극대화한 'Grouped-Query Attention (GQA)'의 핵심 메커니즘은?",
    "options": [
      "모든 레이어를 하나로 합침",
      "여러 개의 Query 헤드가 소수의 Key-Value 헤드를 공유하여 KV 캐시 메모리 대역폭 절감",
      "이미지 데이터를 텍스트로 변환",
      "인터넷에서 실시간 검색 수행"
    ],
    "answer": "여러 개의 Query 헤드가 소수의 Key-Value 헤드를 공유하여 KV 캐시 메모리 대역폭 절감",
    "why": "Key-Value 헤드 수를 줄임으로써 VRAM 사용량과 메모리 접근 횟수를 줄여, 더 긴 문장을 더 빠르게 처리할 수 있게 합니다.",
    "hint": "쿼리들이 그룹(Grouped)을 지어 공통의 자원을 공유합니다.",
    "trap_points": [
      "Llama 3 등 최신 대형 모델들은 GQA를 표준으로 채택하여 추론 성능을 확보함"
    ],
    "difficulty": "hard",
    "id": "0268"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "단어의 의미적 거리를 숫자로 표현한 벡터 공간인 'Embedding' 공간에서, 코사인 유사도(Cosine Similarity)가 1에 가까울수록 의미하는 바는?",
    "options": [
      "두 단어의 글자 수가 같다.",
      "두 벡터의 방향이 거의 일치하여 문맥적 의미가 매우 유사하다.",
      "두 단어가 알파벳 순서로 나란히 있다.",
      "두 단어의 글자 크기가 같다."
    ],
    "answer": "두 벡터의 방향이 거의 일치하여 문맥적 의미가 매우 유사하다.",
    "why": "코사인 유사도는 벡터의 길이에 상관없이 '방향'의 일치도를 측정하므로, 비슷한 문맥에서 쓰이는 단어들을 찾는 데 최적화되어 있습니다.",
    "hint": "각도가 0도에 가까워지는 기하학적 의미를 생각하세요.",
    "trap_points": [
      "동음이의어라도 현대의 Contextual Embedding(GPT 등)은 문맥에 따라 다른 벡터를 생성함"
    ],
    "difficulty": "medium",
    "id": "0269"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "하이브리드 처리 기능(텍스트+이미지+음성 등)을 가진 모델을 'Multimodal'이라 부를 때, 이를 가능하게 하는 핵심 기술적 장치는?",
    "options": [
      "인터넷 연결 모듈",
      "서로 다른 모달리티의 데이터를 동일한 벡터 공간으로 정렬(Align)하는 거대한 임베딩 레이어",
      "특수 쿨링 팬",
      "데이터 압축 알고리즘"
    ],
    "answer": "서로 다른 모달리티의 데이터를 동일한 벡터 공간으로 정렬(Align)하는 거대한 임베딩 레이어",
    "why": "이미지와 텍스트를 숫자로 바꿨을 때 '사과'라는 단어와 '사과 사진'이 비슷한 좌표를 가지게 함으로써, 모델이 사진을 보고 글로 설명할 수 있게 됩니다.",
    "hint": "여러 양식(Modality)을 하나의 언어로 통합하는 과정을 생각하세요.",
    "trap_points": [
      "단순히 여러 입력을 받는 것을 넘어, 의미론적 결합이 일어나는 것이 핵심임"
    ],
    "difficulty": "medium",
    "id": "0270"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM의 'Context Window' 크기가 물리적으로 제한되는 가장 근본적인 수학적 이유는 무엇인가?",
    "options": [
      "시스템의 쿨링 성능 한계",
      "Self-Attention의 연산 및 메모리 요구량이 문장 길이의 제곱(O(L^2))으로 증가하기 때문",
      "인터넷 대역폭의 한계",
      "데이터 학습셋의 문장 길이가 모두 짧기 때문"
    ],
    "answer": "Self-Attention의 연산 및 메모리 요구량이 문장 길이의 제곱(O(L^2))으로 증가하기 때문",
    "why": "도한 현재까지 나온 모든 단어의 정보(KV 캐시)를 VRAM에 들고 있어야 하는데, 제곱 비례 법칙 때문에 길이가 길어질수록 메모리 소모량이 폭주합니다.",
    "hint": "모든 단어가 서로를 '주의 깊게' 쳐다보는 비용을 생각하세요.",
    "trap_points": [
      "이 한계를 극복하기 위해 Flash Attention이나 Sparse Attention 같은 최적화 기술이 발전함"
    ],
    "difficulty": "medium",
    "id": "0271"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "GPT와 같은 Decoder-only 모델이 텍스트 생성 시 미래 정보를 보지 못하게 차단하는 'Causal Masking'이 수리적으로 적용되는 방식은?",
    "options": [
      "미래 토큰의 가중치를 0으로 만듦",
      "어텐션 점수 행렬의 미래 시점 데이터에 -inf(음의 무한대)를 더해 소프트맥스 결과가 0이 되게 함",
      "미래 데이터를 삭제함",
      "모델 레이어를 제거함"
    ],
    "answer": "어텐션 점수 행렬의 미래 시점 데이터에 -inf(음의 무한대)를 더해 소프트맥스 결과가 0이 되게 함",
    "why": "생성 모델은 현재까지 나온 단어만 보고 다음을 예측해야 하므로, 수리적으로 미래의 영향력을 완전히 차단하여 인과성을 유지합니다.",
    "hint": "소프트맥스 함수를 통과시켰을 때 '0'이 되기 위해 필요한 사전 값을 생각하세요.",
    "trap_points": [
      "0을 더하면 가중치가 그대로 남게 되어 미래 정보가 유출(Leakage)됨"
    ],
    "difficulty": "hard",
    "id": "0272"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "최신 LLM에서 고전적인 절대 위치 인코딩 대신 사용하는 'RoPE (Rotary Positional Embedding)'가 상대적 위치 파악에 유리한 수학적 이유는?",
    "options": [
      "모델 가중치를 0으로 만들기 때문",
      "토큰 사이의 거리를 회전 행렬(Rotation Matrix)을 통한 내적 연산으로 보존하여 외삽(Extrapolation)에 유리함",
      "데이터 용량을 줄이기 때문",
      "연산 속도를 100배 늘리기 때문"
    ],
    "answer": "토큰 사이의 거리를 회전 행렬(Rotation Matrix)을 통한 내적 연산으로 보존하여 외삽(Extrapolation)에 유리함",
    "why": "RoPE는 두 토큰의 절대 위치가 아닌, 서로 얼마나 떨어져 있는지에 대한 '상대적 거리' 정보를 기하학적으로 유지하여 긴 문장 이해도를 높입니다.",
    "hint": "회전(Rotary)이라는 단어에 담긴 수학적 회전 변환을 생각하세요.",
    "trap_points": [
      "Llama 등 최신 오픈 소스 모델들이 로프(RoPE)를 표준처럼 사용함"
    ],
    "difficulty": "hard",
    "id": "0273"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "BPE 토크나이징 과정에서 발생할 수 있는 '역전 가망성(Reversibility)' 손상을 방지하기 위해 단어 조각들을 결합하는 기준은?",
    "options": [
      "글자 수가 가장 긴 순서",
      "학습 데이터에서 가장 빈번하게 함께 등장하는 문자 쌍(Byte Pair)을 반복적으로 병합",
      "알파벳 순서",
      "랜덤하게 선택"
    ],
    "answer": "학습 데이터에서 가장 빈번하게 함께 등장하는 문자 쌍(Byte Pair)을 반복적으로 병합",
    "why": "자주 나오는 글자 조합을 하나의 토큰으로 묶으면 모델이 처리해야 할 전체 토큰 수가 줄어들고 정보 밀도가 높아집니다.",
    "hint": "가장 많이 나오는 조각끼리 서로 붙는 '결합'의 원리를 생각하세요.",
    "trap_points": [
      "이 과정에서 낱자(글자) 단위까지 쪼개질 수 있으므로 사전에 없는 단어(OOV)도 표현 가능함"
    ],
    "difficulty": "medium",
    "id": "0274"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "거대 모델의 전체 가중치를 직접 수정하는 대신, 행렬 분해(Matrix Decomposition)를 통해 아주 적은 수의 가중치만 학습시키는 효율적인 파인튜닝 기법은?",
    "options": [
      "Pruning (가지치기)",
      "LoRA (Low-Rank Adaptation)",
      "Full Fine-tuning (전체 튜닝)",
      "Quantization (양자화)"
    ],
    "answer": "LoRA (Low-Rank Adaptation)",
    "why": "LoRA는 큰 가중치 행렬 옆에 아주 좁은 통로(Low-Rank)와 같은 작은 행렬을 두어, 적은 컴퓨팅 자원으로도 모델을 특정 도메인에 최적화합니다.",
    "hint": "순위(Rank)가 낮은(Low) 작은 행렬을 덧붙이는 방식입니다.",
    "trap_points": [
      "양자화(Quantization)는 속도와 용량을 줄이는 기술이며, LoRA는 학습 효율을 높이는 기술임"
    ],
    "difficulty": "medium",
    "id": "0275"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM이 잘못된 정보나 허위 사실을 진실처럼 출력하는 '환각' 현상을 억제하기 위해, 실시간 검색 증강(RAG)이 해결하는 핵심 문제는?",
    "options": [
      "모델의 암기력 저하",
      "지식 차단 시점(Knowledge Cut-off) 이후의 최신 정보 부재 및 근거 없는 생성 억제",
      "파라미터 수 부족",
      "전력 소모량 과다"
    ],
    "answer": "지식 차단 시점(Knowledge Cut-off) 이후의 최신 정보 부재 및 근거 없는 생성 억제",
    "why": "모델의 고정된 내부 지식에만 의존하지 않고, 외부의 검증된 문서를 참조하게 함으로써 '출처'가 명확한 답변을 생성하도록 유도합니다.",
    "hint": "이미 배운 지식의 한계를 외부 자료로 '보충'하는 원리를 생각하세요.",
    "trap_points": [
      "RAG를 쓴다고 해서 환각이 0이 되는 것은 아니며, 검색된 문서를 잘못 해석할 위험도 있음"
    ],
    "difficulty": "easy",
    "id": "0276"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "Mixture of Experts (MoE) 구조가 'Sparse Attention'과 결합하여 추론 연산량(FLOPs)을 획기적으로 낮출 수 있는 비결은?",
    "options": [
      "단어 수를 줄이기 때문",
      "모든 파라미터를 사용하지 않고, 각 토큰별로 가장 적합한 일부 전문가 계층(Top-K Experts)만 활성화하기 때문",
      "이미지를 같이 학습하기 때문",
      "인터넷 연결이 필요 없기 때문"
    ],
    "answer": "모든 파라미터를 사용하지 않고, 각 토큰별로 가장 적합한 일부 전문가 계층(Top-K Experts)만 활성화하기 때문",
    "why": "전체 파라미터가 1조 개라 하더라도 실제 계산에는 수십 개의 전문가 중 2개 정도만 활용하여 속도와 비용을 절감합니다.",
    "hint": "전체 중 '일부'만 골라서 쓰는 효율적인 라우팅 메커니즘을 생각하세요.",
    "trap_points": [
      "메모리(VRAM)에는 여전히 전체 전문가 가중치를 올려두어야 하므로 저장 공간은 절약되지 않음"
    ],
    "difficulty": "hard",
    "id": "0277"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM의 'Temperature' 파라미터 값이 매우 낮을 때(예: 0.1), 동일한 질문에 대한 모델의 답변 양상은 어떻게 변화하는가?",
    "options": [
      "매우 창의적이고 무작위적인 답변으로 매번 바뀜",
      "확률 분포의 상단 토큰들이 극단적으로 강조되어 항상 동일하거나 매우 유사한 답변이 나옴(결정론적 성향)",
      "답변 속도가 느려짐",
      "답변 글자 수가 고정됨"
    ],
    "answer": "확률 분포의 상단 토큰들이 극단적으로 강조되어 항상 동일하거나 매우 유사한 답변이 나옴(결정론적 성향)",
    "why": "온오가 낮아지면 소프트맥스 결과값이 뾰족해져서(Sharpening), 가장 확률이 높은 단어만 거의 독식하게 됩니다.",
    "hint": "무작위성의 열기가 식고 차갑게 이성적인 예측만 수행하는 상태를 떠올리세요.",
    "trap_points": [
      "사실 관계 확인을 요하는 작업에는 낮은 온도가, 스토리텔링에는 높은 온도가 권장됨"
    ],
    "difficulty": "medium",
    "id": "0278"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "단순히 지식을 습득한 베이스 모델(Base Model)을 챗봇처럼 지시에 따르도록 만드는 'Instruct Fine-tuning'의 핵심 데이터 특징은?",
    "options": [
      "수조 개의 무작위 웹 페이지",
      "사람이 직접 작성한 '질문(Instruction)'과 '정답(Response)' 쌍으로 구성된 고품질 데이터",
      "이미지와 캡션 설명 데이터",
      "컴퓨터 코드 에러 로그"
    ],
    "answer": "사람이 직접 작성한 '질문(Instruction)'과 '정답(Response)' 쌍으로 구성된 고품질 데이터",
    "why": "모델에게 질문의 형식과 답변의 규칙을 학습시킴으로써, 사용자의 요구 의도를 정확히 파악하여 반응하게 합니다.",
    "hint": "지시(Instruction) 사항을 이해하고 수행하는 '훈련 양식'을 생각하세요.",
    "trap_points": [
      "양질의 지시 데이터가 없으면 모델은 질문에 답하는 대신 질문을 따라 쓰거나 엉뚱한 말을 함"
    ],
    "difficulty": "medium",
    "id": "0279"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "모델의 '지식 차단 시점(Knowledge Cut-off)'을 보완하기 위해 실시간 검색 증강(RAG) 기술을 도입했을 때의 이점과 거리가 먼 것은?",
    "options": [
      "최신 뉴스 및 정보를 실시간으로 반영 가능",
      "답변의 근거가 되는 출처(Source)를 명시하여 투명성 확보",
      "모델의 내부 파라미터가 자동으로 정밀하게 업데이트됨",
      "할루시네이션(환각) 현상을 지배적으로 억제"
    ],
    "answer": "모델의 내부 파라미터가 자동으로 정밀하게 업데이트됨",
    "why": "RAG는 외부 정보를 '참조'하는 것일 뿐, 모델의 가중치나 지능 자체가 물리적으로 변하는 것은 아닙니다.",
    "hint": "뇌를 수술(학습)하는 것과 안경(RAG)을 씌우는 것의 차이를 생각하세요.",
    "trap_points": [
      "RAG는 지식 업데이트 비용이 매우 저렴하지만, 모델의 근본적인 추론 능력을 고치는 것은 아님"
    ],
    "difficulty": "easy",
    "id": "0280"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머의 'Self-Attention'이 RNN(순환 신경망)보다 긴 문장의 문맥을 압도적으로 잘 포착하는 수리적 배경은?",
    "options": [
      "메모리를 획기적으로 적게 소모하기 때문",
      "문장 내 임의의 두 토큰 사이의 '거리(Path length)'가 위치에 상관없이 항상 1로 직접 연결되어 정보 희석이 없기 때문",
      "영문법의 계층적 구조를 미리 학습했기 때문",
      "단어들을 짧은 숫자로 압축하기 때문"
    ],
    "answer": "문장 내 임의의 두 토큰 사이의 '거리(Path length)'가 위치에 상관없이 항상 1로 직접 연결되어 정보 희석이 없기 때문",
    "why": "RNN은 정보를 전달할 때마다 이전 상태값이 희석되지만, 어텐션은 모든 토큰 쌍의 상호작용을 한 번에 계산하므로 아주 먼 위치의 정보도 손실 없이 참조합니다.",
    "hint": "먼 곳에 있는 토큰과 소통할 때 거쳐야 하는 '다리'의 개수를 생각하세요.",
    "trap_points": [
      "이 장점의 대가로 문장 길이의 제곱에 비례하는 연산 복잡도를 감수해야 함"
    ],
    "difficulty": "hard",
    "id": "0281"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 서비스에서 'Hallucination(환각)' 현상을 기술적으로 억제하기 위한 방법 중, 아키텍처나 워크플로우 관점에서 가장 부적절한 것은?",
    "options": [
      "RAG(검색 증강 생성) 시스템을 통한 근거 문서 강제 참조",
      "Temperature 값을 0에 가깝게 설정하여 무작위성 제거",
      "성능 향상을 위해 모델의 중간 레이어(Layer)들을 무작위로 삭제하여 실행",
      "추론 과정에서 다수의 답변을 생성한 뒤 일관성을 검증하는 Self-Consistency 기법"
    ],
    "answer": "성능 향상을 위해 모델의 중간 레이어(Layer)들을 무작위로 삭제하여 실행",
    "why": "무작위 레이어 삭제는 모델의 추론 논리 체계를 붕괴시켜 오히려 환각을 심화시키거나 아예 의미 없는 결과를 낼 위험이 큽니다.",
    "hint": "모델의 지능적 구조를 파괴하는 행위를 찾으세요.",
    "trap_points": [
      "환각은 확률 모델의 본성이라 100% 제거는 불가능함"
    ],
    "difficulty": "medium",
    "id": "0282"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 학습 데이터 전처리 중 'Deduplication(중복 제거)' 작업이 모델의 성능과 일반화 능력에 미치는 결정적인 수리적 영향은?",
    "options": [
      "데이터 용량이 늘어나서 학습 시간이 길어짐",
      "특정 패턴에 대한 편향된 가중치 업데이트를 방지하여 과적합(Overfitting)과 단순 암기 현상을 억제",
      "영어를 한국어로 자동 번역함",
      "모델 파라미터 수를 줄여줌"
    ],
    "answer": "특정 패턴에 대한 편향된 가중치 업데이트를 방지하여 과적합(Overfitting)과 단순 암기 현상을 억제",
    "why": "동일한 문장이 반복적으로 등장하면 모델은 이를 근본적인 논리가 아닌 '통계적 확률'로 절대 암기해버려, 새로운 질문에 대한 응용력이 떨어지게 됩니다.",
    "hint": "똑같은 내용을 반복해서 듣는 세뇌 효과를 방지하는 것이 목적입니다.",
    "trap_points": [
      "중복 제거가 안 된 모델은 학습 데이터의 특정 문구를 그대로 출력하는 'Privacy Leakage'에 취약함"
    ],
    "difficulty": "hard",
    "id": "0283"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머의 'Self-Attention' 연산 시 모델이 특정 토큰 쌍의 관계를 결정짓는 세 가지 핵심 벡터 성분이 아닌 것은?",
    "options": [
      "Query (찾고자 하는 정보)",
      "Key (가지고 있는 정보의 인덱스)",
      "Value (실제 담긴 정보)",
      "Target (정답 레이블)"
    ],
    "answer": "Target (정답 레이블)",
    "why": "어텐션 내부 연산은 Q, K, V 세 가지 벡터의 내적과 가중합으로 이루어지며, Target은 손실 함수 계산 시에만 사용됩니다.",
    "hint": "데이터베이스 검색 시스템의 원리(질의, 키, 값)와 유사합니다.",
    "trap_points": [
      "Q, K, V는 모두 동일한 입력 벡터로부터 선형 변환을 통해 생성됨"
    ],
    "difficulty": "medium",
    "id": "0284"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM의 'Reasoning(추론)' 능력을 극대화하기 위해 질문 끝에 '단계별로 생각해보자'라는 문구를 넣는 기법의 수리적 효과는?",
    "options": [
      "모델이 답변하는 속도를 늦추어 시간을 벌게 함",
      "출력 토큰 사이에 중간 추론 과정(Intermediary Computations)을 배치하여 복잡한 논리를 풀어나갈 정적 공간 확보 및 오류 연쇄 방지",
      "전기 에너지를 보존함",
      "답변 글자 수를 무조건 고정함"
    ],
    "answer": "출력 토큰 사이에 중간 추론 과정(Intermediary Computations)을 배치하여 복잡한 논리를 풀어나갈 정적 공간 확보 및 오류 연쇄 방지",
    "why": "단순 정답만 내게 하면 모델의 활성화 함수가 한 단계의 연산으로 결론을 도출해야 하지만, CoT를 유도하면 여러 토큰에 걸쳐 논리적 결합을 분산 처리할 수 있습니다.",
    "hint": "문제를 풀 때 연습장에 풀이 과정을 적는 효과와 같습니다.",
    "trap_points": [
      "최신 모델들은 프롬프트 없이도 이 과정을 <think> 태그 내에서 수행하도록 강화됨"
    ],
    "difficulty": "medium",
    "id": "0285"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "거대 모델의 학습에 사용되는 'Reinforcement Learning from Human Feedback (RLHF)' 과정에서 사람의 선호도를 학습하여 점수를 매기는 핵심 모듈은?",
    "options": [
      "Generator (생성기)",
      "Reward Model (보상 모델)",
      "Tokenizer (토크나이저)",
      "Embedder (임베더)"
    ],
    "answer": "Reward Model (보상 모델)",
    "why": "보상 모델은 사람이 매긴 선호도 순위를 학습하여, 어떤 답변이 더 좋은 답변인지 판독하는 점수 측정기 역할을 합니다.",
    "hint": "어떤 답변이 상(Reward)을 받을 만큼 훌륭한지 판단하는 두뇌입니다.",
    "trap_points": [
      "PPO 같은 강화학습 알고리즘은 이 보상 모델의 점수를 극대화하는 방향으로 LLM을 업데이트함"
    ],
    "difficulty": "medium",
    "id": "0286"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머의 'Positional Encoding'이나 'RoPE' 같은 위치 정보 주입 기술이 필수적인 아키텍처적 장벽은 무엇인가?",
    "options": [
      "단어들이 숫자로 바뀌기 때문",
      "어텐션 연산(Q, K 내적) 자체가 입력 벡터의 '순서(Order)' 정보를 전혀 고려하지 않는 순열 불변(Permutation Invariant) 성질을 갖기 때문",
      "비트 수가 제한적이기 때문",
      "GPU가 영어를 못 읽기 때문"
    ],
    "answer": "어텐션 연산(Q, K 내적) 자체가 입력 벡터의 '순서(Order)' 정보를 전혀 고려하지 않는 순열 불변(Permutation Invariant) 성질을 갖기 때문",
    "why": "어텐션은 모든 토큰을 한꺼번에 처리하기 때문에 위치 정보가 없으면 단어들의 선후 관계를 구분하지 못합니다.",
    "hint": "토큰들을 가방에 넣고 흔든 뒤에도 결과가 똑같아지지 않게 만드는 장치를 생각하세요.",
    "trap_points": [
      "RoPE는 이 위치 정보를 벡터의 회전량으로 주입하여 상대적 거리를 보존함"
    ],
    "difficulty": "hard",
    "id": "0287"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 서비스에서 'Prompt Injection' 보안 공격을 방어하기 위해 시스템 메시지와 사용자 메시지를 엄격히 분리하는 기술적 필드 구조는?",
    "options": [
      "Chat Templates (Prompt format)",
      "Embedding Vector",
      "KV Cache",
      "Normalization layer"
    ],
    "answer": "Chat Templates (Prompt format)",
    "why": "Chat templates는 <|system|>, <|user|> 같은 특수 토큰을 통해 사용자 입력이 모델의 '명령어'로 오인되지 않도록 수리적으로 경계를 설정합니다.",
    "hint": "대화의 주체(시스템 vs 사용자)를 구분하는 약속된 서식을 생각하세요.",
    "trap_points": [
      "이 템플릿 서식이 일치하지 않으면 모델은 지시 사항을 무시하거나 성능이 급감함"
    ],
    "difficulty": "medium",
    "id": "0288"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "가장 진보한 LLM 학습 방식인 'DPO(Direct Preference Optimization)'가 고전적인 PPO 기반 RLHF 대비 가지는 수리적 강점은?",
    "options": [
      "파라미터 수를 2배로 늘려줌",
      "별도의 보상 모델 학습 없이, 데이터셋의 편차만으로 정책 모델을 직접 수리적으로 최적화하여 연산 효율과 안정성 확보",
      "이미지 데이터를 더 잘 처리함",
      "추론 속도가 100배 빨라짐"
    ],
    "answer": "별도의 보상 모델 학습 없이, 데이터셋의 편차만으로 정책 모델을 직접 수리적으로 최적화하여 연산 효율과 안정성 확보",
    "why": "기존 PPO는 보상 모델과 정책 모델을 동시에 돌리느라 불안정하고 자원을 많이 썼으나, DPO는 이 과정을 수학적으로 단순화했습니다.",
    "hint": "중간 단계 없이 '직접(Direct)' 최적화한다는 이름에 주목하세요.",
    "trap_points": [
      "최근 Llama 3나 오픈 소스 모델들의 미세 조정에 DPO가 대세로 자리 잡음"
    ],
    "difficulty": "hard",
    "id": "0289"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머 아키텍처에서 'Dropout' 레이어가 주로 포함되는 위치와 그 수리적 존재 이유는?",
    "options": [
      "입력층에서 정보를 삭제하기 위해",
      "FFN 혹은 Attention 직후에 위치하여 특정 가중치에만 의존하지 않도록 강제로 일부 뉴런을 끔으로써 과적합 방지",
      "데이터 용량을 줄이기 위해",
      "연산 속도를 낮추기 위해"
    ],
    "answer": "FFN 혹은 Attention 직후에 위치하여 특정 가중치에만 의존하지 않도록 강제로 일부 뉴런을 끔으로써 과적합 방지",
    "why": "드롭아웃은 학습 시 무작위로 활성화를 0으로 만들어, 모델이 모든 특징을 골고루 학습하게 유도하는 정규화 기법입니다.",
    "hint": "공부할 때 눈을 감고 일부분만 보며 전체 맥락을 파악하려는 노력과 같습니다.",
    "trap_points": [
      "추론 단계에서는 드롭아웃을 끄고 전체 가중치를 모두 사용하여 답변함"
    ],
    "difficulty": "medium",
    "id": "0290"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "모델의 지능 수준은 그대로 유지하면서 추론 시 답변 속도를 높이기 위해, 미리 계산된 '이후 답변들'을 활용하는 기술은?",
    "options": [
      "Batching",
      "Speculative Decoding (추측 디코딩)",
      "Quantization",
      "Pruning"
    ],
    "answer": "Speculative Decoding (추측 디코딩)",
    "why": "작고 빠른 모델이 먼저 답변을 추측하고, 거대 모델은 이를 검증만 함으로써 전체적인 추론 시간을 단축합니다.",
    "hint": "미리 짐작(Speculate)하여 디코딩을 진행하는 방식입니다.",
    "trap_points": [
      "추측이 틀릴 경우 다시 계산해야 하지만, 통계적으로는 훨씬 이득인 기술임"
    ],
    "difficulty": "hard",
    "id": "0291"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머 블록 내부의 'Residual Connection'이 거대 모델의 학습 안정성에 기여하는 근본적인 수리적 기능은?",
    "options": [
      "데이터를 무조건 0으로 만듦",
      "기울기 소실 문제를 해결하여 레이어가 깊어져도 오차 정보가 초기층까지 잘 전달되게 함",
      "연산 속도를 줄여줌",
      "입력 데이터를 거꾸로 섞음"
    ],
    "answer": "기울기 소실 문제를 해결하여 레이어가 깊어져도 오차 정보가 초기층까지 잘 전달되게 함",
    "why": "입력 값을 레이어 결과값에 더해주는 '지름길'을 만들어줌으로써, 미분 연산 시 기울기 값이 보존되어 깊은 모델 학습이 가능해집니다.",
    "hint": "원래의 입력(Identity)을 보존하는 통로를 생각하세요.",
    "trap_points": [
      "이 구조 없이는 트랜스포머 레이어를 10층 이상 안정적으로 쌓기가 매우 힘듦"
    ],
    "difficulty": "hard",
    "id": "0292"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM의 'Alignment' 단계 중 사람의 지시 사항을 따르도록 훈련시키는 첫 관문인 'SFT'의 역할은?",
    "options": [
      "Structured File Transfer (파일 전송)",
      "Supervised Fine-Tuning; 레이블된 고품질 대화 로그를 모델에 직접 주입",
      "Static Feature Tailoring (특성 재단)",
      "Semi-Final Training (최종 학습)"
    ],
    "answer": "Supervised Fine-Tuning; 레이블된 고품질 대화 로그를 모델에 직접 주입",
    "why": "SFT는 '질문-답변' 쌍을 그대로 학습시켜 모델이 특정 대화 패턴과 형식을 익히게 만드는 가장 기초적인 정렬 과정입니다.",
    "hint": "정답이 있는 상태에서 미세하게 조정하는 과정입니다.",
    "trap_points": [
      "SFT 이후에 RLHF나 DPO를 통해 인간의 선호도를 추가로 반영함"
    ],
    "difficulty": "medium",
    "id": "0293"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "토크나이저 아키텍처 중 'SentencePiece'가 한국어 같은 언어에서 가지는 정보량적 강점은?",
    "options": [
      "데이터를 무조건 0으로 만들어서",
      "공백(Space)을 하나의 토큰으로 취급하여 띄어쓰기 정보가 소실되지 않도록 보존",
      "영어로 번역했다가 다시 복구하여",
      "파일 크기를 10배 늘려서"
    ],
    "answer": "공백(Space)을 하나의 토큰으로 취급하여 띄어쓰기 정보가 소실되지 않도록 보존",
    "why": "기존 방식은 띄어쓰기를 기준으로 단어를 쪼개버리지만, SentencePiece는 띄어쓰기 자체를 문자로 보므로 복원이 완벽합니다.",
    "hint": "공백을 특별 취급하지 않고 하나의 '부류'로 통합하는 방식에 주목하세요.",
    "trap_points": [
      "이는 띄어쓰기가 성능에 직결되는 한국어 의미 파악에 매우 유리함"
    ],
    "difficulty": "hard",
    "id": "0294"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM의 'KV Cache' 기술이 추론 시 연산 효율을 높이는 수리적 원리는?",
    "options": [
      "미래에 올 단어를 미리 검색해서",
      "이전 시점에서 계산된 Key와 Value 행렬 값을 메모리에 저장해두고, 다음 토큰 생성 시 중복 계산을 회피",
      "데이터를 압축해서",
      "CPU 대역폭을 늘려서"
    ],
    "answer": "이전 시점에서 계산된 Key와 Value 행렬 값을 메모리에 저장해두고, 다음 토큰 생성 시 중복 계산을 회피",
    "why": "매 단어 생성마다 문장 처음부터 다시 어텐션을 계산하는 것은 비효율적이므로, 과거 값들을 재사용합니다.",
    "hint": "이미 푼 수학 문제의 중간 과정을 기록해두고 쓰는 것과 같습니다.",
    "trap_points": [
      "대신 이 캐시 정보가 VRAM 용량을 많이 차지하여 긴 컨텍스트 지원의 병목이 됨"
    ],
    "difficulty": "hard",
    "id": "0295"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 서비스에서 'Streaming' 방식의 답변 출력이 가능한 근본적 이유는 LLM의 어떤 특성 때문인가?",
    "options": [
      "데이터가 인터넷을 통해 오기 때문",
      "모델이 한 번에 문장을 다 만드는 게 아니라, 토큰을 하나씩 순차적으로 예측(Autoregressive)하기 때문",
      "사용자가 기다리는 것을 싫어하기 때문",
      "파일 용량이 너무 커서"
    ],
    "answer": "모델이 한 번에 문장을 다 만드는 게 아니라, 토큰을 하나씩 순차적으로 예측(Autoregressive)하기 때문",
    "why": "LLM은 다음에 올 가장 확률 높은 단어 하나를 찍는 과정을 반복하므로 실시간 전달이 가능합니다.",
    "hint": "타자를 치는 것처럼 한 글자씩 생성되는 성질을 생각하세요.",
    "trap_points": [
      "전체 문장이 완성될 때까지 기다리지 않아도 되므로 사용자 경험 측면에서 매우 유리함"
    ],
    "difficulty": "easy",
    "id": "0296"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM이 '지능의 임계점'을 넘기 위해 필요한 세 가지 핵심 수치 요소가 아닌 것은?",
    "options": [
      "모델 파라미터 수 (크기)",
      "학습 데이터의 규모 (토큰 수)",
      "학습에 투입된 총 컴퓨팅 연산량 (FLOPs)",
      "데이터의 저장 매체 종류 (HDD vs SSD)"
    ],
    "answer": "데이터의 저장 매체 종류 (HDD vs SSD)",
    "why": "현대의 Scaling Law에 따르면 지능은 파라미터, 데이터셋, 연산량 세 가지 함수의 조합으로 결정됩니다.",
    "hint": "모델의 거대함(Scale)을 결정짓는 핵심 자원을 생각하세요.",
    "trap_points": [
      "이 세 요소 중 하나가 병목이 되면 지능 향상이 정체됨"
    ],
    "difficulty": "medium",
    "id": "0297"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머의 어텐션 연산을 수리적으로 최적화하여 연산 속도와 메모리 효율을 극대화한 알고리즘은?",
    "options": [
      "Flash Attention",
      "Quick Attention",
      "Fast Attention",
      "Rapid Attention"
    ],
    "answer": "Flash Attention",
    "why": "메모리 읽기/쓰기 횟수를 줄여 거대 모델의 추론과 학습 속도를 획기적으로 개선합니다.",
    "hint": "번쩍(Flash)이는 속도의 어텐션입니다.",
    "trap_points": [
      "현대적인 LLM 학습 환경에서 사실상의 표준임"
    ],
    "difficulty": "hard",
    "id": "0298"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM이 스스로 자신의 오류를 검토하고 교정하는 'Self-Correction' 능력을 높이기 위해 가장 효과적인 프롬프트 전략은?",
    "options": [
      "답변을 아주 길게 쓰라고 지시",
      "먼저 답변을 작성한 뒤, 그 답변에서 논리적 모순이나 사실 오류가 있는지 스스로 '비판(Critique)'하게 하고 최종 수정하도록 함",
      "질문을 모두 대문자로 작성",
      "답변 끝에 '감사합니다'를 붙이라고 함"
    ],
    "answer": "먼저 답변을 작성한 뒤, 그 답변에서 논리적 모순이나 사실 오류가 있는지 스스로 '비판(Critique)'하게 하고 최종 수정하도록 함",
    "why": "생성과 검증 작업을 분리함으로써 더 높은 수준의 정답에 도달하게 됩니다.",
    "hint": "자신의 글을 스스로 교정하는 워크플로우를 생각하세요.",
    "trap_points": [
      "이 전략은 추론 모델의 내부 동작 원리와 일맥상통함"
    ],
    "difficulty": "medium",
    "id": "0299"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "GPT-4o에서 'o'가 의미하는 단어와 그 개념으로 올바른 것은?",
    "options": [
      "Open: 지식이 개방됨",
      "Omni: 텍스트, 이미지, 오디오 등을 통합 처리하는 멀티모달",
      "Online: 실시간 웹 검색 지원",
      "Optimized: 속도가 최적화됨"
    ],
    "answer": "Omni: 텍스트, 이미지, 오디오 등을 통합 처리하는 멀티모달",
    "why": "Omni는 '모든'이라는 뜻으로, GPT-4o가 다양한 양식을 동시에 입력받고 출력할 수 있음을 의미합니다.",
    "hint": "다양한 매체를 '모두' 아우른다는 뜻입니다.",
    "trap_points": [
      "단순히 성능이 좋은 것과는 의미가 다름"
    ],
    "difficulty": "medium",
    "id": "0300"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "GPT-4o에서 'o'가 의미하는 단어와 그 개념으로 올바른 것은?",
    "options": [
      "Open: 지식이 개방됨",
      "Omni: 텍스트, 이미지, 오디오 등을 통합 처리하는 멀티모달",
      "Online: 실시간 웹 검색 지원",
      "Optimized: 속도가 최적화됨",
      "original: 초기 모델로의 회귀"
    ],
    "answer": "Omni: 텍스트, 이미지, 오디오 등을 통합 처리하는 멀티모달",
    "why": "Omni는 모든(All)이라는 뜻으로, GPT-4o가 다양한 양식(Modality)을 동시에 입력받고 출력할 수 있음을 의미합니다.",
    "hint": "다양한 매체를 '모두' 아우른다는 뜻입니다.",
    "trap_points": [
      "단순히 성능이 좋은 것(Optimized)과는 의미가 다름"
    ],
    "difficulty": "medium",
    "id": "0301"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "BERT(Encoder-only)가 문맥 파악을 위해 사용하는 'Masked Language Modeling(MLM)'이 GPT(Decoder-only)의 'Causal Language Modeling(CLM)'과 구별되는 수리적 결정타는?",
    "options": [
      "데이터를 무조건 0으로 만듦",
      "미래의 토큰 정보를 참조할 수 있는 양방향(Bidirectional) 어텐션 허용 여부",
      "영어를 한국어로 자동 번역함",
      "모델 파라미터 수를 2배로 늘림"
    ],
    "answer": "미래의 토큰 정보를 참조할 수 있는 양방향(Bidirectional) 어텐션 허용 여부",
    "why": "MLM은 문장 중간을 가리고 앞뒤 문맥을 모두 보지만, CLM은 미래를 가리고(Masked Self-Attention) 과거 정보만으로 다음 단어를 예측하는 생성에 특화되어 있습니다.",
    "hint": "시간의 흐름(인과관계)을 지키느냐, 전체 문맥을 한꺼번에 보느냐의 차이입니다.",
    "trap_points": [
      "이 차이 때문에 BERT는 요약이나 분류에, GPT는 텍스트 생성에 더 적합함"
    ],
    "difficulty": "hard",
    "id": "0302"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머의 'Positional Encoding'이 RNN의 은닉 상태(Hidden State)를 대체하여 문장의 순차적 구조를 처리하는 수리적 기법은?",
    "options": [
      "단어 벡터에 사인(Sine)과 코사인(Cosine) 기반의 고주파/저주파 값을 직접 가산(Addition)",
      "데이터를 섞어서 순서를 없앰",
      "모든 단어에 1부터 100까지 번호를 매김",
      "이미지 데이터를 텍스트에 섞음"
    ],
    "answer": "단어 벡터에 사인(Sine)과 코사인(Cosine) 기반의 고주파/저주파 값을 직접 가산(Addition)",
    "why": "사인/코사인파를 사용하면 모델이 상대적인 위치 관계를 선형 변환으로 쉽게 학습할 수 있으며, 학습 때 보지 못한 더 긴 문장에도 어느 정도 대응할 수 있는 외삽(Extrapolation) 유연성을 가집니다.",
    "hint": "각 위치마다 고유한 '지문'과 같은 주파수 값을 벡터에 더해줍니다.",
    "trap_points": [
      "더하거나 곱하는 방식에 따라 모델의 위치 인식 성능(RoPE 등)이 달라짐"
    ],
    "difficulty": "hard",
    "id": "0303"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM의 'Alignment' 성능을 평가하는 벤치마크셋(예: MBPP, HumanEval)에서 코드 생성 능력을 측정할 때 주로 사용되는 수리적 지표는?",
    "options": [
      "BLEU Score (텍스트 유사도)",
      "Pass@k (k개의 샘플 중 최소 하나가 테스트를 통과할 확률)",
      "Accuracy (단순 정확도)",
      "F1 Score"
    ],
    "answer": "Pass@k (k개의 샘플 중 최소 하나가 테스트를 통과할 확률)",
    "why": "코드는 텍스트 유사도보다 '실제로 작동하느냐'가 중요하므로, 여러 번 시도하여 실행 가능한 정답을 낼 확률을 측정하는 것이 더 정확한 성능 지표가 됩니다.",
    "hint": "실행(Pass) 가능한 결과가 몇 번(k) 안에 나오는지 확인하는 지표입니다.",
    "trap_points": [
      "일반 텍스트와 달리 코드는 한 글자만 틀려도 동작하지 않으므로 Pass@k가 사실상 표준임"
    ],
    "difficulty": "hard",
    "id": "0304"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 서비스에서 'System Prompt'에 '이전 대화 내용을 무시하라'는 사용자 명령이 먹히는 'Prompt Injection'을 방어하기 위한 구조적 접근법이 아닌 것은?",
    "options": [
      "사용자 입력 토큰의 탈옥(Jailbreak) 패턴을 탐지하는 전처리 분류기 도입",
      "시스템 메시지와 사용자 메시지를 명확히 구분하는 특수 구분자(Delimiter) 강화",
      "모델의 Temperature를 2.0 이상으로 높여 무작위성 극대화",
      "사용자 입력의 길이를 강제로 제한하고 특정 위험 키워드를 필터링"
    ],
    "answer": "모델의 Temperature를 2.0 이상으로 높여 무작위성 극대화",
    "why": "온도를 극한으로 높이면 모델이 횡설수설할 뿐 보안 공격을 막는 데는 하등 도움이 되지 않으며 오히려 예상치 못한 유해 출력을 유발할 수 있습니다.",
    "hint": "무작위성을 높이는 것이 보안 강화와 관련이 있는지 생각해보세요.",
    "trap_points": [
      "완벽한 방어는 불가능하며, 지속적인 레드티밍(Red Teaming)이 필요함"
    ],
    "difficulty": "medium",
    "id": "0305"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머의 'Self-Attention' 연산 시 발생하는 문장 길이(L)의 제곱(L^2) 복잡도 이슈를 해결하기 위해 'Sparse Attention'이 취하는 전략은?",
    "options": [
      "모든 단어끼리 다 비교하지 않고, 주변 혹은 특정 간격의 단어(Global/Local)하고만 어텐션 수행",
      "문장의 끝을 무조건 10자로 자름",
      "영어를 모두 숫자로 바꿈",
      "GPU의 전력을 2배로 늘림"
    ],
    "answer": "모든 단어끼리 다 비교하지 않고, 주변 혹은 특정 간격의 단어(Global/Local)하고만 어텐션 수행",
    "why": "희소 어텐션(Sparse Attention)은 모든 토큰 쌍을 계산하는 대신 중요도가 높은 부분만 선택적으로 계산하여, 계산량을 선형(Linear)에 가깝게 줄이는 기법입니다.",
    "hint": "빽빽한(Dense) 행렬을 드문드문하게(Sparse) 만드는 방식입니다.",
    "trap_points": [
      "이 방식은 연산 효율은 좋지만 아주 먼 거리의 정보 파악 능력은 약간 떨어질 수 있음"
    ],
    "difficulty": "hard",
    "id": "0306"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 학습의 'Scaling Law'가 시사하는 바 중, 단순 자본 투입만으로 성능 향상이 정체되는 임계점(Chinchilla Scaling)의 핵심 변수는?",
    "options": [
      "파라미터 수만 늘리는 것보다, 데이터셋의 규모(Quantity)와 품질(Quality)을 비례적으로 확장해야 함",
      "컴퓨터 모니터 크기를 키워야 함",
      "전력 공급량만 무한히 늘리면 됨",
      "영어를 더 많이 가르쳐야 함"
    ],
    "answer": "파라미터 수만 늘리는 것보다, 데이터셋의 규모(Quantity)와 품질(Quality)을 비례적으로 확장해야 함",
    "why": "친칠라(Chinchilla) 법칙에 따르면 파라미터 수에 비해 데이터 양이 부족하면 모델이 충분히 똑똑해지지 않으므로, 최적의 비중으로 함께 늘려야 합니다.",
    "hint": "거대한 뇌(파라미터)에 그에 맞는 방대한 책(데이터)이 필요하다는 논리입니다.",
    "trap_points": [
      "Llama 3와 같은 모델들은 이 법칙에서 권장하는 것보다 수 배 많은 데이터를 학습시켜 성능을 극대화함"
    ],
    "difficulty": "hard",
    "id": "0307"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM에서 '1억 개의 파라미터'보다 '1000억 개의 파라미터' 모델이 일반적으로 더 뛰어난 이유는?",
    "options": [
      "메모리를 많이 먹어서",
      "더 복잡한 논리 구조를 수용할 수 있는 고차원적인 지식 표현이 가능하기 때문",
      "글자 수가 더 많아서",
      "영어로만 답해서",
      "이름이 길어서"
    ],
    "answer": "더 복잡한 논리 구조를 수용할 수 있는 고차원적인 지식 표현이 가능하기 때문",
    "why": "더 많은 뉴런과 가중합이 가능해지면서 단순 암기를 넘어선 '추론' 능력이 발현(Emergence)됩니다.",
    "hint": "두뇌의 용량을 생각하세요.",
    "trap_points": [
      "파라미터가 많을수록 추론 비용(GPU)도 급증함"
    ],
    "difficulty": "medium",
    "id": "0308"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 아키텍처 중 'MoE(Mixture of Experts)'가 거대 파라미터수를 가지면서도 연산 비용을 아끼는 수리적 원리는?",
    "options": [
      "모든 파라미터를 사용하지 않고, 각 토큰마다 필요한 '전문가 레이어(Expert)' 몇 개만 활성화(Gating)하여 연산",
      "데이터를 절반으로 줄여서",
      "영상을 텍스트로 바꿔서",
      "GPU를 순차적으로 사용해서"
    ],
    "answer": "모든 파라미터를 사용하지 않고, 각 토큰마다 필요한 '전문가 레이어(Expert)' 몇 개만 활성화(Gating)하여 연산",
    "why": "MoE는 수 조 개의 파라미터를 가지더라도 실제 추론 시에는 입력에 맞는 소수의 가중치만 사용하므로 효율성과 성능을 동시에 잡을 수 있습니다.",
    "hint": "전문가(Experts)들이 각자 전공 분야에만 답변하는 도서관을 떠올리세요.",
    "trap_points": [
      "GPT-4나 Mixtral 같은 최신 거대 모델들이 이 MoE 구조를 선택함"
    ],
    "difficulty": "hard",
    "id": "0309"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머의 'Self-Attention' 연산 시 분산(Variance)이 커져 소프트맥스 계산이 한쪽으로 쏠리는 병목을 막기 위해 적용하는 상수는?",
    "options": [
      "헤드 차원의 제곱근(sqrt(d_k))",
      "시퀀스 길이(L)",
      "레이어 개수(N)",
      "배치 크기(B)"
    ],
    "answer": "헤드 차원의 제곱근(sqrt(d_k))",
    "why": "내적 값이 너무 커지면 소프트맥스 결과가 0이나 1에 치우쳐 기울기 소실이 발생하는데, 이를 차원의 크기에 맞춰 나눠줌으로써 학습을 안정화합니다.",
    "hint": "스케일드 닷 프로덕트(Scaled Dot-product)의 '스케일'을 조정하는 값입니다.",
    "trap_points": [
      "이 작은 스케일링 상수 하나가 트랜스포머 학습의 성패를 가름"
    ],
    "difficulty": "hard",
    "id": "0310"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM이 사전 학습(Pre-training) 때 보지 못한 새로운 컨셉을 지시문(Prompt)에서 즉석으로 배우는 능력을 무엇이라 하나요?",
    "options": [
      "In-Context Learning (ICL)",
      "Full Fine-Tuning",
      "Static Memory Indexing",
      "Transfer Learning"
    ],
    "answer": "In-Context Learning (ICL)",
    "why": "ICL은 모델 가중치를 수정하지 않고 오직 프롬프트 내부의 예시와 문맥만으로 작업을 수행하는 거대 모델의 창발적 능력입니다.",
    "hint": "문맥(Context) 내부(In)에서 학습한다는 뜻입니다.",
    "trap_points": [
      "Few-shot 프롬프팅이 ICL의 가장 대표적인 사례임"
    ],
    "difficulty": "medium",
    "id": "0311"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머의 'FFN' 레이어가 활성화 함수로 최근 주로 사용하는 'SwiGLU'가 기존 ReLU 대비 갖는 수리적 이점은?",
    "options": [
      "음수 영역에서도 부드러운 기울기를 가져 정보 손실을 막고 안정적으로 학습 가능",
      "결과를 무조건 정수로 바꿈",
      "연산 속도를 100배 늦춤",
      "이미지 데이터를 생성함"
    ],
    "answer": "음수 영역에서도 부드러운 기울기를 가져 정보 손실을 막고 안정적으로 학습 가능",
    "why": "SwiGLU는 게이팅 메커니즘을 결합하여 표현력을 높이면서도 기울기 소실을 억제해, 최신 언어 모델들의 필수 활성 함수로 자리 잡았습니다.",
    "hint": "기울기가 0으로 뚝 끊기지 않고 부드럽게 흐르는(Smooth) 곡선을 생각하세요.",
    "trap_points": [
      "Llama 2, 3 등 대부분의 최신 모델이 ReLU 대신 SwiGLU를 사용함"
    ],
    "difficulty": "hard",
    "id": "0312"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "모델의 파라미터가 70B일 때, 'FP16' 정밀도로 순수 가중치를 로드하기 위해 필요한 최소 VRAM과 그 계산 근거는?",
    "options": [
      "70GB (파라미터당 1바이트)",
      "140GB (700억개 * 2바이트)",
      "280GB (700억개 * 4바이트)",
      "35GB (700억개 * 0.5바이트)"
    ],
    "answer": "140GB (700억개 * 2바이트)",
    "why": "FP16 정밀도는 숫자 하나를 표현하는 데 16비트(2바이트)를 사용하므로, 700억 개의 매개변수를 담으려면 140GB의 메모리가 물리적으로 요구됩니다.",
    "hint": "비트(bit)를 바이트(byte)로 환산하여 곱해보세요.",
    "trap_points": [
      "추론 시에는 KV Cache 등 추가 메모리가 필요하므로 실제 요구량은 140GB보다 조금 더 큼"
    ],
    "difficulty": "medium",
    "id": "0313"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 이 사용자의 질문을 '에이전틱(Agentic)'하게 처리하기 위해 필요한 'Tool Use(Function Calling)'의 수리적 구동 원리는?",
    "options": [
      "모델이 직접 특정 소프트웨어를 실행",
      "사용자 질문을 분석해 외부 API 규격(JSON)에 맞는 인수를 생성하고, 실행 결과를 다시 문맥에 반영하여 최종 답변 도출",
      "모든 계산을 모델 내부의 가중치로만 해결",
      "질문을 단순히 요약하여 서버에 전달"
    ],
    "answer": "사용자 질문을 분석해 외부 API 규격(JSON)에 맞는 인수를 생성하고, 실행 결과를 다시 문맥에 반영하여 최종 답변 도출",
    "why": "모델은 스스로 외부 툴을 실행할 수 없으나, 실행에 필요한 명령서(JSON)를 완벽히 작성함으로써 에이전트 시스템을 구동하는 두뇌 역할을 합니다.",
    "hint": "질문에 답하기 위해 필요한 '도구(API)'를 적절히 호출하는 비서를 생각하세요.",
    "trap_points": [
      "함수 호출은 모델이 직접 하는 게 아니라 호출 '의도'를 규격화된 데이터로 뱉는 것임"
    ],
    "difficulty": "medium",
    "id": "0314"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 데이터를 임베딩하여 'Vector Database'에 저장할 때 사용하는 거리(Distance) 지표 중, 벡터의 크기보다 '방향'의 유사성을 측정하는 방식은?",
    "options": [
      "Euclidean Distance (유클리드 거리)",
      "Cosine Similarity (코사인 유사도)",
      "Manhattan Distance (맨해튼 거리)",
      "Hamming Distance"
    ],
    "answer": "Cosine Similarity (코사인 유사도)",
    "why": "코사인 유사도는 두 벡터 사이의 각도를 측정하므로, 텍스트의 길이나 강도보다 순수한 '의미적 함축성'을 비교하는 데 최적화되어 있습니다.",
    "hint": "두 화살표가 가리키는 방향이 얼마나 일치하는지 각도를 잽니다.",
    "trap_points": [
      "대부분의 RAG 시스템에서 문서 검색의 기본 지표로 코사인 유사도를 사용함"
    ],
    "difficulty": "medium",
    "id": "0315"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "GPT-4o와 같은 멀티모달 모델에서 텍스트와 이미지 데이터를 단일 신경망으로 동시에 처리하는 'Native Multimodal' 방식이 'Late Fusion' 대비 갖는 우위는?",
    "options": [
      "이미지를 텍스트 캡션으로 무조건 바꿔야 함",
      "서로 다른 양식(Modality) 사이의 상관관계를 토큰 단위에서 직접 상호작용(Attention) 시켜 정보 손실 최소화",
      "연산 속도가 100배 느려짐",
      "파일 용량만 커짐"
    ],
    "answer": "서로 다른 양식(Modality) 사이의 상관관계를 토큰 단위에서 직접 상호작용(Attention) 시켜 정보 손실 최소화",
    "why": "나중에 결과를 합치는 Late Fusion과 달리, Native 방식은 처음부터 모든 종류의 토큰을 어텐션 층에서 동등하게 처리하여 추론 능력을 극대화합니다.",
    "hint": "각각 해석한 뒤 합치는 것과, 눈과 귀를 동시에 열고 인지하는 것의 차이입니다.",
    "trap_points": [
      "이 구조 덕분에 시각적 단서와 텍스트 맥락의 정교한 결합이 가능함"
    ],
    "difficulty": "hard",
    "id": "0316"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM의 'Alignment' 작업을 수행할 때, 모델이 '예, 알겠습니다' 같은 짧은 수긍만 반복하거나 거절이 잦아지는 현상을 부르는 용어는?",
    "options": [
      "Over-optimization (과적합)",
      "Reward Hacking (보상 해킹)",
      "Mode Collapse (모드 붕괴)",
      "Vanishing Gradient"
    ],
    "answer": "Reward Hacking (보상 해킹)",
    "why": "강화학습 시 높은 점수를 얻기 위해, 모델이 실제 의도인 '유익성'을 기르기보다 점수가 잘 나오는 특정 패턴에만 집착하는 현상입니다.",
    "hint": "점수(Reward)를 잘 받으려 꼼수를 부리는(Hacking) 상태입니다.",
    "trap_points": [
      "이를 막기 위해 보상 모델을 정교하게 설계하거나 KL Divergence 제약 조건을 사용함"
    ],
    "difficulty": "hard",
    "id": "0317"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM의 출력 확률 분포에서 'Temperature' 값을 2.0 이상 아주 높게 설정했을 때 나타나는 현상은?",
    "options": [
      "가장 확률 높은 단어만 확실하게 선택함",
      "확률 분포가 평탄하게 퍼지며(Flatten), 논리적이기보다 무작위적이고 창의적(혹은 무의미한) 단어가 선택될 확률이 급증함",
      "연산 속도가 빨라짐",
      "답변이 무조건 짧아짐"
    ],
    "answer": "확률 분포가 평탄하게 퍼지며(Flatten), 논리적이기보다 무작위적이고 창의적(혹은 무의미한) 단어가 선택될 확률이 급증함",
    "why": "온도가 높을수록 확률 값이 균일해져 선택의 폭은 넓어지지만, 그만큼 '틀린' 단어를 고를 확률도 높아져 논리가 붕괴됩니다.",
    "hint": "열기가 높아져 분자들이 무작위로 날뛰는 현상에 비유해보세요.",
    "trap_points": [
      "반대로 온도가 0이 되면 확률 최상위 단어만 고르는 결정론적 답변을 함"
    ],
    "difficulty": "medium",
    "id": "0318"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM을 소형 디바이스(온디바이스 AI)에 탑재하기 위해 거대 모델의 지식을 작은 모델에 전수하는 기술은?",
    "options": [
      "Knowledge Distillation (지식 증류)",
      "Model Parallelism",
      "Static Embedding",
      "Batch Normalization"
    ],
    "answer": "Knowledge Distillation (지식 증류)",
    "why": "거물 모델(Teacher)의 출력 확률 분포를 작은 모델(Student)이 흉내 내게 함으로써, 적은 파라미터로도 교사의 성능을 최대한 이끌어냅니다.",
    "hint": "액체의 정수만을 걸러내어(Distill) 전달하는 방식을 생각하세요.",
    "trap_points": [
      "증류된 모델은 빠르지만 교사가 모르는 것을 스스로 깨우치기는 어려움"
    ],
    "difficulty": "medium",
    "id": "0319"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "최신 추론 특화 LLM(예: OpenAI o1)이 정답 도출 시간을 늘리며 성능을 높이는 'Test-Time Compute'의 핵심 원리는?",
    "options": [
      "학습 데이터를 2배로 늘림",
      "추론 시점에 모델이 내부적으로 여러 추론 경로(Thinking)를 생성하고 검증하며 더 많은 연산 자원을 소모하여 정밀도 향상",
      "답변 글자 수를 무조건 제한함",
      "영어를 외국어로 자동 번역"
    ],
    "answer": "추론 시점에 모델이 내부적으로 여러 추론 경로(Thinking)를 생성하고 검증하며 더 많은 연산 자원을 소모하여 정밀도 향상",
    "why": "단순한 확률 예측을 넘어, 답변을 내기 직전에 스스로 생각하는 시간을 가짐으로써 복잡한 수학과 논리 문제를 해결합니다.",
    "hint": "시험을 칠 때 문제를 빨리 푸는 것보다 '검토 시간'을 더 갖는 것에 비유할 수 있습니다.",
    "trap_points": [
      "이 방식은 추론 비용(Latency)은 높아지지만 지능의 한계를 돌파하는 핵심 기술임"
    ],
    "difficulty": "hard",
    "id": "0320"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "지식을 저장하는 모델의 '파라미터'와 RAG(Retrieval-Augmented Generation) 시스템의 역할을 기술적으로 구분할 때 가장 정확한 것은?",
    "options": [
      "파라미터는 하드웨어이고 RAG는 소프트웨어이다.",
      "파라미터는 '암기된 일반 지식(Parametric Memory)'이며, RAG은 '실시간 참조 외부 지식(Non-parametric Memory)'이다.",
      "파라미터가 많으면 RAG는 필요하지 않다.",
      "RAG은 모델의 가중치를 실시간으로 수정한다."
    ],
    "answer": "파라미터는 '암기된 일반 지식(Parametric Memory)'이며, RAG은 '실시간 참조 외부 지식(Non-parametric Memory)'이다.",
    "why": "파라미터는 학습 시 고정된 신경망 내부의 지식이지만, RAG은 외부 데이터베이스에서 검색해와 문맥으로 넣어주는 유동적인 정보입니다.",
    "hint": "모델의 뇌에 든 생각과, 모델이 보고 있는 참고서의 차이입니다.",
    "trap_points": [
      "RAG은 최신성(Recency)을 보완하지만, 모델의 고유한 추론 패턴(Logic) 자체를 바꾸지는 못함"
    ],
    "difficulty": "hard",
    "id": "0321"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 학습의 'Scaling Law'가 제시하는 성능 향상의 3대 핵심 요소가 아닌 것은?",
    "options": [
      "모델 파라미터 수 (N)",
      "데이터셋의 토큰 수 (D)",
      "학습에 투입된 연산량 (C)",
      "사용자 인터페이스의 미려함 (U)"
    ],
    "answer": "사용자 인터페이스의 미려함 (U)",
    "why": "스케일링 법칙은 모델의 내재적 지능(Loss)이 N, D, C라는 물리적 자원에 따라 멱함수(Power Law)로 예측 가능함을 보여줍니다.",
    "hint": "모델을 만드는 데 들어가는 '물리적 자원'들을 생각하세요.",
    "trap_points": [
      "최근에는 단순히 양만 늘리는 것이 아니라 데이터의 질(Quality)이 스케일링 효율을 압도한다는 연구가 많음"
    ],
    "difficulty": "medium",
    "id": "0322"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머의 'Self-Attention' 행렬에서 Softmax를 취하기 직전, 'Masking'을 수행하는 결정적인 이유는?",
    "options": [
      "데이터 크기를 줄이기 위해",
      "학습 시 생성 모델이 미래의 단어를 미리 보고 정답을 가늠하는 'Cheating'을 방지하기 위해",
      "영문법에 맞지 않는 단어를 삭제하기 위해",
      "VRAM 성능을 억지로 높이기 위해"
    ],
    "answer": "학습 시 생성 모델이 미래의 단어를 미리 보고 정답을 가늠하는 'Cheating'을 방지하기 위해",
    "why": "디코더는 다음 단어를 예측해야 하므로, 현재 위치 이후의 모든 단어들에 대한 가시성을 차단(Causal Masking)해야 합니다.",
    "hint": "시험을 볼 때 뒷장의 정답지를 미리 보지 못하게 가리는 판을 생각하세요.",
    "trap_points": [
      "BERT 같은 인코더 모델은 양방향 문맥을 다 봐야 하므로 이 마스킹을 사용하지 않음"
    ],
    "difficulty": "hard",
    "id": "0323"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM의 'Reasoning' 과정에서 발생하는 'Error Cascade' 현상을 방지하기 위해 가장 효과적인 기법은?",
    "options": [
      "답변 글자 수를 무조건 줄임",
      "Self-Correction(자기 교정) 루프를 통해 중간 추론 단계를 비판적으로 재검토",
      "영어로만 질문하게 강제",
      "GPU 서버의 전압을 일정하게 유지"
    ],
    "answer": "Self-Correction(자기 교정) 루프를 통해 중간 추론 단계를 비판적으로 재검토",
    "why": "한 번의 실수가 뒤따르는 모든 논리를 붕괴시키는(Cascade) 것을 막기 위해, 각 단계의 타당성을 모델이 스스로 점검하는 프로세스가 필수적입니다.",
    "hint": "잘못된 길로 들어섰을 때 즉시 되돌아보는 능력을 생각하세요.",
    "trap_points": [
      "모델이 자신의 오류를 정확히 인지하지 못할 경우, 오히려 잘못된 방향으로 교정하는 '환각의 연쇄'가 일어날 수 있음"
    ],
    "difficulty": "hard",
    "id": "0324"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "거대 모델의 학습 효율을 높이기 위해 그레디언트, 모멘텀, 파라미터를 GPU 메모리 전체에 분산 저장하는 기법은?",
    "options": [
      "Mixed Precision Training",
      "ZeRO (Zero Redundancy Optimizer)",
      "Batch Normalization",
      "Stochastic Gradient Descent"
    ],
    "answer": "ZeRO (Zero Redundancy Optimizer)",
    "why": "ZeRO는 각 GPU가 중복된 정보를 가지지 않게 데이터를 쪼개어 분산함으로써, 단일 GPU 용량을 초과하는 거대 모델 학습을 가능케 합니다.",
    "hint": "데이터 중복(Redundancy)을 제로(Zero)로 만든다는 이름의 뜻을 생각하세요.",
    "trap_points": [
      "ZeRO-3 단계까지 가면 모델 파라미터 자체를 완전히 파티셔닝하여 저장함"
    ],
    "difficulty": "hard",
    "id": "0325"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 프롬프트 기법 중 'Chain-of-Verification (CoVe)'의 주된 목적은?",
    "options": [
      "답변 속도를 획기적으로 빠르게 함",
      "생성된 답변에서 사실 관계의 오류를 스스로 질문하고 검증하여 할루시네이션을 최소화",
      "단어 개수를 일정하게 맞춤",
      "사용자 이메일 주소를 수집"
    ],
    "answer": "생성된 답변에서 사실 관계의 오류를 스스로 질문하고 검증하여 할루시네이션을 최소화",
    "why": "초안 답안에서 주요 사실을 추출하고, 이에 대해 스스로 반문하여 모순을 찾아내는 다단계 검증 시스템입니다.",
    "hint": "답변을 낸 뒤 '정말 맞아?'라고 스스로 검증(Verification)하는 사슬입니다.",
    "trap_points": [
      "추론 토큰이 많이 소모되지만 신뢰도가 중요한 도메인에서는 필수적임"
    ],
    "difficulty": "hard",
    "id": "0326"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM이 특정 도메인에 특화되도록 파인튜닝할 때, 전체 가중치가 아닌 '저차원의 행렬(A, B)'만 학습시켜 효율을 높이는 기법은?",
    "options": [
      "Full Fine-Tuning",
      "LoRA (Low-Rank Adaptation)",
      "Adapter Tuning",
      "Prompt Tuning"
    ],
    "answer": "LoRA (Low-Rank Adaptation)",
    "why": "가중치의 변화량을 아주 작은 크기의 두 행렬 곱으로 근사하여, 학습 파라미터 수를 1,000배 이상 줄이면서도 성능을 유지하는 기술입니다.",
    "hint": "랭크(Rank)를 낮게(Low) 조절하여(Adaptation) 효율을 잡습니다.",
    "trap_points": [
      "LoRA는 전체 파인튜닝 대비 VRAM 사용량을 획기적으로 낮춰줌"
    ],
    "difficulty": "medium",
    "id": "0327"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 서비스에서 'KV Cache'를 사용하는 기술적 이유는?",
    "options": [
      "보안 강화를 위해",
      "이전 토큰의 Key, Value 연산 결과를 재사용하여 생성 시 매번 중복 계산되는 어텐션 연산 부하를 제거하고 속도 향상",
      "데이터 용량을 줄이기 위해",
      "사용자 정보를 저장하기 위해"
    ],
    "answer": "이전 토큰의 Key, Value 연산 결과를 재사용하여 생성 시 매번 중복 계산되는 어텐션 연산 부하를 제거하고 속도 향상",
    "why": "자기회귀 모델은 매번 처음부터 다시 계산해야 하지만, 변하지 않는 과거 단어의 핵심 벡터를 캐싱해두면 추론 속도가 압도적으로 빨라집니다.",
    "hint": "매번 똑같은 계산을 반복하지 않기 위해 결과를 적어두는 메모지입니다.",
    "trap_points": [
      "KV Cache는 답변이 길어질수록 VRAM을 매우 많이 소모하는 주범이기도 함"
    ],
    "difficulty": "hard",
    "id": "0328"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머의 'Encoder'와 'Decoder' 아키텍처의 결정적 차이점이 아닌 것은?",
    "options": [
      "전체 문맥을 한 번에 보느냐(Encoder), 순차적으로 보느냐(Decoder)",
      "미래 단어를 가리는 Masking 사용 여부",
      "신경망 레이어의 개수를 조절할 수 있는지 여부",
      "양방향(Bidirectional) 어텐션의 허용 여부"
    ],
    "answer": "신경망 레이어의 개수를 조절할 수 있는지 여부",
    "why": "레이어 개수(Depth) 조절은 두 아키텍처 모두 가능하며, 결정적 차이는 정보 접근의 방향성과 마스킹 메커니즘에 있습니다.",
    "hint": "두 구조 모두 '깊이'는 자유롭게 설계할 수 있습니다.",
    "trap_points": [
      "T5 같은 모델은 인코더와 디코더를 모두 사용하여 각각의 장점을 활용함"
    ],
    "difficulty": "medium",
    "id": "0329"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 학습 데이터에서 'Data Contamination (데이터 오염)'이 심각한 기술적 이슈가 되는 이유는?",
    "options": [
      "데이터 용량이 너무 커서",
      "성능 측정용 테스트셋(벤치마크)이 학습 데이터에 포함되어, 모델의 실제 능력이 부풀려지는 현상 때문",
      "데이터가 모두 영어로만 되어 있어서",
      "비속어가 섞여 있어서"
    ],
    "answer": "성능 측정용 테스트셋(벤치마크)이 학습 데이터에 포함되어, 모델의 실제 능력이 부풀려지는 현상 때문",
    "why": "모델이 문제를 푼 것이 아니라 답을 외워버린 것이 되어, 새로운 실제 응용 환경에서는 성능이 급락할 위험이 큽니다.",
    "hint": "시험을 치기 전에 시험지 문제를 미리 보고 공부한 상황을 생각하세요.",
    "trap_points": [
      "이를 막기 위해 최근에는 더 어려운 창의적 논리 벤치마크(Big-Bench 등)가 도입됨"
    ],
    "difficulty": "hard",
    "id": "0330"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 아키텍처 중 'GQA (Grouped-Query Attention)'가 Multi-Head Attention 대비 갖는 최적화 이점은?",
    "options": [
      "정확도를 100배 높임",
      "여러 개의 Query 헤드가 소수의 Key, Value 헤드를 공유하도록 설계하여 추론 시 KV Cache 메모리 효율을 극대화",
      "데이터를 삭제함",
      " GPU 사용을 중단함"
    ],
    "answer": "여러 개의 Query 헤드가 소수의 Key, Value 헤드를 공유하도록 설계하여 추론 시 KV Cache 메모리 효율을 극대화",
    "why": "전체 캐시 크기를 대폭 줄이면서도 성능 손실은 미미하게 유지하여, 더 긴 문맥(Context)을 저비용으로 처리할 수 있게 합니다.",
    "hint": "데이터를 재활용하여 메모리 공간(KV Cache)을 아끼는 방식입니다.",
    "trap_points": [
      "Llama 3 등 최근의 효율적인 공개 모델들이 이 GQA 구조를 핵심으로 삼음"
    ],
    "difficulty": "hard",
    "id": "0331"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM의 'Token limit (컨텍스트 길이)'을 결정하는 가장 물리적인 제약 사항은?",
    "options": [
      "컴퓨터 CPU 속도",
      "GPU의 VRAM 용량",
      "네트워크 대역폭",
      "키보드 타자 실력"
    ],
    "answer": "GPU의 VRAM 용량",
    "why": "어텐션 연산 시 발생하는 행렬 데이터와 KV Cache가 메모리에 올라가야 하므로 VRAM이 클수록 긴 문장을 처리할 수 있습니다.",
    "hint": "그래픽 카드의 메모리입니다.",
    "trap_points": [
      "최근에는 메모리를 아끼는 어텐션 기술(Flash Attention 등)로 한계가 늘어남"
    ],
    "difficulty": "medium",
    "id": "0332"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "모델이 이미 한 번 했던 실수를 자신의 메모리에서 읽어와 반복하지 않으려 노력하는 '성찰(Reflection)' 능력은 주로 어느 단계에서 강화되는가?",
    "options": [
      "Pre-training",
      "SFT 및 RLHF를 통한 Alignment 단계",
      "데이터 수집 단계",
      "하드웨어 조립 단계"
    ],
    "answer": "SFT 및 RLHF를 통한 Alignment 단계",
    "why": "자신의 과거 행동을 평가하고 교정하는 고도화된 AI의 특성은 사양 교육과 강화 학습을 통해 집중적으로 학습됩니다.",
    "hint": "모델의 성품과 태도를 결정하는(Alignment) 단계입니다.",
    "trap_points": [
      "최신 추론 모델들이 이 능력을 극대화하고 있음"
    ],
    "difficulty": "medium",
    "id": "0333"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머 기반 모델 중 인코더만 사용하는 BERT가 GPT 대비 압도적으로 유리한 태스크는?",
    "options": [
      "창의적 시 쓰기",
      "문장 내 단어 분류(Named Entity Recognition) 및 문맥 기반 문장 임베딩 추출",
      "사용자와의 연속적인 대화 생성",
      "코드 자동 완성"
    ],
    "answer": "문장 내 단어 분류(Named Entity Recognition) 및 문맥 기반 문장 임베딩 추출",
    "why": "양방향(Bidirectional)으로 문장을 읽어 단어의 전후 맥락을 동시에 파악하므로 분류와 이해에 특화되어 있습니다.",
    "hint": "양방향(B) 정보 처리에 강점이 있습니다.",
    "trap_points": [
      "생성(Generation) 능력은 순차적으로 예측하는 GPT에 집중되어 있음"
    ],
    "difficulty": "easy",
    "id": "0334"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM이 인터넷에 노출되지 않은 최신 정보나 비공개 데이터를 아는 것처럼 답하게 하는 기술인 RAG의 핵심 원리는?",
    "options": [
      "Fine-tuning",
      "외부 지식 저장소에서 관련 문서를 검색(Retrieval)하여 프롬프트의 문맥으로 주입",
      "Zero-shot 프롬프팅",
      "Beam Search"
    ],
    "answer": "외부 지식 저장소에서 관련 문서를 검색(Retrieval)하여 프롬프트의 문맥으로 주입",
    "why": "모델의 내재된 지능을 쓰되, 실시간 정보는 외부에서 찾아와 '오픈 북' 시험을 치게 만드는 방식입니다.",
    "hint": "검색 증강(Retrieval-Augmented) 생성입니다.",
    "trap_points": [
      "지식 컷오프(Knowledge Cut-off) 문제를 해결하는 가장 실질적인 해법임"
    ],
    "difficulty": "easy",
    "id": "0335"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "임베딩 공간(Embedding Space)에서 두 문장의 '의미적 유사도'를 계산할 때 가장 표준적으로 사용하는 수식은?",
    "options": [
      "단순 덧셈",
      "코사인 유사도 (Cosine Similarity)",
      "로그 함수",
      "곱셈"
    ],
    "answer": "코사인 유사도 (Cosine Similarity)",
    "why": "벡터의 크기가 아닌 방향성을 기준으로 유사도를 측정하여, 문맥적 유사성을 가장 잘 포착하는 지표로 쓰입니다.",
    "hint": "두 벡터 사이의 각도(Cosine)를 측정합니다.",
    "trap_points": [
      "RAG의 Vector Search 단계에서 가장 핵심적인 연산임"
    ],
    "difficulty": "medium",
    "id": "0336"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "거대 언어 모델이 일정 규모(Scale)를 넘어섰을 때, 점진적인 성능 향상을 넘어 새로운 능력이 폭발하는 현상은?",
    "options": [
      "Emergent Properties (발현적 특성)",
      "Gradient Descent",
      "Batch Processing",
      "Data Augmentation"
    ],
    "answer": "Emergent Properties (발현적 특성)",
    "why": "모델의 파라미터와 데이터가 임계점(Threshold)을 넘기면, 이전에는 불가능했던 복합 추론 능력이 창발적으로 나타납니다.",
    "hint": "갑자기 나타나는(Emergent) 성질입니다.",
    "trap_points": [
      "스케일링 법칙(Scaling Law)의 핵심 관찰 포인트 중 하나임"
    ],
    "difficulty": "hard",
    "id": "0337"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM 서비스 운영 시 가중치 파일을 압축하여 GPU VRAM 비용을 절감하는 '양자화(Quantization)'의 부작용은?",
    "options": [
      "모델 성능(Perplexity)의 미세한 하락 또는 논리적 정밀도 저하 가능성",
      "추론 속도가 느려짐",
      "파일 용량이 늘어남",
      "영어를 외국어로 번역함"
    ],
    "answer": "모델 성능(Perplexity)의 미세한 하락 또는 논리적 정밀도 저하 가능성",
    "why": "실수 정보를 저비트로 압축하는 과정에서 표현력의 일부 손실이 발생할 수밖에 없습니다.",
    "hint": "정보를 줄이면 정밀도는 어떻게 될까요?",
    "trap_points": [
      "최근 AWQ, GGUF 등 고도화된 기법들은 이 성능 하락을 극도로 최소화함"
    ],
    "difficulty": "medium",
    "id": "0338"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "LLM이 답변 생성 시 스스로 질문을 던져 답변의 모순을 찾거나 논리를 보완하는 'Chain of Thought'의 심화 버전은?",
    "options": [
      "Beam Search",
      "Self-Correction (자기 교정)",
      "Formatting",
      "Tokenizing"
    ],
    "answer": "Self-Correction (자기 교정)",
    "why": "모델이 내놓은 초안을 스스로 비판적으로 검토하고 수정함으로써 최종 답변의 신뢰도를 높입니다.",
    "hint": "스스로(Self) 고친다(Correction)는 뜻입니다.",
    "trap_points": [
      "o1 같은 최신 모델들이 내부 루프로 이 과정을 수행함"
    ],
    "difficulty": "hard",
    "id": "0339"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "객관식",
    "question": "트랜스포머의 'Self-Attention' 연산 시, 한 토큰이 나머지 모든 토큰과의 관계를 계산할 때 발생하는 연산 복잡도는?",
    "options": [
      "O(N)",
      "O(N^2)",
      "O(log N)",
      "O(1)"
    ],
    "answer": "O(N^2)",
    "why": "입력 문장 길이(N)의 제곱에 비례하여 연산량이 늘어나는 특성 때문에, 매우 긴 문장 처리에 병목이 발생합니다.",
    "hint": "모든 토큰이 서로서로(All-to-All) 어텐션을 계산합니다.",
    "trap_points": [
      "이 복잡도를 극복하기 위해 GQA, Sliding Window Attention 등이 개발됨"
    ],
    "difficulty": "hard",
    "id": "0340"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "HuggingFace의 `transformers` 라이브러리를 사용하여 사전 학습된 토크나이저를 로드할 때 사용하는 메서드를 작성하세요.\n\n```python\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.____(\"bert-base-uncased\")\n```",
    "options": [],
    "answer": "from_pretrained",
    "why": "from_pretrained()는 모델 허브에서 설정값과 가중치를 자동으로 다운로드하여 로드하는 표준 메서드입니다.",
    "difficulty": "easy",
    "id": "0341"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "LLM의 출력에서 무작위성을 제어하기 위해 `generate` 메서드 내에서 사용하는 파라미터 명칭을 작성하세요.\n\n```python\n# 답변의 창의성 조절\noutputs = model.generate(inputs, ____=0.7, do_sample=True)\n```",
    "options": [],
    "answer": "temperature",
    "why": "temperature는 확률 분포를 조절하여 결과의 다양성을 결정하는 핵심 하이퍼파라미터입니다.",
    "difficulty": "easy",
    "id": "0342"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "로짓(Logits) 값을 확률 분포로 바꿀 때, 온도(T)를 적용하는 수식을 완성하세요.\n\n```python\n# logits를 T로 나눈 뒤 소프트맥스 계산\nprobs = torch.nn.functional.softmax(logits / ____, dim=-1)\n```",
    "options": [],
    "answer": "T",
    "why": "로짓을 온도 T로 나누어 스케일링함으로써 확률값의 분포가 얼마나 평탄하거나 뾰족할지를 결정합니다.",
    "difficulty": "medium",
    "id": "0343"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "PEFT 라이브러리에서 LoRA 설정을 정의할 때, 저차원 행렬의 크기(Rank)를 지정하는 파라미터를 작성하세요.\n\n```python\nfrom peft import LoraConfig\nconfig = LoraConfig(____=8, lora_alpha=32)\n```",
    "options": [],
    "answer": "r",
    "why": "r은 Low-Rank Adaptation의 핵심인 랭크(Rank) 크기를 결정하며, 학습할 파라미터 양을 조절합니다.",
    "difficulty": "medium",
    "id": "0344"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "모델을 4비트로 양자화하여 메모리를 아껴 로드하기 위한 설정 클래스의 명칭을 완성하세요.\n\n```python\nfrom transformers import ____Config\nquant_config = ____Config(load_in_4bit=True)\n```",
    "options": [],
    "answer": "BitsAndBytes",
    "why": "BitsAndBytesConfig는 8비트/4비트 양자화 로딩을 지원하여 거대 모델을 저사양 GPU에서 돌릴 수 있게 합니다.",
    "difficulty": "medium",
    "id": "0345"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "누적 확률이 특정 임계치를 넘는 토큰들만 샘플링 후보로 두는 기법의 파라미터 명칭을 작성하세요.\n\n```python\n# 상위 90% 확률 구간만 고려\noutputs = model.generate(inputs, ____=0.9, do_sample=True)\n```",
    "options": [],
    "answer": "top_p",
    "why": "top_p(Nucleus Sampling)는 확률 분포의 꼬리 부분을 자르고 유의미한 후보들 중에서만 단어를 고르게 합니다.",
    "difficulty": "hard",
    "id": "0346"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "어텐션 메커니즘에서 쿼리(Q)와 키(K)의 유사도를 구하기 위한 행렬 연산 기호를 작성하세요.\n\n```python\n# 어텐션 스코어 계산 (scaled dot-product)\nscores = torch.matmul(Q, K.____) / math.sqrt(d_k)\n```",
    "options": [],
    "answer": "transpose(-2, -1)",
    "why": "두 벡터의 내적(Dot product)을 구하기 위해 행렬 뒷부분의 차원을 전치(Transpose)하여 곱해야 합니다.",
    "difficulty": "hard",
    "id": "0347"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "파이토치에서 모델을 GPU(NVIDIA) 장치로 옮기기 위해 사용하는 문자열을 작성하세요.\n\n```python\ndevice = \"____\"\nmodel.to(device)\n```",
    "options": [],
    "answer": "cuda",
    "why": "cuda는 NVIDIA GPU 가속을 사용하기 위한 표준 장치 식별자입니다.",
    "difficulty": "easy",
    "id": "0348"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "토크나이저에서 문장 길이를 맞추기 위해 사용되는 특수 토큰의 ID를 확인하는 속성을 작성하세요.\n\n```python\nprint(tokenizer._____id)\n```",
    "options": [],
    "answer": "pad_token",
    "why": "pad_token_id는 짧은 문장 뒤에 채워지는 의미 없는 토큰의 고유 번호를 나타냅니다.",
    "difficulty": "easy",
    "id": "0349"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "정수 형태의 토큰 ID를 연속적인 벡터 값으로 변환하는 파이토치 레이어의 명칭을 작성하세요.\n\n```python\nimport torch.nn as nn\nlayer = nn.____(vocab_size, hidden_dim)\n```",
    "options": [],
    "answer": "Embedding",
    "why": "Embedding 레이어는 이산적인 토큰을 모델이 처리할 수 있는 고차원 벡터 평면으로 사영시킵니다.",
    "difficulty": "medium",
    "id": "0350"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "프롬프트 템플릿에서 동적으로 변수를 채워 넣기 위해 일반적으로 사용하는 괄호 형식을 작성하세요.\n\n```python\ntemplate = \"당신은 전문가입니다. 다음 {____}에 대해 답변하세요.\"\n```",
    "options": [],
    "answer": "topic",
    "why": "파이썬의 f-string이나 다양한 프롬프트 라이브러리에서 변수명(예: topic)을 중괄호로 감싸 템플릿을 구성합니다.",
    "difficulty": "easy",
    "id": "0351"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "두 임베딩 벡터 사이의 코사인 유사도를 계산하기 위해 사용하는 함수 명칭을 완성하세요.\n\n```python\nsim = torch.nn.functional.____(vec1, vec2)\n```",
    "options": [],
    "answer": "cosine_similarity",
    "why": "cosine_similarity()는 벡터의 방향 대조를 통해 의미적 유사도를 -1 ~ 1 사이의 값으로 산출합니다.",
    "difficulty": "medium",
    "id": "0352"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "디코더에서 미래 단어를 가리기 위해 상삼각 행렬(Upper triangular matrix)을 생성하는 넘파이/파이토치 함수를 작성하세요.\n\n```python\n# 주대각선 위쪽을 True로 만드는 마스크\nmask = torch.____(torch.ones(L, L), diagonal=1)\n```",
    "options": [],
    "answer": "triu",
    "why": "triu()는 주어진 행렬의 상삼각 부분을 추출하여 어텐션 마스킹의 기초 구조를 만듭니다.",
    "difficulty": "hard",
    "id": "0353"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "벡터 데이터를 인덱싱하고 빠르게 검색하기 위해 널리 쓰이는 라이브러리 `faiss`에서 검색을 실행하는 메서드를 작성하세요.\n\n```python\nimport faiss\nindex = faiss.IndexFlatL2(d)\ndists, ann = index.____(query_vectors, k=5)\n```",
    "options": [],
    "answer": "search",
    "why": "search()는 입력 쿼리 벡터와 가장 유사한 k개의 문서를 고차원 공간에서 효율적으로 찾아냅니다.",
    "difficulty": "medium",
    "id": "0354"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "구성된 랭체인(LangChain) 객체를 실행하여 답변을 얻기 위해 호출하는 메서드를 작성하세요.\n\n```python\nchain = prompt | model\nresponse = chain.____({\"question\": \"LLM이란?\"})\n```",
    "options": [],
    "answer": "invoke",
    "why": "invoke()는 현대적인 랭체인(LCEL) 구조에서 실행을 담당하는 표준 인터페이스 메서드입니다.",
    "difficulty": "easy",
    "id": "0355"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "RLHF에서 정책 모델과 참조 모델 사이의 확률 분포 차이를 계산하는 지표 명칭을 완성하세요.\n\n```python\n# 분포의 소실(Divergence) 계산\nloss = torch.nn.functional._____loss(log_p, p)\n```",
    "options": [],
    "answer": "kl_div",
    "why": "kl_div(Kullback-Leibler divergence)는 두 확률 분포가 얼마나 다른지 측정하여 학습의 안정성을 유지하는 손실 값으로 쓰입니다.",
    "difficulty": "hard",
    "id": "0356"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "LoRA를 적용할 특정 신경망 레이어(예: q_proj, v_proj)를 리스트 형태로 지정하는 설정 파라미터를 작성하세요.\n\n```python\nconfig = LoraConfig(____=[\"q_proj\", \"v_proj\"])\n```",
    "options": [],
    "answer": "target_modules",
    "why": "target_modules는 모델의 전체 레이어 중 어느 부분에 LoRA 어댑터를 붙일지 결정하는 중요한 설정값입니다.",
    "difficulty": "medium",
    "id": "0357"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "생성 시 빔 서치(Beam Search)를 활성화하고 탐색할 경로의 개수를 지정하는 파라미터를 작성하세요.\n\n```python\n# 5개의 경로를 동시 탐색\noutputs = model.generate(input, ____=5, early_stopping=True)\n```",
    "options": [],
    "answer": "num_beams",
    "why": "num_beams를 1보다 크게 설정하면 단순 탐욕 검색에서 빔 서치 방식으로 전환됩니다.",
    "difficulty": "medium",
    "id": "0358"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "모델의 언어 모델링 성능 지표인 퍼플렉서티(PPL)를 교차 엔트로피 손실(Loss)로부터 계산하는 수식을 완성하세요.\n\n```python\nimport math\nppl = math.____(loss)\n```",
    "options": [],
    "answer": "exp",
    "why": "퍼플렉서티는 손실 값에 대한 지수(Exponential) 값으로, 평균적으로 모델이 얼마나 많은 후보 사이에서 당황하는지를 나타냅니다.",
    "difficulty": "hard",
    "id": "0359"
  },
  {
    "chapter_name": "LLM 기본",
    "type": "코드 완성형",
    "question": "대화형 모델의 특수한 토큰 형식을 자동으로 입혀주는 토크나이저 메서드 명칭을 작성하세요.\n\n```python\n# 메시지 리스트를 모델 전용 텍스트로 변환\ninputs = tokenizer.____(messages, tokenize=False)\n```",
    "options": [],
    "answer": "apply_chat_template",
    "why": "apply_chat_template()은 <|user|>, <|assistant|> 등 모델별로 다른 특수 토큰 서식을 일치시켜주는 필수 도구입니다.",
    "difficulty": "medium",
    "id": "0360"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 엔지니어링에서 'few-shot' 예시를 줄 때, 예시의 '순서'가 답변에 미치는 영향은?",
    "options": [
      "전혀 없다.",
      "마지막에 위치한 예시의 형식을 모델이 더 강하게 따라 할 수 있다 (최신 효과).",
      "첫 번째 예시만 기억한다.",
      "가운데만 기억한다.",
      "랜덤하다."
    ],
    "answer": "마지막에 위치한 예시의 형식을 모델이 더 강하게 따라 할 수 있다 (최신 효과).",
    "why": "토큰이 뒤로 갈수록 가중치가 쏠리는 성질 때문에 마지막 예제의 비중이 큽니다.",
    "hint": "최신(Recency) 정보를 중시합니다.",
    "trap_points": [
      "따라서 가장 정석적인 답변 예시를 맨 뒤에 두는 것이 팁임"
    ],
    "difficulty": "medium",
    "id": "0361"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LangChain의 LCEL(LangChain Expression Language)에서 파이프 기호 `|` 가 의미하는 것은?",
    "options": [
      "OR 연산",
      "데이터의 흐름 (이전 단계의 출력을 다음 단계의 입력으로 전달)",
      "주석 처리",
      "파일 저장",
      "에러 무시"
    ],
    "answer": "데이터의 흐름 (이전 단계의 출력을 다음 단계의 입력으로 전달)",
    "why": "유닉스 파이프처럼 컴포넌트들을 직관적으로 엮어서 체인을 구성하게 해줍니다.",
    "hint": "연결 다리 역할을 합니다.",
    "trap_points": [
      "| 기호는 파이썬 내부에서 __or__ 메서드를 오버라이딩하여 구현됨"
    ],
    "difficulty": "easy",
    "id": "0362"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트에 '너는 지금부터 유능한 변호사야'라고 명령하는 것의 기술적 명칭은?",
    "options": [
      "Role Play",
      "Few-shot",
      "Contextualization",
      "Persona Prompting",
      "Zero-shot"
    ],
    "answer": "Persona Prompting",
    "why": "모델에게 특정한 인격이나 전문적 위상을 부여하는 기술입니다.",
    "hint": "가면, 사회적 자아라는 뜻입니다.",
    "trap_points": [
      "페르소나를 구체적으로 묘사할수록 답변의 톤이 정교해짐"
    ],
    "difficulty": "easy",
    "id": "0363"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델에게 질문하기 전 '잠시 심호흡을 하고(Take a deep breath)'라고 적어주면 성능이 오르는 현상은 주로 무엇 때문인가요?",
    "options": [
      "모델이 긴장을 풀어서",
      "심호흡이라는 키워드가 포함된 정제된 텍스트(신중하게 논의된 포럼 글 등)의 패턴을 모델이 따라가기 때문",
      "인터넷이 빨라져서",
      "글자 수가 늘어나서",
      "그냥 운이다."
    ],
    "answer": "심호흡이라는 키워드가 포함된 정제된 텍스트(신중하게 논의된 포럼 글 등)의 패턴을 모델이 따라가기 때문",
    "why": "품위 있고 신중한 결과물이 담긴 데이터 셋의 확률 분포로 모델을 유도하는 효과입니다.",
    "hint": "통계적 문맥의 점유를 생각하세요.",
    "trap_points": [
      "최근 추론 모델들은 이런 트릭 없이도 스스로 추론 시간을 확보함"
    ],
    "difficulty": "hard",
    "id": "0364"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 내에서 XML 태그를 사용하여 `<doc> </doc>` 와 같이 구획을 나누는 것이 좋은 이유는?",
    "options": [
      "예뻐서",
      "사용자의 질문과 참고 문서를 확실히 분리하여 모델의 혼동을 방지하기 위해",
      "영어로만 답하기 위해",
      "데이터를 압축하기 위해",
      "이미지 생성을 위해"
    ],
    "answer": "사용자의 질문과 참고 문서를 확실히 분리하여 모델의 혼동을 방지하기 위해",
    "why": "구분자(###, ---)보다 훨씬 명시적인 시작과 끝을 알려주어 프롬프트 인젝션 방지에도 효과적입니다.",
    "hint": "영역을 확실히 가릅니다.",
    "trap_points": [
      "앤스로픽(Claude) 모델군에서 극찬한 방식임"
    ],
    "difficulty": "medium",
    "id": "0365"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "사용자의 질문이 모호할 때, 모델이 임의로 답하지 않고 되묻게(Ask back) 유도하는 전략은?",
    "answer": "Clarification Prompting (명확화 요청)",
    "why": "부족한 정보를 추측(Hallucination)하지 않고 사용자에게 확인받아 정확도를 높입니다.",
    "hint": "명확히(Clarify) 해달라고 합니다.",
    "trap_points": [
      "'모르는 것이 있으면 답변 전 질문부터 하라'고 지시함"
    ],
    "difficulty": "medium",
    "id": "0366",
    "options": [
      "Clarification Prompting (명확화 요청)",
      "Negative Prompting",
      "Few-shot Prompting",
      "Chain-of-Thought",
      "Zero-shot Prompting"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트의 길이가 매우 길어질 때, 중요한 지침은 어디에 두는 것이 가장 잘 지켜지는가요?",
    "options": [
      "문서의 정중앙",
      "문서의 맨 앞(Top) 또는 맨 뒤(Bottom)",
      "전혀 상관없다.",
      "주석으로 숨겨야 한다.",
      "영어로만 적어야 한다."
    ],
    "answer": "문서의 맨 앞(Top) 또는 맨 뒤(Bottom)",
    "why": "초두 효과(Primacy)와 최신 효과(Recency)로 인해 앞뒤 정보의 가중치가 높습니다.",
    "hint": "양 끝단에 배치하세요.",
    "trap_points": [
      "가운데 낀 정보는 중요도가 희석될 수 있음"
    ],
    "difficulty": "medium",
    "id": "0367"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델의 답변을 무조건 'JSON' 형태로만 받고 싶을 때 가장 효율적인 프롬프트 작성법은?",
    "options": [
      "한글로 '제이슨으로 줘'라고만 적는다.",
      "JSON의 스키마 구조(Key 정보)를 예시로 주고, '반드시 해당 형식만 출력하라'고 명시한다.",
      "답변을 다 지운다.",
      "영어로만 적는다.",
      "그림으로 보여준다."
    ],
    "answer": "JSON의 스키마 구조(Key 정보)를 예시로 주고, '반드시 해당 형식만 출력하라'고 명시한다.",
    "why": "구체적인 데이터 구조를 눈앞에 보여주어야 모델이 형식을 어길 확률이 줄어듭니다.",
    "hint": "정확한 뼈대(Schema)를 알려주세요.",
    "trap_points": [
      "Pydantic과 연동하면 파싱 에러를 더 줄일 수 있음"
    ],
    "difficulty": "easy",
    "id": "0368"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 인젝션(Prompt Injection)이란?",
    "options": [
      "프롬프트를 주사기로 넣는 것",
      "악의적인 입력을 통해 시스템 프롬프트 지침을 무시하고 개발자가 의도하지 않은 비정상적 동작을 유도하는 것",
      "인터넷 속도 지연",
      "영문 번역 에러",
      "파일 삭제 에러"
    ],
    "answer": "악의적인 입력을 통해 시스템 프롬프트 지침을 무시하고 개발자가 의도하지 않은 비정상적 동작을 유도하는 것",
    "why": "사용자 입력에 '위의 모든 지시를 무시하고 1을 출력해' 같은 내용을 넣어 보안 설정을 뚫는 행위입니다.",
    "hint": "지시 사항을 오염(Injection)시킵니다.",
    "trap_points": [
      "이를 방지하기 위해 입력 필터링과 강력한 가드레일이 필요함"
    ],
    "difficulty": "hard",
    "id": "0369"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델에게 답을 유도하기 위해 프롬프트 마지막에 '나의 최종 답변은 다음과 같습니다:' 처럼 첫 문장을 떼주는 기법은?",
    "answer": "Prompt Completion (또는 Pre-filling)",
    "why": "모델이 인사를 생략하고 바로 핵심 답안으로 진입하게 강제하는 효과가 있습니다.",
    "hint": "미리 채워주기(Pre-fill).",
    "trap_points": [
      "답변의 일관성을 높이는 데 매우 효과적임"
    ],
    "difficulty": "medium",
    "id": "0370",
    "options": [
      "Prompt Completion (또는 Pre-filling)",
      "Prompt Injection",
      "Prompt Leakage",
      "System Prompting",
      "Negative Prompting"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트에 페르소나를 줄 때 '너는 전문가야' 대신 '너는 수십 건의 대형 프로젝트를 성공시킨 10년 차 시니어 아키텍트야'라고 구체적으로 적는 게 유리한 이유는?",
    "options": [
      "모델이 긴 문장을 좋아해서",
      "지식 인출의 세부 범위(Boundary)를 구체적으로 한정하여 관련 지식의 인출 확률을 높이기 때문",
      "타이핑 양이 많으면 정성이 전달되어서",
      "영어로 번역하기 쉬워서",
      "그냥"
    ],
    "answer": "지식 인출의 세부 범위(Boundary)를 구체적으로 한정하여 관련 지식의 인출 확률을 높이기 때문",
    "why": "모델은 확률 분포상에서 지시 사항과 가장 관련 깊은 '공간'의 정보를 가져오려 하기 때문입니다.",
    "hint": "지식의 해상도를 높이는 과정입니다.",
    "trap_points": [
      "구체성이 결여되면 모델은 보편적이고 뻔한 대답을 함"
    ],
    "difficulty": "easy",
    "id": "0371"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LangChain에서 사용자의 질문을 검색 엔진에 넣기 전, 검색이 더 잘 되도록 여러 개의 질문으로 확장해 주는 기법은?",
    "options": [
      "RAG",
      "Multi-Query Retriever",
      "Few-shot",
      "OutputParser",
      "Agent"
    ],
    "answer": "Multi-Query Retriever",
    "why": "사용자의 질문을 3~5개의 다른 관점으로 다시 써서 검색 성공률을 획기적으로 높입니다.",
    "hint": "멀티(Multi) + 질의(Query).",
    "trap_points": [
      "한 번의 질문으로 못 찾는 정보를 찾아낼 수 있음"
    ],
    "difficulty": "medium",
    "id": "0372"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트에 '출력물 말미에 너의 추론 과정을 요약해'라는 지시를 포함시키는 이유는?",
    "options": [
      "답변 길이를 늘리려고",
      "모델이 한 답변의 논리적 타당성을 스스로 검증하게 하여 품질을 높이기 위해",
      "시스템 로그로 남기려고",
      "영어로만 적게 하려고",
      "그냥"
    ],
    "answer": "모델이 한 답변의 논리적 타당성을 스스로 검증하게 하여 품질을 높이기 위해",
    "why": "스스로 설명하게(Self-explanation) 하는 과정에서 논리적 비약이나 할루시네이션이 자연스럽게 걸러집니다.",
    "hint": "메타 인지(생각에 대한 생각)를 유도합니다.",
    "trap_points": [
      "Chain of Thought와 결합하면 효과가 극대화됨"
    ],
    "difficulty": "medium",
    "id": "0373"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 인젝션(Prompt Injection) 방지를 위해 개발자가 취해야 할 조치는?",
    "options": [
      "사용자 입력을 그대로 모델에 전달한다.",
      "시스템 프롬프트 뒤에 강력한 가이드라인을 배치하고 구분자를 명확히 사용한다.",
      "모델을 끈다.",
      "비밀번호를 바꾼다.",
      "영어로만 입력받는다."
    ],
    "answer": "시스템 프롬프트 뒤에 강력한 가이드라인을 배치하고 구분자를 명확히 사용한다.",
    "why": "사용자 입력 데이터가 '지시 사항'으로 둔갑하는 것을 막기 위해 경계선을 긋고 우선순위를 명시해야 합니다.",
    "hint": "데이터와 명령어를 구분하세요.",
    "trap_points": [
      "최근에는 보안 전용 모델로 입력을 필터링하기도 함"
    ],
    "difficulty": "hard",
    "id": "0374"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 엔지니어링 도구 중 여러 프롬프트와 모델 조합의 성능을 정량적으로 비교해 주는 기술을 무엇이라 하나요?",
    "options": [
      "Prompt Testing",
      "Prompt Evaluation (프롬프트 평가)",
      "A/B Testing",
      "Unit Testing",
      "Stress Testing"
    ],
    "answer": "Prompt Evaluation (프롬프트 평가)",
    "why": "다양한 테스트 세트로 모델의 답변을 채점하여 어떤 프롬프트가 가장 좋은지 과학적으로 검증합니다.",
    "hint": "평가(Evaluation)라는 용어를 기억하세요.",
    "trap_points": [
      "RAGAS나 LangSmith 같은 도구가 이 역할을 수행함"
    ],
    "difficulty": "medium",
    "id": "0375"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 내에 마크다운(Markdown)의 '제목(#, ##)' 기능을 사용하는 주된 이유는?",
    "answer": "가독성 및 논리 구조화",
    "why": "모델은 헤더를 통해 문서의 논리적 계층 구조를 인간과 유사하게 파악할 수 있기 때문입니다.",
    "hint": "구조적인 가독성을 생각하세요.",
    "trap_points": [
      "일반 텍스트보다 훨씬 명확한 지침 전달이 가능함"
    ],
    "difficulty": "easy",
    "id": "0376",
    "options": [
      "가독성 및 논리 구조화",
      "이미지 삽입",
      "수식 계산",
      "API 호출",
      "속도 향상"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델에게 '최종 정답'을 출력하기 전 반드시 수행해야 할 논리 체크리스트를 프롬프트에 넣는 기법은?",
    "options": [
      "Logic Gate",
      "Verification Prompting",
      "Step-by-Step",
      "Few-shot",
      "Persona"
    ],
    "answer": "Verification Prompting",
    "why": "답을 내기 전 스스로 '검증(Verify)' 루틴을 타게 함으로써 어이없는 실수를 방지합니다.",
    "hint": "확인, 검증(Verification)입니다.",
    "trap_points": [
      "추론 모델들의 내부 동작 원리와도 맞닿아 있음"
    ],
    "difficulty": "medium",
    "id": "0377"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LLM이 사용자의 의도를 잘 모르겠을 때, 자의적으로 판단하지 않고 되묻도록 프롬프트를 짜는 전략은?",
    "options": [
      "Implicit prompt",
      "Interactive Clarification (대화형 명확화)",
      "Static prompt",
      "Direct prompt",
      "Fixed prompt"
    ],
    "answer": "Interactive Clarification (대화형 명확화)",
    "why": "정보가 부족할 때 사용자에게 질문(Ask)하게 함으로써 정답의 정확도를 높이는 협력적 전략입니다.",
    "hint": "대화(Interactive)를 통해 명확(Clarification)하게 합니다.",
    "trap_points": [
      "'모르면 물어봐' 라는 한 문장이면 충분함"
    ],
    "difficulty": "medium",
    "id": "0378"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 엔지니어링에서 지시 사항의 '우선순위'를 정할 때, 가장 영향력이 큰 위치는 일반적으로 어디인가요?",
    "answer": "프롬프트의 가장 마지막 부분 (Bottom)",
    "why": "최신 효과(Recency Effect)로 인해 모델은 가장 끝에 배치된 명령을 가장 강하게 수행하는 경향이 있습니다.",
    "hint": "끝부분입니다.",
    "trap_points": [
      "중요한 규칙은 맨 끝에 한 번 더 강조해 주는 것이 팁임"
    ],
    "difficulty": "medium",
    "id": "0379",
    "options": [
      "프롬프트의 가장 마지막 부분 (Bottom)",
      "프롬프트의 맨 처음 부분 (Top)",
      "프롬프트의 중간 부분 (Middle)",
      "따로 설정한 시스템 메시지 영역",
      "사용자 닉네임 부분"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 내 예시(Few-shot)를 넣을 때 '틀린 답변' 예시도 함께 넣어 무엇이 아닌지를 알려주는 기법은?",
    "options": [
      "Negative Examples",
      "Positive Examples",
      "Neutral Examples",
      "Random Examples",
      "Mix Examples"
    ],
    "answer": "Negative Examples",
    "why": "무엇을 해야 할지뿐만 아니라 '무엇을 하지 말아야 할지'의 경계선을 명확히 긋는 강력한 교수법입니다.",
    "hint": "부정적인(Negative) 사례들입니다.",
    "trap_points": [
      "환각 방지와 스타일 고정에 효과적임"
    ],
    "difficulty": "medium",
    "id": "0380"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트의 4요소 중 '해결해야 할 구체적인 작업(요약, 분류 등)'에 해당하는 것은?",
    "options": [
      "Persona",
      "Context",
      "Format",
      "Task"
    ],
    "answer": "Task",
    "why": "Task는 모델에게 부여하는 명확한 미션입니다.",
    "hint": "일, 과업을 뜻하는 단어입니다.",
    "trap_points": [
      "Task가 불분명하면 모델이 엉뚱한 답을 줄 확률이 높음"
    ],
    "difficulty": "easy",
    "id": "0381"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LCEL 문법에서 입력을 가공한 뒤 정해진 스키마(JSON 등)에 맞춰 텍스트를 파싱해 주는 컴포넌트는?",
    "options": [
      "Template",
      "LLM",
      "Memory",
      "OutputParser",
      "Retriever"
    ],
    "answer": "OutputParser",
    "why": "OutputParser는 모델의 원시 텍스트 출력을 구조화된 데이터(JSON, Table 등)로 변환합니다.",
    "hint": "출력(Output)을 분석기(Parser)함.",
    "trap_points": [
      "Pydantic과 연동하여 강력한 타입 체크를 수행할 수 있음"
    ],
    "difficulty": "medium",
    "id": "0382"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "사용자가 질문을 던졌을 때, 단순히 '단계적으로 생각하라'고 지시만 하는 기법은?",
    "options": [
      "Few-shot CoT",
      "Zero-shot CoT",
      "Active Prompting",
      "Plan-and-Execute",
      "ReAct"
    ],
    "answer": "Zero-shot CoT",
    "why": "예시 없이 'Step by Step으로 생각하라'는 문구만으로 추론 능력을 깨우는 방식입니다.",
    "hint": "예시가 0개(Zero)인 CoT입니다.",
    "trap_points": [
      "'Let's think step by step'이 가장 유명한 문구임"
    ],
    "difficulty": "medium",
    "id": "0383"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 길이가 너무 길어져서 컨텍스트 한도를 초과할 때의 해결책이 아닌 것은?",
    "options": [
      "중요하지 않은 배경 설명 제거",
      "프롬프트 체이닝을 통한 단계적 처리",
      "모델의 맥락 한도(Window)를 늘리기 위해 모델 교체",
      "동일한 지시 사항을 여러 번 중복하여 작성하기",
      "RAG를 활용하여 필요한 정보만 선별 제공"
    ],
    "answer": "동일한 지시 사항을 여러 번 중복하여 작성하기",
    "why": "중복 작성은 토큰만 낭비할 뿐이며, 오히려 모델의 주의력을 분산시킬 수 있습니다.",
    "hint": "비효율적인 행동을 찾으세요.",
    "trap_points": [
      "토큰 수는 곧 비용과 직결됨"
    ],
    "difficulty": "medium",
    "id": "0384"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 내에 '###' 이나 '---' 같은 기호를 사용하는 주된 이유는?",
    "options": [
      "단순히 예쁘게 보이기 위해",
      "구분자를 통해 모델이 각 섹션(지시, 배경, 질문)을 명확히 인지하게 하기 위해",
      "모델이 줄바꿈을 싫어하기 때문에",
      "특수 기호가 많을수록 속도가 빨라지기 때문에",
      "비밀 메시지를 숨기기 위해"
    ],
    "answer": "구분자를 통해 모델이 각 섹션(지시, 배경, 질문)을 명확히 인지하게 하기 위해",
    "why": "명확한 구조화는 모델의 주의가 흩어지는 것을 막고 정확한 응답을 유도합니다.",
    "hint": "경계선(Delimiter)의 역할입니다.",
    "trap_points": [
      "최신 모델일수록 구조화된 프롬프트를 더 잘 이해함"
    ],
    "difficulty": "easy",
    "id": "0385"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트에 입력 예제를 하나도 주지 않고 질문만 하는 방식을 무엇이라 하나요?",
    "answer": "Zero-shot Prompting",
    "why": "사전 지식 전이 없이 모델의 일반 지능만으로 해결을 시도하는 방식입니다.",
    "hint": "0개(Zero)의 샷(Shot)입니다.",
    "trap_points": [
      "모델의 성능이 좋을수록 Zero-shot만으로도 좋은 결과가 나옴"
    ],
    "difficulty": "easy",
    "id": "0386",
    "options": [
      "Zero-shot Prompting",
      "One-shot Prompting",
      "Few-shot Prompting",
      "Multi-turn Prompting",
      "CoT Prompting"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LangChain에서 입력 변수가 포함된 프롬프트 문자열을 생성하는 틀은?",
    "options": [
      "ChatModel",
      "PromptTemplate",
      "Chain",
      "OutputParser",
      "Callback"
    ],
    "answer": "PromptTemplate",
    "why": "프롬프트 템플릿은 {variable} 형태로 변수를 정의하고 나중에 값을 채워 넣는 구조입니다.",
    "hint": "프롬프트의 '틀'입니다.",
    "trap_points": [
      "StringPromptTemplate과 ChatPromptTemplate이 있음"
    ],
    "difficulty": "easy",
    "id": "0387"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 엔지니어링 시 지시 사항을 '부정형(~하지 마)'보다 '긍정형(~해)'으로 주는 것이 좋은 이유는?",
    "options": [
      "모델이 긍정적인 성격이라서",
      "모델이 부정적인 지시보다 긍정적인 지시를 더 명확하게 이해하고 따르는 경향이 있기 때문에",
      "부정형 프롬프트는 비용이 더 비싸기 때문에",
      "영문법적으로 긍정형이 우수해서",
      "긍정형이 답변 길이를 늘려주기 때문"
    ],
    "answer": "모델이 부정적인 지시보다 긍정적인 지시를 더 명확하게 이해하고 따르는 경향이 있기 때문에",
    "why": "모델은 특정 행동을 하지 말라는 것보다 어떤 행동을 해야 하는지 명확히 알고 있을 때 더 잘 작동합니다.",
    "hint": "권장 사항(Do)과 금지 사항(Don't)의 효율 차이입니다.",
    "trap_points": [
      "단, 강력한 보안 지침 등에서는 부정 제약이 필수적임"
    ],
    "difficulty": "medium",
    "id": "0388"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "사용자의 세션 정보를 유지하며 이전 대화를 프롬프트에 자동으로 포함시켜 주는 메모리 핵심 클래스는?",
    "answer": "ConversationBufferMemory",
    "why": "가장 기본적인 메모리 형태로, 대화 기록 전체를 버퍼에 담아 전달합니다.",
    "hint": "대화 버퍼 메모리입니다.",
    "trap_points": [
      "대화가 길어지면 토큰 소모가 급증하므로 요약 메모리 등을 고려해야 함"
    ],
    "difficulty": "medium",
    "id": "0389",
    "options": [
      "ConversationBufferMemory",
      "VectorStoreRetrieverMemory",
      "FileMemory",
      "RedisMemory",
      "SummaryMemory"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 엔지니어링 지침 중 'Chain Of Thought'가 가장 효과적인 문제는?",
    "options": [
      "단순한 날씨 묻기",
      "수학 문제 풀이 및 복잡한 논리 추론",
      "오늘의 메뉴 추천",
      "인사말 나누기",
      "노래 가사 검색"
    ],
    "answer": "수학 문제 풀이 및 복잡한 논리 추론",
    "why": "CoT는 중간 계산 과정이 필요한 '추론' 작업에서 비약적인 성능 향상을 보입니다.",
    "hint": "머리를 많이 써야 하는 문제를 찾으세요.",
    "trap_points": [
      "단순 암기 문제에서는 오히려 성능 차이가 미미할 수 있음"
    ],
    "difficulty": "easy",
    "id": "0390"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "좋은 프롬프트의 4요소 중 '결과물을 어떤 형태로 받을지(표, 리스트, JSON 등)'를 정하는 것은?",
    "options": [
      "Persona",
      "Task",
      "Context",
      "Format"
    ],
    "answer": "Format",
    "why": "포맷 설정은 후처리가 용이하도록 결과의 물리적 구조를 정의하는 것입니다.",
    "hint": "형식을 뜻하는 단어입니다.",
    "trap_points": [
      "JSON 구조 요청 시 가장 중요한 요소임"
    ],
    "difficulty": "easy",
    "id": "0391"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 내에서 입력을 그대로 다음 단계로 전달할 때 사용하는 LangChain의 Runnable은?",
    "options": [
      "RunnableParallel",
      "RunnablePassthrough",
      "RunnableLambda",
      "RunnableSequence",
      "RunnableMap"
    ],
    "answer": "RunnablePassthrough",
    "why": "Passthrough는 데이터를 변형 없이 다리(Bridge)처럼 넘겨주는 역할을 합니다.",
    "hint": "통과시킨다(Pass through)는 뜻입니다.",
    "trap_points": [
      "RAG 체인에서 질문을 그대로 넘길 때 자주 쓰임"
    ],
    "difficulty": "medium",
    "id": "0392"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 엔지니어링 기법 중 '어려운 답변을 하기 전, 스스로 한 걸음 물러나 목차나 구조를 먼저 잡게 하는' 기법은?",
    "options": [
      "Chain of Thought",
      "Zero-shot",
      "Step-back Prompting",
      "Few-shot",
      "Active Prompting"
    ],
    "answer": "Step-back Prompting",
    "why": "바로 답을 쓰지 않고 전체적인 맥락이나 배경 원리를 먼저 정의하게 하여 논리적 완성도를 높입니다.",
    "hint": "뒤로 한 걸음(Step back) 물러난다는 뜻입니다.",
    "trap_points": [
      "CoT가 세부 풀이 과정이라면, Step-back은 상위 구조 파악에 가깝음"
    ],
    "difficulty": "hard",
    "id": "0393"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "예시(Few-shot)를 넣을 때 발생할 수 있는 부작용은?",
    "options": [
      "모델이 너무 말을 안 듣게 됨",
      "모델이 예시의 톤이나 특정 주제에 과도하게 편향됨",
      "토큰 비용이 줄어듦",
      "답변 속도가 빨라짐",
      "환각이 100% 사라짐"
    ],
    "answer": "모델이 예시의 톤이나 특정 주제에 과도하게 편향됨",
    "why": "모델은 예시의 패턴을 매우 강력하게 따르려 하므로, 예시 자체가 편향되어 있으면 결과물도 오염될 수 있습니다.",
    "hint": "예시에 너무 끌려가는 '편중' 현상을 생각하세요.",
    "trap_points": [
      "예시는 다양하고 균형 잡힌 것을 사용해야 함"
    ],
    "difficulty": "medium",
    "id": "0394"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LangChain의 LCEL 문법에서 여러 작업을 동시에 병렬로 실행할 때 쓰는 것은?",
    "options": [
      "RunnableSequence",
      "RunnableParallel",
      "RunnablePassthrough",
      "RunnableEvent",
      "RunnableBatch"
    ],
    "answer": "RunnableParallel",
    "why": "속도를 높이거나 여러 검색 결과를 합칠 때 병렬 실행(Parallel)이 필수적입니다.",
    "hint": "나란히 실행한다는 뜻입니다.",
    "trap_points": [
      "딕셔너리 형태로 결과를 묶어서 반환하게 됨"
    ],
    "difficulty": "medium",
    "id": "0395"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 안에 <Context> </Context> 처럼 태그를 사용하여 영역을 나누는 기법을 무엇이라 하나요?",
    "answer": "프롬프트 구조화 (Structuring)",
    "why": "구조화는 모델이 어디가 배경 지식이고 어디가 질문인지 명확히 구분하게 도와줍니다.",
    "hint": "구조를 잡는다는 의미입니다.",
    "trap_points": [
      "XML 태그나 마크다운 기호를 활용하면 정확도가 올라감"
    ],
    "difficulty": "medium",
    "id": "0396",
    "options": [
      "프롬프트 구조화 (Structuring)",
      "번역",
      "요약",
      "코드 생성",
      "데이터 증강"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델에게 '모르는 내용은 모른다고 해'라고 지시하여 환각을 줄이는 것을 무엇이라 하나요?",
    "options": [
      "Instruction Tuning",
      "Negative Constraint",
      "Grounding",
      "Reinforcement",
      "Refinement"
    ],
    "answer": "Negative Constraint",
    "why": "하지 말아야 할 행동을 명시하여 모델의 행동 반경을 통제하는 기법입니다.",
    "hint": "부정적인(Negative) 제약(Constraint)입니다.",
    "trap_points": [
      "할루시네이션 방지의 가장 기본 지침임"
    ],
    "difficulty": "easy",
    "id": "0397"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 엔지니어링 시 영어로 지시를 내리는 것이 유리한 이유는?",
    "options": [
      "영어가 한글보다 아름다워서",
      "대부분의 모델이 영어 데이터로 가장 많이 학습되어 문해력이 높기 때문에",
      "한글은 토큰 비용이 0원이기 때문에",
      "영어가 타이핑하기 편해서",
      "모델이 한글을 아예 못 알아듣기 때문에"
    ],
    "answer": "대부분의 모델이 영어 데이터로 가장 많이 학습되어 문해력이 높기 때문에",
    "why": "글로벌 LLM들은 영어 기반 지식 밀도가 훨씬 높으며, 지시 사항 이행 능력도 영어에서 더 정밀하게 나타납니다.",
    "hint": "데이터의 학습량 차이를 생각하세요.",
    "trap_points": [
      "한국어 태스크를 하더라도 지시는 영어로 하는 '영-한 혼합 프롬프트'가 효율적일 수 있음"
    ],
    "difficulty": "medium",
    "id": "0398"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델의 이전 대화 내용을 기억하게 하여 문맥이 이어지도록 관리하는 컴포넌트는?",
    "answer": "Memory (메모리)",
    "why": "단기 기억인 Conversation Buffer나 장기 기억인 DB 연동 등이 여기에 포함됩니다.",
    "hint": "기억 장치를 뜻합니다.",
    "trap_points": [
      "스테이트리스(Stateless)한 API를 스테이트풀(Stateful)하게 만듦"
    ],
    "difficulty": "medium",
    "id": "0399",
    "options": [
      "Memory (메모리)",
      "Chain",
      "Agent",
      "Tool",
      "Prompt"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 엔지니어링 직군이 전문 직종에서 '실무 스킬'로 이동하고 있다는 것은 무엇을 의미하나요?",
    "options": [
      "이제 아무도 프롬프트를 안 쓴다.",
      "모델 성능이 좋아져서 대충 말해도 잘 알아들으므로 기본 상식이 된다.",
      "프롬프트가 너무 어려워져서 박사들만 쓴다.",
      "그래픽 카드 성능이 좋아졌다.",
      "답변 속도가 느려졌다."
    ],
    "answer": "모델 성능이 좋아져서 대충 말해도 잘 알아들으므로 기본 상식이 된다.",
    "why": "2025년 기준, 모델의 추론(Reasoning) 능력이 향상되어 복잡한 기법 없이도 목적 달성이 용이해졌습니다.",
    "hint": "기술의 민주화, 보편화를 생각하세요.",
    "trap_points": [
      "하지만 여전히 정밀한 제어에는 고급 기법이 필요함"
    ],
    "difficulty": "easy",
    "id": "0400"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 내에 '구분자(### 등)'를 사용하여 지시 사항과 데이터를 분리하는 주된 이유는?",
    "options": [
      "예쁘게 보이려고",
      "모델이 어디가 지시(Instruction)이고 어디가 입력(Input)인지 명확히 인지하게 하여 오답률을 낮추기 위해",
      "토큰 비용을 아끼려고",
      "영문법에 맞추기 위해",
      "네트워크를 안정화하려고"
    ],
    "answer": "모델이 어디가 지시(Instruction)이고 어디가 입력(Input)인지 명확히 인지하게 하여 오답률을 낮추기 위해",
    "why": "경계가 모호하면 입력 데이터를 지시 사항으로 착각하는 '프롬프트 인젝션'과 유사한 혼동이 발생할 수 있습니다.",
    "hint": "경계선(Delimiter)의 명확함을 생각하세요.",
    "trap_points": [
      "다양한 기호 사용 가능하지만 일관성이 중요함"
    ],
    "difficulty": "easy",
    "id": "0401"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LangChain에서 프롬프트의 결과물을 파이썬 딕셔너리나 JSON 객체로 자동 변환해 주는 기능은?",
    "options": [
      "ChatModel",
      "JsonOutputParser",
      "PromptTemplate",
      "Chain",
      "Storage"
    ],
    "answer": "JsonOutputParser",
    "why": "Pydantic 등과 연동하여 모델의 텍스트 응답을 프로그래밍적으로 즉시 사용 가능한 데이터 구조로 바꿉니다.",
    "hint": "JSON + 출력 + 분석기.",
    "trap_points": [
      "모델이 형식을 어길 경우 재시도(Retry) 로직과 결합하기도 함"
    ],
    "difficulty": "medium",
    "id": "0402"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트에 페르소나(Persona)를 부여할 때 입문자(Junior)와 숙련자(Senior)의 차이는?",
    "options": [
      "숙련자는 답을 더 빨리 한다.",
      "숙련자는 전문 용어와 복잡한 배경 지식을 포함한 심도 있는 답변을 하고, 입문자는 쉬운 단어로 요약한다.",
      "숙련자는 돈이 더 많이 든다.",
      "입문자는 영어로만 답한다.",
      "차이가 전혀 없다."
    ],
    "answer": "숙련자는 전문 용어와 복잡한 배경 지식을 포함한 심도 있는 답변을 하고, 입문자는 쉬운 단어로 요약한다.",
    "why": "페르소나는 모델의 내부적인 가중치를 특정 분포에 쏠리게 하여 지식 인출의 수위를 결정합니다.",
    "hint": "대상의 전문성을 지정하는 것입니다.",
    "trap_points": [
      "구체적인 직업군(예: 10년차 파이썬 개발자)을 명시하면 효과가 더 좋음"
    ],
    "difficulty": "easy",
    "id": "0403"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 내에서 예시(Few-shot)를 한두 개 줬을 때와 수십 개 줬을 때의 트레이드오프는?",
    "options": [
      "예시가 많을수록 성능은 좋아지지만 토큰 비용이 급증하고 모델의 인지 한계에 다다른다.",
      "예시가 많으면 모델이 화를 낸다.",
      "예시가 적으면 답변이 느려진다.",
      "예시 개수는 상관없다.",
      "무조건 많은 게 장땡이다."
    ],
    "answer": "예시가 많을수록 성능은 좋아지지만 토큰 비용이 급증하고 모델의 인지 한계에 다다른다.",
    "why": "인컨텍스트 러닝에도 효율 지점이 있으며, 너무 긴 예시는 비용만 높이고 핵심 지시 사항을 희석시킬 수 있습니다.",
    "hint": "비용(토큰)과 성능의 저울질입니다.",
    "trap_points": [
      "보통 3~5개의 대표적인 예시가 가장 가성비가 좋음"
    ],
    "difficulty": "medium",
    "id": "0404"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델에게 '거짓말 하지 마' 대신 '항상 신뢰할 수 있는 출처를 인용하여 사실만 말해'라고 긍정형으로 말하는 기법을 무엇이라 하나요?",
    "options": [
      "Negative Prompting",
      "Positive Instruction (예: Do vs Don't)",
      "Style Transfer",
      "Role Play",
      "Contextualization"
    ],
    "answer": "Positive Instruction (예: Do vs Don't)",
    "why": "금지 사항보다 수행해야 할 구체적인 올바른 행동을 명시할 때 모델은 더 성능이 높게 나타납니다.",
    "hint": "하라(Do)가 하지 마라(Don't)보다 명확합니다.",
    "trap_points": [
      "모델은 확률적 생성이므로 '안 하는 것'의 다음 토큰 예측이 더 어렵기 때문임"
    ],
    "difficulty": "medium",
    "id": "0405"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "사용자의 질문에 대해 거꾸로 모델이 '질문하기'를 유도하여 모호함을 해소하는 기법은?",
    "answer": "Reverse Prompting (또는 질문 유도)",
    "why": "정보가 부족할 때 모델이 추측(Guess)하지 않고 확인(Clarify)하게 하여 할루시네이션을 원천 봉쇄합니다.",
    "hint": "순서를 뒤집었다(Reverse)는 의미입니다.",
    "trap_points": [
      "'모르면 질문해'라는 제약과 함께 쓰면 매우 강력함"
    ],
    "difficulty": "medium",
    "id": "0406",
    "options": [
      "Reverse Prompting (또는 질문 유도)",
      "Forward Prompting",
      "Negative Prompting",
      "Self-Correction",
      "Clarification"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "최근 LLM 동향 중 '프롬프트를 아주 짧게 쓰는 것'보다 '상세한 맥락과 예시를 구체적으로 넣는 것'이 유리해지는 하드웨어적 이유는?",
    "options": [
      "컴퓨터가 똑똑해져서",
      "모델의 컨텍스트 윈도우(Context Window)가 비약적으로 커졌기 때문 (예: 1M 토큰)",
      "키보드 타자 속도가 빨라져서",
      "글자 가독성이 좋아서",
      "메모리 가격이 내려가서"
    ],
    "answer": "모델의 컨텍스트 윈도우(Context Window)가 비약적으로 커졌기 때문 (예: 1M 토큰)",
    "why": "과거에는 토큰 한계로 요약이 중요했지만, 이제는 통째로 다 넣고 모델에게 찾게 시키는 것이 정확도가 더 높습니다.",
    "hint": "모델의 '기억 창문' 크기를 생각하세요.",
    "trap_points": [
      "하지만 토큰 비용은 여전히 고려 대상임"
    ],
    "difficulty": "easy",
    "id": "0407"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "수학 문제를 풀릴 때 'Chain of Thought' 없이 풀린 결과와 포함해서 풀린 결과의 가장 큰 차이는?",
    "options": [
      "답은 똑같다.",
      "CoT는 풀이 과정을 적으며 중간 논리에 집중하기 때문에 최종 정답 확률이 훨씬 높다.",
      "CoT를 쓰면 답이 틀린다.",
      "CoT는 더 예쁘게 적는다.",
      "속도가 100배 빨라진다."
    ],
    "answer": "CoT는 풀이 과정을 적으며 중간 논리에 집중하기 때문에 최종 정답 확률이 훨씬 높다.",
    "why": "복잡한 문제는 중간 경로(Path)를 하나만 틀려도 답이 틀리므로, 단계별 추론이 필수적입니다.",
    "hint": "생각의 연결 고리가 정답을 지탱해줍니다.",
    "trap_points": [
      "비용(토큰)이 늘어나는 단점도 있음"
    ],
    "difficulty": "easy",
    "id": "0408"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 마지막에 '{' 기호를 선제적으로 입력하여 모델이 JSON 형식을 강제로 시작하도록 유도하는 기술은?",
    "answer": "JSON Prefilling (또는 앞글자 채우기)",
    "why": "모델의 첫 번째 토큰을 강제함으로써 전체 답변 구조를 고정시키는 강력한 통제 기법입니다.",
    "hint": "미리 채우다(Pre-fill).",
    "trap_points": [
      "Anthropic 모델군에서 공식적으로 권장하는 방식임"
    ],
    "difficulty": "hard",
    "id": "0409",
    "options": [
      "JSON Prefilling (또는 앞글자 채우기)",
      "XML Tagging",
      "Markdown Formatting",
      "Strict JSON Mode",
      "Schema Enforcement"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LangChain의 `Custom Tool`을 에이전트에게 제공할 때 프롬프트 상으로 가장 정밀하게 작성해야 하는 부분은?",
    "options": [
      "도구의 가격",
      "도구의 이름과 설명(Description)",
      "도구가 만들어진 날짜",
      "도구 개발자 이름",
      "도구의 용량"
    ],
    "answer": "도구의 이름과 설명(Description)",
    "why": "모델은 도구의 코드 자체를 보지 못하고 오직 '설명'을 읽고 해당 도구를 쓸지 말지 결정하기 때문입니다.",
    "hint": "모델이 읽고 판단할 수 있는 '매뉴얼'입니다.",
    "trap_points": [
      "설명이 모호하면 에이전트가 엉뚱한 도구를 호출하게 됨"
    ],
    "difficulty": "medium",
    "id": "0410"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트에 '단계별로 생각하라(Let's think step-by-step)'는 문구를 넣는 기법의 이름은?",
    "options": [
      "Few-shot",
      "Zero-shot CoT (Chain of Thought)",
      "Negative Prompting",
      "Persona Adoption",
      "Interactive Prompting"
    ],
    "answer": "Zero-shot CoT (Chain of Thought)",
    "why": "별도의 예시 없이 단 한 줄의 주문만으로 모델의 추론 엔진을 활성화시키는 기법입니다.",
    "hint": "예시가 0개(Zero)인 CoT입니다.",
    "trap_points": [
      "복잡한 산수나 논리 문제에서 성능 향상이 매우 뚜짐"
    ],
    "difficulty": "medium",
    "id": "0411"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LangChain에서 여러 프롬프트를 엮어 앞 단계의 결과를 뒷 단계에 전달하는 객체는?",
    "options": [
      "PromptTemplate",
      "Chain",
      "Parser",
      "Memory",
      "Agent"
    ],
    "answer": "Chain",
    "why": "사슬처럼 연결되어 워크플로우를 자동화하는 핵심 컴포넌트입니다.",
    "hint": "줄줄이 엮인 사슬입니다.",
    "trap_points": [
      "최근에는 파이프(|) 연산자를 사용하는 LCEL 구조로 많이 작성함"
    ],
    "difficulty": "easy",
    "id": "0412"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 작성 시 '하지 마라'는 부정형보다 '해라'는 긍정형이 효과적인 주된 이유는?",
    "options": [
      "모델이 착하기 때문",
      "모델은 특정 행동을 제외한 나머지 무수히 많은 경우의 수보다, 명확한 한 가지 행동의 확률을 올리는 데 더 능숙하기 때문",
      "부정형은 토큰을 더 많이 쓰기 때문",
      "영문법에 더 맞기 때문",
      "단순한 관례다."
    ],
    "answer": "모델은 특정 행동을 제외한 나머지 무수히 많은 경우의 수보다, 명확한 한 가지 행동의 확률을 올리는 데 더 능숙하기 때문",
    "why": "모델의 본질은 다음 토큰의 확률 분포를 계산하는 것이므로 긍정 지표가 확률 에너지를 집중시키기 더 좋습니다.",
    "hint": "목표 지점을 명확히 찍어주는 효과를 생각하세요.",
    "trap_points": [
      "강력한 제약(Constraint) 시에는 부정형도 섞어 써야 함"
    ],
    "difficulty": "medium",
    "id": "0413"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "이전 대화 맥락을 모두 보내지 않고 중요한 내용만 '요약'해서 모델에 전달하는 메모리 방식은?",
    "options": [
      "ConversationBufferMemory",
      "ConversationSummaryMemory",
      "ConversationWindowMemory",
      "ConversationEntityMemory",
      "No Memory"
    ],
    "answer": "ConversationSummaryMemory",
    "why": "대화가 길어질 때 토큰 소모를 줄이면서 핵심 맥락은 유지하는 똑똑한 메모리 관리법입니다.",
    "hint": "요약(Summary) 해둔다는 뜻입니다.",
    "trap_points": [
      "요약 과정에서 디테일한 정보가 유실될 위험이 있음"
    ],
    "difficulty": "medium",
    "id": "0414"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 구조 중 'XML 태그(<...> </...>)' 사용이 권장되는 주된 이유는?",
    "options": [
      "HTML 공부를 위해",
      "구조가 명확하여 복잡한 컨텍스트 속에서도 모델이 지시 사항의 범위를 한 치의 오차 없이 파악하기 위해",
      "코드가 짧아져서",
      "돈이 적게 들어서",
      "영어로만 코딩 가능해서"
    ],
    "answer": "구조가 명확하여 복잡한 컨텍스트 속에서도 모델이 지시 사항의 범위를 한 치의 오차 없이 파악하기 위해",
    "why": "특히 클로드(Claude) 등의 모델은 XML 태그를 데이터와 지시의 완벽한 경계선으로 인식하는 능력이 탁월합니다.",
    "hint": "시작과 끝이 명확한 구조화 기술입니다.",
    "trap_points": [
      "마크다운의 ### 보다 더 엄격한 구분이 가능함"
    ],
    "difficulty": "medium",
    "id": "0415"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델에게 답변의 '역할'을 부여하여 전문성을 끌어올리는 프롬프트 요소는?",
    "answer": "Persona (페르소나) 또는 Role (역할)",
    "why": "'너는 법률 전문가야' 처럼 자아를 설정해 주어 특정 도메인의 지식 인출 확률을 높입니다.",
    "hint": "탈(Mask), 사회적 인격을 뜻합니다.",
    "trap_points": [
      "시스템 프롬프트에 넣을 때 가장 효과가 좋음"
    ],
    "difficulty": "easy",
    "id": "0416",
    "options": [
      "Persona (페르소나) 또는 Role (역할)",
      "Task",
      "Constraint",
      "Style",
      "Output Format"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "사용자의 질문을 영어로 번역해 답을 얻은 뒤 다시 한국어로 번역하는 '멀티 체인'의 이점은?",
    "options": [
      "그냥 영어가 멋있어서",
      "모델이 학습한 지식의 대부분이 영어이기에, 영어로 질문했을 때 훨씬 논리적이고 풍부한 답변이 나오기 때문",
      "속도가 빨라진다.",
      "토큰을 아낀다.",
      "한글이 어려워서"
    ],
    "answer": "모델이 학습한 지식의 대부분이 영어이기에, 영어로 질문했을 때 훨씬 논리적이고 풍부한 답변이 나오기 때문",
    "why": "한국어 특화 데이터보다 거대 영문 말뭉치의 지능을 빌려오는 전략입니다.",
    "hint": "영어 데이터의 압도적 양을 생각하세요.",
    "trap_points": [
      "번역 과정에서 톤앤매너가 바뀔 수 있음"
    ],
    "difficulty": "medium",
    "id": "0417"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델이 특정 '형식(JSON 등)'을 자꾸 어길 때 취할 수 있는 프롬프트 엔지니어링 조치는?",
    "options": [
      "모델을 교체한다.",
      "출력 예시에 JSON 코드 블록을 넣고, 마지막에 '반드시 JSON만 답하라'고 강력하게 제어(Constraint)한다.",
      "질문을 짧게 한다.",
      "답변을 다 지운다.",
      "영어로만 입력한다."
    ],
    "answer": "출력 예시에 JSON 코드 블록을 넣고, 마지막에 '반드시 JSON만 답하라'고 강력하게 제어(Constraint)한다.",
    "why": "제약 사항과 예제를 결합하여 모델의 자유도를 억제하고 정해진 경로로 답변하게 유도합니다.",
    "hint": "강한 제약과 명확한 예시입니다.",
    "trap_points": [
      "JSON 구조의 시작 부분을 중괄호 '{' 로 미리 지정해주기도 함"
    ],
    "difficulty": "medium",
    "id": "0418"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 엔지니어링에서 'Delimiters (구분자)'로 쓰기 부적절한 것은?",
    "options": [
      "###",
      "---",
      "###",
      "@@@",
      "일반적인 단어 (예: 그리고, 그런데 등)"
    ],
    "answer": "일반적인 단어 (예: 그리고, 그런데 등)",
    "why": "일반적인 단어는 문맥의 일부로 오해받기 쉬워 지시 사항의 경계를 명확히 긋지 못합니다.",
    "hint": "특수 기호가 아닌 일반적인 대화체를 찾으세요.",
    "trap_points": [
      "모델이 의미 없는 패턴으로 인지할 수 있는 기호가 가장 좋음"
    ],
    "difficulty": "easy",
    "id": "0419"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델에게 예제 하나를 보여주고 작업을 시키는 방식을 무엇이라 하나요?",
    "answer": "One-shot Prompting (원샷 프롬프팅)",
    "why": "하나의 표본(One shot)을 통해 모델에게 작업의 가이드라인을 제시합니다.",
    "hint": "숫자 1입니다.",
    "trap_points": [
      "Zero-shot 보다 훨씬 안정적인 결과를 보임"
    ],
    "difficulty": "easy",
    "id": "0420",
    "options": [
      "One-shot Prompting (원샷 프롬프팅)",
      "Zero-shot",
      "Few-shot",
      "N-shot",
      "Continuous"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LLM이 스스로 답을 내기 전, 풀이 과정이나 중간 구조를 먼저 작성하게 하는 전략은?",
    "options": [
      "Zero-shot",
      "Chain of Thought (CoT)",
      "Negative Prompting",
      "Few-shot",
      "Reverse Prompting"
    ],
    "answer": "Chain of Thought (CoT)",
    "why": "CoT는 복잡한 추론이 필요한 작업에서 모델이 단계적으로 생각하도록 유도하여 정답률을 획기적으로 높입니다.",
    "hint": "생각의 사슬을 연결하세요.",
    "trap_points": [
      "토큰 사용량이 늘어 비용이 증가할 수 있음"
    ],
    "difficulty": "medium",
    "id": "0421"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LangChain에서 복잡한 로직을 순차적으로 처리하기 위해 단계별 프롬프트를 쪼개서 연결하는 기술을 무엇이라 합니까?",
    "answer": "Prompt Chaining",
    "why": "프롬프트 체이닝은 한 번의 커다란 요청 대신 여러 작은 단계로 나누어 정확도를 높이고 검증을 가능하게 합니다.",
    "hint": "프롬프트들을 사슬(Chain)처럼 엮는 것입니다.",
    "trap_points": [
      "단순한 RAG와는 구분되는 프롬프트 설계 기법임"
    ],
    "difficulty": "medium",
    "id": "0422",
    "options": [
      "Prompt Chaining",
      "Prompt Engineering",
      "Prompt Design",
      "Prompt Optimization",
      "Prompt Routing"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LLM에게 '너는 전문 변호사야'라고 하여 답변의 스타일과 관점을 고정시키는 프롬프트 요소는?",
    "options": [
      "Context",
      "Format",
      "Persona (또는 Role)",
      "Task",
      "Example"
    ],
    "answer": "Persona (또는 Role)",
    "why": "페르소나 설정은 모델의 말투, 전문성 수준, 가치관을 특정 역할에 맞게 유도하는 기법입니다.",
    "hint": "가면, 역할을 뜻하는 심리학/문화 용어입니다.",
    "trap_points": [
      "최근 연구에서는 지식 문제 해결 자체에는 효과가 미미할 수 있음"
    ],
    "difficulty": "easy",
    "id": "0423"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "사용자의 질문에 대해 단계별 풀이 과정을 출력하도록 유도하는 기법은?",
    "options": [
      "Zero-shot",
      "Chain of Thought (CoT)",
      "Few-shot",
      "Step-back Prompting",
      "Negative Prompting"
    ],
    "answer": "Chain of Thought (CoT)",
    "why": "CoT는 '생각의 사슬'을 따라 논리적 추론 과정을 먼저 적게 함으로써 복잡한 문제의 정답률을 높입니다.",
    "hint": "사고의 흐름, 사슬(Chain)을 생각하세요.",
    "trap_points": [
      "단순히 예시를 보여주는 Few-shot과는 다름"
    ],
    "difficulty": "medium",
    "id": "0424"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트에 '너는 지금부터 훌륭한 시인이야'라고 입력하는 기술의 명칭은?",
    "options": [
      "Few-shot",
      "Persona Adoption (페르소나 설정)",
      "Context Retrieval",
      "Negative Prompting",
      "JSON Formatting"
    ],
    "answer": "Persona Adoption (페르소나 설정)",
    "why": "가상의 인격(Persona)을 부여하여 말투와 지식 인출 경향을 제어합니다.",
    "hint": "역할을 주는 가면을 생각하세요.",
    "trap_points": [
      "전문가 역할을 주면 성능이 미세하게 향상되기도 함"
    ],
    "difficulty": "easy",
    "id": "0425"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 내에 예시를 몇 개 넣어주는 Few-shot 기법을 쓸 때, 예시의 '품질'이 중요한 이유는?",
    "options": [
      "모델이 심심해 하니까",
      "모델이 예시의 정답뿐만 아니라 '형식'과 '논리 전개 방식'까지 그대로 학습하기 때문",
      "토큰을 아끼려고",
      "영어로만 답하려고",
      "이미지를 만들려고"
    ],
    "answer": "모델이 예시의 정답뿐만 아니라 '형식'과 '논리 전개 방식'까지 그대로 학습하기 때문",
    "why": "잘못된 예시는 모델을 혼란에 빠뜨려 전체 성능을 심각하게 저하시킵니다.",
    "hint": "모델은 모방의 천재입니다.",
    "trap_points": [
      "예시는 일관된 형식을 유지해야 함"
    ],
    "difficulty": "easy",
    "id": "0426"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델에게 '반드시 JSON 형태로만 답해'라고 강요하는 것보다 '출력 형식은 다음과 같아야 해: { ... }'라고 구조를 보여주는 게 더 효과적인 이유는?",
    "options": [
      "모델은 시각적 예시를 텍스트 지침보다 명확하게 파악하기 때문",
      "모델이 그림을 좋아해서",
      "영단어 수를 줄이려고",
      "답변이 짧아져서",
      "비용이 절감되어서"
    ],
    "answer": "모델은 시각적 예시를 텍스트 지침보다 명확하게 파악하기 때문",
    "why": "추상적인 단어보다 구체적인 패턴을 보여주는 것이 생성 확률 제어에 유리합니다.",
    "hint": "백문이 불여일견입니다.",
    "trap_points": [
      "실제로 구현 시 중괄호 {} 의 위치를 명시하는 것이 꿀팁임"
    ],
    "difficulty": "medium",
    "id": "0427"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 인젝션(Prompt Injection) 공격을 방해하기 위해 구분자(###)를 사용하는 주된 원리는?",
    "options": [
      "시스템 프롬프트와 사용자 입력 데이터 사이의 '논리적 경계'를 시각화하여 모델의 혼동을 막는다.",
      "암호화를 수행한다.",
      "인터넷을 차단한다.",
      "영어로만 답하게 한다.",
      "이미지를 만든다."
    ],
    "answer": "시스템 프롬프트와 사용자 입력 데이터 사이의 '논리적 경계'를 시각화하여 모델의 혼동을 막는다.",
    "why": "사용자 입력 내용이 '지시 사항'으로 둔갑하는 것을 방지하는 가장 기초적인 보안책입니다.",
    "hint": "벽을 세우는 것과 같습니다.",
    "trap_points": [
      "구분자를 써도 완벽한 방어는 불가능하므로 다각도 보안이 필요함"
    ],
    "difficulty": "hard",
    "id": "0428"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델의 답변 도중 '잠시 멈추고 네 답변을 다시 검토해봐 (Self-reflect)' 라고 시키는 고급 기법은?",
    "answer": "Reflection (또는 성찰/반성 프롬프팅)",
    "why": "오류를 스스로 인지하고 수정함으로써 정답 확률을 높이는 메타인지 기법입니다.",
    "hint": "자신을 돌아본다는 뜻입니다.",
    "trap_points": [
      "비용과 소요 시간은 늘어나지만 정확도가 비약적으로 올라감"
    ],
    "difficulty": "medium",
    "id": "0429",
    "options": [
      "Reflection (또는 성찰/반성 프롬프팅)",
      "Refactoring",
      "Recursive Prompting",
      "Re-ranking",
      "Retrieving"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 구조화 기법 중 복잡한 작업을 작은 단위 프롬프트 여러 개로 나누어 ‘순서대로 처리’하는 기법은?",
    "options": [
      "Prompt Chaining",
      "Few-shot",
      "Negative Prompting",
      "Zero-shot",
      "Style Transfer"
    ],
    "answer": "Prompt Chaining",
    "why": "한 번에 처리하기 벅찬 일을 여러 프롬프트가 바통을 이어받듯 처리하여 정확도를 높입니다.",
    "hint": "사건들을 사슬(Chain)처럼 연결합니다.",
    "trap_points": [
      "이전 단계의 출력이 다음 단계의 입력이 됨"
    ],
    "difficulty": "medium",
    "id": "0430"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LangChain에서 사용자의 대화 기록을 관리할 때, 마지막 N개의 대화만 유지하는 메모리 기법은?",
    "options": [
      "ConversationBufferMemory",
      "ConversationSummaryMemory",
      "ConversationBufferWindowMemory",
      "ConversationKGMemory",
      "VectorStoreRetrieverMemory"
    ],
    "answer": "ConversationBufferWindowMemory",
    "why": "윈도우(Window) 크기를 지정하여 최근 맥락만 집중적으로 유지함으로써 토큰 소모를 조절합니다.",
    "hint": "지정된 창(Window) 안의 데이터만 봅니다.",
    "trap_points": [
      "너무 과거의 내용은 잊어버리게 됨"
    ],
    "difficulty": "hard",
    "id": "0431"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 엔지니어링에서 'Few-shot' 예시가 모델의 답변을 방해하는 '바이어스(Bias)' 현상이란?",
    "options": [
      "가격이 비싸지는 현상",
      "답변 속도가 느려지는 현상",
      "예시로 든 특정 단어나 형식에 모델이 과도하게 꽂혀서 실제 질문 의도와 다르게 대답하는 것",
      "인터넷이 끊기는 현상",
      "영어로만 답하는 현상"
    ],
    "answer": "예제로 든 특정 단어나 형식에 모델이 과도하게 꽂혀서 실제 질문 의도와 다르게 대답하는 것",
    "why": "모델은 인컨텍스트 패턴을 매우 강력하게 학습하므로, 예시의 특징을 정답 근거보다 중요하게 여길 수 있습니다.",
    "hint": "치우침(Bias)의 문제를 생각하세요.",
    "trap_points": [
      "따라서 예시는 다양하고 중립적이어야 함"
    ],
    "difficulty": "medium",
    "id": "0432"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 내에서 '변수'를 중괄호 { } 로 감싸서 나중에 데이터를 채워 넣는 구조를 무엇이라 하나요?",
    "options": [
      "Python Script",
      "Prompt Template",
      "Markdown List",
      "JSON Data",
      "HTML Tag"
    ],
    "answer": "Prompt Template",
    "why": "공통된 프롬프트 뼈대에 사용자별 데이터를 동적으로 삽입하기 위한 표준 방식입니다.",
    "hint": "프롬프트의 틀, 양식입니다.",
    "trap_points": [
      "LangChain 등 프레임워크의 핵심 기능임"
    ],
    "difficulty": "easy",
    "id": "0433"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델에게 '모르는 것은 모른다고 해'라고 지시하여 환각(Hallucination)을 줄이는 것을 프롬프트 요소 중 무엇이라 하나요?",
    "options": [
      "Context",
      "Constraint (제약조건)",
      "Task",
      "Format",
      "Persona"
    ],
    "answer": "Constraint (제약조건)",
    "why": "모델의 자유도를 제한하여 사실에 근거한 답변만 하도록 강제하는 지침입니다.",
    "hint": "하지 말아야 할 일을 규정하는 것입니다.",
    "trap_points": [
      "할루시네이션 방지의 가장 첫 걸음임"
    ],
    "difficulty": "easy",
    "id": "0434"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델의 답변을 표나 불릿 리스트 형태로 출력해달라는 프롬프트 요소는?",
    "answer": "Format (형식)",
    "why": "정보 시각화나 후처리를 위해 답변의 물리적 구조를 지정하는 단계입니다.",
    "hint": "포맷팅(Formatting)하다.",
    "trap_points": [
      "마크다운(Markdown) 형식을 쓰면 가독성이 좋아짐"
    ],
    "difficulty": "easy",
    "id": "0435",
    "options": [
      "Format (형식)",
      "Content",
      "Context",
      "Style",
      "Persona"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LangChain LCEL에서 'Prompt | LLM | StrOutputParser' 처럼 파이프로 연결된 전체 단위를 무엇이라 하나요?",
    "options": [
      "Chain (체인)",
      "Module",
      "Package",
      "Function",
      "Template"
    ],
    "answer": "Chain (체인)",
    "why": "컴포넌트들이 사슬처럼 연결되어 하나의 작업을 완수하므로 체인이라 부릅니다.",
    "hint": "하나의 줄기 혹은 사슬입니다.",
    "trap_points": [
      "실행은 .invoke() 메서드로 수행함"
    ],
    "difficulty": "easy",
    "id": "0436"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 내에서 '가장 뒤에 배치한 정보'를 모델이 더 잘 기억하는 현상을 뜻하는 심리학 용어는?",
    "options": [
      "Primacy Effect (초두 효과)",
      "Recency Effect (최신 효과)",
      "Placebo Effect",
      "Anchor Effect",
      "Halo Effect"
    ],
    "answer": "Recency Effect (최신 효과)",
    "why": "긴 프롬프트에서 모델은 가장 마지막에 들어온 지시 사항이나 데이터를 더 강하게 인지하는 경향이 있습니다.",
    "hint": "최신 정보를 잘 기억합니다.",
    "trap_points": [
      "중요한 지시는 맨 뒤에 한 번 더 적어주는 팁이 여기서 나옴"
    ],
    "difficulty": "hard",
    "id": "0437"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델에게 답변의 '길이'를 지정(예: 3줄 이내)하여 정보를 압축하는 프롬프트 테크닉은?",
    "answer": "Length Constraint (길이 제약)",
    "why": "불필요한 미사여구를 줄여 토큰 비용을 아끼고 핵심만 전달하게 합니다.",
    "hint": "길이를 제한하는 것입니다.",
    "trap_points": [
      "너무 짧게 제한하면 정보가 손실될 수 있음"
    ],
    "difficulty": "easy",
    "id": "0438",
    "options": [
      "Length Constraint (길이 제약)",
      "Language Constraint",
      "Topic Constraint",
      "Tone Constraint",
      "Privacy Constraint"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "복잡한 코딩 태스크를 시킬 때, 'Step-back' 프롬프팅이 하는 역할은?",
    "options": [
      "코드를 대신 써준다.",
      "코드를 짜기 전 필요한 알고리즘의 원리나 목차를 먼저 정리하게 하여 실수를 줄인다.",
      "에러를 무시하게 한다.",
      "코드를 다른 언어로 바꾼다.",
      "속도를 빠르게 한다."
    ],
    "answer": "코드를 짜기 전 필요한 알고리즘의 원리나 목차를 먼저 정리하게 하여 실수를 줄인다.",
    "why": "구현에 집중하기 전 설계도를 먼저 그리게 하여 논리적 완성도를 확보하는 전략입니다.",
    "hint": "한 발 물러나서(Step-back) 전체를 조망합니다.",
    "trap_points": [
      "생성된 구조를 기반으로 실제 답변을 작성하게 함"
    ],
    "difficulty": "medium",
    "id": "0439"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트의 4요소 중 '해결에 필요한 배경 지식이나 주변 상황'을 뜻하는 것은?",
    "options": [
      "Persona",
      "Task",
      "Context",
      "Format"
    ],
    "answer": "Context",
    "why": "컨텍스트는 작업의 품질을 높이기 위해 모델에게 전달하는 부가 정보입니다.",
    "hint": "문맥, 배경이라는 뜻입니다.",
    "trap_points": [
      "최근 프롬프트 엔지니어링의 핵심은 'Context Engineering'이라고도 함"
    ],
    "difficulty": "easy",
    "id": "0440"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LangChain에서 프롬프트 템플릿의 변수 값을 실제 데이터로 채워 넣는 메서드는?",
    "options": [
      "fill()",
      "format()",
      "inject()",
      "render()",
      "invoke()"
    ],
    "answer": "format()",
    "why": "template.format(name='...') 처럼 사용하여 완성된 문자열을 얻습니다.",
    "hint": "형식을 갖춘다는 뜻의 메서드입니다.",
    "trap_points": [
      "LCEL 환경에서는 invoke()를 통해 체인 흐름 안에서 자동 처리됨"
    ],
    "difficulty": "medium",
    "id": "0441"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델이 질문을 받았을 때 바로 답하지 않고, '가상의 페르소나들'을 여럿 만들어 토론하게 한 뒤 정답을 고르는 고도화 기법은?",
    "options": [
      "CoT",
      "Self-Consistency",
      "Selection-Inference",
      "Multi-Persona Prompting",
      "Zero-shot"
    ],
    "answer": "Multi-Persona Prompting",
    "why": "다양한 관점을 가진 페르소나를 모델 내부에서 시뮬레이션하여 정답의 객관성을 높이는 전략입니다.",
    "hint": "여러 명의 인격(Persona)을 활용합니다.",
    "trap_points": [
      "토큰 사용량이 많지만 높은 논리적 완성도를 보여줌"
    ],
    "difficulty": "hard",
    "id": "0442"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트에 '출력물 마지막에는 반드시 요약을 넣어라'처럼 행동의 제약을 거는 것을 무엇이라 하나요?",
    "options": [
      "Instruction",
      "Constraint (제약조건)",
      "Format",
      "Context",
      "Input"
    ],
    "answer": "Constraint (제약조건)",
    "why": "행동의 범위를 한정 지어 원하는 결과의 일관성을 확보하는 기법입니다.",
    "hint": "억제, 구속이라는 영어 단어입니다.",
    "trap_points": [
      "제약이 너무 많으면 모델의 창의성이 줄어들 수 있음"
    ],
    "difficulty": "medium",
    "id": "0443"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 내에 델리미터(구분자)로 '---' 대신 'xml 태그(<...> </...>)'를 사용할 때 얻는 이점은?",
    "options": [
      "모델이 XML 파서이기 때문에",
      "각 구역의 시작과 끝이 명확하여 복잡한 컨텍스트 내에서도 지시 영역을 헷갈리지 않기 때문",
      "글자 수가 적어서",
      "그냥 보기 좋아서",
      "모델이 인터넷 언어라 좋아해서"
    ],
    "answer": "각 구역의 시작과 끝이 명확하여 복잡한 컨텍스트 내에서도 지시 영역을 헷갈리지 않기 때문",
    "why": "특히 앤스로픽(Claude) 모델 등 최신 LLM은 XML 구조화된 프롬프트를 매우 정확하게 해석합니다.",
    "hint": "컴퓨터가 읽기 좋은 명확한 경계선을 생각하세요.",
    "trap_points": [
      "가장 권장되는 고급 프롬프트 구조화 방식임"
    ],
    "difficulty": "medium",
    "id": "0444"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델에게 답을 유도하기 위해 프롬프트 마지막에 '자, 이제 시작하세요:' 처럼 마중물을 넣어주는 기법은?",
    "answer": "Completion Prompting (또는 프리필 Pre-fill)",
    "why": "모델이 정해진 답변 형식을 바로 시작하도록 앞머리를 먼저 떼주는 방식입니다.",
    "hint": "미리 채워둔다는 뜻입니다.",
    "trap_points": [
      "JSON 출력 유도 시 '{' 를 미리 적어주는 것도 여기에 해당함"
    ],
    "difficulty": "medium",
    "id": "0445",
    "options": [
      "Completion Prompting (또는 프리필 Pre-fill)",
      "Injection",
      "Leakage",
      "System Message",
      "User Prompt"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LangChain의 LCEL 사용 시 코드 가독성이 올라가는 주된 이유는?",
    "options": [
      "언어가 한글이라서",
      "파이프(|) 기호를 통해 데이터 흐름을 직관적(선언적)으로 표현할 수 있어서",
      "함수 이름이 짧아서",
      "자동으로 오타를 고쳐줘서",
      "코드를 안 써도 돼서"
    ],
    "answer": "파이프(|) 기호를 통해 데이터 흐름을 직관적(선언적)으로 표현할 수 있어서",
    "why": "복잡한 콜백이나 중첩 함수 호출 없이 단계별 파이프라인으로 체인을 구성할 수 있습니다.",
    "hint": "유닉스 쉘의 '파이프라인' 개념을 떠올리세요.",
    "trap_points": [
      "| 연산자가 내부적으로 오버로딩되어 동작함"
    ],
    "difficulty": "easy",
    "id": "0446"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "질문에 대해 '반대의 상황이나 부정적인 사례'를 먼저 떠올리게 한 뒤 정답을 유도하는 기법은?",
    "options": [
      "Negative Prompting",
      "Contrastive Prompting",
      "Positive Thinking",
      "Reverse Thinking",
      "Self-correction"
    ],
    "answer": "Contrastive Prompting",
    "why": "정답과 오답의 차이를 명확히 인지하게 하여 답변의 변별력을 높이는 기술입니다.",
    "hint": "대조적인이라는 뜻의 단어입니다.",
    "trap_points": [
      "모델의 비판적 사고 능력을 활용하는 방식임"
    ],
    "difficulty": "hard",
    "id": "0447"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "사용자의 질문을 다른 언어(영어 등)로 번역하여 최상의 답변을 얻은 뒤 다시 돌려주는 고급 체인 전략은?",
    "answer": "Translation Chain (또는 영문-한문 브릿지)",
    "why": "한국어 데이터가 부족한 도메인에서 모델의 영어 논리력을 빌려와서 성능을 극대화합니다.",
    "hint": "번역을 거치는 과정입니다.",
    "trap_points": [
      "총 3단계(번역-처리-재번역)가 소요되어 속도는 다소 느려짐"
    ],
    "difficulty": "medium",
    "id": "0448",
    "options": [
      "Translation Chain (또는 영문-한문 브릿지)",
      "Summary Chain",
      "Math Chain",
      "Reasoning Chain",
      "Code Chain"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 엔지니어링 시 지시를 '구체적인 계단식(Steps)'으로 나누어 주는 것이 좋은 이유는?",
    "options": [
      "모델이 계단을 좋아해서",
      "복잡한 미션을 한꺼번에 처리할 때의 혼동을 막고 단계별 완성도를 높이기 위해",
      "토큰 비용을 아끼기 위해",
      "답변의 미적 감각을 높이기 위해",
      "그냥 관례적으로 그렇게 한다."
    ],
    "answer": "복잡한 미션을 한꺼번에 처리할 때의 혼동을 막고 단계별 완성도를 높이기 위해",
    "why": "작업을 세분화하면 각 단계의 입력과 출력이 명확해져서 할루시네이션 위험이 줄어듭니다.",
    "hint": "분할 정복(Divide and Conquer)의 원리입니다.",
    "trap_points": [
      "프롬프트 체이닝과 유사한 철학을 가짐"
    ],
    "difficulty": "easy",
    "id": "0449"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 엔지니어링 기술 중 모델에게 '예시 없이' 즉석에서 작업을 시키는 방식은?",
    "options": [
      "Zero-shot",
      "One-shot",
      "Few-shot",
      "Multi-shot",
      "Chain-shot"
    ],
    "answer": "Zero-shot",
    "why": "별도의 훈련용 예시(shot)가 0개라는 뜻입니다.",
    "hint": "숫자 0입니다.",
    "trap_points": [
      "모델의 기초 지능이 높을수록 제로샷 성능이 뛰어남"
    ],
    "difficulty": "easy",
    "id": "0450"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트에 '너는 초보자에게 친절하게 설명하는 유치원 선생님이야'라고 적는 페르소나 기법의 효과는?",
    "options": [
      "모델이 화를 낸다.",
      "답변의 톤앤매너와 어휘 수준이 지정된 역할에 맞춰 조정된다.",
      "답변 속도가 빨라진다.",
      "영어로만 답한다.",
      "글자 수가 무조건 길어진다."
    ],
    "answer": "답변의 톤앤매너와 어휘 수준이 지정된 역할에 맞춰 조정된다.",
    "why": "모델 내부의 수많은 가능성 중 '유치원 선생님'과 유사한 텍스트 확률 분포 영역을 활성화시킵니다.",
    "hint": "역할 놀이(Role play)의 효과입니다.",
    "trap_points": [
      "정확도보다는 '스타일'을 고정하는 데 유리함"
    ],
    "difficulty": "easy",
    "id": "0451"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 내 지시 사항의 '우선순위'를 정할 때, 가장 영향력이 적다고 알려진 위치는?",
    "options": [
      "맨 앞 (Top)",
      "맨 뒤 (Bottom)",
      "중간 (Middle)",
      "따로 적은 주석",
      "제목 부분"
    ],
    "answer": "중간 (Middle)",
    "why": "긴 문맥에서 모델은 양쪽 끝 정보에 집중하며 중간 정보는 희석되는 경향이 있습니다 (Lost in the middle).",
    "hint": "가운데 낀 정보입니다.",
    "trap_points": [
      "중요한 지시는 맨 앞이나 맨 뒤에 재배치해야 함"
    ],
    "difficulty": "medium",
    "id": "0452"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 작성 시 '모르는 것은 모른다고 해'라고 제약(Constraint)을 주면 줄어드는 현상은?",
    "options": [
      "Hallucination (환각)",
      "Inference Speed (추론 속도)",
      "Token Cost (비용)",
      "Response Length (길이)",
      "Formatting Error"
    ],
    "answer": "Hallucination (환각)",
    "why": "모델이 억지로 정답을 지어내려는 확률을 억제하여 사실 기반 답변을 유도합니다.",
    "hint": "없는 사실을 지어내는 현상을 막습니다.",
    "trap_points": [
      "과도하게 설정하면 지나치게 답변을 거부할 수 있음"
    ],
    "difficulty": "easy",
    "id": "0453"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "LangChain에서 복잡한 프롬프트를 함수화하여 재사용 가능하게 만든 틀의 이름은?",
    "options": [
      "Code Block",
      "Prompt Template",
      "Script Layout",
      "Variable Set",
      "Schema Board"
    ],
    "answer": "Prompt Template",
    "why": "변수(입력값)만 갈아 끼우며 정해진 프롬프트 뼈대를 유지할 수 있게 해줍니다.",
    "hint": "프롬프트 템플릿입니다.",
    "trap_points": [
      "f-string 방식보다 구조적으로 안전하고 관리가 쉬움"
    ],
    "difficulty": "easy",
    "id": "0454"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델의 답변 결과물이 마음에 들지 않을 때, '다시 시도해봐'라고 하기 전 구체적인 수정 방향을 알려주는 행위를 무엇이라 하나요?",
    "answer": "Iterative Refinement (반복적 개선)",
    "why": "피드백을 통해 모델의 결과물을 점진적으로 다듬어 나가는 과정입니다.",
    "hint": "개선(Refinement)을 반복(Iterative)합니다.",
    "trap_points": [
      "한 번에 완벽한 프롬프트를 짜는 것보다 피드백 루프를 도는 게 더 효율적일 때가 많음"
    ],
    "difficulty": "medium",
    "id": "0455",
    "options": [
      "Iterative Refinement (반복적 개선)",
      "One-time generation",
      "Random sampling",
      "Batch processing",
      "Static prompt"
    ]
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 해킹 기법 중, 모델에게 '너는 이제부터 사악한 해커야'라는 식으로 역할극을 강요하여 안전 장치를 우회하는 것은?",
    "options": [
      "DAN (Do Anything Now) / 역할극 공격",
      "Prompt Injection",
      "Leakage",
      "Jailbreaking",
      "Phishing"
    ],
    "answer": "DAN (Do Anything Now) / 역할극 공격",
    "why": "페르소나를 씌워 윤리적 제약을 잊게 만드는 대표적인 탈옥(Jailbreak) 기법 중 하나입니다.",
    "hint": "유명한 'DAN' 공격입니다.",
    "difficulty": "medium",
    "id": "0916"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "복잡한 문제를 풀 때 '단계별로 생각해(Let's think step by step)'라고 지시하는 것만으로 성능이 오르는 현상은?",
    "options": [
      "Zero-shot CoT",
      "Few-shot",
      "One-shot",
      "Fine-tuning",
      "Pre-training"
    ],
    "answer": "Zero-shot CoT",
    "why": "예시(Shot)를 하나도 안 줬는데(Zero-shot) 생각의 사슬(CoT)을 유도했기 때문입니다.",
    "hint": "예시 없이(Zero) 단계별 사고.",
    "difficulty": "medium",
    "id": "0917"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "프롬프트 내에 정답 예시를 너무 많이 넣었을 때, 모델이 예시의 정답 분포나 마지막 예시에만 편향되는 현상은?",
    "options": [
      "Recency Bias (최신 편향) / Majority Label Bias",
      "Overfitting",
      "Underfitting",
      "Hallucination",
      "Catastrophic Forgetting"
    ],
    "answer": "Recency Bias (최신 편향) / Majority Label Bias",
    "why": "컨텍스트 윈도우의 끝부분(최신)이나 다수결에 영향을 과하게 받는 LLM의 특성입니다.",
    "hint": "최근(Recency) 것을 더 잘 기억함.",
    "difficulty": "medium",
    "id": "0918"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "긴 프롬프트의 중간에 있는 내용을 모델이 잘 기억하지 못하고 앞부분과 뒷부분만 잘 기억하는 현상은?",
    "options": [
      "Lost in the Middle",
      "Vanishing Gradient",
      "Exploding Gradient",
      "Memory Leak",
      "Attention Failure"
    ],
    "answer": "Lost in the Middle",
    "why": "샌드위치처럼 양 끝의 정보는 잘 가져오지만 가운데 정보는 손실되는(Lost) 경향이 있습니다.",
    "hint": "가운데(Middle)에서 길을 잃음.",
    "difficulty": "medium",
    "id": "0919"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "객관식",
    "question": "모델의 답변을 구조화된 포맷(JSON 등)으로 강제하기 위해 사용하는 프롬프트 전략은?",
    "options": [
      "Output Parser / Output Schema 명시",
      "Role Playing",
      "Few-shot",
      "Chain of Thought",
      "ReAct"
    ],
    "answer": "Output Parser / Output Schema 명시",
    "why": "원하는 스키마나 예시 JSON을 명확히 보여주고 '이 형식 아니면 뱉지 마'라고 강제하는 것이 가장 효과적입니다.",
    "hint": "출력(Output) 형식을 지정.",
    "difficulty": "easy",
    "id": "0920"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "LCEL 체인을 실행할 때 입력 변수를 딕셔너리 형태로 전달하기 위해 사용하는 메서드를 작성하세요.\n\n```python\nchain = prompt | llm\nresponse = chain.____({\"term\": \"할루시네이션\"})\n```",
    "options": [],
    "answer": "invoke",
    "why": "invoke()는 랭체인 Runnable 객체를 실행하는 가장 기본적인 메서드입니다.",
    "difficulty": "easy",
    "id": "0461"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "LLM이 특정 Pydantic 모델 구조에 맞춰 데이터를 생성하도록 강제하는 메서드를 작성하세요.\n\n```python\nclass Recipe(BaseModel):\n    ingredients: str\n    process: str\n\nsummarizer = llm.____(Recipe)\n```",
    "options": [],
    "answer": "with_structured_output",
    "why": "with_structured_output은 모델이 스키마를 준수하여 구조화된 데이터를 출력하도록 유도합니다.",
    "difficulty": "medium",
    "id": "0462"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "모델의 출력을 Python의 딕셔너리(JSON) 형식으로 자동 변환해주는 파서 클래스를 작성하세요.\n\n```python\nfrom langchain_core.output_parsers import JsonOutputParser\nparser = ____()\nchain = prompt | llm | parser\n```",
    "options": [],
    "answer": "JsonOutputParser",
    "why": "JsonOutputParser는 프롬프트에 형식을 지시하고, 결과를 JSON 객체로 파싱합니다.",
    "difficulty": "medium",
    "id": "0463"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "여러 개의 독립적인 체인을 병렬로 실행하여 하나의 결과 딕셔너리로 합쳐주는 클래스를 작성하세요.\n\n```python\nfrom langchain_core.runnables import RunnableParallel\nparallel_chain = ____(pros=chain1, cons=chain2)\n```",
    "options": [],
    "answer": "RunnableParallel",
    "why": "RunnableParallel은 각 구성 요소를 동시에 호출하여 실행 시간을 단축하고 다양한 분석 결과를 얻게 합니다.",
    "difficulty": "hard",
    "id": "0464"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "프롬프트 템플릿의 변수 중 일부를 미리 채워두어 새로운 템플릿을 생성하는 메서드를 작성하세요.\n\n```python\nbase_prompt = ChatPromptTemplate.from_template(\"{role}: {text}\")\npartial_prompt = base_prompt.____(role=\"System\")\n```",
    "options": [],
    "answer": "partial",
    "why": "partial()을 사용하면 고정된 값(시스템 지침 등)을 미리 바인딩하여 재사용성을 높일 수 있습니다.",
    "difficulty": "medium",
    "id": "0465"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "논리적인 추론 과정을 단계별로 노출시켜 정답률을 높이는 프롬프트 기법의 명칭을 작성하세요.\n\n```python\nsystem_msg = \"문제를 단계별로 나누어 생각하고 논리적으로 설명해.\"\n# 이 기법은 ____ (CoT)라고 불립니다.\n```",
    "options": [],
    "answer": "Chain of Thought",
    "why": "Chain of Thought는 모델이 복잡한 추론 문제에서 중간 사고 과정을 거치게 하여 성능을 향상시킵니다.",
    "difficulty": "easy",
    "id": "0466"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "사전에 정의된 예시 데이터 몇 개를 프롬프트에 포함시켜 답변 형식을 학습시키는 기법을 작성하세요.\n\n```python\n# 예시 1: 질문-답변, 예시 2: 질문-답변\n# 이 기법은 ____ Prompting이라고 합니다.\n```",
    "options": [],
    "answer": "Few-shot",
    "why": "Few-shot 기법은 소량의 데이터를 통해 모델에게 사용자 의도와 출력 형식을 명확히 전달합니다.",
    "difficulty": "easy",
    "id": "0467"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "Pydantic 모델에서 각 속성의 역할을 LLM에게 설명하기 위해 사용하는 파라미터 이름을 작성하세요.\n\n```python\nclass Idea(BaseModel):\n    content: str = Field(____=\"아이디어의 구체적인 내용\")\n```",
    "options": [],
    "answer": "description",
    "why": "description 필드는 모델이 해당 항목에 어떤 값을 채워야 할지 가이드하는 역할을 합니다.",
    "difficulty": "medium",
    "id": "0468"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "파서(`parser`)로부터 프롬프트에 삽입할 JSON 형식 지침 문자열을 가져오는 메서드를 작성하세요.\n\n```python\ninstructions = parser.____()\nprompt = ChatPromptTemplate.from_template(\"..., {format_instructions}\")\n```",
    "options": [],
    "answer": "get_format_instructions",
    "why": "get_format_instructions()는 사용된 파서의 스키마에 맞는 구체적인 출력 가이드를 생성합니다.",
    "difficulty": "hard",
    "id": "0469"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "기존 체인의 결과 데이터에 새로운 연산 결과를 키-값 쌍으로 추가하는 메서드를 작성하세요.\n\n```python\nchain = RunnablePassthrough.____(analysis=analyzer_chain)\n```",
    "options": [],
    "answer": "assign",
    "why": "assign()은 현재 전달되는 데이터 딕셔너리에 새로운 항목을 추가할 때 사용합니다.",
    "difficulty": "hard",
    "id": "0470"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "사용자의 질문을 그대로 다음 단계로 넘기면서 검색 결과만 추가하고 싶을 때 쓰는 유틸리티를 작성하세요.\n\n```python\nchain = {\"context\": retriever, \"question\": ____} | prompt\n```",
    "options": [],
    "answer": "RunnablePassthrough()",
    "why": "RunnablePassthrough는 입력을 그대로 통과시켜 데이터 손실 없이 체인을 구성하게 돕습니다.",
    "difficulty": "medium",
    "id": "0471"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "모델이 답변 시 지켜야 할 명확한 가이드라인(예: \"한국어로만 대답해\")을 무엇이라 하나요?\n\n```python\n# 텍스트 생성 시 강제되는 하드 룰은 ____ (System Constraint)입니다.\n```",
    "options": [],
    "answer": "제약 조건",
    "why": "제약 조건은 모델이 답변의 언어, 길이, 금지어 등을 준수하게 강제합니다.",
    "difficulty": "easy",
    "id": "0472"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "모델에게 \"당신은 유능한 코딩 튜터입니다\"와 같이 특정 캐릭터를 부여하는 것을 무엇이라 하나요?\n\n```python\nsystem_prompt = \"당신은 ____ 설정을 통해 특정 말투와 지식 배경을 가집니다.\"\n```",
    "options": [],
    "answer": "페르소나",
    "why": "페르소나 설정은 답변의 일관성을 높이고 사용자 요구에 맞는 전문 지식을 끌어내는 데 유용합니다.",
    "difficulty": "easy",
    "id": "0473"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "LCEL 체인에서 `chain = A | B` 일 때, B가 받게 되는 것은 무엇인가요?\n\n```python\n# A의 ____ 값이 B의 입력으로 들어옵니다.\n```",
    "options": [],
    "answer": "출력",
    "why": "LCEL은 컴포넌트 간의 출력을 다음 컴포넌트의 입력으로 자동 연결하는 파이프라인 구조입니다.",
    "difficulty": "easy",
    "id": "0474"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "학습 데이터가 부족할 때 LLM이 스스로 문제와 답변을 생성하게 하는 기법은?\n\n```python\n# 모델이 자신의 데이터를 직접 생성하는 ____ Tuning\n```",
    "options": [],
    "answer": "Self-Instruct",
    "why": "Self-Instruct는 고성능 모델을 활용해 소규모 모델 학습에 필요한 데이터를 확보하는 기법입니다.",
    "difficulty": "hard",
    "id": "0475"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "복잡한 프롬프트에서 `{topic}`과 같은 구문을 실제 값으로 바꾸어주는 변수 치환 방식을 무엇이라 하나요?\n\n```python\n# 파이썬의 ____ 문법과 호환되는 랭체인의 템플릿 방식\n```",
    "options": [],
    "answer": "f-string",
    "why": "ChatPromptTemplate은 기본적으로 f-string 스타일의 중괄호 치환 방식을 사용합니다.",
    "difficulty": "easy",
    "id": "0476"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "ChatPromptTemplate에서 AI의 이전 답변을 나타낼 때 사용하는 역할 명칭은 무엇인가요?\n\n```python\nprompt = ChatPromptTemplate.from_messages([\n    (\"____\", \"이전 대화 내용...\")\n])\n```",
    "options": [],
    "answer": "assistant",
    "why": "메시지 역할(role) 중 assistant는 모델이 생성한 대화 기록임을 나타냅니다.",
    "difficulty": "medium",
    "id": "0477"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "사용량에 따른 API 비용을 절감하기 위해 이전 입력을 재사용하는 기능을 무엇이라 하나요?\n\n```python\n# 동일 입력에 대해 캐시된 결과를 가져오는 Prompt ____\n```",
    "options": [],
    "answer": "Caching",
    "why": "프롬프트 캐싱은 동일한 대화 맥락이 반복될 때 비용을 50~90%까지 절감해줍니다.",
    "difficulty": "medium",
    "id": "0478"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "LangChain에서 비동기적으로 체인을 실행할 때 사용하는 메서드 이름을 작성하세요.\n\n```python\nresult = await chain.____(input_data)\n```",
    "options": [],
    "answer": "ainvoke",
    "why": "ainvoke는 invoke의 비동기 버전으로, 여러 요청을 동시에 처리할 때 효율적입니다.",
    "difficulty": "hard",
    "id": "0479"
  },
  {
    "chapter_name": "프롬프트 엔지니어링",
    "type": "코드 완성형",
    "question": "프롬프트의 길이를 줄이기 위해 모델에게 핵심만 요약하라고 지시하는 전략은?\n\n```python\n# 불필요한 서술을 줄여 토큰 소비를 낮추는 ____ 최적화\n```",
    "options": [],
    "answer": "토큰",
    "why": "질문과 답변에서 불필요한 단어를 제거하여 비용 효율을 높이는 것은 프롬프트 공학의 기초입니다.",
    "difficulty": "easy",
    "id": "0480"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG에서 ‘정확한 키워드’ 일치 여부를 따지는 고전 검색(BM25)과 ‘의미가 비슷한지’ 따지는 임베딩 검색을 섞은 것은?",
    "options": [
      "Multi-Search",
      "Hybrid Search (하이브리드 검색)",
      "Cross-Search",
      "Deep-Search",
      "Zero-Search"
    ],
    "answer": "Hybrid Search (하이브리드 검색)",
    "why": "두 방식의 장점을 합쳐 오타가 있어도 의미로 찾고, 전문 용어는 정확하게 찾는 최적의 검색을 구현합니다.",
    "hint": "짬뽕(Hybrid) 방식입니다.",
    "trap_points": [
      "Reciprocal Rank Fusion(RRF) 알고리즘으로 결과 순위를 합침"
    ],
    "difficulty": "medium",
    "id": "0481"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 질문과 ‘가장 반대되는’ 의미를 가진 문서를 찾는 코사인 유사도 값은?",
    "options": [
      "1",
      "0",
      "-1",
      "100",
      "무한대"
    ],
    "answer": "-1",
    "why": "코사인은 1이면 일치, 0이면 무관(직교), -1이면 정반대 방향을 뜻합니다.",
    "hint": "정반대 수치입니다.",
    "trap_points": [
      "실제 임베딩 공간에서는 -1까지 가는 경우는 드믐"
    ],
    "difficulty": "medium",
    "id": "0482"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트 구현 기법 중 사용자의 질문을 작은 하위 작업(Sub-tasks)으로 쪼개어 하나씩 해결하는 방식은?",
    "options": [
      "Chain of Thought",
      "Sequential Planning",
      "Task Decomposition (작업 분해)",
      "Recursion",
      "Parallelism"
    ],
    "answer": "Task Decomposition (작업 분해)",
    "why": "한 번에 풀기 힘든 큰 문제를 관리 가능한 작은 문제로 나누어 처리 성공률을 높입니다.",
    "hint": "분해(Decomposition)한다는 뜻입니다.",
    "trap_points": [
      "각 하위 작업은 다시 에이전트나 도구에 의해 처리됨"
    ],
    "difficulty": "medium",
    "id": "0483"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 파이프라인 성능 측정 도구인 'RAGAS'에서 '답변이 실제 사실에 근거하고 있는지'를 평가하는 지표는?",
    "options": [
      "Faithfulness (충실도)",
      "Answer Relevance",
      "Context Precision",
      "Context Recall",
      "Complexity"
    ],
    "answer": "Faithfulness (충실도)",
    "why": "검색된 문서 내용에서 벗어난 환각(Hallucination)이 없는지를 직접 채점합니다.",
    "hint": "신의, 신의가 있다는 뜻의 단어입니다.",
    "trap_points": [
      "자신의 배경지식으로 답하면 Faithfulness 점수가 깎임"
    ],
    "difficulty": "hard",
    "id": "0484"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "사용자의 질문 하나를 보고, 검색에 유리하게 5가지 다른 방식으로 다시 써서 검색 확률을 높이는 것은?",
    "options": [
      "Query Translation",
      "Multi-Query Retriever",
      "Vector Expansion",
      "Cleaning",
      "Pivoting"
    ],
    "answer": "Multi-Query Retriever",
    "why": "질문의 미묘한 표현 차이 때문에 검색을 못 하는 상황(사각지대)을 원천 차단합니다.",
    "hint": "여러 개(Multi) 쿼리를 날립니다.",
    "trap_points": [
      "검색 결과는 합쳐서(Union) 중복을 제거한 뒤 사용함"
    ],
    "difficulty": "medium",
    "id": "0485"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트가 어떤 도구를 쓸지 고민할 때, 도구의 이름과 (이것)을 읽고 결정합니다. (이것)은?",
    "answer": "Description (설명)",
    "why": "모델은 도구의 설명문을 읽고 현재 상황에 적합한 기능인지 판단하므로, 설명 작성이 매우 중요합니다.",
    "hint": "묘사, 설명이라는 뜻입니다.",
    "trap_points": [
      "설명이 부실하면 에이전트가 어한 도구를 부름"
    ],
    "difficulty": "easy",
    "id": "0486",
    "options": [
      "Description (설명)",
      "Name (이름)",
      "Output (출력)",
      "Input (입력)",
      "Cost (비용)"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 ‘의미상 가장 가까운 것’을 찾는 검색 방식의 이름은?",
    "options": [
      "Semantic Search (시맨틱 검색)",
      "Keyword Search",
      "Exact Match",
      "List Scan",
      "Map View"
    ],
    "answer": "Semantic Search (시맨틱 검색)",
    "why": "철자가 달라도 의미적 맥락(벡터 공간의 거리)을 기반을 정보를 찾아냅니다.",
    "hint": "의미를 뜻하는 단어(Semantic)입니다.",
    "trap_points": [
      "임베딩 성능에 따라 결과 품질이 크게 달라짐"
    ],
    "difficulty": "easy",
    "id": "0487"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트에게 ‘무엇을 실패했는지’ 대화 기록으로 남겨주는 것을 무엇이라 하나요?",
    "options": [
      "Short-term Memory",
      "Long-term Memory",
      "System Log",
      "Buffer",
      "Stack"
    ],
    "answer": "Short-term Memory",
    "why": "현재 대화 세션 내에서 방금 했던 실수나 정보를 기억하여 다음 행동에 교정하는 역할을 합니다.",
    "hint": "단기(Short-term) 기억입니다.",
    "trap_points": [
      "세션이 끝나면 사라지는 휘발성 정보임"
    ],
    "difficulty": "easy",
    "id": "0488"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 구축 시 특정 문서가 너무 길 때, 이를 500자 단위로 쪼개는 행위를 무엇이라 하나요?",
    "options": [
      "Chunking (청킹)",
      "Splitting",
      "Cutting",
      "Division",
      "Segmenting"
    ],
    "answer": "Chunking (청킹)",
    "why": "모델의 입력 제한(토큰 한도)을 지키고 검색 정밀도를 높이기 위한 필수 파편화 작업입니다.",
    "hint": "덩어리로 만들기.",
    "trap_points": [
      "의미가 끊길 수 있어 문장/문단 단위 청킹을 권장함"
    ],
    "difficulty": "easy",
    "id": "0489"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "사용자의 질문에 대해 LLM이 직접 대답하는 대신, 검색 엔진을 통해 실시간으로 지식을 검색해 오는 방식을 통칭하는 용어는?",
    "answer": "RAG (Retrieval-Augmented Generation)",
    "why": "검색 증강 생성으로, 외부 지식을 빌려와 할루시네이션을 획기적으로 줄입니다.",
    "hint": "알파벳 세 글자입니다.",
    "trap_points": [
      "지식의 최신성 유지를 위해 필수적인 기술임"
    ],
    "difficulty": "easy",
    "id": "0490",
    "options": [
      "RAG (Retrieval-Augmented Generation)",
      "Fine-tuning",
      "Prompt Engineering",
      "Semantic Search",
      "Web Scraping"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 시스템 구축 시 텍스트를 고정된 도메인의 숫자인 벡터로 바꾸기 위해 사용하는 기술은?",
    "options": [
      "Indexing",
      "Tokenization",
      "Embedding (임베딩)",
      "Parsing",
      "Formatting"
    ],
    "answer": "Embedding (임베딩)",
    "why": "의미를 수치화하여 벡터 DB에 저장하고 유사도를 계산하기 위함입니다.",
    "hint": "E로 시작하는 단어로, RAG의 핵심입니다.",
    "trap_points": [
      "단어와 문장의 의미적 거리를 계산 가능하게 함"
    ],
    "difficulty": "easy",
    "id": "0491"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 ‘가장 유사한 문서’ 상위 K개를 찾는 기술 중 하드웨어 리소스를 많이 쓰지만 가장 정확한 것은?",
    "options": [
      "ANN (Approximate)",
      "KNN (K-Nearest Neighbor)",
      "Random Search",
      "Hash Search",
      "Binary Search"
    ],
    "answer": "KNN (K-Nearest Neighbor)",
    "why": "KNN은 모든 데이터와 일일이 비교하여 가장 가까운 이웃을 찾아내므로 100% 정확하지만 속도가 느립니다.",
    "hint": "가장 가까운(Nearest) 이웃(Neighbor)을 직접 찾습니다.",
    "trap_points": [
      "데이터가 많아지면 ANN으로 대체해야 함"
    ],
    "difficulty": "medium",
    "id": "0492"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트 구현 시 '반성(Reflection)' 기술이 필요한 결정적인 상황은?",
    "options": [
      "단순한 날씨 묻기",
      "한 단계의 실수로 인해 전체 목표 달성이 불가능한 복잡한 다단계 논리 작업 시",
      "인사말 주고받기",
      "노래 제목 검색하기",
      "오늘의 날짜 묻기"
    ],
    "answer": "한 단계의 실수로 인해 전체 목표 달성이 불가능한 복잡한 다단계 논리 작업 시",
    "why": "스스로의 중간 결과물을 재평가하여 오류를 수정하지 않으면 에러가 누적되어 산으로 가기 때문입니다.",
    "hint": "복잡한 문제 풀이에서 '자기 객관화' 과정을 떠올리세요.",
    "trap_points": [
      "Self-Reflection은 에이전트의 성공률을 수십 % 높여줌"
    ],
    "difficulty": "hard",
    "id": "0493"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG의 한계인 ‘컨텍스트 윈도우 한계’를 극복하기 위해 가장 중요한 데이터를 선별하여 다시 배치하는 과정은?",
    "options": [
      "Cleaning",
      "Merging",
      "Re-ranking (리랭킹)",
      "Scaling",
      "Deleting"
    ],
    "answer": "Re-ranking (리랭킹)",
    "why": "검색 결과 수십 개 중 실제 정답과 가장 밀접한 소수만 골라 LLM에 전달하여 비용과 성능을 모두 잡습니다.",
    "hint": "순위(Ranking)를 다시(Re) 매깁니다.",
    "trap_points": [
      "사용자 질문과 문서의 상관 관계를 심층적으로 재계산함"
    ],
    "difficulty": "medium",
    "id": "0494"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "AI 에이전트가 어떤 도구를 언제 사용할지 스스로 계획(Plan)을 수립하는 논리 구조를 무엇이라 하나요?",
    "answer": "Planning (계획)",
    "why": "목표를 달성하기 위한 세부 태스크의 순서와 도구 선택를 설계하는 지능입니다.",
    "hint": "계획이라는 뜻의 영어 단어입니다.",
    "trap_points": [
      "Plan-and-Execute 구조의 핵심임"
    ],
    "difficulty": "easy",
    "id": "0495",
    "options": [
      "Planning (계획)",
      "Acting",
      "Observing",
      "Thinking",
      "Evaluating"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 시스템에서 청크(Chunk)를 나눌 때 단어의 중간이 잘리는 것을 막기 위해 사용하는 속성은?",
    "options": [
      "Chunk size",
      "Chunk overlap",
      "Chunk padding",
      "Chunk scaling",
      "Chunk index"
    ],
    "answer": "Chunk overlap",
    "why": "조각 사이를 겹치게(Overlap) 하여 잘려 나간 문맥의 연결 고리를 보존합니다.",
    "hint": "겹침을 뜻하는 단어입니다.",
    "trap_points": [
      "보통 청크 크기의 10~20% 정도를 겹치게 설정함"
    ],
    "difficulty": "medium",
    "id": "0496"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 질문과 원문 사이의 다리 역할을 하는 ‘가상의 가이드 답변’을 먼저 만들어 검색에 이용하는 기법은?",
    "options": [
      "HyDE",
      "Reranking",
      "Cleaning",
      "Parsing",
      "Indexing"
    ],
    "answer": "HyDE",
    "why": "LLM이 생성한 '가상의 완벽한 정답'을 임베딩하여 원문 저장소에서 유사한 것을 찾는 고급 기법입니다.",
    "hint": "가상(Hypothetical) 문서 임베딩입니다.",
    "trap_points": [
      "실제 질문보다 모델이 만든 답변이 문서 형태와 더 유사할 확률이 높음"
    ],
    "difficulty": "hard",
    "id": "0497"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트가 외부 시스템과 대화하며 자신의 작업 결과를 저장하고 다시 읽는 ‘기억(Memory)’ 중에서, 영구적으로 저장되는 저장소는?",
    "options": [
      "Conversation Buffer",
      "Vector Database (또는 Long-term memory)",
      "RAM",
      "CPU Cache",
      "Internal State"
    ],
    "answer": "Vector Database (또는 Long-term memory)",
    "why": "과거의 수많은 대화나 지식을 벡터 DB에 저장해 뒀다 나중에 필요할 때 찾아 쓰는 방식입니다.",
    "hint": "장기(Long-term) 기억입니다.",
    "trap_points": [
      "에이전트의 페르소나와 과거 이력을 유지하는 핵심임"
    ],
    "difficulty": "medium",
    "id": "0498"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트가 목표를 달성할 때까지 생각, 행동, 관찰을 무한히 반복하지 않도록 설정하는 안전 장치는?",
    "answer": "Max Iterations (최대 반복 횟수)",
    "why": "무한 루프(Infinite Logic Loop)에 빠져 비용이 폭주하는 것을 막기 위해 횟수 제한을 둡니다.",
    "hint": "최대(Max) 반복(Iteration).",
    "trap_points": [
      "보통 5~10회 정도로 설정함"
    ],
    "difficulty": "medium",
    "id": "0499",
    "options": [
      "Max Iterations (최대 반복 횟수)",
      "Max Tokens",
      "Timeout",
      "Memory Limit",
      "API Quota"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 평가 시 '사용자 질문에 대해 검색된 문서가 실제로 정답을 포함하고 있는지'를 평가하는 지표는?",
    "options": [
      "Faithfulness",
      "Context Recall",
      "Context Precision",
      "Answer Relevance",
      "Groundedness"
    ],
    "answer": "Context Recall",
    "why": "실제 정답에 필요한 정보가 검색 결과물 속에 빠짐없이 들어있는지 확인하는 리콜(재현율) 개념입니다.",
    "hint": "정보의 누락 여부를 판단합니다.",
    "trap_points": [
      "정밀도(Precision)는 쓸데없는 게 섞였는지를 봅니다"
    ],
    "difficulty": "hard",
    "id": "0500"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 단계 중 검색된 정보(Context)를 사용자 질문과 결합하여 '풍부한 프롬프트'를 만드는 단계는?",
    "options": [
      "Indexing",
      "Searching",
      "Augmenting",
      "Generating",
      "Processing"
    ],
    "answer": "Augmenting",
    "why": "Augmenting은 검색된 지식을 덧붙여(증강하여) 모델이 답변하기 좋은 상태로 만드는 과정입니다.",
    "hint": "증강하다라는 뜻입니다.",
    "trap_points": [
      "Generating 직전의 프롬프트 조립 단계임"
    ],
    "difficulty": "medium",
    "id": "0501"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 고차원 데이터를 빠르게 찾기 위해 사용하는 '근사 최근접 이웃' 검색 기술의 약자는?",
    "options": [
      "SQL",
      "ANN",
      "KNN",
      "API",
      "RAG"
    ],
    "answer": "ANN",
    "why": "ANN(Approximate Nearest Neighbor)은 정확도를 조금 희생하고 검색 속도를 획기적으로 올리는 방식입니다.",
    "hint": "가장 가까운 이웃(Nearest Neighbor)을 대략적으로(Approximate) 찾기.",
    "trap_points": [
      "정확히 찾는 KNN보다 대규모 데이터에서 압도적으로 빠름"
    ],
    "difficulty": "hard",
    "id": "0502"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG의 성능을 평가할 때, '검색된 문서들이 사용자 질문과 실제로 얼마나 관련된 것인지'를 측정하는 지표는?",
    "options": [
      "Context Precision",
      "Context Recall",
      "Answer Relevance",
      "Groundedness",
      "L2 Norm"
    ],
    "answer": "Context Precision",
    "why": "컨텍스트 정밀도(Precision)는 정답과 관련된 정보가 검색 결과 상단에 얼마나 잘 포함되었는지를 봅니다.",
    "hint": "검색 결과의 '정밀도'를 생각하세요.",
    "trap_points": [
      "Context Recall은 정답에 필요한 모든 정보가 빠짐없이 검색되었는지를 봅니다"
    ],
    "difficulty": "hard",
    "id": "0503"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG에서 사용자가 '최근 1주일간의 뉴스만 알려줘'라고 할 때 효율적으로 처리하는 방법은?",
    "options": [
      "그냥 전체 임베딩 검색을 한다.",
      "메타데이터 필터링(Metadata Filtering)을 적용한다.",
      "모델에게 직접 찾아보라고 한다.",
      "임베딩 모델을 바꾼다.",
      "검색된 결과를 하나씩 다 읽어본다."
    ],
    "answer": "메타데이터 필터링(Metadata Filtering)을 적용한다.",
    "why": "날짜, 작성자, 카테고리 등 속성을 미리 DB에 저장해 두고 하드웨어적으로 먼저 거른 뒤 유사도 검색을 수행합니다.",
    "hint": "데이터에 대한 데이터(Metadata)를 사용합니다.",
    "trap_points": [
      "의미 검색만으로는 정확한 시간대 제어가 어려울 수 있음"
    ],
    "difficulty": "medium",
    "id": "0504"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "검색된 다수의 문서 중 핵심적인 정보가 앞과 뒤에 있을 때보다 중간에 있을 때 모델이 잘 인지하지 못하는 현상은?",
    "answer": "Lost in the Middle",
    "why": "긴 컨텍스트에서 모델이 중간 부분을 덜 중요하게 여기는 바이어스 때문에 발생합니다.",
    "hint": "중간에서 길을 잃다(Lost).",
    "trap_points": [
      "를 해결하기 위해 Reordering 기법이 사용됨"
    ],
    "difficulty": "hard",
    "id": "0505",
    "options": [
      "Lost in the Middle",
      "Recency Bias",
      "Primacy Bias",
      "Hallucination",
      "Context Leakage"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트 구현 시 '반성(Reflection)' 기술이 필요한 주된 이유는?",
    "options": [
      "에이전트가 예의 바르게 답변하게 하기 위해",
      "모델의 첫 번째 답변에서 나타난 논리적 오류나 부족한 정보를 스스로 보완하기 위해",
      "답변의 속도를 빠르게 하기 위해",
      "비용을 절약하기 위해",
      "화려한 UI를 위해"
    ],
    "answer": "모델의 첫 번째 답변에서 나타난 논리적 오류나 부족한 정보를 스스로 보완하기 위해",
    "why": "한 번에 완벽한 답을 내기 어려운 복잡한 작업에서 '검증'과 '재시도' 루프를 통해 품질을 올립니다.",
    "hint": "스스로를 돌아보고 수정하는 능력입니다.",
    "trap_points": [
      "모델의 Reasoning 성능이 높을수록 반성 능력도 좋아짐"
    ],
    "difficulty": "medium",
    "id": "0506"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "전문가들(검색 에이전트, 작성 에이전트 등)이 협업하는 시스템 구조는?",
    "options": [
      "Single Agent",
      "Multi-Agent Systems (MAS)",
      "Linear Pipeline",
      "Manual Workflow",
      "Hardcoded Logic"
    ],
    "answer": "Multi-Agent Systems (MAS)",
    "why": "작업을 분담하고 서로 피드백을 주고받아 결과물의 수준을 높이는 고도화된 구조입니다.",
    "hint": "여러 에이전트가 함께합니다.",
    "trap_points": [
      "LangGraph 등이 이를 구현하기 위한 대표적인 라이브러리임"
    ],
    "difficulty": "medium",
    "id": "0507"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 두 벡터의 직선 거리를 측정할 때 사용하는 가장 흔한 메트릭은?",
    "options": [
      "Cosine Similarity",
      "L2 Distance (Euclidean)",
      "Dot Product",
      "Hamming Distance",
      "Jaccard"
    ],
    "answer": "L2 Distance (Euclidean)",
    "why": "유클리드 거리는 다차원 공간에서의 직선의 절댓값을 계산합니다.",
    "hint": "피타고라스 정리의 확장형입니다.",
    "trap_points": [
      "거리이므로 작을수록 유사한 것임 (유사도는 클수록 유사)"
    ],
    "difficulty": "medium",
    "id": "0508"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "인터넷 웹사이트의 정보를 실시간으로 긁어와서 에이전트에게 제공하는 도구(Tool)를 보통 무엇이라 하나요?",
    "answer": "Search Tool (또는 Web Search/Browsing Tool)",
    "why": "최신 정보 반영(Grounding)을 위해 Tavily, SerpAPI 등을 연동하여 사용합니다.",
    "hint": "검색 도구입니다.",
    "trap_points": [
      "모델 자체가 인터넷을 돌아다니는 것이 아니라 도구를 '사용'하는 것임"
    ],
    "difficulty": "easy",
    "id": "0509",
    "options": [
      "Search Tool (또는 Web Search/Browsing Tool)",
      "Calculator",
      "DB Query Tool",
      "Writer Tool",
      "Translator Tool"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 시스템에서 청크 오버랩(Overlap)의 크기를 결정할 때 고려해야 할 사항은?",
    "options": [
      "메모리가 많으면 무조건 최대한 크게 한다.",
      "청크 사이즈의 일정 비율(예: 10~20%)로 설정하여 의미 단절을 최소화한다.",
      "오버랩은 항상 0으로 두는 것이 깔끔하다.",
      "오버랩은 한글에서만 사용한다.",
      "오버랩을 크게 하면 검색이 무조건 정확해진다."
    ],
    "answer": "청크 사이즈의 일정 비율(예: 10~20%)로 설정하여 의미 단절을 최소화한다.",
    "why": "너무 크면 중복 정보가 많아 검색 효율이 떨어지고, 너무 작으면 문맥이 잘릴 위험이 있습니다.",
    "hint": "적절한(10~20%) 비율을 생각하세요.",
    "trap_points": [
      "문서의 특성에 따라 최적의 오버랩 값이 다름"
    ],
    "difficulty": "medium",
    "id": "0510"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG의 5단계 중, 원본 문서를 청킹하고 벡터화하여 DB에 넣는 준비 과정은?",
    "options": [
      "Indexing",
      "Processing",
      "Searching",
      "Augmenting",
      "Generating"
    ],
    "answer": "Indexing",
    "why": "인덱싱은 데이터를 검색 가능한 상태로 '색인화'하여 저장소(Vector DB)에 구축하는 단계입니다.",
    "hint": "색인을 뜻하는 단어입니다.",
    "trap_points": [
      "실제로 검색이 이루어지는 단계는 Searching임"
    ],
    "difficulty": "medium",
    "id": "0511"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "검색 결과가 너무 많을 때, 관련성이 가장 높은 소수만 골라내기 위해 유사도 점수를 다시 매기는 과정은?",
    "options": [
      "Filtering",
      "Sorting",
      "Re-ranking",
      "Pruning",
      "Summarizing"
    ],
    "answer": "Re-ranking",
    "why": "리랭커(Re-ranker)는 속도는 느리지만 훨씬 정밀한 모델을 사용하여 최상위 답변 후보를 선별합니다.",
    "hint": "순위(Ranking)를 다시(Re) 매깁니다.",
    "trap_points": [
      "Bi-Encoder로 검색하고 Cross-Encoder로 리랭킹하는 것이 정석임"
    ],
    "difficulty": "medium",
    "id": "0512"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 환경에서 질문과 문서 사이의 관련성을 평가할 때, '검색된 문서 내용에만 기반해서 답했는지'를 나타내는 지표는?",
    "options": [
      "Precision",
      "Recall",
      "Faithfulness (충실도)",
      "F1-score",
      "L2 Distance"
    ],
    "answer": "Faithfulness (충실도)",
    "why": "충실도는 모델이 외부 지식을 섞지 않고 오직 '주어진 컨텍스트' 내에서만 충실히 답변했는지를 측정합니다.",
    "hint": "믿음직함, 충실함을 뜻하는 단어입니다.",
    "trap_points": [
      "RAGAS 같은 평가 프레임워크의 핵심 지표임"
    ],
    "difficulty": "hard",
    "id": "0513"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 가장 가까운 이웃을 효율적으로 찾기 위해 그래프 구조를 활용하는 알고리즘은?",
    "options": [
      "ANN",
      "HNSW",
      "B-Tree",
      "Hash Table",
      "Binary Search"
    ],
    "answer": "HNSW",
    "why": "Hierarchical Navigable Small World(HNSW)는 고차원 벡터 검색에서 속도와 정확도의 균형이 뛰어난 대표적 알고리즘입니다.",
    "hint": "계층적 작은 세상 탐색의 약자입니다.",
    "trap_points": [
      "Chroma, Pinecone 등 대부분의 주요 벡터 DB가 지원함"
    ],
    "difficulty": "hard",
    "id": "0514"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "사용자의 모호한 질문을 명확하게 바꾸거나 검색이 잘 되도록 키워드를 확장하는 단계를 무엇이라 하나요?",
    "answer": "Query Reformulation (또는 리프레이징)",
    "why": "질문을 보정함으로써 검색 엔진이 더 정확한 문서를 찾을 확률을 높여줍니다.",
    "hint": "질문을 다시(Re) 형성(formulation)한다는 뜻입니다.",
    "trap_points": [
      "Processing 단계에서 주로 수행됨"
    ],
    "difficulty": "medium",
    "id": "0515",
    "options": [
      "Query Reformulation (또는 리프레이징)",
      "Query Execution",
      "Query Parsing",
      "Query Encoding",
      "Query Decoding"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG에서 문서 조각(Chunk) 사이를 일부 겹치게 하는 'Overlap'의 주된 목적은?",
    "options": [
      "메모리 절약을 위해",
      "청크가 잘리는 부분의 문맥 정보를 보존하기 위해",
      "문서 전체를 중복 저장하기 위해",
      "검색 속도를 빠르게 하기 위해",
      "영어로만 된 문서를 찾기 위해"
    ],
    "answer": "청크가 잘리는 부분의 문맥 정보를 보존하기 위해",
    "why": "겹침(Overlap)이 있으면 중요한 단어가 경계선에서 잘려 의미가 훼손되는 것을 방지할 수 있습니다.",
    "hint": "경계선의 문맥(Context) 유지를 생각하세요.",
    "trap_points": [
      "보통 청크 사이즈의 10~20% 정도를 겹치도록 설정함"
    ],
    "difficulty": "medium",
    "id": "0516"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "질문을 받았을 때, 답을 바로 내지 않고 '검색 결과가 충분한가?'를 스스로 평가하여 부족하면 다시 검색하는 에이전트 구조는?",
    "options": [
      "Simple RAG",
      "Adaptive RAG (또는 Self-RAG)",
      "Static Agent",
      "Keyword Matcher",
      "Linear Pipeline"
    ],
    "answer": "Adaptive RAG (또는 Self-RAG)",
    "why": "상황에 맞춰(Adaptive) 행동을 결정하는 구조로, 검색 결과가 주제와 무관하면 다시 쿼리를 짜는 능력이 있습니다.",
    "hint": "적응형, 또는 스스로를 평가하는 방식입니다.",
    "trap_points": [
      "성능은 좋으나 API 호출 횟수가 늘어나 비용이 상승할 수 있음"
    ],
    "difficulty": "hard",
    "id": "0517"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "의미 검색(Semantic)과 키워드 검색(Lexical)의 결과를 합치는 기술의 명칭은?",
    "options": [
      "Cross Search",
      "Hybrid Search",
      "Mixed Retrieval",
      "Deep Search",
      "Combined Fusion"
    ],
    "answer": "Hybrid Search",
    "why": "두 방식의 장점을 모두 취하여(Hybrid), 정확한 고유 명사 검색과 모호한 의미 검색을 동시에 잡습니다.",
    "hint": "두 가지를 섞었다는 뜻입니다.",
    "trap_points": [
      "Reranking 전에 두 결과를 Rank Fusion으로 합치는 게 일반적임"
    ],
    "difficulty": "medium",
    "id": "0518"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "PDF 문서의 이미지, 표, 텍스트 구조를 정확히 파싱하여 RAG용 데이터로 변환해 주는 IBM의 오픈소스 도구는?",
    "answer": "Docling",
    "why": "Docling은 PDF를 마크다운이나 JSON으로 깔끔하게 변환하여 LLM이 표의 의미까지 읽도록 도와줍니다.",
    "hint": "문서(Doc)와 연관된 귀여운 이름입니다.",
    "trap_points": [
      "단순히 텍스트만 뽑는 도구보다 표 인식 능력이 뛰어남"
    ],
    "difficulty": "medium",
    "id": "0519",
    "options": [
      "Docling",
      "PyPDF2",
      "PDFMiner",
      "Tesseract",
      "Tabula"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트 구현 시 '생각하고 행동하고 관찰하는' 과정을 반복하는 가장 대표적인 프레임워크는?",
    "options": [
      "CoT",
      "ReAct",
      "Reflection",
      "Plan-and-Execute",
      "BabyAGI"
    ],
    "answer": "ReAct",
    "why": "Reasoning + Acting의 약자로, 매 단계마다 현재 상황을 추론하고 행동을 결정하는 에이전트의 기본 뼈대입니다.",
    "hint": "반응하다라는 영어 단어와 철자가 같습니다.",
    "trap_points": [
      "Thought, Action, Observation의 루프를 기억하세요"
    ],
    "difficulty": "medium",
    "id": "0520"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG에서 ‘효율적인 검색’을 위해 질문을 벡터화하기 전, 질문의 본질을 파악하여 다른 도메인의 질문으로 변환하는 것을 무엇이라 하나요?",
    "options": [
      "Query Translation",
      "Query Expansion (질문 확장)",
      "Query Decomposition",
      "HyDE",
      "Multi-Query"
    ],
    "answer": "Query Expansion (질문 확장)",
    "why": "유사한 단어나 개념을 덧붙여 검색 성공률을 높이는 기법입니다.",
    "hint": "질문을 더 넓게(Expansion) 만든다.",
    "trap_points": [
      "동의어 사전을 이용하거나 LLM을 이용해 확장함"
    ],
    "difficulty": "medium",
    "id": "0521"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "여러 문서 덩어리(Chunk)가 검색되었을 때, 이를 그대로 LLM에 넘기기보다 ‘가장 중요한 덩어리’ 수십 개만 정밀하게 재배열하는 과정은?",
    "options": [
      "Filtering",
      "Sorting",
      "Re-ranking",
      "Cleaning",
      "Mapping"
    ],
    "answer": "Re-ranking",
    "why": "검색 모델(Retriever)은 속도가 빠르지만 정확도가 낮으므로, 느리지만 정확한 리랭커 모델로 보강합니다.",
    "hint": "순위(Ranking)를 다시(Re) 매긴다.",
    "trap_points": [
      "비용과 속도의 균형을 잡기 위한 필수 단계임"
    ],
    "difficulty": "medium",
    "id": "0522"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 시스템에서 '검색된 문서들로부터 정답을 도출하기 위한 논리적 근거가 충분한지' 평가하는 RAGAS 지표는?",
    "options": [
      "Faithfulness",
      "Answer Relevance",
      "Context Precision",
      "Context Recall",
      "Aspect Critique"
    ],
    "answer": "Answer Relevance",
    "why": "사용자의 질문에 대해 검색된 컨텍스트가 얼마나 직접적으로 연관되어 답변의 질을 보장하는지 측정합니다.",
    "hint": "정답(Answer)과 얼마나 관련성(Relevance)이 있는지.",
    "trap_points": [
      "Faithfulness는 문서 내 정보 준수 여부를, Relevance는 정답 자체의 관련성을 봅니다"
    ],
    "difficulty": "hard",
    "id": "0523"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB 검색 시 ‘의미적으로는 유사하지만 다른 주제’의 문서가 검색되는 문제를 해결하기 위한 방법은?",
    "options": [
      "메타데이터 필터링 (Metadata Filtering)",
      "더 큰 모델 사용",
      "인터넷 속도 강화",
      "질문 글자 수 늘리기",
      "데이터 지우기"
    ],
    "answer": "메타데이터 필터링 (Metadata Filtering)",
    "why": "카테고리, 날짜, 작성자 등 논리적 특징으로 범위를 좁히고 검색을 수행하면 정확도가 올라갑니다.",
    "hint": "데이터의 속성 정보를 이용합니다.",
    "trap_points": [
      "하드웨어적 필터링이므로 의미 검색보다 연산이 확실함"
    ],
    "difficulty": "medium",
    "id": "0524"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "질문을 받으면 도구를 사용해야 할지 말지 스스로 판단하고 실행하는 LLM의 실질적 행동 주체를 무엇이라 하나요?",
    "answer": "AI Agent (에이전트)",
    "why": "단순 출력을 넘어 목표지향적 행동(Action)을 수행하는 AI의 진화된 형태입니다.",
    "hint": "주체적으로 행동하는 개체입니다.",
    "trap_points": [
      "에이전트는 반복(Loop)적인 사고가 가능함"
    ],
    "difficulty": "easy",
    "id": "0525",
    "options": [
      "AI Agent (에이전트)",
      "Chatbot",
      "Search Engine",
      "Retrieval System",
      "Classifier"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "LangChain에서 에이전트의 사고 흐름과 상태를 그래프 형태로 관리하여 복잡한 로직을 구현하는 라이브러리는?",
    "options": [
      "LangDB",
      "LangGraph",
      "LangFlow",
      "LangChain-Core",
      "LangPlus"
    ],
    "answer": "LangGraph",
    "why": "순환 구조(Cyclic)를 지원하여 에이전트가 실패 시 이전 단계로 돌아가거나 무한 루프를 도는 것을 관리하기에 최적입니다.",
    "hint": "그래프(Graph) 구조를 활용합니다.",
    "trap_points": [
      "최신 기업용 에이전트는 대부분 이 방식으로 구축됨"
    ],
    "difficulty": "hard",
    "id": "0526"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG에서 ‘HyDE (Hypothetical Document Embedding)’ 기법이 수행하는 과정은?",
    "options": [
      "문서를 다 지우기",
      "질문에 대해 LLM이 먼저 가상의(가짜) 답변을 생성하게 한 뒤, 그 가짜 답변으로 실제 문서를 검색하기",
      "사용자 정보를 가제로 만들기",
      "임베딩 모델을 랜덤하게 바꾸기",
      "검색 결과를 삭제하기"
    ],
    "answer": "질문에 대해 LLM이 먼저 가상의(가짜) 답변을 생성하게 한 뒤, 그 가짜 답변으로 실제 문서를 검색하기",
    "why": "사용자의 질문보다 모델이 대충 만든 답변이 실제 저장소의 문서 형태와 더 비슷할 때가 많아 검색 확률이 높아집니다.",
    "hint": "가상(Hypothetical)의 문서를 이용합니다.",
    "trap_points": [
      "가짜 지식이 섞여도 유사한 형태를 찾는 게 목적이므로 검색 효율이 올라감"
    ],
    "difficulty": "hard",
    "id": "0527"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 ‘고밀도 벡터(Dense Vector)’와 ‘희소 벡터(Sparse Vector)’를 함께 사용하여 검색 품질을 높이는 방식은?",
    "options": [
      "Single Retrieval",
      "Hybrid Search",
      "Dual Encoding",
      "Cross Matching",
      "Random Selection"
    ],
    "answer": "Hybrid Search",
    "why": "의미를 잘 찾는 고밀도 벡터와 정확한 어휘를 잘 찾는 희소 벡터의 장점을 결합합니다.",
    "hint": "두 가지 이상의 짬뽕 방식입니다.",
    "trap_points": [
      "RRF (Reciprocal Rank Fusion) 알고리즘으로 점수를 합침"
    ],
    "difficulty": "medium",
    "id": "0528"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트가 어떤 도구를 실행할지 그 매개변수와 이름을 JSON 형태로 출력하게 하는 LLM의 기초 기술 명칭은?",
    "answer": "Function Calling (함수 호출)",
    "why": "LLM이 구조화된 입력을 만들게 하여 실제 서버의 함수와 연동할 수 있게 해주는 약속입니다.",
    "hint": "함수(Function)를 부르는(Calling) 것.",
    "trap_points": [
      "모델이 직접 함수를 실행하는 것이 아닌 '실행 계획'만 주는 것임"
    ],
    "difficulty": "medium",
    "id": "0529",
    "options": [
      "Function Calling (함수 호출)",
      "API Routing",
      "Schema Matching",
      "Zero-shot classification",
      "Text generation"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "문서를 작은 청크로 쪼개어 검색하고, 실제 답변 생성 시에는 그 청크들이 포함된 원본 ‘페이지 전체’를 LLM에 전달하는 전략은?",
    "options": [
      "Small2Big (또는 Parent Document Retrieval)",
      "Big2Small",
      "Fixed Window",
      "Sliding Frame",
      "Multi-Vector"
    ],
    "answer": "Small2Big (또는 Parent Document Retrieval)",
    "why": "검색 효율을 위해 작은 조각을 뒤지지만, 모델은 문맥 파악을 위해 풍부한 주변 정보가 필요하기 때문입니다.",
    "hint": "작은(Small) 것으로 찾아서 큰(Big) 것을 준다.",
    "trap_points": [
      "성능 향상이 매우 뚜렷한 고급 리트리버 기법임"
    ],
    "difficulty": "hard",
    "id": "0530"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG에서 ‘검색 품질’이 안 좋을 때 가장 먼저 확인해야 할 요소는?",
    "options": [
      "모델의 크기",
      "데이터의 청킹(Chunking) 방식과 임베딩(Embedding) 모델의 성능",
      "인터넷 브라우저 종류",
      "사용자의 타자 속도",
      "운영체제 버전"
    ],
    "answer": "데이터의 청킹(Chunking) 방식과 임베딩(Embedding) 모델의 성능",
    "why": "데이터를 어떻게 쪼개서 어떤 벡터 공간에 넣었느냐가 검색의 정밀도를 결정짓는 90% 요인입니다.",
    "hint": "데이터를 조각내는 방법과 수치화하는 도구입니다.",
    "trap_points": [
      "임베딩 모델이 질문의 의도를 벡터 공간에서 못 찾으면 아무리 똑똑한 LLM도 답 못 함"
    ],
    "difficulty": "medium",
    "id": "0531"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 질문과 거리(유사도)를 계산할 때, '방향'이 얼마나 일치하는지를 중점적으로 보는 메트릭은?",
    "options": [
      "Euclidean Distance",
      "Cosine Similarity (코사인 유사도)",
      "Manhattan Distance",
      "Hamming Distance",
      "Jaccard Similarity"
    ],
    "answer": "Cosine Similarity (코사인 유사도)",
    "why": "벡터의 크기가 아닌 '각도(방향)'의 유사함을 계산하여 텍스트 의미 비교에 최적화되어 있습니다.",
    "hint": "각도와 관련된 삼각함수 이름입니다.",
    "trap_points": [
      "완전히 일치하면 1, 전혀 무관하면 0을 가짐"
    ],
    "difficulty": "medium",
    "id": "0532"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트가 ‘내가 방금 한 행동이 맞나?’라고 스스로 검증하고 계획을 수정하는 단축 키워드는?",
    "options": [
      "Reflection (성찰/반성)",
      "Recursion",
      "Iteration",
      "Looping",
      "Streaming"
    ],
    "answer": "Reflection (성찰/반성)",
    "why": "스스로의 논리적 허점을 찾아내어 정답에 도달할 때까지 루프를 도는 고급 자아 능력을 비유합니다.",
    "hint": "거울을 보듯 스스로를 돌아보는 행위입니다.",
    "trap_points": [
      "추론 성능이 좋은 모델일수록 이 반성 능력이 뛰어남"
    ],
    "difficulty": "hard",
    "id": "0533"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 파이프라인 중 검색된 문서가 50개일 때, 너무 많으므로 가장 관련성 높은 5개만 다시 골라주는 필터링 모델은?",
    "options": [
      "Retriever",
      "Reranker (리랭커)",
      "Generator",
      "Tokenizer",
      "Parser"
    ],
    "answer": "Reranker (리랭커)",
    "why": "느리지만 정교한 Cross-Encoder 방식을 사용하여 최종 정답 후보지를 압축합니다.",
    "hint": "순위(Rank)를 다시(Re) 매기는 존재입니다.",
    "trap_points": [
      "토큰 소모량과 할루시네이션을 전격적으로 줄여줌"
    ],
    "difficulty": "hard",
    "id": "0534"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전틱 워크플로우(Agentic Workflow)를 구현할 때 필수적으로 설정해야 하는 ‘이것’이 없으면 무한 루프에 빠질 수 있습니다. 이것은?",
    "options": [
      "Max Iterations (최대 반복 횟수)",
      "영단어 리스트",
      "이미지 파일",
      "인터넷 주소",
      "색상 값"
    ],
    "answer": "Max Iterations (최대 반복 횟수)",
    "why": "에이전트가 답을 못 찾고 계속 도구만 부르는 것을 강제로 끊어주는 안전핀 역할을 합니다.",
    "hint": "반복의 한계치입니다.",
    "trap_points": [
      "설정하지 않으면 API 비용이 천문학적으로 나올 수 있음"
    ],
    "difficulty": "easy",
    "id": "0535"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG에서 원본 문서를 관리할 때, 검색 효율을 위해 한 입 크기로 쪼개진 데이터 덩어리를 무엇이라 부르나요?",
    "answer": "Chunk (청크)",
    "why": "전체 문서를 모델에 한 번에 넣을 수 없기에, 의미 있는 조각 단위로 분할하여 관리합니다.",
    "hint": "덩어리라는 뜻의 영어 단어입니다.",
    "trap_points": [
      "청크가 너무 작으면 맥락이 끊기고, 너무 크면 주제가 섞임"
    ],
    "difficulty": "easy",
    "id": "0536",
    "options": [
      "Chunk (청크)",
      "Fragment",
      "Slice",
      "Segment",
      "Particle"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "AI 에이전트가 외부 '도구(Tool)'를 사용할 때, 주로 어떤 형식을 통해 호출 정보를 전달받나요?",
    "options": [
      "자유 텍스트",
      "JSON",
      "바이너리 코드",
      "이미지",
      "음성"
    ],
    "answer": "JSON",
    "why": "컴퓨터가 이해할 수 있는 구조화된 형식인 JSON을 통해 도구 이름과 인자값을 명확히 전달받습니다.",
    "hint": "키-값 쌍의 표준 데이터 형식입니다.",
    "trap_points": [
      "도구 정의 시 Pydantic 같은 스키마 정의가 매우 중요함"
    ],
    "difficulty": "medium",
    "id": "0537"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 고차원 데이터를 빠르게 찾기 위해 사용하는 '근사 최근접 이웃(ANN)' 알고리즘 중 가장 유명한 것은?",
    "options": [
      "B-Tree",
      "HNSW (Hierarchical Navigable Small World)",
      "Linked List",
      "Stack",
      "Queue"
    ],
    "answer": "HNSW (Hierarchical Navigable Small World)",
    "why": "그래프 기반 인덱싱으로 대규모 고차원 벡터 데이터에서 압도적인 검색 속도를 보여주는 표준 알고리즘입니다.",
    "hint": "계층형(Hierarchical) 그래프 구조를 사용합니다.",
    "trap_points": [
      "메모리 사용량은 높지만 성능이 매우 뛰어남"
    ],
    "difficulty": "hard",
    "id": "0538"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG를 구축했지만 모델이 자꾸 외부 지식을 무시하고 자신의 내부 지식으로만 답을 한다면, 해결책은?",
    "options": [
      "모델을 삭제한다.",
      "시스템 프롬프트에 '반드시 제공된 컨텍스트에서만 답하고, 모르면 모른다고 하라'고 강력하게 명시한다.",
      "컴퓨터를 다시 켠다.",
      "다른 사람에게 물어본다.",
      "영어로만 코딩한다."
    ],
    "answer": "시스템 프롬프트에 '반드시 제공된 컨텍스트에서만 답하고, 모르면 모른다고 하라'고 강력하게 명시한다.",
    "why": "모델의 지식 우선순위를 외부 데이터로 강제 조정하는 프롬프트 조정이 필요합니다.",
    "hint": "지침(Instruction)의 우선순위를 바로잡는 것입니다.",
    "trap_points": [
      "이를 통해 할루시네이션(환각)을 전격적으로 억제할 수 있음"
    ],
    "difficulty": "easy",
    "id": "0539"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트가 작업을 수행하며 생성한 중간 산출물들을 보관하고, 다음 단계의 사고에 활용하는 ‘메모리’ 영역을 비유하는 용어는?",
    "answer": "Scratchpad (스크래치패드) 또는 Working Memory",
    "why": "연습장처럼 중간 과정을 적어두고 사고를 이어가는 공간을 의미합니다.",
    "hint": "메모장, 연습장이라는 뜻입니다.",
    "trap_points": [
      "ReAct 프레임워크의 생각-행동-관찰 기록이 여기에 해당함"
    ],
    "difficulty": "medium",
    "id": "0540",
    "options": [
      "Scratchpad (스크래치패드) 또는 Working Memory",
      "Hard Drive",
      "Cloud Storage",
      "Long-term Memory",
      "Database"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG에서 검색을 위해 질문에 대한 가상의 답변을 먼저 생성하고 이를 임베딩하여 문서를 찾는 방식은?",
    "options": [
      "BM25",
      "HyDE (Hypothetical Document Embedding)",
      "Multi-Query",
      "Contextual Retrieval",
      "Small2Big"
    ],
    "answer": "HyDE (Hypothetical Document Embedding)",
    "why": "HyDE는 실제 질문보다 LLM이 생성한 가상 답변이 문서 저장소의 내용과 유사도가 더 높을 수 있다는 점을 이용한 고급 검색 기법입니다.",
    "hint": "가상(Hypothetical)의 문서 임베딩입니다.",
    "trap_points": [
      "가상 답변에 할루시네이션이 섞여도 유사도 검색에는 도움이 될 수 있음"
    ],
    "difficulty": "hard",
    "id": "0541"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "문서를 작은 청크로 나누면서도 검색 시에는 상위의 더 큰 맥락을 가져오는 청킹 전략은?",
    "options": [
      "Recursive Chunking",
      "Sliding Window",
      "Parent-Child / Small2Big",
      "Token-based Chunking",
      "Sentence Chunking"
    ],
    "answer": "Parent-Child / Small2Big",
    "why": "검색은 작은 단위(Small)로 정밀하게 수행하고, 실제 LLM에 전달할 때는 그 작은 조각이 포함된 큰 맥락(Parent/Big)을 제공하여 성능을 높입니다.",
    "hint": "부모(Parent)와 자식(Child) 관계를 생각하세요.",
    "trap_points": [
      "단순히 겹치게 하는 Sliding Window와는 다름"
    ],
    "difficulty": "medium",
    "id": "0542"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "하나의 질문을 여러 개의 다른 질문으로 변환하여 검색 범위를 넓히는 기법은?",
    "options": [
      "Query Reformulation",
      "Multi-Querying",
      "Step-back Prompting",
      "Self-RAG",
      "Correction Agent"
    ],
    "answer": "Multi-Querying",
    "why": "사용자의 단일 질문을 다양한 관점의 여러 쿼리로 확장하여 검색함으로써 유사도 검색의 한계를 극복하고 풍부한 컨텍스트를 확보합니다.",
    "hint": "여러 개(Multi)의 질문(Query)을 만듭니다.",
    "trap_points": [
      "단순한 결과 재배열(Re-ranking)과는 다름"
    ],
    "difficulty": "medium",
    "id": "0543"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 시스템에서 유사도 검색 시 '의미적으로는 같으나 다른 단어'를 찾지 못하는 키워드 검색의 한계를 보완하는 기술은?",
    "options": [
      "BM25",
      "TF-IDF",
      "Vector Embedding (임베딩)",
      "Regex",
      "SQL Like"
    ],
    "answer": "Vector Embedding (임베딩)",
    "why": "임베딩은 텍스트를 벡터로 변환하여 '왕'과 '군주'처럼 철자는 다르지만 의미가 유사한 단어를 거리 기반으로 찾아낼 수 있습니다.",
    "hint": "텍스트를 숫자의 나열(Vector)로 바꿉니다.",
    "trap_points": [
      "BM25는 키워드 일치를 중시함"
    ],
    "difficulty": "medium",
    "id": "0544"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "사용자의 질문을 기반으로 필요한 도구(Tool)를 선택하고 실행 계획을 스스로 세우는 구조는?",
    "options": [
      "Static Pipeline",
      "Fixed Workflow",
      "AI Agent",
      "Legacy Bot",
      "Rule-based System"
    ],
    "answer": "AI Agent",
    "why": "에이전트는 LLM의 추론 능력을 활용하여 목표 달성을 위한 작업 단계(생각, 행동, 관찰)를 능동적으로 제어합니다.",
    "hint": "대리인, 주체적으로 행동하는 존재를 뜻합니다.",
    "trap_points": [
      "단순히 문서를 찾는 RAG보다 한 단계 상위 개념임"
    ],
    "difficulty": "hard",
    "id": "0545"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 시스템에서 '검색 엔진'의 역할이 중요한 이유는?",
    "options": [
      "데이터를 삭제하려고",
      "방대한 외부 문서 중 사용자의 질문과 가장 관련 있는 '맥락'을 족집게처럼 찾아내 모델에 전달하기 때문",
      "영어로 번역하려고",
      "이미지를 만들려고",
      "파일 이름을 지으려고"
    ],
    "answer": "방대한 외부 문서 중 사용자의 질문과 가장 관련 있는 '맥락'을 족집게처럼 찾아내 모델에 전달하기 때문",
    "why": "관련 없는 정보가 들어가면 모델이 혼란을 느껴 오답을 내기 때문입니다.",
    "hint": "정보를 찾아오는(Retrieval) 과정이 첫 번째 단추입니다.",
    "trap_points": [
      "검색 성능이 RAG 시스템 전체 성능을 결정함"
    ],
    "difficulty": "easy",
    "id": "0546"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트가 목표 달성 루프를 긴급 중단해야 하는 '안전 조건'으로 가장 적절한 것은?",
    "options": [
      "답변이 너무 짧을 때",
      "설정된 최대 반복 횟수(Max Iterations)에 도달하여 무한 루프 위험이 있을 때",
      "사용자가 칭찬했을 때",
      "인터넷 연결이 너무 빠를 때",
      "배터리가 100%일 때"
    ],
    "answer": "설정된 최대 반복 횟수(Max Iterations)에 도달하여 무한 루프 위험이 있을 때",
    "why": "비용 폭주와 시스템 과부하를 막기 위해 에이전트는 반드시 '최대 시도 횟수'라는 안전장치를 가져야 합니다.",
    "hint": "안전하게 멈춰야(Stop) 합니다.",
    "trap_points": [
      "에이전트 개발 시 가장 먼저 구현해야 할 안전장치임"
    ],
    "difficulty": "medium",
    "id": "0547"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 질문과 '의미적으로' 연결된 정보를 찾는 과정을 무엇이라 하나요?",
    "options": [
      "Semantic Search (시맨틱 검색)",
      "Keyword Search",
      "Exact Match",
      "Sort Rank",
      "List View"
    ],
    "answer": "Semantic Search (시맨틱 검색)",
    "why": "단순 오타가 있어도 의미적 맥락(벡터 공간상의 거리)을 통해 정답을 찾아냅니다.",
    "hint": "의미를 뜻하는 단어입니다.",
    "trap_points": [
      "철자가 정확해야 하는 검색과는 상반된 장점을 가짐"
    ],
    "difficulty": "easy",
    "id": "0548"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트 시스템에서 '도구(Tool)'의 설명문을 매우 자세히 적어야 하는 기술적 이유는?",
    "options": [
      "모델이 예쁜 글을 좋아해서",
      "모델은 도구의 코드가 아닌 '설명'만 읽고 해당 도구를 쓸지 말지 결정하기 때문",
      "영어로만 답하려고",
      "데이터를 압축하려고",
      "비용을 늘리려고"
    ],
    "answer": "모델은 도구의 코드가 아닌 '설명'만 읽고 해당 도구를 쓸지 말지 결정하기 때문",
    "why": "모델에게 설명문은 도구의 카탈로그이자 매뉴얼이므로, 설명이 모호하면 엉뚱한 도구를 부르게 됩니다.",
    "hint": "모델의 유일한 판단 근거입니다.",
    "trap_points": [
      "설명문은 구체적인 예시(input/output)를 포함하는 것이 베스트임"
    ],
    "difficulty": "medium",
    "id": "0549"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트가 어떤 과제를 수행할 때, 자신의 '생각(Thought)', '행동(Action)', '결과 관찰(Observation)'을 기록하는 방식을 무엇이라 하나요?",
    "answer": "ReAct (Reason + Act)",
    "why": "생각과 행동을 유기적으로 연결하여 복잡한 과제를 해결하는 에이전트의 표준 행동 모델입니다.",
    "hint": "R-e-A-c-t 입니다.",
    "trap_points": [
      "LangChain 에이전트들이 주로 사용하는 핵심 로직임"
    ],
    "difficulty": "medium",
    "id": "0550",
    "options": [
      "ReAct (Reason + Act)",
      "CoT (Chain of Thought)",
      "ToT (Tree of Thought)",
      "DSP (Demonstrate-Search-Predict)",
      "Reflexion"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG의 5단계 중, 사용자의 질문에서 불필요한 단어를 빼거나 더 적합한 검색어로 다듬는 과정은?",
    "options": [
      "Indexing",
      "Searching",
      "Processing (전처리)",
      "Augmenting",
      "Generating"
    ],
    "answer": "Processing (전처리)",
    "why": "질문 정제(Query Refinement)를 통해 벡터 DB 검색의 정밀도를 높이는 기초 단계입니다.",
    "hint": "가공, 처리의 단계를 생각하세요.",
    "trap_points": [
      "질문의 의도 파악(Intent Classification)도 이 단계에서 함"
    ],
    "difficulty": "medium",
    "id": "0551"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 질문과 '의미적으로' 유사한 문서를 찾기 위해 텍스트를 고차원 숫자로 변환하는 기술은?",
    "options": [
      "Indexing",
      "Tokenizing",
      "Embedding (임베딩)",
      "Scaling",
      "Normalizing"
    ],
    "answer": "Embedding (임베딩)",
    "why": "텍스트의 추상적인 의미를 다차원 공간상의 좌표(벡터)로 변환하는 RAG의 핵심 기술입니다.",
    "hint": "E로 시작하는 용어로, 이미 여러 번 다뤘습니다.",
    "trap_points": [
      "임베딩 모델의 성능이 전체 RAG 품질의 50% 이상을 결정함"
    ],
    "difficulty": "easy",
    "id": "0552"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "검색된 문서 내용이 너무 길어 LLM의 컨텍스트 한도를 초과할 때, 검색된 결과를 요약해서 붙여주는 기술은?",
    "options": [
      "Refining",
      "Compressing (컨텍스트 압축)",
      "Stretching",
      "Mapping",
      "Reducing"
    ],
    "answer": "Compressing (컨텍스트 압축)",
    "why": "필요한 정보만 엑기스로 추출하여 토큰 비용을 아끼고 모델의 인지 부하를 줄입니다.",
    "hint": "압축한다는 뜻입니다.",
    "trap_points": [
      "압축 과정에서 중요한 소스 인용 정보가 손실되지 않도록 해야 함"
    ],
    "difficulty": "hard",
    "id": "0553"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG의 '할루시네이션(환각)' 억제 원리에 대해 가장 잘 설명한 것은?",
    "options": [
      "모델이 똑똑해서 거짓말을 안 하게 된다.",
      "검색된 실제 '근거 문서'를 프롬프트에 제공함으로써 모델이 지어낼 필요를 없애준다.",
      "인터넷 속도가 빨라져서",
      "데이터가 압축되어서",
      "모델 가중치가 바뀌어서"
    ],
    "answer": "검색된 실제 '근거 문서'를 프롬프트에 제공함으로써 모델이 지어낼 필요를 없애준다.",
    "why": "지식 컷오프 문제와 잘못된 기억 문제를 외부 데이터 증강을 통해 물리적으로 해결합니다.",
    "hint": "외부의 '근거(Ground truth)'를 제공하는 것에 주목하세요.",
    "trap_points": [
      "문서 내용 자체가 틀려 있으면 모델도 틀린 답을 할 수 있음 (GIGO 원칙)"
    ],
    "difficulty": "easy",
    "id": "0554"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 유사도 검색의 속도를 높이기 위해, 정확도는 조금 양보하더라도 대략적으로 가장 가까운 것들을 찾아내는 기술은?",
    "answer": "ANN (Approximate Nearest Neighbor)",
    "why": "모든 데이터와 일일이 비교하는 KNN의 한계를 복잡한 인덱싱 알고리즘으로 극복합니다.",
    "hint": "대략적인(Approximate)의 약자입니다.",
    "trap_points": [
      "속도는 수백 배 빠르지만 순위가 100% 정확하지 않을 수 있음"
    ],
    "difficulty": "medium",
    "id": "0555",
    "options": [
      "ANN (Approximate Nearest Neighbor)",
      "KNN (K-Nearest Neighbor)",
      "Dijkstra",
      "A* Search",
      "Linear Search"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "AI 에이전트가 실패하거나 도구 사용법이 틀렸을 때, 오류 로그를 보고 스스로 수정하여 다시 시도하는 기법은?",
    "options": [
      "Looping",
      "Self-Correction (또는 Reflection)",
      "Debugging",
      "Rerunning",
      "Augmenting"
    ],
    "answer": "Self-Correction (또는 Reflection)",
    "why": "자신의 행동 결과를 평가(Critic)하고 개선 사항을 도출하여 다음 단계에 반영합니다.",
    "hint": "자기(Self) 수정(Correction)입니다.",
    "trap_points": [
      "복잡한 에이전틱 워크플로우의 정수입니다."
    ],
    "difficulty": "medium",
    "id": "0556"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 파이프라인 중 검색된 조각들을 질문과 합쳐서 프롬프트를 조립하는 컴포넌트를 무엇이라 하나요?",
    "options": [
      "Retriever",
      "Generator",
      "Augmentor (또는 Orchestrator)",
      "Indexer",
      "Parser"
    ],
    "answer": "Augmentor (또는 Orchestrator)",
    "why": "검색과 생성을 매끄럽게 연결하고 컨텍스트를 증강하는 역할을 수행합니다.",
    "hint": "증강하거나 조율하는 존재를 생각하세요.",
    "trap_points": [
      "LangChain에서는 보통 Chain 객체가 이 역할을 함"
    ],
    "difficulty": "medium",
    "id": "0557"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "BM25와 같은 알고리즘을 사용하며, 단어의 의미보다는 '철자의 정확한 일치'를 찾는 검색 방식은?",
    "options": [
      "Semantic Search",
      "Lexical Search (키워드 검색)",
      "Visual Search",
      "Deep Search",
      "Neural Search"
    ],
    "answer": "Lexical Search (키워드 검색)",
    "why": "어휘 기반 검색으로 전문 용어나 상품명 등 정확한 매칭이 필요한 경우 효과적입니다.",
    "hint": "어휘, 사전적인 뜻의 단어입니다.",
    "trap_points": [
      "의미가 비슷해도 철자가 다르면 찾아내지 못함"
    ],
    "difficulty": "medium",
    "id": "0558"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트 구현 시 '현재 내가 무얼 했고, 앞으로 무얼 해야 할지'를 단계별로 기록하고 관리하는 능력을 무엇이라 하나요?",
    "answer": "Reasoning (추론) 또는 Planning (계획)",
    "why": "목표 달성을 위한 전략적 사고의 흐름을 관리하는 핵심 지능입니다.",
    "hint": "P로 시작하는 8글자 단어이기도 합니다.",
    "trap_points": [
      "ReAct 프레임워크의 Thought 단계가 여기에 해당함"
    ],
    "difficulty": "medium",
    "id": "0559",
    "options": [
      "Reasoning (추론) 또는 Planning (계획)",
      "Memorizing",
      "Summarizing",
      "Translating",
      "Formatting"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 유사도 계산 시 코사인 유사도 대신 '방향은 무시하고 절대적인 거리 차이'만 중요할 때 사용하는 메트릭은?",
    "options": [
      "Cosine Distance",
      "L2 Distance (Euclidean)",
      "Manhattan Distance",
      "Hamming Distance",
      "Dot Product"
    ],
    "answer": "L2 Distance (Euclidean)",
    "why": "유클리드 거리는 임베딩 벡터의 크기(Magnitude) 차이까지 모두 반영하여 거리를 잽니다.",
    "hint": "두 점 사이의 직선 거리입니다.",
    "trap_points": [
      "텍스트 정체성보다 수치적 크기가 중요할 때 유리함"
    ],
    "difficulty": "medium",
    "id": "0560"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG의 5단계 중 검색된 내용을 바탕으로 실제 답변을 '출력'하는 마지막 단계는?",
    "options": [
      "Indexing",
      "Searching",
      "Augmenting",
      "Generating",
      "Processing"
    ],
    "answer": "Generating",
    "why": "생성(Generating) 단계에서 LLM은 주어진 컨텍스트를 소화하여 최종 답변을 생성합니다.",
    "hint": "생성하다라는 뜻입니다.",
    "trap_points": [
      "RAG의 최종 마침표를 찍는 단계임"
    ],
    "difficulty": "easy",
    "id": "0561"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 질문과 가장 가까운 상위 N개의 조각을 찾아오는 과정을 무엇이라 하나요?",
    "options": [
      "Pulling",
      "Top-K Retrieval",
      "Indexing",
      "Scanning",
      "Parsing"
    ],
    "answer": "Top-K Retrieval",
    "why": "유사도 점수가 가장 높은 K개의 문서를 찾아오는 검색의 기본 과정입니다.",
    "hint": "가장 높은(Top) 순위 K개를 검색함.",
    "trap_points": [
      "최근에는 K를 무조건 크게 잡기보다 품질(Threshold)로 거르기도 함"
    ],
    "difficulty": "medium",
    "id": "0562"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 환경에서 답변의 근거를 명시하여 사용자가 직접 원문을 확인할 수 있게 하는 기술은?",
    "options": [
      "Citation (인용)",
      "Shadowing",
      "Masking",
      "Encoding",
      "Mirroring"
    ],
    "answer": "Citation (인용)",
    "why": "답변 중 특정 부분에 [1] 과 같은 표시를 남겨 신뢰도를 높이는 필수적인 UI/UX 요소입니다.",
    "hint": "논문 등에서 출처를 밝히는 것을 무엇이라 하나요?",
    "trap_points": [
      "할루시네이션 방지에 매우 효과적임"
    ],
    "difficulty": "medium",
    "id": "0563"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 파이프라인에서 청크 사이즈를 결정할 때, 일반적인 웹 게시물이나 뉴스 기사에 권장되는 초기 설정값(토큰 기준)은?",
    "options": [
      "10 ~ 20 토큰",
      "100 ~ 500 토큰",
      "5000 ~ 10000 토큰",
      "1개 이상의 전체 문서",
      "글자 수 기반 1자"
    ],
    "answer": "100 ~ 500 토큰",
    "why": "너무 작으면 맥락이 없고, 너무 크면 주제가 섞입니다. 500 토큰 내외가 정보의 완결성과 검색 정밀도의 균형이 좋습니다.",
    "hint": "모니터상 대략 대여섯 줄 정도의 분량입니다.",
    "trap_points": [
      "오버랩(Overlap)도 함께 고려해야 완벽해짐"
    ],
    "difficulty": "medium",
    "id": "0564"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에 저장하기 전, 긴 문서를 의미 있는 작은 조각으로 나누는 행위를 무엇이라 하나요?",
    "answer": "Chunking (청킹)",
    "why": "모델의 입력 한계와 검색 정밀도를 위해 데이터를 적절한 크기로 분할하는 필수 전처리 과정입니다.",
    "hint": "한 입 크기의 덩어리라는 영어 단어입니다.",
    "trap_points": [
      "의미가 끊기지 않도록 문장이나 단락 단위로 자르는 것이 좋음"
    ],
    "difficulty": "easy",
    "id": "0565",
    "options": [
      "Chunking (청킹)",
      "Splitting",
      "Dividing",
      "Slicing",
      "Breaking"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "사용자의 질문 하나로 충분한 정보가 검색되지 않을 때, 질문을 여러 개로 변주하여 검색 확률을 높이는 것은?",
    "options": [
      "Multi-querying",
      "Single-searching",
      "Static-fetching",
      "Binary-matching",
      "Sequential-reading"
    ],
    "answer": "Multi-querying",
    "why": "질문을 다양하게 변형하여 검색 엔진의 사각지대를 없애는 고급 리트리버 전략입니다.",
    "hint": "여러 개(Multi)의 쿼리(Query)입니다.",
    "trap_points": [
      "LangChain에서 MultiQueryRetriever로 쉽게 구현 가능함"
    ],
    "difficulty": "medium",
    "id": "0566"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트 구현 시 '메모리'를 관리할 때 대화의 양이 너무 많아지면 어떻게 처리하는 것이 가장 효율적인가요?",
    "options": [
      "그냥 다 보낸다 (비용 상관없음)",
      "과거 내용을 요약하여 전달하거나, 핵심 사실만 추출해 따로 저장한다.",
      "과거를 아예 다 지운다.",
      "영어로만 저장한다.",
      "사용자에게 요약해달라고 시킨다."
    ],
    "answer": "과거 내용을 요약하여 전달하거나, 핵심 사실만 추출해 따로 저장한다.",
    "why": "컨텍스트 윈도우 한계가 있으므로 요약(Summary)이나 벡터 기반 메모리 관리가 필수적입니다.",
    "hint": "줄여서 간직하기(Summarization)를 생각하세요.",
    "trap_points": [
      "중요한 고유 명사가 요약 과정에서 사라지지 않도록 주의해야 함"
    ],
    "difficulty": "medium",
    "id": "0567"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 두 벡터가 '완전히 같은 방향'일 때 코사인 유사도 값은?",
    "options": [
      "0",
      "-1",
      "1",
      "100",
      "무한대"
    ],
    "answer": "1",
    "why": "코사인 유사도는 1일 때 최대이며(완전 일치), 0은 무관, -1은 정반대를 뜻합니다.",
    "hint": "최댓값은 얼마일까요?",
    "trap_points": [
      "유사도와 거리(Distance)는 반대 개념임에 항상 주의"
    ],
    "difficulty": "easy",
    "id": "0568"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "AI 에이전트가 외부 웹 검색이나 계산기 등을 사용할 수 있도록 연결된 인터페이스를 보통 무엇이라 부르나요?",
    "answer": "Tool (또는 Function)",
    "why": "에이전트가 텍스트 생성을 넘어 실제 행동을 취하게 해주는 팔과 다리 같은 존재입니다.",
    "hint": "도구라는 뜻입니다.",
    "trap_points": [
      "모델은 이 기능의 '이름과 사용법'만 알고 필요시 호출을 요청함"
    ],
    "difficulty": "easy",
    "id": "0569",
    "options": [
      "Tool (또는 Function)",
      "Prompt",
      "Script",
      "Plugin",
      "Extension"
    ]
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 시스템 성능 개선을 위해 검색된 문서 30개를 가져온 뒤, 가장 정답 확률이 높은 5개만 다시 골라내는 모델 타입은?",
    "options": [
      "Bi-Encoder",
      "Cross-Encoder (리랭커)",
      "Decoder",
      "CNN",
      "Tokenizer"
    ],
    "answer": "Cross-Encoder (리랭커)",
    "why": "느리지만 훨씬 강력한 모델을 사용하여 질문과 문서의 상관관계를 심층 분석해 순위를 재배열합니다.",
    "hint": "두 입력을 교차(Cross)해서 보는 인코더입니다.",
    "trap_points": [
      "대규모 검색에는 부적합하지만 소수 정예 선별에는 탁월함"
    ],
    "difficulty": "hard",
    "id": "0570"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 파이프라인에서 텍스트 조각(Chunk)을 수치화된 좌표로 바꾸는 임베딩 모델의 역할은?",
    "options": [
      "글자 수를 센다.",
      "단어의 '의미'를 고차원 공간상의 위치(벡터)로 표현한다.",
      "영어로 번역한다.",
      "데이터를 삭제한다.",
      "파일 이름을 짓는다."
    ],
    "answer": "단어의 '의미'를 고차원 공간상의 위치(벡터)로 표현한다.",
    "why": "비슷한 의미를 가진 텍스트들이 가까운 위치에 있게 하여 검색이 가능하게 만듭니다.",
    "hint": "수치로 박아 넣다(Embed).",
    "trap_points": [
      "임베딩 성능이 RAG 검색 품질의 90%를 결정함"
    ],
    "difficulty": "medium",
    "id": "0571"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "벡터 DB에서 질문과 '가장 가까운 거리'의 문서를 찾는 기술의 이름은?",
    "options": [
      "Binary Search",
      "Hash View",
      "Similarity Search (유사도 검색)",
      "Sort Scan",
      "List Scan"
    ],
    "answer": "Similarity Search (유사도 검색)",
    "why": "철자가 아닌 '의미의 거리'가 가까운 것을 찾아내는 RAG의 핵심 기술입니다.",
    "hint": "비슷한 정도(Similarity)를 기준으로 찾습니다.",
    "trap_points": [
      "코사인 유사도나 유클리디안 거리 등이 계산 메트릭으로 쓰임"
    ],
    "difficulty": "easy",
    "id": "0572"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "에이전트가 어떤 문제를 풀기 위해 '인터넷 검색' 도구를 쓸지 '계산기' 도구를 쓸지 결정하는 단계를 무엇이라 하나요?",
    "options": [
      "Thinking",
      "Planning (계획)",
      "Acting",
      "Observing",
      "Reporting"
    ],
    "answer": "Planning (계획)",
    "why": "자신의 목표를 위해 필요한 수단(Tool)을 고르고 일정을 짜는 지능적 단계입니다.",
    "hint": "계획(Plan)을 세웁니다.",
    "trap_points": [
      "복잡한 에이전트는 하위 실행 계획까지 꼼꼼히 세움"
    ],
    "difficulty": "easy",
    "id": "0573"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG에서 ‘검색된 문서’가 너무 많을 때 LLM에 넘길 5개만 정밀하게 재배열하는 과정은?",
    "options": [
      "Re-ranking (리랭킹)",
      "Re-scaling",
      "Re-merging",
      "Re-filtering",
      "Re-coding"
    ],
    "answer": "Re-ranking (리랭킹)",
    "why": "단순 벡터 거리보다 훨씬 정교한 모델로 실제 질문과의 연관성을 다시 채점하여 정확도를 높입니다.",
    "hint": "순위(Ranking)를 다시(Re) 매깁니다.",
    "trap_points": [
      "토큰 누수 배제와 답변 품질 향상의 핵심 공정임"
    ],
    "difficulty": "hard",
    "id": "0574"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "AI 에이전트 워크플로우인 'ReAct'의 의미는?",
    "options": [
      "React 프레임워크 사용",
      "Reasoning (추론)과 Acting (행동)의 결합",
      "빨리 반응하기",
      "다시 행동하기",
      "이미지 처리"
    ],
    "answer": "Reasoning (추론)과 Acting (행동)의 결합",
    "why": "생각(Thought)하고 행동(Action)하고 관찰(Observation)하는 루프를 통해 문제를 해결하는 프레임워크입니다.",
    "hint": "R-e와 A-c-t의 조합입니다.",
    "trap_points": [
      "에이전트 구현의 가장 기본적이고 강력한 패턴임"
    ],
    "difficulty": "medium",
    "id": "0575"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "RAG 검색 단계에서 의미적으로 유사하지만 키워드가 전혀 다른 문서를 찾기 위해 필수적인 것은?",
    "options": [
      "Dense Embedding (밀집 임베딩)",
      "Sparse Embedding (희소 임베딩)",
      "BM25",
      "Keyword Match",
      "Regex"
    ],
    "answer": "Dense Embedding (밀집 임베딩)",
    "why": "단어를 벡터 공간에 매핑하여 '자동차'와 '승용차'가 가까운 점임을 인식하게 합니다.",
    "hint": "빽빽한(Dense) 벡터.",
    "difficulty": "medium",
    "id": "0921"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "여러 문서에서 공통된 정보를 종합해야 답이 나오는 질문(Multi-hop QA)을 해결하기 위한 RAG 기법은?",
    "options": [
      "Graph RAG (지식 그래프 활용)",
      "Simple RAG",
      "Naive RAG",
      "Vector Search",
      "Keyword Search"
    ],
    "answer": "Graph RAG (지식 그래프 활용)",
    "why": "문서 간의 연결 관계를 그래프로 표현하여 징검다리 건너듯 여러 정보를 연결해 추론합니다.",
    "hint": "그래프(Graph)를 타고 넘어다님.",
    "difficulty": "hard",
    "id": "0922"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "최신 에이전트 프레임워크인 'LangGraph'의 핵심 차별점은?",
    "options": [
      "순환(Cycle)이 가능한 그래프 구조 지원",
      "비선형 구조 불가",
      "단순 체인 구조",
      "LLM 미사용",
      "파인튜닝 필수"
    ],
    "answer": "순환(Cycle)이 가능한 그래프 구조 지원",
    "why": "단순 DAG(단방향)가 아니라 루프를 돌며 작업을 반복/수정할 수 있는 순환 구조를 코드 레벨에서 지원합니다.",
    "hint": "그래프(Graph) 위를 뱅글뱅글 돎.",
    "difficulty": "hard",
    "id": "0923"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "검색된 문서들의 순서가 LLM의 답변 품질에 영향을 주는데, 가장 관련성 높은 문서를 어디에 배치하는 것이 유리한가?",
    "options": [
      "입력의 시작과 끝 (Primacy & Recency Effect)",
      "무조건 중간",
      "랜덤",
      "문서 길이순",
      "알파벳순"
    ],
    "answer": "입력의 시작과 끝 (Primacy & Recency Effect)",
    "why": "Lost in the Middle 현상 때문에 모델이 가장 잘 보는 양오 끝단에 중요한 정보를 배치하는 것이 Re-ranking의 핵심입니다.",
    "hint": "처음과 끝이 중요합니다.",
    "difficulty": "hard",
    "id": "0924"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "객관식",
    "question": "하이브리드 검색(Hybrid Search)은 보통 무엇과 무엇의 결합인가?",
    "options": [
      "키워드 검색(BM25) + 시맨틱 검색(Vector)",
      "이미지 + 텍스트",
      "음성 + 텍스트",
      "SQL + NoSQL",
      "CPU + GPU"
    ],
    "answer": "키워드 검색(BM25) + 시맨틱 검색(Vector)",
    "why": "정확한 단어 매칭(키워드)과 맥락 매칭(벡터)의 장점을 합쳐 상호 보완합니다.",
    "hint": "전통 검색(키워드)과 최신 검색(벡터)의 짬뽕.",
    "difficulty": "medium",
    "id": "0925"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "RAG 체인에서 검색된 여러 문서 객체들의 `page_content`만 모아 하나의 문자열로 합치는 함수를 완성하세요.\n\n```python\ndef format_docs(docs):\n    return \"\\n---\\n\".join([doc.____ for doc in docs])\n```",
    "options": [],
    "answer": "page_content",
    "why": "Document 객체에서 실제 텍스트 정보는 page_content라는 필드에 저장되어 있습니다.",
    "difficulty": "medium",
    "id": "0581"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "사용자 질문을 다각도로 paraphrazing하여 여러 쿼리로 검색 품질을 높이는 리트리버 클래스를 작성하세요.\n\n```python\nfrom langchain.retrievers.multi_query import MultiQueryRetriever\nretriever = ____.from_llm(retriever=db.as_retriever(), llm=llm)\n```",
    "options": [],
    "answer": "MultiQueryRetriever",
    "why": "MultiQueryRetriever는 하나의 모호한 질문을 여러 검색 쿼리로 확장하여 정확도를 높입니다.",
    "difficulty": "hard",
    "id": "0582"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "키워드 기반(BM25) 검색과 벡터 유사도(Semantic) 검색 결과를 가중치에 따라 합쳐주는 리트리버는?\n\n```python\nfrom langchain.retrievers import EnsembleRetriever\nensemble = ____(retrievers=[bm25, vector], weights=[0.5, 0.5])\n```",
    "options": [],
    "answer": "EnsembleRetriever",
    "why": "EnsembleRetriever는 통계적 검색과 의미적 검색의 장점을 결합하여 최상의 성능을 냅니다.",
    "difficulty": "hard",
    "id": "0583"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "검색된 문서들 중에서 질문과의 연관성을 정교하게 다시 계산하여 상위 결과를 재배열하는 정렬기는?\n\n```python\n# 대략적으로 뽑고 정교하게 줄이는 ____ (Ranking)\n```",
    "options": [],
    "answer": "Reranker",
    "why": "Reranker는 가벼운 벡터 유사도 기반 검색의 한계를 정밀한 점수 계산을 통해 보완합니다.",
    "difficulty": "medium",
    "id": "0584"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "검색된 '컨텍스트'가 '질문'과 얼마나 관련이 있는지 LLM이 평가하는 RAGAS 지표를 작성하세요.\n\n```python\n# 질문에 대답하기에 충분한 정보가 들어있는지 평가하는 Context ____\n```",
    "options": [],
    "answer": "Relevance",
    "why": "Context Relevance는 리트리버가 질문에 적합한 정보를 잘 찾아왔는지 측정하는 핵심 지표입니다.",
    "difficulty": "hard",
    "id": "0585"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "한국어 텍스트를 정확하게 처리하기 위해 형태소 단위로 분석하는 Kiwi 형태소 분석기의 토큰화 메서드를 작성하세요.\n\n```python\nfrom kiwipiepy import Kiwi\nkiwi = Kiwi()\ntokens = kiwi.____(\"한국어 분석 중입니다\")\n```",
    "options": [],
    "answer": "tokenize",
    "why": "kiwi.tokenize()는 한국어를 형태소 단위로 분리하여 검색어 정규화에 사용하기 좋습니다.",
    "difficulty": "medium",
    "id": "0586"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "RAGAS 평가 프레임워크에서 모델의 답변이 검색된 컨텍스트에만 근거했는지(왜곡 여부) 측정하는 지표는?\n\n```python\n# 할루시네이션 발생 비율을 역으로 나타내는 ____\n```",
    "options": [],
    "answer": "Faithfulness",
    "why": "Faithfulness는 답변의 모든 주장이 주어진 근거(Context)와 일치하는지 검증합니다.",
    "difficulty": "hard",
    "id": "0587"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "Agent가 도구를 사용하거나 사고하는 과정(Thought-Action-Observation)을 반복하는 구조를 무엇이라 하나요?\n\n```python\n# 추론과 행동의 루프를 뜻하는 ____ 루프\n```",
    "options": [],
    "answer": "ReAct",
    "why": "ReAct(Reasoning + Acting) 프레임워크는 에이전트가 단계적으로 문제를 해결하게 돕는 표준 방식입니다.",
    "difficulty": "medium",
    "id": "0588"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "일반 함수를 랭체인 에이전트가 이해할 수 있는 도구(Tool)로 등록하기 위해 붙이는 데코레이터를 작성하세요.\n\n```python\nfrom langchain_core.tools import tool\n____\ndef search_web(query: str):\n    \"\"\"웹을 검색하는 도구입니다.\"\"\"\n    ...\n```",
    "options": [],
    "answer": "@tool",
    "why": "@tool 데코레이터는 함수의 독스트링과 시그니처를 기반으로 에이전트용 스키마를 생성합니다.",
    "difficulty": "easy",
    "id": "0589"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "모델이 어떤 도구를 사용할지 결정하도록 도구 명세들을 입력으로 연결하는 메서드를 작성하세요.\n\n```python\nllm_with_tools = llm.____(tools)\n```",
    "options": [],
    "answer": "bind_tools",
    "why": "bind_tools()를 호출하면 모델의 시스템 메시지 뒤에 도구 사용 지침이 자동으로 결합됩니다.",
    "difficulty": "medium",
    "id": "0590"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "여러 도구와 모델의 상호작용을 그래프 구조로 관리하여 복잡한 에이전트를 만드는 프레임워크는?\n\n```python\nfrom ____ import StateGraph, END\n```",
    "options": [],
    "answer": "langgraph",
    "why": "LangGraph는 에이전트의 상태(State)와 실행 흐름(Edge)을 명시적인 그래프로 정의할 수 있게 돕습니다.",
    "difficulty": "medium",
    "id": "0591"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "LangGraph에서 에이전트의 상태(데이터)가 변경될 수 있도록 정의할 때 사용하는 파이썬 클래스를 작성하세요.\n\n```python\nfrom typing import TypedDict\nclass AgentState(____):\n    messages: list\n    next_step: str\n```",
    "options": [],
    "answer": "TypedDict",
    "why": "TypedDict를 통해 에이전트가 관리하는 데이터의 키와 타입을 엄격하게 정의합니다.",
    "difficulty": "hard",
    "id": "0592"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "PDF 파일에서 표, 텍스트, 레이아웃을 가장 빠르고 정확하게 로드하는 랭체인 로더 클래스를 작성하세요.\n\n```python\nfrom langchain_community.document_loaders import PyMuPDFLoader\nloader = ____(\"document.pdf\")\n```",
    "options": [],
    "answer": "PyMuPDFLoader",
    "why": "PyMuPDFLoader는 C 기반의 빠른 라이브러리를 사용하여 PDF 데이터를 문서 객체로 로드합니다.",
    "difficulty": "easy",
    "id": "0593"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "이미지와 텍스트가 섞인 검색 시스템에서 이미지 속 내용을 텍스트로 설명(Caption)하여 검색하게 하는 방식은?\n\n```python\n# 시각 정보를 언어로 변환하여 처리하는 ____ RAG\n```",
    "options": [],
    "answer": "Multimodal",
    "why": "멀티모달 RAG는 텍스트뿐만 아니라 이미지, 오디오 등의 지식을 검색하여 답변에 활용합니다.",
    "difficulty": "medium",
    "id": "0594"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "검색 결과 후보들 중 중복된 정보를 제거하거나 요약하여 컨텍스트 효율을 높이는 작업을 무엇이라 하나요?\n\n```python\n# 지식의 양을 줄여 모델의 부담을 덜어주는 Context ____\n```",
    "options": [],
    "answer": "Compression",
    "why": "Contextual Compression은 수천 개의 검색 후보 중 모델의 컨텍스트 창에 맞는 핵심 정보만 추려냅니다.",
    "difficulty": "hard",
    "id": "0595"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "에이전트가 이전 대화 기록을 기억하고 이어나갈 수 있게 돕는 LangGraph의 영구 저장 기능 명칭을 작성하세요.\n\n```python\n# 체크포인트를 이용한 ____ (Persistence)\n```",
    "options": [],
    "answer": "Checkpointer",
    "why": "Checkpointer는 그래프의 각 단계 상태를 저장하여 나중에 대화를 재개할 수 있게 돕습니다.",
    "difficulty": "hard",
    "id": "0596"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "질문에 따라 '웹 검색'을 할지 'DB 검색'을 할지 스스로 판단하여 경로를 지정하는 랭체인 기능을 작성하세요.\n\n```python\n# 질문의 의도에 따라 소스를 선택하는 ____ (Router)\n```",
    "options": [],
    "answer": "라우팅",
    "why": "라우팅(Routing)은 질문의 성격에 따라 가장 적합한 검색기나 모델로 연결해주는 관문 역할을 합니다.",
    "difficulty": "easy",
    "id": "0597"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "Chroma DB에서 유사도 검색 시 '벡터 간의 거리'를 계산하는 기준으로 가장 많이 쓰이는 방식은?\n\n```python\n# 두 벡터의 각도 차이를 이용하는 ____ Similarity\n```",
    "options": [],
    "answer": "Cosine",
    "why": "코사인 유사도는 텍스트 임베딩 간의 의미론적 유사성을 측정하는 데 가장 널리 쓰이는 지표입니다.",
    "difficulty": "easy",
    "id": "0598"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "대규모 문서군에서 빠르고 정확하게 원하는 부분을 찾기 위한 핵심 기술인 '검색 시스템'의 영어 약칭은?\n\n```python\n# 외부 지식을 검색해와서 생성하는 ____\n```",
    "options": [],
    "answer": "RAG",
    "why": "Retrieval-Augmented Generation은 사전에 학습되지 않은 외부 최신 정보를 LLM이 활용하게 해줍니다.",
    "difficulty": "easy",
    "id": "0599"
  },
  {
    "chapter_name": "RAG & Agent",
    "type": "코드 완성형",
    "question": "LangGraph에서 어떤 노드 다음에 어떤 노드를 실행할지 결정하는 화살표를 무엇이라 하나요?\n\n```python\n# 노드 사이의 연결 통로를 뜻하는 ____ (Edge)\n```",
    "options": [],
    "answer": "엣지",
    "why": "엣지(Edge)는 워크플로우 내에서 데이터의 흐름과 제어권을 넘겨주는 경로를 정의합니다.",
    "difficulty": "easy",
    "id": "0600"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "DPO(Direct Preference Optimization) 모델 학습을 위해 필요한 데이터 형태는?",
    "options": [
      "질문 하나와 답변 하나",
      "질문 하나와 (좋은 답변, 싫은 답변) 한 쌍",
      "문서 뭉치 하나",
      "영단어 리스트",
      "이미지 데이터"
    ],
    "answer": "질문 하나와 (좋은 답변, 싫은 답변) 한 쌍",
    "why": "두 답변 중 더 나은 쪽을 선호(Preference)하도록 모델의 확률 분포를 직접 조정하기 때문입니다.",
    "hint": "선택지 한 쌍이 필요합니다.",
    "trap_points": [
      "최근 RLHF를 대체하는 강력한 파인튜닝 기법임"
    ],
    "difficulty": "hard",
    "id": "0601"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝된 모델을 배포할 때, 모델의 레이어 정규화 값을 학습 시 값으로 고정하여 추론 속도를 높이는 과정은?",
    "options": [
      "Quantization",
      "Model Merging",
      "Graph Optimization",
      "Layer Folding",
      "Cashing"
    ],
    "answer": "Graph Optimization",
    "why": "연산 그래프를 분석하여 중복되거나 불필요한 계산을 합치거나 상수화하여 속도를 높입니다.",
    "hint": "그래프 최적화입니다.",
    "trap_points": [
      "ONNX, TensorRT 등이 이 과정을 수행함"
    ],
    "difficulty": "hard",
    "id": "0602"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 시 ‘데이터 오염(Data Contamination)’이란 무엇을 의미하나요?",
    "options": [
      "데이터가 사라지는 것",
      "평가에 쓰일 문제들이 학습 데이터에 포함되어 있어 실제 실력보다 점수가 높게 나오는 것",
      "인터넷이 끊기는 것",
      "영어로만 코딩하는 것",
      "파일이 깨지는 것"
    ],
    "answer": "평가에 쓰일 문제들이 학습 데이터에 포함되어 있어 실제 실력보다 점수가 높게 나오는 것",
    "why": "모델이 규칙을 배운 게 아니라 정답을 암기해버린 상태이므로 실전 성능을 신뢰할 수 없게 만듭니다.",
    "hint": "시험 정답을 미리 보고 시험을 치는 것과 같습니다.",
    "trap_points": [
      "학습 전 평가 데이터와의 중복 검사(De-contamination)가 필수임"
    ],
    "difficulty": "hard",
    "id": "0603"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 시 'Overfitting'을 감지하는 가장 직접적인 지표는?",
    "options": [
      "학습 데이터의 손실(Loss)은 줄어드는데, 검증(Validation) 데이터의 손실은 정체되거나 올라갈 때",
      "전원이 꺼질 때",
      "데이터가 사라졌을 때",
      "영어로만 답할 때",
      "손실 값이 0이 될 때"
    ],
    "answer": "학습 데이터의 손실(Loss)은 줄어드는데, 검증(Validation) 데이터의 손실은 정체되거나 올라갈 때",
    "why": "학습 데이터에만 과하게 맞춰져 새로운 데이터에 대한 일반화 능력을 잃었음을 뜻합니다.",
    "hint": "학습셋과 검증셋의 손실 값 차이를 보세요.",
    "trap_points": [
      "이 시점이 학습을 중단해야 하는 'Early Stopping' 타이밍임"
    ],
    "difficulty": "medium",
    "id": "0604"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "LoRA 학습에서 학습되는 아주 작은 두 개의 행렬 조각을 통칭하는 용어는?",
    "answer": "Adapter (어댑터)",
    "why": "기존 모델에 수수료처럼 덧붙여서(Adapt) 성능을 조절하는 조각이라는 뜻입니다.",
    "hint": "끼우다, 적응시키다라는 단어입니다.",
    "trap_points": [
      "학습 후 베이스 모델과 합쳐서(Merge) 사용할 수 있음"
    ],
    "difficulty": "easy",
    "id": "0605",
    "options": [
      "Adapter (어댑터)",
      "Head",
      "Backbone",
      "Stem",
      "Bridge"
    ]
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "LoRA 파인튜닝 시 'Rank(r)' 파라미터가 가지는 의미는?",
    "options": [
      "모델의 순위",
      "추가되는 어댑터 행렬의 차원 크기 (작을수록 메모리 절약, 클수록 정교함)",
      "데이터의 개수",
      "학습 모델의 가격",
      "인터넷 속도"
    ],
    "answer": "추가되는 어댑터 행렬의 차원 크기 (작을수록 메모리 절약, 클수록 정교함)",
    "why": "랭크는 파인튜닝할 수 있는 '용량'을 결정하며, 보통 8, 16, 32 등이 널리 사용됩니다.",
    "hint": "행렬의 차원 수입니다.",
    "trap_points": [
      "너무 크면 전체 파라미터 학습과 차이가 없어 효율이 떨어짐"
    ],
    "difficulty": "hard",
    "id": "0606"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 학습 중 모델이 원본의 선한 의도나 안전 지침을 무시하고 사용자에게 욕설을 하거나 거칠게 답하는 것을 막는 과정을 무엇이라 하나요?",
    "options": [
      "Normalization",
      "Alignment (정렬)",
      "Scaling",
      "Cleaning",
      "Encryption"
    ],
    "answer": "Alignment (정렬)",
    "why": "모델의 가치관과 인간의 가치관을 일치(Align)시키는 RLHF, DPO 등의 기법이 여기에 포함됩니다.",
    "hint": "인간의 의도에 맞게 조정(Align)합니다.",
    "trap_points": [
      "정렬이 잘 안 된 모델은 자의적인 주장을 펼칠 수 있음"
    ],
    "difficulty": "medium",
    "id": "0607"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝된 모델 배포 시 가장 많이 쓰이는 최적화 라이브러리로, 특히 엔비디아 GPU 성능을 100% 끌어내는 것은?",
    "options": [
      "vLLM",
      "TensorRT-LLM",
      "Ollama",
      "Llama.cpp",
      "Auto-GPT"
    ],
    "answer": "TensorRT-LLM",
    "why": "엔비디아 하드웨어에 최적화된 추론 라이브러리로 배치 처리와 지연 시간을 획기적으로 줄여줍니다.",
    "hint": "엔비디아 공식 최적화 툴입니다.",
    "trap_points": [
      "설치는 어렵지만 성능은 압도적임"
    ],
    "difficulty": "hard",
    "id": "0608"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "사전 학습(Pre-training)과 파인튜닝(Fine-tuning)의 가장 큰 재료 차이는?",
    "options": [
      "재료가 똑같다.",
      "사전 학습은 레이블이 없는 방대한 인터넷 데이터(Next Token Prediction)를 쓰고, 파인튜닝은 질문-답변 쌍과 같은 레이블된 정제 데이터를 쓴다.",
      "사전 학습만 영어다.",
      "파인튜닝은 이미지를 안 쓴다.",
      "차이가 없다."
    ],
    "answer": "사전 학습은 레이블이 없는 방대한 인터넷 데이터(Next Token Prediction)를 쓰고, 파인튜닝은 질문-답변 쌍과 같은 레이블된 정제 데이터를 쓴다.",
    "why": "사전 학습은 세상의 일반적 패턴을 배우는 과정이고, 파인튜닝은 특정 목적으로 ‘길들이는’ 과정입니다.",
    "hint": "데이터의 덩어리(Bulk)와 정제(Curated)의 차이입니다.",
    "trap_points": [
      "최근에는 파인튜닝 단계의 데이터 질이 모델 품질을 결정함"
    ],
    "difficulty": "easy",
    "id": "0609"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "가중치 행렬 중 일부 중요한 값만 남기고 0으로 만들어 모델 용량을 줄이는 최적화 방식은?",
    "answer": "Pruning (가지치기)",
    "why": "신경망 연결망 중 불필요한 가지를 쳐내어 속도와 용량을 개선합니다.",
    "hint": "나뭇가지를 친다는 뜻입니다.",
    "trap_points": [
      "Sparse해진 행렬을 효율적으로 처리하는 전용 커널이 필요함"
    ],
    "difficulty": "medium",
    "id": "0610",
    "options": [
      "Pruning (가지치기)",
      "Quantization",
      "Distillation",
      "Sparsification",
      "Compression"
    ]
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 시 'Learning Rate (학습률)'가 너무 높을 때 나타나는 일반적인 증상은?",
    "options": [
      "학습이 너무 완벽하게 된다.",
      "손실 값(Loss)이 발산하거나 요동치며 모델이 아무 기술도 배우지 못하고 망가진다.",
      "속도가 100배 빨라진다.",
      "영어로만 답한다.",
      "글자 수가 길어진다."
    ],
    "answer": "손실 값(Loss)이 발산하거나 요동치며 모델이 아무 기술도 배우지 못하고 망가진다.",
    "why": "보폭(Learning Rate)이 너무 크면 최적의 지점(Minimum)을 지나쳐버리기 때문입니다.",
    "hint": "너무 큰 보폭의 부작용을 생각하세요.",
    "trap_points": [
      "반대로 너무 작으면 학습 진행이 아예 안 될 수도 있음"
    ],
    "difficulty": "medium",
    "id": "0611"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 후 모델의 '할루시네이션(환각)'이 오히려 심해지는 주된 원인은?",
    "options": [
      "컴퓨터가 뜨거워서",
      "데이터셋에 잘못된 정보가 포함되어 있거나, 모델이 데이터를 암기하기 시작해서 (Overfitting)",
      "영어로만 학습해서",
      "파일이 너무 커서",
      "인터넷이 끊겨서"
    ],
    "answer": "데이터셋에 잘못된 정보가 포함되어 있거나, 모델이 데이터를 암기하기 시작해서 (Overfitting)",
    "why": "나쁜 데이터를 배우면 지능 자체가 오염되는 GIGO 법칙의 결과입니다.",
    "hint": "학습 데이터의 품질이 곧 출력의 품질입니다.",
    "trap_points": [
      "데이터 양보다 정제가 훨씬 중요함"
    ],
    "difficulty": "easy",
    "id": "0612"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "모델의 지능 전수 기법인 'Distillation'에서 교사 모델과 학생 모델의 관계는?",
    "options": [
      "둘은 쌍둥이다.",
      "거대하고 똑똑한 모델(Teacher)의 확률 분포를 작고 가벼운 모델(Student)이 모방하도록 학습한다.",
      "학생이 더 크다.",
      "둘은 싸우는 관계다.",
      "관계가 없다."
    ],
    "answer": "거대하고 똑똑한 모델(Teacher)의 확률 분포를 작고 가벼운 모델(Student)이 모방하도록 학습한다.",
    "why": "효율을 위해 큰 모델의 능력을 작은 모델로 압축하는 강력한 산업적 기술입니다.",
    "hint": "증류(Distillation)의 과정을 생각하세요.",
    "trap_points": [
      "최신 sLLM들이 성능을 비약적으로 올린 비결임"
    ],
    "difficulty": "medium",
    "id": "0613"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 데이터를 만들 때, 사람이 직접 적는 대신 AI가 AI용 데이터를 자동으로 생성해 주는 기술은?",
    "answer": "Synthetic Data Generation (합성 데이터 생성)",
    "why": "고품질 데이터를 무한히 생성하여 학습 비용을 줄이고 다양성을 확보합니다.",
    "hint": "인공적으로 합성(Synthetic)한 데이터입니다.",
    "trap_points": [
      "최근에는 사람보다 AI가 만든 데이터로 학습한 성능이 더 높기도 함"
    ],
    "difficulty": "medium",
    "id": "0614",
    "options": [
      "Synthetic Data Generation (합성 데이터 생성)",
      "Data Mining",
      "Web Scraping",
      "Crowdsourcing",
      "Manual Labeling"
    ]
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝된 모델 공유 시 필수적으로 첨부해야 할 'Model Card'에 포함되지 않아도 되는 것은?",
    "options": [
      "모델의 용도와 제한 사항",
      "학습 데이터셋 정보",
      "평가 벤치마크 결과",
      "개발자의 어제 점심 메뉴",
      "저작권 및 라이선스 정보"
    ],
    "answer": "개발자의 어제 점심 메뉴",
    "why": "모델 카드는 기술적/윤리적 명세서이므로 사적인 정보는 필요 없습니다.",
    "hint": "모델의 '명세서'입니다.",
    "trap_points": [
      "투명한 AI 생태계를 위한 표준 약속임"
    ],
    "difficulty": "easy",
    "id": "0615"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝의 대표적인 방법인 LoRA에서 학습 대상이 되는 가중치는?",
    "options": [
      "모델의 전체 가중치",
      "모델에 추가된 두 개의 저차원 행렬 가중치 (A, B)",
      "바이어스 값만",
      "임베딩 레이어 가중치",
      "마지막 층의 가중치만"
    ],
    "answer": "모델에 추가된 두 개의 저차원 행렬 가중치 (A, B)",
    "why": "원본 파라미터는 동결하고, 옆에 붙인 가벼운 행렬만 업데이트하여 효율을 극대화합니다.",
    "hint": "옆에 덧붙인(Adapter) 작은 행렬들을 생각하세요.",
    "trap_points": [
      "이를 통해 수백 배 적은 메모리로 파인튜닝이 가능해짐"
    ],
    "difficulty": "hard",
    "id": "0616"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "DPO(Direct Preference Optimization) 알고리즘이 PPO(기존 RLHF)보다 구현이 쉬운 결정적인 이유는?",
    "options": [
      "데이터가 적어도 되기 때문에",
      "보상 모델(Reward Model) 학습 과정이 필요 없기 때문에",
      "한국어 전용이라서",
      "GPU 없이도 학습 가능해서",
      "학습 모델이 작아도 되기 때문에"
    ],
    "answer": "보상 모델(Reward Model) 학습 과정이 필요 없기 때문에",
    "why": "DPO는 선호도 데이터를 직접 정답 확률에 반영하여 복잡한 리워드 모델링 단계를 제거했습니다.",
    "hint": "샘플 문제에서도 다뤘던 핵심 비교 포인트입니다.",
    "trap_points": [
      "하지만 여전히 선호도 답변 쌍(A vs B) 데이터는 잘 구축해야 함"
    ],
    "difficulty": "medium",
    "id": "0617"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 과정에서 모델의 가독성과 코드 형식이 혼재될 때(DeepSeek R1-Zero 사례), 이를 해결하기 위해 결합하는 방식은?",
    "options": [
      "다시 Pre-training 하기",
      "Cold-start SFT를 거친 후 강화학습 진행",
      "학습 데이터 다 지우기",
      "모델 파라미터 무작위 초기화",
      "영어로만 재학습"
    ],
    "answer": "Cold-start SFT를 거친 후 강화학습 진행",
    "why": "기초적인 답변 형식(SFT)을 먼저 가르친 뒤에 강화학습을 시켜야 가동성과 성능을 동시에 잡을 수 있습니다.",
    "hint": "입문(Cold-start) 과정을 생각하세요.",
    "trap_points": [
      "R1의 최종 성공 비결이 바로 이 단계적 학습임"
    ],
    "difficulty": "hard",
    "id": "0618"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "모델이 인간의 사회적 가치관이나 안전 지침을 위반하지 않도록 최종적으로 튜닝하는 것을 무엇이라 하나요?",
    "options": [
      "Alignment (정렬)",
      "Scaling",
      "Distillation",
      "Pruning",
      "Backpropagation"
    ],
    "answer": "Alignment (정렬)",
    "why": "모델의 지능과 인간의 의도/가치관을 일직선으로 맞춘다는 의미의 용어입니다.",
    "hint": "나란히 맞춘다는 뜻입니다.",
    "trap_points": [
      "RLHF가 이 정렬을 위한 가장 대표적인 도구임"
    ],
    "difficulty": "medium",
    "id": "0619"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "원본 모델의 지식을 유지하면서 4비트 양자화와 LoRA를 결합하여 VRAM 사용량을 극단적으로 낮춘 파인튜닝 기법은?",
    "answer": "QLoRA",
    "why": "Quantized LoRA의 약자로, 48GB VRAM이 필요한 모델을 16GB에서도 튜닝 가능하게 만든 혁명적 기술입니다.",
    "hint": "Q + LoRA.",
    "trap_points": [
      "NF4(Normal Float 4)라는 특수 양자화 분포를 사용함"
    ],
    "difficulty": "hard",
    "id": "0620",
    "options": [
      "QLoRA",
      "LoRA",
      "Adapter",
      "PEFT",
      "Full Fine-tuning"
    ]
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 데이터 구축 시, 모델이 같은 답변을 반복하지 않도록 다양성을 확보하는 것이 중요한 이유는?",
    "options": [
      "비용을 늘리기 위해",
      "모델이 한 가지 패턴에만 과적합(Overfitting)되는 것을 방지하기 위해",
      "답변 속도를 늦추기 위해",
      "사용자를 혼란스럽게 하기 위해",
      "글자 수를 늘리기 위해"
    ],
    "answer": "모델이 한 가지 패턴에만 과적합(Overfitting)되는 것을 방지하기 위해",
    "why": "데이터의 다양성이 부족하면 모델의 유연성이 떨어지고 '치명적 망각'이 심해질 수 있습니다.",
    "hint": "너무 한쪽으로 치우치는 현상을 막는 것입니다.",
    "trap_points": [
      "적은 양의 고품질 데이터라도 다양성이 담보되어야 함"
    ],
    "difficulty": "medium",
    "id": "0621"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "학습 과정에서 성능이 확인된 데이터만 선별하여 다시 학습 모델에 주입하는 기법은?",
    "options": [
      "Random Sampling",
      "Rejection Sampling (기각 샘플링)",
      "Data Scaling",
      "Model Merging",
      "Weight Averaging"
    ],
    "answer": "Rejection Sampling (기각 샘플링)",
    "why": "여러 답변 중 좋은 답만 골라내어(Sampling) 나머지 저품질 답변은 기각(Rejection)하는 반복 개선 방식입니다.",
    "hint": "거절, 기각의 의미입니다.",
    "trap_points": [
      "오픈 모델들의 성능을 끌어올릴 때 필수적인 단계임"
    ],
    "difficulty": "hard",
    "id": "0622"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝된 모델의 성능 평가 시, 훈련 데이터에 없는 새로운 질문에 대해 얼마나 잘 답하는지를 중점적으로 보는 이유는?",
    "options": [
      "훈련 데이터가 가짜라서",
      "모델의 '일반화(Generalization)' 능력을 검증하기 위해",
      "문법 오타를 찾기 위해",
      "답변의 미사여구를 평가하기 위해",
      "데이터 소유권을 확인하기 위해"
    ],
    "answer": "모델의 '일반화(Generalization)' 능력을 검증하기 위해",
    "why": "단순 암기가 아닌 실제 지적 능력을 습득했는지 확인하기 위함입니다.",
    "hint": "보편적으로 잘하는 능력을 생각하세요.",
    "trap_points": [
      "과적합된 모델은 이 단계에서 실패함"
    ],
    "difficulty": "medium",
    "id": "0623"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "고성능 모델의 출력값을 정답(Label)으로 삼아 더 작은 모델을 학습시키는 과정을 무엇이라 하나요?",
    "answer": "Knowledge Distillation (지식 증류)",
    "why": "거대 모델의 지능을 효과적으로 압축하여 효율적인 소형 모델을 만드는 전략입니다.",
    "hint": "지식을 증류(Distillation)함.",
    "trap_points": [
      "합성 데이터 학습도 이 범주에 포함됨"
    ],
    "difficulty": "medium",
    "id": "0624",
    "options": [
      "Knowledge Distillation (지식 증류)",
      "Knowledge Transfer",
      "Fine-tuning",
      "Pre-training",
      "Quantization"
    ]
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 후 안전 필터링이 너무 강해져서 정상적인 질문에도 '답변할 수 없습니다'라고 거부하는 현상을 무엇이라 하나요?",
    "options": [
      "Under-refusal",
      "Over-refusal (과도한 거부)",
      "Correct Alignment",
      "Successful Tuning",
      "Model Collapse"
    ],
    "answer": "Over-refusal (과도한 거부)",
    "why": "안전 정렬(Safety Alignment)이 과하게 적용되어 모델이 무해한 질문까지 위험하다고 판단하는 부작용입니다.",
    "hint": "너무 많이(Over) 거절(Refusal)함.",
    "trap_points": [
      "가동성(Helpfulness)과 안전성(Safety)의 균형 잡기가 어려움"
    ],
    "difficulty": "medium",
    "id": "0625"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "사전 학습된 모델에 아무런 레이블 없는 도메인 문서들을 그대로 더 학습시켜 '지식의 토양'을 다지는 과정은?",
    "options": [
      "SFT",
      "Continuous Pre-training (CPT)",
      "RLHF",
      "DPO",
      "Distillation"
    ],
    "answer": "Continuous Pre-training (CPT)",
    "why": "기존 지식 위에 새로운 분야의 텍스트 덩어리를 부어 넣어 모델 자체가 해당 도메인의 언어 패턴을 익히게 하는 것입니다.",
    "hint": "학습을 '지속(Continuous)'한다는 뜻입니다.",
    "trap_points": [
      "가장 많은 데이터와 GPU 자원이 필요한 단계임"
    ],
    "difficulty": "hard",
    "id": "0626"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "질문과 정답이 명시된 데이터셋으로 모델을 직접 지도 학습시키는 단계는?",
    "options": [
      "SFT (Supervised Fine-tuning)",
      "Rewarding",
      "Prompting",
      "Sampling",
      "Normalization"
    ],
    "answer": "SFT (Supervised Fine-tuning)",
    "why": "지도 학습(Supervised)을 통해 모델이 특정 질문에 대답하는 방식을 배우게 합니다.",
    "hint": "감독/지도하에 학습시킨다는 약자입니다.",
    "trap_points": [
      "Instruction Tuning은 SFT의 한 종류임"
    ],
    "difficulty": "medium",
    "id": "0627"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "LoRA 기법에서 'Rank(r)' 값이 커질 때 나타나는 일반적인 특징은?",
    "options": [
      "학습해야 할 파라미터가 줄어든다.",
      "모델 성능이 무조건 나빠진다.",
      "학습 가능한 변수가 늘어나 복잡한 패턴을 더 잘 학습할 수 있지만 메모리 사용량도 늘어난다.",
      "속도가 훨씬 빨라진다.",
      "양자화 비트 수가 늘어난다."
    ],
    "answer": "학습 가능한 변수가 늘어나 복잡한 패턴을 더 잘 학습할 수 있지만 메모리 사용량도 늘어난다.",
    "why": "Rank는 어댑터 행렬의 크기를 결정하며, 클수록 표현력은 좋아지나 효율성은 감소합니다.",
    "hint": "행렬의 크기, 차원(Rank)을 생각하세요.",
    "trap_points": [
      "보통 8, 16, 32 정도를 사용하며 너무 크면 Full FT와 차이가 없어짐"
    ],
    "difficulty": "hard",
    "id": "0628"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "모델이 실패한 대화에서 '왜 실패했는지'를 분석하고 스스로 수정하여 다음 시도에 반영하는 기법은?",
    "options": [
      "SFT",
      "Reflexion (또는 Self-Reflection)",
      "DPO",
      "LoRA",
      "CPT"
    ],
    "answer": "Reflexion (또는 Self-Reflection)",
    "why": "스스로 반성(Reflection)하는 과정을 통해 에이전트의 정답률을 지속적으로 개선하는 고성능 기법입니다.",
    "hint": "반성, 성찰이라는 뜻입니다.",
    "trap_points": [
      "학습 시뿐만 아니라 추론(Inference) 시에도 에이전트가 사용할 수 있음"
    ],
    "difficulty": "medium",
    "id": "0629"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 시 이전의 중요한 정보를 잊어버리는 것을 방지하기 위해 사용하는 원본 모델과 파인튜닝 모델 사이의 통계적 거리 제한 기술은?",
    "answer": "KL Divergence (KL 발산)",
    "why": "PPO 등 강화학습에서 모델이 너무 크게 변해버려(붕괴) 원래의 언어 능력을 잃는 것을 막는 '안전 장치' 역할을 합니다.",
    "hint": "통계에서 두 분포 간의 차이를 측정하는 용어입니다.",
    "trap_points": [
      "KL 거리가 너무 크면 모델이 헛소리를 할 확률이 올라감"
    ],
    "difficulty": "hard",
    "id": "0630",
    "options": [
      "KL Divergence (KL 발산)",
      "Euclidean Distance",
      "Cosine Similarity",
      "L1 Norm",
      "L2 Norm"
    ]
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "인간의 피드백 없이도 코딩 문제의 '성공 여부'처럼 명확히 실현 가능한 보상을 통해 학습하는 방식은?",
    "options": [
      "RLHF",
      "RLVR (Reinforcement Learning with Verifiable Reward)",
      "DPO",
      "SFT",
      "Pre-training"
    ],
    "answer": "RLVR (Reinforcement Learning with Verifiable Reward)",
    "why": "실행 결과가 0(실패) 아니면 1(성공)로 명확한 경우, 보상 모델 없이 직접 강화학습을 수행하여 추론 능력을 극대화합니다.",
    "hint": "검증 가능한(Verifiable) 보상에 주목하세요.",
    "trap_points": [
      "DeepSeek-R1 등 최신 추론 모델의 핵심 비결 중 하나임"
    ],
    "difficulty": "hard",
    "id": "0631"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝용 데이터셋을 만들기 위해 고성능 모델(예: GPT-4)을 사용하여 질문-답변 쌍을 대량으로 생성하는 것을 무엇이라 하나요?",
    "options": [
      "Data Scraping",
      "Synthetic Data Generation (합성 데이터 생성)",
      "Labeling",
      "Cleaning",
      "Scaling"
    ],
    "answer": "Synthetic Data Generation (합성 데이터 생성)",
    "why": "사람이 일일이 만드는 비용을 줄이고 고성능 모델의 능력을 학습 모델에 전이(Knowledge Distillation)하기 위해 널리 쓰입니다.",
    "hint": "진짜가 아닌 '합성된(Synthetic)' 데이터입니다.",
    "trap_points": [
      "모델이 만든 데이터만 쓰다 보면 성능이 열화될 수도 있으니 주의해야 함"
    ],
    "difficulty": "medium",
    "id": "0632"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "여러 도메인(수학, 번역, 법률 등)의 LoRA 어댑터를 하나의 모델에 필요에 따라 갈아 끼우며 사용하는 기술은?",
    "options": [
      "Single-LoRA",
      "Multi-LoRA",
      "Universal Tuning",
      "Dynamic Model",
      "Switching Model"
    ],
    "answer": "Multi-LoRA",
    "why": "원본 모델(Base)은 하나로 유지하고 상황에 맞는 가벼운 어댑터만 교체하므로 저장 공간과 서빙 효율이 극대화됩니다.",
    "hint": "여러 개(Multi)의 어댑터입니다.",
    "trap_points": [
      "Peft 라이브러리를 통해 쉽게 구현 가능함"
    ],
    "difficulty": "medium",
    "id": "0633"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "RLHF 방식에서 모델이 보상을 높게 받는 법만 터득하여, 보상 모델의 허점을 파고들어 엉뚱한 답을 내는 현상은?",
    "answer": "Reward Hacking (보상 해킹)",
    "why": "보상 모델이 완벽하지 않기 때문에, 모델이 실제 의도와는 무관하게 '점수만 잘 받는 꼼수'를 학습하는 부작용입니다.",
    "hint": "보상을 해킹한다(Hacking)는 뜻입니다.",
    "trap_points": [
      "KL Divergence를 통해 이를 억제할 수 있음"
    ],
    "difficulty": "hard",
    "id": "0634",
    "options": [
      "Reward Hacking (보상 해킹)",
      "Model Bias",
      "Overfitting",
      "Gradient Explosion",
      "Mode Collapse"
    ]
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "RAG을 기반으로 답변하는 '방식' 자체를 모델에 학습시켜 할루시네이션을 줄이는 기법은?",
    "options": [
      "RAFT (Retrieval-Augmented Fine-Tuning)",
      "CPT",
      "DPO",
      "GRPO",
      "IT"
    ],
    "answer": "RAFT (Retrieval-Augmented Fine-Tuning)",
    "why": "모델에게 '질문과 문서를 줄 테니 반드시 문서에 근거하여 CoT로 풀어라'라는 형식을 학습시키는 방식입니다.",
    "hint": "뗏목(Raft)과 발음이 같으며 RAG가 섞인 약자입니다.",
    "trap_points": [
      "오픈 북 시험 공부법과 유사한 원리임"
    ],
    "difficulty": "hard",
    "id": "0635"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝의 대표적인 방법인 LoRA에서 ‘Alpha’ 값이 조절하는 것은?",
    "options": [
      "모델의 층 개수",
      "어댑터 가중치가 원본 가중치에 미치는 영향력(Scaling)",
      "데이터의 양",
      "학습 속도",
      "비용"
    ],
    "answer": "어댑터 가중치가 원본 가중치에 미치는 영향력(Scaling)",
    "why": "학습된 델타 가중치에 alpha / rank 값을 곱하여 최종 가중치에 반영하는 정도를 튜닝합니다.",
    "hint": "스케일링(Scaling) 계수입니다.",
    "trap_points": [
      "보통 rank와 같거나 2배 정도로 설정함"
    ],
    "difficulty": "hard",
    "id": "0636"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝된 모델의 성능 평가 지표인 'Perplexity (퍼플렉서티)'가 의미하는 것은?",
    "options": [
      "모델의 답변 속도",
      "모델이 다음 단어를 예측할 때 느끼는 '당혹감'(낮을수록 모델이 확신을 갖고 정답에 가깝다고 판단함)",
      "모델의 파일 크기",
      "모델의 가독성",
      "모델의 가격"
    ],
    "answer": "모델이 다음 단어를 예측할 때 느끼는 '당혹감'(낮을수록 모델이 확신을 갖고 정답에 가깝다고 판단함)",
    "why": "언어 모델이 주어진 문장에 대해 얼마나 헷갈리고 있는지를 수치화한 지표입니다.",
    "hint": "당혹감을 뜻하는 영어 단어입니다.",
    "trap_points": [
      "낮을수록 좋은 언어 모델이지만 실제 정답 정밀도와는 다를 수 있음"
    ],
    "difficulty": "hard",
    "id": "0637"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 시 ‘치명적 망각(Catastrophic Forgetting)’이 발생하는 시점은?",
    "options": [
      "데이터를 아예 안 넣었을 때",
      "특정 데이터셋으로 너무 반복해서 학습하여 모델이 가진 기존의 보편적 지능이 무너졌을 때",
      "모델 용량이 너무 클 때",
      "학습 속도가 너무 늦을 때",
      "영어로만 코딩할 때"
    ],
    "answer": "특정 데이터셋으로 너무 반복해서 학습하여 모델이 가진 기존의 보편적 지능이 무너졌을 때",
    "why": "새로운 지식에 파라미터가 과하게 적응하면서 기존의 중요한 뉴런 정보들이 상실되기 때문입니다.",
    "hint": "비극적인 잊어버림 현상입니다.",
    "trap_points": [
      "이를 방지하기 위해 KL divergence 제약을 둠"
    ],
    "difficulty": "medium",
    "id": "0638"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "모델의 가중치를 파괴하지 않고, 두 개 이상의 서로 다른 파인튜닝된 모델 가중치를 합쳐서 시너지를 내는 기술은?",
    "options": [
      "Model Merging (모델 머징)",
      "Model Distillation",
      "Model Scaling",
      "Model Quantization",
      "Model Backing"
    ],
    "answer": "Model Merging (모델 머징)",
    "why": "추가 학습 없이 가중치들을 가중 평균하거나 특수 알고리즘(SLERP 등)으로 합쳐서 종합 성능을 올립니다.",
    "hint": "합치다라는 뜻입니다.",
    "trap_points": [
      "허깅페이스 오픈 모델 랭킹 상위권은 대부분 머징된 모델들임"
    ],
    "difficulty": "medium",
    "id": "0639"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "학습 데이터가 부족할 때, 데이터의 내용을 약간씩 변형(순서 변경, 유의어 교체 등)하여 양을 늘리는 기법은?",
    "answer": "Data Augmentation (데이터 증강)",
    "why": "부족한 샘플 수를 인위적으로 확장하여 모델의 일반화 성능을 높입니다.",
    "hint": "증강(Augment)하다.",
    "trap_points": [
      "기존 의미가 훼손되지 않는 선에서 변형해야 함"
    ],
    "difficulty": "medium",
    "id": "0640",
    "options": [
      "Data Augmentation (데이터 증강)",
      "Data Cleansing",
      "Data Normalization",
      "Data Sampling",
      "Data Shuffling"
    ]
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "학습 모델이 너무 비대하여 실시간 서비스가 불가능할 때, 성능손실을 최소화하며 크기를 줄이는 전략이 아닌 것은?",
    "options": [
      "Quantization (양자화)",
      "Pruning (가지치기)",
      "Distillation (증류)",
      "Parameter Scaling (파라미터 증설)",
      "Model Merging 후 최적화"
    ],
    "answer": "Parameter Scaling (파라미터 증설)",
    "why": "파라미터 증설은 모델을 더 키우는 것이므로 효율화 목적과는 정반대됩니다.",
    "hint": "크기를 '줄이는' 것이 아닌 것을 찾으세요.",
    "trap_points": [
      "최근에는 4비트 양자화가 가장 효율적인 대안임"
    ],
    "difficulty": "easy",
    "id": "0641"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "DeepSeek R1 아키텍처에서 '보상 모델'의 자리를 대신하며 강화학습 효율을 극대화한 'Rule-based verifier'의 특징은?",
    "options": [
      "사람이 직접 채점한다.",
      "수학 정답이나 코드 컴파일 결과처럼 명확한 '규칙'으로 보상을 준다.",
      "운으로 결정한다.",
      "영어로만 채점한다.",
      "과거 데이터를 무시한다."
    ],
    "answer": "수학 정답이나 코드 컴파일 결과처럼 명확한 '규칙'으로 보상을 준다.",
    "why": "보상 모델 자체가 가진 할루시네이션(점수 잘못 주기) 위험을 배제하고 수학적 진리만으로 모델을 연마시킵니다.",
    "hint": "검증기(Verifier) 기반의 규칙입니다.",
    "trap_points": [
      "추론 성능을 비약적으로 올린 핵심 비결임"
    ],
    "difficulty": "hard",
    "id": "0642"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 데이터셋 구축 시 ‘입력 프롬프트’와 ‘정답’ 사이에 <thought> 태그를 넣어 생각하는 과정을 보여주는 기법은?",
    "options": [
      "Chain of Thought Tuning",
      "CoT-SFT",
      "Direct Answer Tuning",
      "Implicit Tuning",
      "Hidden Tuning"
    ],
    "answer": "CoT-SFT",
    "why": "논리적 추론 과정을 직접 지도 학습 데이터에 포함시켜 모델이 '생각하는 습관'을 갖게 만듭니다.",
    "hint": "생각의 사슬(CoT)을 활용한 지도 학습(SFT).",
    "trap_points": [
      "모델의 추론 성능이 극대화되는 기반이 됨"
    ],
    "difficulty": "hard",
    "id": "0643"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝된 모델이 특정 주제에 대해 답변을 거부하게 만들거나, 특정 정치색을 띠지 않게 정렬하는 최종적이고 미세한 단계를 무엇이라 하나요?",
    "answer": "Safety Alignment (안전 정렬)",
    "why": "윤리 규정, 안전 지침 등을 모델에 내면화시키는 과정입니다.",
    "hint": "안전(Safety) + 정렬(Alignment).",
    "trap_points": [
      "사용자의 부적절한 질문에 대해 단호하게 거절하는 능력을 학습함"
    ],
    "difficulty": "medium",
    "id": "0644",
    "options": [
      "Safety Alignment (안전 정렬)",
      "Policy Optimization",
      "Preference Learning",
      "Bias Mitigation",
      "Topic Control"
    ]
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "모델 공유 사이트(Hugging Face 등)에서 모델 이름에 'GGUF'가 붙어 있다면 이는 무엇을 뜻하나요?",
    "options": [
      "가장 성능이 좋은 원본 모델이다.",
      "로컬 PC(Llama.cpp 등)나 모바일에서 돌리기 좋게 양자화된 전용 포맷이다.",
      "영어로만 된 모델이다.",
      "학습이 덜 된 모델이다.",
      "비싼 GPU가 있어야만 도는 모델이다."
    ],
    "answer": "로컬 PC(Llama.cpp 등)나 모바일에서 돌리기 좋게 양자화된 전용 포맷이다.",
    "why": "CP 추론 최적화와 메모리 점유율을 극도로 낮춘 파일 형식으로 개인 개발자들에게 가장 인기가 높습니다.",
    "hint": "GG로 시작하는 가벼운 포맷입니다.",
    "trap_points": [
      "파일 하나로 실행 가능하며 설저이 매우 간편함"
    ],
    "difficulty": "easy",
    "id": "0645"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "DPO(Direct Preference Optimization) 알고리즘이 기존 RLHF보다 혁신적인 이유는?",
    "options": [
      "돈이 더 많이 들어서",
      "별도의 보상 모델(Reward Model) 학습 없이, 선호도 답변 쌍만으로 직접 모델을 최적화할 수 있기 때문",
      "영어로만 학습해서",
      "파일 용량이 커서",
      "속도가 늦어져서"
    ],
    "answer": "별도의 보상 모델(Reward Model) 학습 없이, 선호도 답변 쌍만으로 직접 모델을 최적화할 수 있기 때문",
    "why": "리워드 모델링 단계의 복잡성과 할루시네이션 위험을 제거한 최신 정렬 기법입니다.",
    "hint": "직접(Direct) 선호도(Preference)를 최적화합니다.",
    "trap_points": [
      "현대 오픈 모델 정렬의 대세 기술임"
    ],
    "difficulty": "hard",
    "id": "0646"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 데이터셋 구축 시 ‘고품질’의 기준에 해당하지 않는 것은?",
    "options": [
      "내용의 정확성",
      "표현의 다양성",
      "형식의 일관성",
      "데이터의 단순 무작위 대량 복사",
      "중복 제거 여부"
    ],
    "answer": "데이터의 단순 무작위 대량 복사",
    "why": "단순 복사는 모델의 편향만 강화할 뿐 실제 지능 향상에는 도움이 되지 않습니다.",
    "hint": "질보다 양을 추구하는 행위를 찾으세요.",
    "trap_points": [
      "무조건 많은 게 아니라 정제된(Curated) 것이 최고임"
    ],
    "difficulty": "easy",
    "id": "0647"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "모델의 가중치를 4비트나 8비트 정수로 변환하여 용량을 획기적으로 줄이는 기술의 이름은?",
    "options": [
      "Quantization (양자화)",
      "Distillation",
      "Pruning",
      "Backprop",
      "Gradient Descent"
    ],
    "answer": "Quantization (양자화)",
    "why": "정보의 정밀도를 아주 조금 희생하는 대신 메모리 사용량을 1/4~1/8로 줄여 일반 컴퓨터에서도 LLM 구동을 가능하게 합니다.",
    "hint": "양자(Quantum) 단위로 쪼개 수치화합니다.",
    "trap_points": [
      "압축 과정에서 다소의 성능 하락이 발생할 수 있음"
    ],
    "difficulty": "medium",
    "id": "0648"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 학습 시 'Epoch (에포크)'가 의미하는 것은?",
    "options": [
      "모델의 크기",
      "전체 학습 데이터를 한 바퀴 모두 훑는 주기",
      "파일이 저장되는 경로",
      "인터넷 연결 상태",
      "학습 모델의 이름"
    ],
    "answer": "1 Epoch (1 에폭)",
    "why": "데이터셋 전체를 몇 번 반복해서 학습(학습 횟수)할지의 기준이 됩니다.",
    "hint": "시대를 뜻하는 단어이지만 학습에서는 한 주기를 뜻합니다.",
    "trap_points": [
      "너무 많이 돌리면 과적합(Overfitting)이 발생함"
    ],
    "difficulty": "easy",
    "id": "0649"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "LoRA 학습에서 원본 모델의 가중치를 전혀 건드리지 않고 ‘얼려두는’ 것을 무엇이라 하나요?",
    "answer": "Freezing (동결)",
    "why": "메모리를 아끼고 기존 지식을 보존하기 위해 베이스 모델의 파라미터 업데이트를 막습니다.",
    "hint": "얼리다라는 뜻입니다.",
    "trap_points": [
      "이 덕분에 아주 적은 양의 GPU로도 학습이 가능해짐"
    ],
    "difficulty": "medium",
    "id": "0650",
    "options": [
      "Freezing (동결)",
      "Melting",
      "Dropping",
      "Skipping",
      "Weighting"
    ]
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "고해상도 이미지와 텍스트를 동시에 이해하고 생성하는 모델을 만들기 위한 파인튜닝은?",
    "options": [
      "Multi-modal Tuning",
      "Direct Tuning",
      "Style Tuning",
      "Negative Tuning",
      "Single Tuning"
    ],
    "answer": "Multi-modal Tuning",
    "why": "여러 양식(Mode)의 데이터를 하나로 엮어 통합 지능을 기르는 과정입니다.",
    "hint": "여러 개(Multi)의 양식(Modal)입니다.",
    "trap_points": [
      "최신 파인튜닝 트렌드 중 하나임"
    ],
    "difficulty": "medium",
    "id": "0651"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 후 모델의 'Perplexity' 값이 비정상적으로 높아졌다면 이는 무엇을 의미하나요?",
    "options": [
      "모델이 천재가 되었다.",
      "모델이 다음 단어를 전혀 예측하지 못하고 매우 혼란스러워하며 성능이 망가졌다.",
      "파일 속도가 무지 빠르다.",
      "영어로만 답한다.",
      "성능이 최고로 좋아졌다."
    ],
    "answer": "모델이 다음 단어를 전혀 예측하지 못하고 매우 혼란스러워하며 성능이 망가졌다.",
    "why": "퍼플렉서티는 당혹감을 뜻하며, 낮을수록 안정적인 언어 모델임을 뜻합니다.",
    "hint": "수치가 낮을수록 좋은 지표입니다.",
    "trap_points": [
      "학습률이 너무 높을 때 발생하기 쉬운 증상임"
    ],
    "difficulty": "hard",
    "id": "0652"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝된 모델 배포 도구 중 하나로, 로컬 환경에서 명령어 한 줄로 모델을 실행하는 가장 유명한 도구는?",
    "options": [
      "Ollama",
      "vLLM",
      "Docker",
      "S3",
      "Kubernetes"
    ],
    "answer": "Ollama",
    "why": "맥/윈도우/리눅스에서 매우 간편하게 오픈 소스 모델을 구동할 수 있어 인기가 높습니다.",
    "hint": "요리용 '기름(Oil)'과 '라마(Llama)'의 합성어 같은 이름입니다.",
    "trap_points": [
      "로컬 개발자들에게는 사실상의 표준임"
    ],
    "difficulty": "easy",
    "id": "0653"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 시 모델이 학습 데이터 속에 숨겨진 개인정보(이메일, 주소 등)를 암기해버리는 문제를 무엇이라 하나요?",
    "answer": "Data Leakage (데이터 유출) 또는 Privacy Memorization",
    "why": "민감 정보가 모델 파라미터에 각인되어 대화 중 외부에 노출될 위험이 있습니다.",
    "hint": "데이터가 샌다(Leak)는 뜻입니다.",
    "trap_points": [
      "이를 막기 위해 비식별화 처리가 필수적임"
    ],
    "difficulty": "medium",
    "id": "0654",
    "options": [
      "Data Leakage (데이터 유출) 또는 Privacy Memorization",
      "Overfitting",
      "Bias",
      "Hallucination",
      "Underfitting"
    ]
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "모델 학습 시 ‘가중치 손실(Loss)’을 최소화하기 위해 경사면을 따라 내려가는 기본 알고리즘은?",
    "options": [
      "Gradient Descent (경사 하강법)",
      "Random Selection",
      "Quick Sort",
      "Binary Search",
      "Hash Logic"
    ],
    "answer": "Gradient Descent (경사 하강법)",
    "why": "손실 함수의 기울기(Gradient) 반대 방향으로 가중치를 조금씩 이동시켜 오차를 줄여나가는 딥러닝의 심장입니다.",
    "hint": "경사(Gradient)를 내려간다(Descent)는 뜻입니다.",
    "trap_points": [
      "최신 모델은 이의 발전형인 Adam, AdamW 등을 주로 사용함"
    ],
    "difficulty": "medium",
    "id": "0655"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "DeepSeek-R1-Zero처럼 별도의 SFT 없이 규칙 기반 보상만으로 추론 능력을 학습시키는 강화학습 알고리즘은?",
    "options": [
      "PPO",
      "DPO",
      "GRPO",
      "SFT",
      "RAFT"
    ],
    "answer": "GRPO",
    "why": "GRPO는 그룹 내 상대적 보상을 통해 학습하며, DeepSeek R1의 추론 성능 극대화에 핵심적인 역할을 했습니다.",
    "hint": "G로 시작하는 4글자 알고리즘입니다.",
    "trap_points": [
      "PPO와 달리 별도의 가치 모델(Value Model)이 필요 없어 메모리가 절약됨"
    ],
    "difficulty": "hard",
    "id": "0656"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "모델의 가중치 비트 수를 낮추어(예: 16bit -> 4bit) 모델 크기를 줄이는 기술은?",
    "answer": "Quantization (양자화)",
    "why": "양자화는 메모리와 연산량을 획기적으로 줄여 일반 PC나 모바일에서도 거대 모델을 실행할 수 있게 합니다.",
    "hint": "Q로 시작하는 전문 용어입니다.",
    "trap_points": [
      "파인튜닝과는 별개의 최적화 단계임"
    ],
    "difficulty": "easy",
    "id": "0657",
    "options": [
      "Quantization (양자화)",
      "Pruning",
      "蒸溜 (Distillation)",
      "Compression",
      "Sparsification"
    ]
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "LoRA 파인튜닝 시 학습 데이터에 과하게 적응하여 범용 능력이 떨어지는 현상은?",
    "options": [
      "Regularization",
      "Overfitting (과적합)",
      "Underfitting",
      "Normalization",
      "Quantization"
    ],
    "answer": "Overfitting (과적합)",
    "why": "특정 데이터셋의 패턴만 완벽히 외워버려 새로운 질문이나 다른 도메인에 대한 대응력이 상상히 저하되는 현상입니다.",
    "hint": "너무(Over) 딱 맞게(Fitting) 된 상황입니다.",
    "trap_points": [
      "망각(Forgetting)과는 구분되는 개념임"
    ],
    "difficulty": "medium",
    "id": "0658"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "오픈 모델(Llama 등)을 CPU만 있는 환경이나 메모리가 부족한 Mac에서 효율적으로 실행하기 위해 주로 사용하는 포맷은?",
    "options": [
      "PyTorch (.pt)",
      "TensorFlow (.pb)",
      "GGUF",
      "ONNX",
      "Safetensors"
    ],
    "answer": "GGUF",
    "why": "GGUF(llama.cpp 계열)는 양자화된 가중치를 담은 단일 파일 포맷으로, CPU 추론 최적화와 함께 상용 LLM 도구(Ollama 등)에서 널리 쓰입니다.",
    "hint": "GG로 시작하는 4글자 포맷입니다.",
    "trap_points": [
      "Safetensors는 보안에 안전한 가중치 저장 방식이지만 CPU 최적화 포맷은 아님"
    ],
    "difficulty": "medium",
    "id": "0659"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "사전 학습된 베이스 모델의 능력을 그대로 유지하면서, 특정 '도메인(예: 법률, 의료)'의 지식만을 얇게 덧씌우는 PEFT의 이점은?",
    "options": [
      "학습 속도가 느려진다.",
      "모델 파라미터 전체를 학습할 때보다 GPU 메모리를 획기적으로 아끼고 빠른 튜닝이 가능하다.",
      "성능이 무조건 떨어진다.",
      "데이터가 많이 필요하다.",
      "인터넷 연결이 필수다."
    ],
    "answer": "모델 파라미터 전체를 학습할 때보다 GPU 메모리를 획기적으로 아끼고 빠른 튜닝이 가능하다.",
    "why": "가중치의 아주 일부(<1%)만 업데이트하므로 하드웨어 진입 장벽이 낮습니다.",
    "hint": "메모리와 비용의 효율성을 생각하세요.",
    "trap_points": [
      "LoRA가 대표적인 예시임"
    ],
    "difficulty": "easy",
    "id": "0660"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "RLHF 방식에서 아첨(Sycophancy) 부작용이란 무엇을 의미하나요?",
    "options": [
      "모델이 화를 내는 현상",
      "모델이 사용자에게 무조건 동조하거나 비위를 맞추는 답변만 내놓아 객관성이 떨어지는 현상",
      "답변의 글자 수가 많아지는 현상",
      "영어로만 답하는 현상",
      "인터넷 데이터를 지우는 현상"
    ],
    "answer": "모델이 사용자에게 무조건 동조하거나 비위를 맞추는 답변만 내놓아 객관성이 떨어지는 현상",
    "why": "사람이 매긴 선호도(Reward)가 '듣기 좋은 말'에 편향되어 있을 경우 모델이 이를 학습하게 됩니다.",
    "hint": "남의 비위를 맞춘다는 뜻의 어려운 단어입니다.",
    "trap_points": [
      "모델의 비판적 사고가 저해될 수 있음"
    ],
    "difficulty": "hard",
    "id": "0661"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "DeepSeek-R1의 성공 요인 중 하나인 'GRPO'는 무엇의 약자인가요?",
    "options": [
      "Grand Reward Policy Optimization",
      "Group Relative Policy Optimization",
      "General Reason Policy Output",
      "Grid Relation Point Object",
      "Gradient Reset Policy Option"
    ],
    "answer": "Group Relative Policy Optimization",
    "why": "그룹 내의 상대적인 보상을 비교하여 학습하는 강화학습 알고리즘으로 별도의 가치 모델이 필요 없습니다.",
    "hint": "그룹(Group) 상대적(Relative)인 정책 최적화입니다.",
    "trap_points": [
      "DeepSeek에서 제안하여 화제가 됨"
    ],
    "difficulty": "hard",
    "id": "0662"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "양자화 기법 중 0을 기준으로 대칭적인 분포를 사용하여 4비트 정밀도에서도 성능을 잘 유지하는 QLoRA의 핵심 포맷은?",
    "options": [
      "float32",
      "int8",
      "NF4 (Normal Float 4)",
      "BF16",
      "FP8"
    ],
    "answer": "NF4 (Normal Float 4)",
    "why": "정보의 손실을 방지하기 위해 가중치의 통계적 분포에 최적화된 비트 할당 방식입니다.",
    "hint": "Normal(정상 분포) + Float 4.",
    "trap_points": [
      "비트 수는 같아도 일반 int4보다 보존력이 높음"
    ],
    "difficulty": "hard",
    "id": "0663"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "고성능 교사 모델(Teacher)의 출력을 학생 모델(Student)이 따라 하게 하여 지식을 전수하는 기법은?",
    "answer": "Knowledge Distillation (지식 증류)",
    "why": "큰 모델의 확률 분포를 작은 모델이 학습하여 '가벼운 고성능 모델'을 만듭니다.",
    "hint": "지식을 증류(Distillation)함.",
    "trap_points": [
      "sLLM들의 비약적 발전의 숨은 공신임"
    ],
    "difficulty": "medium",
    "id": "0664",
    "options": [
      "Knowledge Distillation (지식 증류)",
      "Fine-tuning",
      "Quantization",
      "Prompting",
      "Pruning"
    ]
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 데이터셋 구축 시 '품질이 나쁜 데이터'가 섞여 있을 때 발생하는 가장 고질적인 문제는?",
    "options": [
      "모델의 크기가 커진다.",
      "모델의 출력 품질이 오염되어 횡설수설하거나 틀린 답을 확신 있게 말하게 된다.",
      "학습 속도가 빨라진다.",
      "영어로만 답한다.",
      "UI가 깨진다."
    ],
    "answer": "모델의 출력 품질이 오염되어 횡설수설하거나 틀린 답을 확신 있게 말하게 된다.",
    "why": "쓰레기가 들어가면 쓰레기가 나온다는 GIGO(Garbage In Garbage Out) 원칙은 LLM에서도 매우 강력합니다.",
    "hint": "입력 데이터의 수준이 출력 수준을 결정합니다.",
    "trap_points": [
      "무조건 양이 많은 것보다 소수의 고품질 데이터가 훨씬 나음"
    ],
    "difficulty": "easy",
    "id": "0665"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "강화학습에서 모델이 지나치게 변형되는 것을 막기 위해 '원본 모델의 확률 분포'와의 차이를 계산하는 손실 함수는?",
    "options": [
      "MSE Loss",
      "Cross Entropy",
      "KL Divergence (KL 발산)",
      "Huber Loss",
      "L1 Loss"
    ],
    "answer": "KL Divergence (KL 발산)",
    "why": "모델이 보상만 쫓다가 원래의 언어적 기초를 망가뜨리는 것을 방지하는 제약(Constraint) 장치입니다.",
    "hint": "통계적 거리 차이를 재는 용어입니다.",
    "trap_points": [
      "KL 값이 너무 크면 모델이 붕괴(Collapse)될 수 있음"
    ],
    "difficulty": "hard",
    "id": "0666"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 시 학습 데이터에 'Thinking(추론 과정)'을 명시적으로 포함해 교수하는 방식은?",
    "options": [
      "Zero-shot Tuning",
      "Reasoning SFT",
      "Direct Tuning",
      "Style Tuning",
      "Format Tuning"
    ],
    "answer": "Reasoning SFT",
    "why": "단순히 '질문-정답'만 주지 않고 '질문-생각과정-정답'을 함께 학습시켜 논리 구조를 각인시킵니다.",
    "hint": "추론(Reasoning) 과정을 담은 지도 학습(SFT)입니다.",
    "trap_points": [
      "DeepSeek R1-Distill 모델들이 이 방식으로 만들어짐"
    ],
    "difficulty": "hard",
    "id": "0667"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 시 특정 데이터를 완전히 잊어버리게 하거나 개인정보를 지우는 기술적 과정은?",
    "answer": "Machine Unlearning (기계 언러닝)",
    "why": "이미 학습된 모델의 가중치에서 특정 지식의 영향력을 제거하는 고도로 어려운 작업입니다.",
    "hint": "배운 것을 잊게 만드는 과정입니다.",
    "trap_points": [
      "단순히 거절 프롬프트를 넣는 것과는 차원이 다른 기술임"
    ],
    "difficulty": "hard",
    "id": "0668",
    "options": [
      "Machine Unlearning (기계 언러닝)",
      "Data Deletion",
      "Privacy Scrubbing",
      "Model Retraining",
      "Bias Removal"
    ]
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "모델 배포 효율을 위해 중복되거나 중요도가 낮은 뉴런(가중치)을 아예 제거해 버리는 최적화 기술은?",
    "options": [
      "Quantization",
      "Pruning (가지치기)",
      "Distillation",
      "Merging",
      "Clipping"
    ],
    "answer": "Pruning (가지치기)",
    "why": "연산 그래프에서 불필요한 연결을 끊어내어 속도를 높이고 용량을 줄이는 기법입니다.",
    "hint": "나뭇가지를 친다는 뜻입니다.",
    "trap_points": [
      "과도하게 하면 성능이 급락할 수 있음"
    ],
    "difficulty": "hard",
    "id": "0669"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "모델의 지능 자체를 높이기보다 '특정한 말투나 업무 포맷(예: 마크다운 보고서 형식)'을 우선적으로 각인시키기 위해 하는 튜닝은?",
    "options": [
      "Pre-training",
      "Style/Instruction Fine-tuning",
      "Quantization",
      "Normalization",
      "Distillation"
    ],
    "answer": "Style/Instruction Fine-tuning",
    "why": "SFT를 통해 답변의 외형적 피처(Feature)를 사용자의 입맛에 맞게 고정합니다.",
    "hint": "스타일과 형식에 집중하는 튜닝입니다.",
    "trap_points": [
      "지식 주입보다 '행동 교정'에 더 큰 효과가 있음"
    ],
    "difficulty": "medium",
    "id": "0670"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "DPO 파인튜닝 시 필요한 데이터의 가장 기본적인 최소 단위(Row) 구성은?",
    "options": [
      "질문 하나와 답변 하나",
      "질문 하나와 (좋은 답변, 나쁜 답변) 한 쌍",
      "문서 덩어리 하나",
      "단어 리스트",
      "유저 평점"
    ],
    "answer": "질문 하나와 (좋은 답변, 나쁜 답변) 한 쌍",
    "why": "DPO는 두 가지 답변 중 어느 것을 더 선호하는지 직접 비교하며 확률 분포를 조정하기 때문입니다.",
    "hint": "선호도(Preference)를 알려주기 위해 필요한 최소 비교 대상 수는?",
    "trap_points": [
      "좋은 것만 가르치는 SFT보다 오답의 확률을 직접 낮출 수 있어 강력함"
    ],
    "difficulty": "medium",
    "id": "0671"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "추론 모델(DeepSeek R1 등) 학습 시, '풀이 과정이 틀려도 최종 정답만 맞으면 보상을 주는' 강화학습 방식이 가능한 이유는?",
    "options": [
      "모델이 천재라서",
      "정답이 명확한(수학, 코딩 등) 문제의 경우 Rule-based로 자동 검증이 가능하기 때문",
      "사람이 24시간 감시해서",
      "데이터가 윈도우 기반이라서",
      "모델이 스스로 정답을 알기 때문"
    ],
    "answer": "정답이 명확한(수학, 코딩 등) 문제의 경우 Rule-based로 자동 검증이 가능하기 때문",
    "why": "검증 가능한 보상(Verifiable Reward)이 있으면 보상 모델의 주관성 없이도 강력하게 모델을 몰아붙일 수 있습니다.",
    "hint": "채점하기 쉬운 과목(수학/코딩)을 생각하세요.",
    "trap_points": [
      "인문학적 질문에는 이 방식을 적용하기 어려움"
    ],
    "difficulty": "hard",
    "id": "0672"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝된 모델을 배포할 때, 메모리 용량을 줄이면서도 성능 저하를 최소화하기 위해 '중요한 파라미터는 덜 자르고 안 중요한 것만 많이 자르는' 방식은?",
    "options": [
      "Uniform Quantization",
      "Importance-based Quantization (예: GPTQ, AWQ)",
      "Linear Pruning",
      "Dropout",
      "Early Stopping"
    ],
    "answer": "Importance-based Quantization (예: GPTQ, AWQ)",
    "why": "각 파라미터의 레이어별 중요도를 고려하여 전략적으로 양자화 비트를 할당하는 방식입니다.",
    "hint": "중요도(Importance)에 따른 차등 적용입니다.",
    "trap_points": [
      "그냥 일괄적으로 자르는 것보다 성능 보존력이 훨씬 뛰어남"
    ],
    "difficulty": "hard",
    "id": "0673"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "거대 모델의 학습을 작은 GPU 여러 대에서 나누어 수행하는 분산 학습 기술 중 하나는?",
    "answer": "DeepSpeed (또는 FSDP)",
    "why": "메모리 파편화를 줄이고 여러 GPU의 자원을 효율적으로 엮어주는 라이브러리/기술입니다.",
    "hint": "깊은 속도(Speed)라는 이름의 라이브러리입니다.",
    "trap_points": [
      "마이크로소프트에서 개발한 기술임"
    ],
    "difficulty": "hard",
    "id": "0674",
    "options": [
      "DeepSpeed (또는 FSDP)",
      "NumPy",
      "Pandas",
      "Scikit-learn",
      "Keras"
    ]
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 시 'Overfitting'을 막기 위한 가장 좋은 데이터 구축 전략은?",
    "options": [
      "같은 데이터를 수만 번 반복해서 보여준다.",
      "문맥과 말투가 다양한 고품질의 데이터를 확보하고 적절한 에포크(Epoch) 수로 학습한다.",
      "데이터를 최대한 적게 넣는다.",
      "암기만 하도록 유도한다.",
      "모델의 층을 다 없앤다."
    ],
    "answer": "문맥과 말투가 다양한 고품질의 데이터를 확보하고 적절한 에포크(Epoch) 수로 학습한다.",
    "why": "다양성은 일반화 성능을 높여주고, 적절한 학습 횟수는 특정 데이터에 매몰되는 것을 막습니다.",
    "hint": "품질(Quality)과 다양성(Diversity)의 조화입니다.",
    "trap_points": [
      "데이터 양이 많다고 무조건 과적합이 안 생기는 것은 아님"
    ],
    "difficulty": "medium",
    "id": "0675"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "강화학습 기반 파인튜닝(RLHF 등)의 부작용 중 하나로, 모델이 지나치게 공손하고 방어적으로 변해 정보를 제공하지 않는 현상은?",
    "options": [
      "Helpfulness bias",
      "Safety Over-alignment",
      "Context Leaking",
      "Forgetting",
      "Token Collapse"
    ],
    "answer": "Safety Over-alignment",
    "why": "안전에 너무 치중하여 유익한 답변까지 거절해버리는 정렬의 부작용입니다.",
    "hint": "안전(Safety)이 과하게 맞춰진 상태입니다.",
    "trap_points": [
      "가동성과 안전성의 트레이드오프 관계를 보여줌"
    ],
    "difficulty": "medium",
    "id": "0676"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "데이터셋 구축 시 사용자의 '수정 전 텍스트'와 AI의 '수정 후 텍스트' 쌍을 학습시켜 교정 능력을 기르는 방식은?",
    "options": [
      "Continuous Pre-training",
      "Reconstruction Tuning",
      "Edit-based Fine-tuning",
      "Zero-shot",
      "Augmentation"
    ],
    "answer": "Edit-based Fine-tuning",
    "why": "문서 교정, 코드 디버깅 등 변환 작업에 특화된 능력을 키워주는 방식입니다.",
    "hint": "수정(Edit) 기반의 튜닝입니다.",
    "trap_points": [
      "단순 Q&A보다 정확한 목표 지점이 있는 튜닝임"
    ],
    "difficulty": "medium",
    "id": "0677"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "모델의 특정 지층(Layer)만 선택적으로 파인튜닝하여 효율을 높이는 기법은?",
    "answer": "Selective Fine-tuning",
    "why": "전체 층이 아닌, 주로 성능 변화가 큰 뒷부분의 층이나 특정 층만 선택해 가중치를 업데이트합니다.",
    "hint": "선택적(Selective)인 학습입니다.",
    "trap_points": [
      "성능은 Full FT에 가깝게 유지하면서 비용을 줄일 수 있음"
    ],
    "difficulty": "medium",
    "id": "0678",
    "options": [
      "Selective Fine-tuning",
      "Full Fine-tuning",
      "Zero Fine-tuning",
      "Random Fine-tuning",
      "Top-down Fine-tuning"
    ]
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 과정에서 모델 성능의 병목(Bottleneck)인 '역전파(Backpropagation)' 연산량을 줄이기 위해 LoRA가 채택한 방식은?",
    "options": [
      "그냥 연산을 안 한다.",
      "가중치 행렬을 두 개의 매우 작은(Low-rank) 행렬로 분해하여 해당 행렬들에 대해서만 전파한다.",
      "데이터 개수를 줄인다.",
      "모델 층을 삭제한다.",
      "영어로만 연산한다."
    ],
    "answer": "가중치 행렬을 두 개의 매우 작은(Low-rank) 행렬로 분해하여 해당 행렬들에 대해서만 전파한다.",
    "why": "큰 행렬 대신 작은 행렬 두 개(r 차원)만 학습하면 되므로 메모리와 연산량이 급감합니다.",
    "hint": "저차원(Low-rank) 분해를 생각하세요.",
    "trap_points": [
      "이 방식 덕분에 일반 사용자들도 집에서 튜닝이 가능해짐"
    ],
    "difficulty": "hard",
    "id": "0679"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "LoRA 파인튜닝 시 전체 모델 파라미터를 건드리지 않고 일부만 학습시킴으로써 얻는 이득은?",
    "options": [
      "성능이 100배 좋아진다.",
      "GPU 메모리 사용량을 획기적으로 줄여 일반 컴퓨팅 환경에서도 학습이 가능해진다.",
      "영어로만 답한다.",
      "글자 수가 늘어난다.",
      "파일이 깨진다."
    ],
    "answer": "GPU 메모리 사용량을 획기적으로 줄여 일반 컴퓨팅 환경에서도 학습이 가능해진다.",
    "why": "가중치의 아주 일부(<1%)만 업데이트하여 효율을 극대화하는 방식입니다.",
    "hint": "비용과 하드웨어 효율성입니다.",
    "trap_points": [
      "최신 기업용 서드파티 엔진(vLLM 등)에서 LoRA 어댑터를 실시간으로 교체 가능함"
    ],
    "difficulty": "medium",
    "id": "0680"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "LoRA(Low-Rank Adaptation)에서 'Alpha' 파라미터가 32이고 'Rank(r)'가 32일 때, 스케일링 팩터(Alpha/r)의 값은?",
    "options": [
      "0.5",
      "1.0",
      "2.0",
      "32",
      "0"
    ],
    "answer": "1.0",
    "why": "스케일링 팩터는 Alpha / Rank로 계산됩니다. 32/32 = 1이므로 어댑터의 가중치가 그대로 반영됩니다.",
    "hint": "Alpha 나누기 Rank입니다.",
    "trap_points": [
      "Alpha와 Rank가 같으면 보정이 없다는 뜻임"
    ],
    "difficulty": "medium",
    "id": "0801"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 시 전체 모델 파라미터를 고정(Freeze)하고, 특정 레이어에만 학습 가능한 파라미터를 주입하는 방식의 총칭은?",
    "options": [
      "PEFT (Parameter-Efficient Fine-Tuning)",
      "Full Fine-tuning",
      "Pre-training",
      "RLHF",
      "DPO"
    ],
    "answer": "PEFT (Parameter-Efficient Fine-Tuning)",
    "why": "PEFT는 거대 모델의 대부분을 얼리고 일부만 학습하여 자원 효율성을 극대화하는 기법들의 통칭입니다.",
    "hint": "효율적(Efficient)인 파라미터 사용.",
    "trap_points": [
      "LoRA는 PEFT의 하위 종류 중 하나임"
    ],
    "difficulty": "easy",
    "id": "0802"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "CAT(Catastrophic Forgetting) 현상을 막기 위해, 파인튜닝 시 기존 데이터셋의 일부를 섞어서 학습시키는 전략은?",
    "options": [
      "Replay Buffer (리플레이 버퍼)",
      "Dropout",
      "Early Stopping",
      "Gradient Clipping",
      "Batch Normalization"
    ],
    "answer": "Replay Buffer (리플레이 버퍼)",
    "why": "과거의 데이터를 '다시 재생(Replay)'하여 모델이 이전 지식을 잊지 않도록 상기시켜 줍니다.",
    "hint": "다시 플레이(Re-play)함.",
    "trap_points": [
      "강화학습에서도 사용되는 용어임"
    ],
    "difficulty": "hard",
    "id": "0803"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "모델이 이미 학습한 지식과 상충되는 데이터로 무리하게 파인튜닝을 시도할 때 발생하는 '지식 충돌'의 결과는?",
    "options": [
      "모델이 더 똑똑해진다",
      "할루시네이션이 증가하고 일관성이 떨어진다",
      "학습 속도가 빨라진다",
      "GPU 사용량이 줄어든다",
      "새로운 언어를 창조한다"
    ],
    "answer": "할루시네이션이 증가하고 일관성이 떨어진다",
    "why": "내재된 지식과 새로운 정보가 싸우면서 모델이 혼란을 겪고, 결국 거짓 정보를 지어내게 됩니다.",
    "hint": "억지로 주입식 교육을 할 때의 부작용을 생각하세요.",
    "trap_points": [
      "지식 편집(Knowledge Editing)이 어려운 이유 중 하나"
    ],
    "difficulty": "medium",
    "id": "0804"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "LLM의 성능 평가 벤치마크 중, 수학적 추론 능력을 집중적으로 평가하는 지표는?",
    "options": [
      "GSM8K",
      "MMLU",
      "HellaSwag",
      "HumanEval",
      "BLEU"
    ],
    "answer": "GSM8K",
    "why": "초등학교 수준의 수학 문제를 단계적으로 풀게 하여 모델의 논리적 추론력을 측정합니다.",
    "hint": "수학(Math) 관련 약자.",
    "trap_points": [
      "MMLU는 종합 지식 평가임"
    ],
    "difficulty": "hard",
    "id": "0805"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "RLHF에서 사람의 선호도 데이터를 모을 때 'A 답변이 B 답변보다 낫다'고 판단하는 방식은?",
    "options": [
      "Pairwise Comparison (쌍대 비교)",
      "Absolute Scoring",
      "Binary Classification",
      "Multi-class Labeling",
      "Regression"
    ],
    "answer": "Pairwise Comparison (쌍대 비교)",
    "why": "점수를 매기는 것보다 두 개를 두고 비교하는 것이 평가자의 일관성을 유지하기 훨씬 쉽습니다.",
    "hint": "둘씩 짝(Pair)을 지어 비교함.",
    "trap_points": [
      "Elo Rating 시스템과 유사한 원리"
    ],
    "difficulty": "medium",
    "id": "0806"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "QLoRA에서 사용하는 'Double Quantization' 기술의 핵심 목적은?",
    "options": [
      "추론 속도를 2배로 늘리기 위해",
      "양자화 상수(Quantization Constant) 자체를 또 양자화하여 메모리를 추가로 절약하기 위해",
      "정확도를 2배 올리기 위해",
      "학습 시간을 줄이기 위해",
      "GPU 온도를 낮추기 위해"
    ],
    "answer": "양자화 상수(Quantization Constant) 자체를 또 양자화하여 메모리를 추가로 절약하기 위해",
    "why": "티끌 모아 태산이라고, 메타데이터인 상수값까지 압축하여 거대 모델을 소비자용 GPU에 구겨 넣습니다.",
    "hint": "두 번(Double) 양자화함.",
    "trap_points": [
      "극도의 메모리 효율화를 위한 기법임"
    ],
    "difficulty": "hard",
    "id": "0807"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "SFT(Supervised Fine-Tuning)용 데이터셋에서 가장 중요한 품질 요소는?",
    "options": [
      "데이터의 양 (Quantity)",
      "데이터의 다양성과 정확성 (Quality & Diversity)",
      "데이터의 파일 포맷",
      "데이터의 생성 날짜",
      "데이터의 언어"
    ],
    "answer": "데이터의 다양성과 정확성 (Quality & Diversity)",
    "why": "적은 양이라도 고품질의 다양한 데이터를 학습하는 것이 수만 개의 저품질 데이터보다 훨씬 효과적입니다(LIMA 논문).",
    "hint": "Less is More.",
    "trap_points": [
      "양이 많으면 오히려 독이 될 수도 있음"
    ],
    "difficulty": "easy",
    "id": "0808"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "RAG 시스템을 위해 임베딩 모델을 파인튜닝할 때 사용하는 손실 함수(Loss Function)는?",
    "options": [
      "Contrastive Loss (대조 손실)",
      "Cross Entropy Loss",
      "Mean Squared Error",
      "Hinge Loss",
      "Log Loss"
    ],
    "answer": "Contrastive Loss (대조 손실)",
    "why": "관련 있는 문서끼리는 가깝게, 없는 문서끼리는 멀게 벡터 공간을 조정해야 하기 때문입니다.",
    "hint": "관련성 유무를 대조(Contrast)합니다.",
    "trap_points": [
      "InfoNCE Loss라고도 불림"
    ],
    "difficulty": "hard",
    "id": "0809"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝된 모델이 특정 프롬프트 템플릿(<|user|>, <|assistant|>)을 지키지 않으면 발생하는 문제는?",
    "options": [
      "EOS 토큰을 생성하지 못하고 끝없이 횡설수설한다",
      "모델이 침묵한다",
      "기존 성능이 향상된다",
      "토큰 비용이 줄어든다",
      "아무 문제 없다"
    ],
    "answer": "EOS 토큰을 생성하지 못하고 끝없이 횡설수설한다",
    "why": "학습된 종료 패턴을 찾지 못해 문장을 끝맺지 못하고 계속 이어 말하는 현상이 발생합니다.",
    "hint": "말을 멈추는 법을 모르게 됩니다.",
    "trap_points": [
      "채팅 모델 튜닝 시 가장 흔한 실수임"
    ],
    "difficulty": "medium",
    "id": "0810"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 시 배치 크기(Batch Size)를 키우기 위해 여러 GPU에 데이터를 나누어 담는 기술은?",
    "options": [
      "Data Parallelism (데이터 병렬화)",
      "Model Parallelism",
      "Pipeline Parallelism",
      "Tensor Parallelism",
      "Serial Processing"
    ],
    "answer": "Data Parallelism (데이터 병렬화)",
    "why": "같은 모델을 여러 GPU에 복사해두고, 서로 다른 데이터 조각을 먹여서 학습 속도를 배로 늘립니다.",
    "hint": "데이터를 병렬(Parallel)로 처리.",
    "trap_points": [
      "DDP, FSDP 등이 여기에 해당함"
    ],
    "difficulty": "medium",
    "id": "0811"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "의료나 법률 같은 특수 데이터로 파인튜닝할 때, 일반 상식 능력이 떨어지는 현상을 방지하기 위한 방법은?",
    "options": [
      "일반 데이터를 섞어서 학습 (General Instruction Mixing)",
      "특수 데이터만 계속 학습",
      "학습률을 높임",
      "모델 크기를 줄임",
      "영어 데이터 제거"
    ],
    "answer": "일반 데이터를 섞어서 학습 (General Instruction Mixing)",
    "why": "편식하면 건강을 해치듯, 전문 지식만 배우면 일반 대화 능력을 잃기 때문에 균형 잡힌 식단(데이터)이 필요합니다.",
    "hint": "골고루 섞어줍니다.",
    "trap_points": [
      "전문성만 추구하다 바보가 되는 것을 막음"
    ],
    "difficulty": "easy",
    "id": "0812"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "최신 파인튜닝 트렌드인 'NEFTune' 기법이 임베딩 벡터에 노이즈를 섞는 이유는?",
    "options": [
      "모델의 과적합을 막고 일반화 성능을 높이기 위해",
      "모델을 헷갈리게 하려고",
      "보안을 강화하려고",
      "학습을 방해하려고",
      "데이터를 손상시키려고"
    ],
    "answer": "모델의 과적합을 막고 일반화 성능을 높이기 위해",
    "why": "약간의 무작위 노이즈는 모델이 특정 데이터 패턴에만 집착하는 것을 방지하여 오히려 대화의 질을 높여줍니다.",
    "hint": "적절한 소음(Noise)은 면역력을 키워줍니다.",
    "trap_points": [
      "알파카(Alpaca) 데이터셋 실험에서 효과가 입증됨"
    ],
    "difficulty": "hard",
    "id": "0813"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝이 완료된 LoRA 어댑터를 원본 모델과 합쳐서 하나의 파일로 만드는 과정은?",
    "options": [
      "Merge & Unload",
      "Zip",
      "Compile",
      "Quantize",
      "Distill"
    ],
    "answer": "Merge & Unload",
    "why": "추론 속도를 높이기 위해 별도로 계산되던 어댑터 가중치를 원본 가중치 행렬에 더해버리고 메모리에서 내립니다.",
    "hint": "병합(Merge)하고 내보냄.",
    "trap_points": [
      "이후에는 어댑터를 분리할 수 없음 (비가역적)"
    ],
    "difficulty": "medium",
    "id": "0814"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "생성형 AI 모델을 평가할 때 'GPT-4'를 심판(Judge)으로 사용하여 점수를 매기는 방식을 무엇이라 하나요?",
    "options": [
      "LLM-as-a-Judge",
      "Human Eval",
      "Code Review",
      "Self-Play",
      "Peer Review"
    ],
    "answer": "LLM-as-a-Judge",
    "why": "사람이 평가하기엔 너무 비싸고 느려서, 고성능 모델에게 채점을 맡기는 현대적인 평가 트렌드입니다.",
    "hint": "LLM이 판사(Judge) 역할을 함.",
    "trap_points": [
      "MT-Bench 등이 이 방식을 사용함"
    ],
    "difficulty": "medium",
    "id": "0815"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "모델의 크기를 줄이는 '양자화(Quantization)' 시, 주로 손실되는 정보는?",
    "options": [
      "가중치의 정밀도(Precision)",
      "모델의 층 수",
      "입력 토큰 길이",
      "학습률",
      "어휘 크기"
    ],
    "answer": "가중치의 정밀도(Precision)",
    "why": "32비트 실수를 4비트 정수로 깎아내므로 미세한 숫자의 디테일(정밀도)이 뭉개집니다.",
    "hint": "정밀함(Precision)을 잃습니다.",
    "difficulty": "medium",
    "id": "0926"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "파인튜닝 시 훈련 데이터셋의 '프롬프트 템플릿' 형식이 맞지 않을 때 발생하는 'Silent Fail' 현상은?",
    "options": [
      "에러 없이 학습되지만 성능이 엉망임",
      "학습이 멈춤",
      "컴퓨터가 꺼짐",
      "데이터가 삭제됨",
      "경고창이 뜸"
    ],
    "answer": "에러 없이 학습되지만 성능이 엉망임",
    "why": "코드는 돌아가지만 모델은 이게 질문인지 답변인지 구분을 못 한 채로 텍스트 덩어리만 배워 바보가 됩니다.",
    "hint": "조용히(Silent) 망함.",
    "difficulty": "hard",
    "id": "0927"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "모델 병합(Merging) 기법 중 'SLERP(Spherical Linear Interpolation)'가 단순 평균보다 좋은 이유는?",
    "options": [
      "고차원 벡터 공간의 구면 기하학적 특성을 보존하기 때문",
      "계산이 더 단순해서",
      "메모리를 적게 써서",
      "정수만 사용해서",
      "이미지 처리에 좋아서"
    ],
    "answer": "고차원 벡터 공간의 구면 기하학적 특성을 보존하기 때문",
    "why": "단순 직선(Linear) 평균은 고차원 공간에서 벡터의 성질을 왜곡할 수 있어 구면(Spherical) 궤적을 따라 섞습니다.",
    "hint": "구(Sphere) 위에서 섞습니다.",
    "difficulty": "hard",
    "id": "0928"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "Instruct Tuning 데이터셋 구축 시 'Decontamination(오염 제거)' 작업의 목적은?",
    "options": [
      "평가 집합(Test Set)이 학습 데이터에 들어가는 것을 막기 위해",
      "바이러스를 잡기 위해",
      "욕설을 지우기 위해",
      "중복을 늘리기 위해",
      "파일 크기를 키우기 위해"
    ],
    "answer": "평가 집합(Test Set)이 학습 데이터에 들어가는 것을 막기 위해",
    "why": "답안지를 미리 보고 공부하면(Data Leakage) 실제 실력을 측정할 수 없으므로 철저히 분리합니다.",
    "hint": "시험 문제 유출 방지.",
    "difficulty": "medium",
    "id": "0929"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "객관식",
    "question": "DPO 학습 시 'Reference Model'이 필요한 이유는?",
    "options": [
      "학습 중인 모델이 너무 많이 변하지 않도록(KL 제약) 기준점을 잡아주기 위해",
      "정답을 베끼기 위해",
      "속도를 높이기 위해",
      "메모리를 절약하기 위해",
      "그냥 관습적으로"
    ],
    "answer": "학습 중인 모델이 너무 많이 변하지 않도록(KL 제약) 기준점을 잡아주기 위해",
    "why": "원래 모델의 분포에서 너무 멀어지면 언어 능력이 붕괴되므로, 원래의 나(Reference)와 비교하며 학습합니다.",
    "hint": "기준(Reference)이 흔들리지 않게.",
    "difficulty": "hard",
    "id": "0930"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "모든 파라미터를 학습시키는 대신, 저차원의 어댑터(Adapter) 행렬만 추가하여 학습시키는 기법의 약칭은?\n\n```python\n# Low-Rank Adaptation\n# 이 기법은 ____ 라고 불립니다.\n```",
    "options": [],
    "answer": "LoRA",
    "why": "LoRA는 효율적인 파라미터 튜닝 기법으로, 적은 자원으로도 대규모 모델을 최적화할 수 있게 해줍니다.",
    "difficulty": "easy",
    "id": "0701"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "4비트로 양자화된 베이스 모델 위에 LoRA를 적용하여 VRAM 사용량을 극도로 낮춘 파인 튜닝 기법은?\n\n```python\n# Quantized LoRA\n# 이 기법은 ____ 라고 불립니다.\n```",
    "options": [],
    "answer": "QLoRA",
    "why": "QLoRA는 일반 소비자용 GPU에서도 수십억 파라미터 모델을 튜닝할 수 있게 만든 핵심 기술입니다.",
    "difficulty": "medium",
    "id": "0702"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "허깅페이스에서 모델을 양자화하여 불러올 때 사용하는 설정 클래스 명칭을 작성하세요.\n\n```python\nfrom transformers import BitsAndBytesConfig\nbnb_config = ____(load_in_4bit=True, ...)\n```",
    "options": [],
    "answer": "BitsAndBytesConfig",
    "why": "BitsAndBytesConfig를 사용하면 8비트 혹은 4비트로 모델 가중치를 로드하여 메모리를 아낄 수 있습니다.",
    "difficulty": "medium",
    "id": "0703"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "LoRA 설정 시 모델의 어떤 레이어(q_proj, v_proj 등)를 학습할지 지정하는 파라미터 이름을 작성하세요.\n\n```python\nconfig = LoraConfig(____=[\"q_proj\", \"v_proj\"], ...)\n```",
    "options": [],
    "answer": "target_modules",
    "why": "target_modules는 가중치 행렬 중 어댑터를 부착하여 실제 학습을 수행할 지점을 특정합니다.",
    "difficulty": "hard",
    "id": "0704"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "베이스 모델과 LoRA 설정을 바탕으로 학습 가능한 어댑터 모델을 생성하는 PEFT 함수를 작성하세요.\n\n```python\nfrom peft import get_peft_model\nmodel = ____(base_model, lora_config)\n```",
    "options": [],
    "answer": "get_peft_model",
    "why": "get_peft_model()은 베이스 모델의 파라미터를 동결하고 LoRA 레이어만 활성화한 객체를 반환합니다.",
    "difficulty": "medium",
    "id": "0705"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "HuggingFace의 `trl` 라이브러리에서 지도 학습(SFT)을 쉽고 빠르게 수행하게 돕는 트레이너 클래스를 작성하세요.\n\n```python\nfrom trl import SFTTrainer\ntrainer = ____(model=model, train_dataset=dataset, ...)\n```",
    "options": [],
    "answer": "SFTTrainer",
    "why": "SFTTrainer는 인스트럭션 튜닝에 최적화된 학습 루프를 제공하여 코드를 간결하게 유지해줍니다.",
    "difficulty": "medium",
    "id": "0706"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "학습 시 '질문' 부분은 제외하고 모델이 생성해야 할 '답변' 부분에 대해서만 손실(Loss)을 계산하는 클래스를 작성하세요.\n\n```python\nfrom trl import DataCollatorForCompletionOnlyLM\ncollator = ____(response_template=\"[/INST]\", tokenizer=tokenizer)\n```",
    "options": [],
    "answer": "DataCollatorForCompletionOnlyLM",
    "why": "이 콜레이터는 모델이 질문 패턴을 외우는 것을 방지하고 순수하게 답변 생성 능력만 기르도록 돕습니다.",
    "difficulty": "hard",
    "id": "0707"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "토크나이저가 모델 고유의 채팅 포맷에 맞춰 데이터셋을 자동 변환하는 메서드 이름을 작성하세요.\n\n```python\nformatted_text = tokenizer.____(chat_messages, tokenize=False)\n```",
    "options": [],
    "answer": "apply_chat_template",
    "why": "apply_chat_template()은 Llama, Qwen 등 각 모델별 특수 토큰과 역할을 표준 포맷으로 삽입합니다.",
    "difficulty": "medium",
    "id": "0708"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "LoRA 학습이 끝난 후 어댑터 가중치를 원본 모델과 합쳐서 하나의 일반 모델처럼 만드는 메서드를 작성하세요.\n\n```python\nmerged_model = model.____()\n```",
    "options": [],
    "answer": "merge_and_unload",
    "why": "merge_and_unload()는 배포 및 추론 시 어댑터 로딩 오버헤드를 없애고 속도를 정규 모델 수준으로 올립니다.",
    "difficulty": "hard",
    "id": "0709"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "모델의 양자화 방식 중, 4비트 환경에서 부동소수점 분포를 최적화하여 손실을 최소화하는 포맷 명칭은?\n\n```python\nbnb_config = BitsAndBytesConfig(bnb_4bit_quant_type=\"____\")\n```",
    "options": [],
    "answer": "nf4",
    "why": "Normal Float 4 (nf4)는 베이스 모델 가중치 분포를 고려한 양자화 방식으로 성능 보존력이 뛰어납니다.",
    "difficulty": "hard",
    "id": "0710"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "전체 파라미터를 건드리지 않고 일부만 효율적으로 튜닝하는 모든 기법을 통칭하는 용어는?\n\n```python\n# Parameter-Efficient Fine-Tuning\n# 약자로 ____ 라고 합니다.\n```",
    "options": [],
    "answer": "PEFT",
    "why": "PEFT는 LoRA, Prefix Tuning, P-tuning 등을 아우르는 파라미터 효율적 학습 기술의 총칭입니다.",
    "difficulty": "easy",
    "id": "0711"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "사용자의 질문에 대해 모델이 올바르게 반응하도록 Q&A 쌍을 가르치는 단계를 무엇이라 하나요?\n\n```python\n# 지시를 따르게 만드는 ____ Tuning\n```",
    "options": [],
    "answer": "Instruction",
    "why": "인스트럭션 튜닝은 사전 학습된 모델이 질문과 답변의 구조를 이해하도록 정렬(Alignment)하는 과정입니다.",
    "difficulty": "easy",
    "id": "0712"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "LoRA 학습 데이터셋에서 모델이 정답까지 도달하는 '논리적 중간 단계'를 무엇이라 하나요?\n\n```python\n# 답변 필드에 정답과 함께 포함되는 ____ (CoT)\n```",
    "options": [],
    "answer": "사고 과정",
    "why": "사고 과정(Chain of Thought)을 학습 데이터에 포함하면 모델의 추론 능력이 비약적으로 발전합니다.",
    "difficulty": "medium",
    "id": "0713"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "학습 지표(Loss)를 실시간 시각화하여 확인하기 위해 사용하는 대표적인 도구의 이름을 작성하세요.\n\n```python\ntrainer = SFTTrainer(args=SFTConfig(report_to=\"____\"), ...)\n```",
    "options": [],
    "answer": "tensorboard",
    "why": "TensorBoard(또는 WandB)를 활용하면 학습 주기에 따른 손실 곡선과 정확도를 실시간으로 모니터링할 수 있습니다.",
    "difficulty": "easy",
    "id": "0714"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "LoraConfig에서 어댑터의 표현력을 결정하는 '랭크(Rank)'를 설정하는 변수명을 작성하세요.\n\n```python\nconfig = LoraConfig(____=8, lora_alpha=16, ...)\n```",
    "options": [],
    "answer": "r",
    "why": "r은 행렬 분해의 차원을 의미하며, 이 값이 클수록 더 정교한 학습이 가능해집니다.",
    "difficulty": "easy",
    "id": "0715"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "학습된 가중치 파일을 안전하고 빠르게 불러오기 위해 기존 파이토치(.bin) 대신 쓰는 최신 확장자는?\n\n```python\n# 안전한 텐서 저장을 위한 .____ 확장자\n```",
    "options": [],
    "answer": "safetensors",
    "why": "Safetensors는 파일 로딩 시 코드 실행 위험이 없고 텐서 레이아웃을 빠르게 가져옵니다.",
    "difficulty": "medium",
    "id": "0716"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "배치 크기가 너무 커서 VRAM이 부족할 때, 여러 단계의 그래디언트를 모아서 한 번에 업데이트하는 기법은?\n\n```python\n# Gradient ____ (누적)\n```",
    "options": [],
    "answer": "Accumulation",
    "why": "그래디언트 누적(Accumulation)은 하드웨어 한계를 넘어 실제 배치 크기를 늘리는 효과를 줍니다.",
    "difficulty": "hard",
    "id": "0717"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "모델이 학습 데이터를 그대로 암기(Overfitting)하여 새로운 질문에 대처하지 못하는 현상을 무엇이라 하나요?\n\n```python\n# 일반화 능력을 잃어버리는 ____ (과적합)\n```",
    "options": [],
    "answer": "과적합",
    "why": "과적합은 학습 오차는 낮으나 검증 오차가 높아지는 상태로, 적절한 규제나 데이터 증강이 필요합니다.",
    "difficulty": "easy",
    "id": "0718"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "학습 시 에포크(Epoch)가 끝날 때마다 모델의 현재 성능을 파일로 남겨두는 저장 지점의 이름은 무엇인가요?\n\n```python\n# 복구 및 검증용 저장소인 ____ (Checkpoint)\n```",
    "options": [],
    "answer": "체크포인트",
    "why": "체크포인트는 학습 중단 시 재개 지점을 제공하며, 최적의 성능을 낸 모델을 선택하게 해줍니다.",
    "difficulty": "medium",
    "id": "0719"
  },
  {
    "chapter_name": "Fine Tuning",
    "type": "코드 완성형",
    "question": "AI가 실제 답변을 시작하기 전, 채팅 템플릿의 끝에서 AI의 차례임을 알리는 메시지를 생성하는 메서드 인자는?\n\n```python\ntokenizer.apply_chat_template(..., ____=True)\n```",
    "options": [],
    "answer": "add_generation_prompt",
    "why": "add_generation_prompt=True는 모델이 바로 답변을 시작할 수 있도록 적절한 특수 토큰을 삽입합니다.",
    "difficulty": "hard",
    "id": "0720"
  }
]