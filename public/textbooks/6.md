# π“ [ν•™μµ λ…ΈνΈ] κµμ¬ 6. LLM Fine Tuning (PDF κΈ°λ° + μ‹¤λ¬΄ λ³΄μ¶©)

μ΄ κµμ¬λ” μ›λ³Έ PDF **"LLM Fine Tuning"**μ λ‚΄μ©μ„ κΈ°λ°μΌλ΅ ν•λ©°, νμΈνλ‹μ ν•µμ‹¬ κ°λ…κ³Ό ν¨μ¨μ μΈ ν•™μµ λ°©λ²•(PEFT)μ„ μ •λ¦¬ν–μµλ‹λ‹¤.

---

## 1. Fine Tuning (νμΈνλ‹) μ΄λ€?
### π― κ°λ…κ³Ό λ©μ 
- **Pre-trained Model (μ‚¬μ „ ν•™μµ λ¨λΈ)**: μ΄λ―Έ λ°©λ€ν• λ°μ΄ν„°λ¥Ό ν•™μµν•μ—¬ μΌλ°μ μΈ μ§€μ‹μ„ κ°€μ§„ λ¨λΈ (μ: GPT-4, LLaMA).
- **Fine Tuning**: μ‚¬μ „ ν•™μµλ λ¨λΈμ— **νΉμ • λ„λ©”μΈμ λ°μ΄ν„°**λ¥Ό μ¶”κ°€λ΅ ν•™μµμ‹μΌ, ν•΄λ‹Ή λ¶„μ•Όμ μ „λ¬Έκ°€λ΅ λ§λ“λ” κ³Όμ •μ…λ‹λ‹¤.
- **λΉ„μ **: λ€ν•™ μ΅Έμ—…μƒ(Pre-trained)μ—κ² μμ‚¬ μλ ¨ κ³Όμ •(Fine Tuning)μ„ κ±°μΉκ² ν•μ—¬ μ „λ¬Έμλ΅ λ§λ“λ” κ²ƒκ³Ό κ°™μµλ‹λ‹¤.

### π† RAGμ™€μ μ°¨μ΄
- **RAG**: μ±…μ„ ν΄λ†“κ³  μ¤ν”λ¶ μ‹ν—μ„ λ³΄λ” κ²ƒ (μ™Έλ¶€ μ§€μ‹ κ²€μƒ‰). μµμ‹  μ •λ³΄λ‚ μ •ν™•ν• μ‚¬μ‹¤ μ „λ‹¬μ— μ λ¦¬.
- **Fine Tuning**: μ§€μ‹μ„ λ¨Έλ¦Ώμ†μ— μ•”κΈ°ν•λ” κ²ƒ. λ§ν¬, ν•μ‹, μ „λ¬Έμ μΈ μ‘μ—…μ„ μ²΄ν™”ν•λ” λ° μ λ¦¬.

---

## 2. ν•™μµ λ°©λ²•μ μΆ…λ¥
1.  **SFT (Supervised Fine-Tuning)**: "μ§λ¬Έ-λ‹µλ³€" μμ λ°μ΄ν„°λ¥Ό μ£Όμ…ν•μ—¬ "μ΄λ΄ λ• μ΄λ ‡κ² λ€λ‹µν•΄"λΌκ³  κ°€λ¥΄μΉλ” κ°€μ¥ κΈ°λ³Έμ μΈ μ§€λ„ ν•™μµ λ°©μ‹μ…λ‹λ‹¤.
2.  **RLHF (Reinforcement Learning from Human Feedback)**: λ¨λΈμ λ‹µλ³€μ— λ€ν•΄ μΈκ°„μ΄ μ μ(Reward)λ¥Ό λ§¤κ²¨, λ” μΆ‹μ€ λ‹µλ³€μ„ ν•λ„λ΅ κ°•ν™” ν•™μµμ„ μ‹ν‚¤λ” κ³ κΈ‰ κ³Όμ •μ…λ‹λ‹¤.

---

## 3. PEFT (Parameter-Efficient Fine-Tuning)
κ±°λ€ μ–Έμ–΄ λ¨λΈ(LLM)μ€ νλΌλ―Έν„°κ°€ λ„λ¬΄ λ§μ•„(μμ‹­μ–µ~μμ²μ–µ κ°), μ „μ²΄λ¥Ό λ‹¤ μ¬ν•™μµ(Full Fine-Tuning)ν•λ ¤λ©΄ μ—„μ²­λ‚ λΉ„μ©κ³Ό μ‹κ°„μ΄ λ“­λ‹λ‹¤.

### π“‰ LoRA (Low-Rank Adaptation)
- μ „μ²΄ νλΌλ―Έν„°λ¥Ό κ±΄λ“λ¦¬μ§€ μ•κ³ , **μΌλ¶€ ν•µμ‹¬ νλΌλ―Έν„°(Adapter)**λ§ λ”°λ΅ λ–Όμ–΄λ‚΄μ–΄ ν•™μµμ‹ν‚¤λ” κΈ°μ μ…λ‹λ‹¤.
- **μ¥μ **:
    1.  **μ μ€ λΉ„μ©**: GPU λ©”λ¨λ¦¬ μ‚¬μ©λ‰μ„ νκΈ°μ μΌλ΅ μ¤„μ—¬μ¤λ‹λ‹¤. (μΌλ° κ·Έλν”½μΉ΄λ“λ΅λ„ κ°€λ¥)
    2.  **λΉ λ¥Έ μ†λ„**: ν•™μµν•  μ–‘μ΄ μ μ–΄ μ†λ„κ°€ λΉ λ¦…λ‹λ‹¤.
    3.  **μ„±λ¥ μ μ§€**: μ „μ²΄ ν•™μµκ³Ό κ±°μ λ€λ“±ν• μ„±λ¥μ„ λƒ…λ‹λ‹¤.

---

## 4. μ‹¤μ „ νμΈνλ‹ ν”„λ΅μ„Έμ¤
1.  **λ°μ΄ν„° μ¤€λΉ„**: `{ "instruction": "...", "output": "..." }` ν•νƒμ JSON λ°μ΄ν„°μ…‹μ„ μ¤€λΉ„ν•©λ‹λ‹¤.
2.  **λ¨λΈ μ„ νƒ**: λ² μ΄μ¤ λ¨λΈ(μ: Llama-3-8B)μ„ μ„ νƒν•©λ‹λ‹¤.
3.  **ν•™μµ(Training)**: LoRA λ“±μ„ μ‚¬μ©ν•μ—¬ ν•™μµμ„ λλ¦½λ‹λ‹¤. (Google Colab λ“± ν™μ© κ°€λ¥)
4.  **κ²€μ¦(Evaluation)**: ν•™μµλ λ¨λΈμ΄ μλ„λ€λ΅ λ‹µλ³€ν•λ”μ§€ ν…μ¤νΈν•©λ‹λ‹¤.