# 📘 [학습 노트] 교재 4. 프롬프트 엔지니어링 (LangChain & Agents)

## 1. 프롬프트 엔지니어링의 정석
프롬프트는 단순한 질문이 아니라, 모델의 결과물 품질을 제어하는 **선언적 프로그래밍**입니다.

### 🏗 프롬프트의 4대 구성 요소
1.  **Instruction (지시)**: 모델이 수행할 구체적인 작업(요약, 분류, 변환 등)
2.  **Context (맥락)**: 답변 완성도를 높이기 위한 배경 지식이나 제약 조건
3.  **Input Data (입력 데이터)**: 처리가 필요한 실제 텍스트나 질문
4.  **Output Indicator (출력 형식)**: JSON, 표, 마크다운 등 원하는 형식을 명시

### 🏷 XML과 구분자(Delimiter)의 힘
- 최신 LLM(Claude, GPT-4o 등)은 정보를 구조화하여 전달할 때 가독성이 높아집니다.
- XML 태그(`<context>`, `<example>`)를 사용하면 지시사항과 데이터를 명확히 분리할 수 있어 지시 이행력이 향상됩니다.
- `---`나 `###`와 같은 구분자는 모델이 집중해야 할 경계를 알려주는 효과적인 도구입니다.

---

## 2. 심화 프롬프팅 전략
단순한 질문을 넘어 고차원적인 지능을 끌어내는 기법들입니다.

### 🧠 추론 유도 (Reasoning)
- **Zero-shot CoT**: 예시 없이 "단계별로 생각해(Let's think step by step)"라는 문구만으로 논리적 오답을 줄입니다.
- **Few-shot Prompting**: 예시를 줄 때는 단순히 정답만 주는 것보다, **'정답에 도달하는 과정'**을 포함시킨 예시(Shot)가 훨씬 효과적입니다.
- **Self-Consistency**: 여러 개의 CoT 추론 경로를 생성하게 한 뒤, 가장 많이 나온 정답을 투표(Majority Vote)하여 최종 답을 결정합니다.
- **Least-to-Most**: 복잡한 문제를 작은 부분 문제들로 먼저 나누게 한 뒤 순차적으로 해결하게 지시합니다.

### 🛡 프롬프트 보안 및 해킹 (Prompt Injection)
- **Injection**: 사용자 입력을 통해 시스템의 원래 지시사항을 무시하게 만드는 공격.
- **Leaking**: 시스템 프롬프트(기밀 정보)를 출력하게 만드는 공격.
- **방어 기법**: 
    - **Delimiters**: 입력 데이터와 지시를 엄격히 분리.
    - **Post-instruction**: 사용자 입력 데이터 뒤에 "기존 지시를 다시 한 번 확인하라"고 덧붙이는 방식.
    - **Output Validation**: 결과물이 미리 정의된 형식을 벗어나면 차단.

---

## 3. LangChain Expression Language (LCEL)
체인을 파이프 연산자(`|`)로 결합하여 데이터 흐름을 추상화하는 현대적인 방식입니다.

### 🧬 핵심 Runnable 객체 분석
- **`RunnableSequence` (`|`)**: 단계별 연결.
- **`RunnableParallel`**: 여러 태스크를 동시에 병렬 실행 (예: 동일 질문에 대해 다른 검색기 3개 동시 사용).
- **`RunnablePassthrough`**: 입력받은 데이터를 수정 없이 다음 단계로 전달하거나, 딕셔너리 형태로 데이터를 주입할 때 사용.
- **`RunnableLambda`**: 사용자 정의 파이썬 함수를 체인 중간에 직접 삽입.
- **`with_fallbacks`**: 모델의 API 오류나 용량 제한 발생 시 즉시 다른 모델(예: GPT → Claude)로 교체 실행.

### 🛠 출력 파서 (Output Parser)
- **JsonOutputParser**: Pydantic 모델이나 스키마를 정의하여 항상 구조화된 JSON을 보장받습니다.
- **StrOutputParser**: 모델의 원문 메시지를 문자열로 깔끔하게 변환합니다.

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# LCEL 체인 구성 (Prompt | Model | Parser)
prompt = ChatPromptTemplate.from_template("{topic}에 대해 설명해줘.")
model = ChatOpenAI(model="gpt-4o")
chain = prompt | model | StrOutputParser()

# 실행
result = chain.invoke({"topic": "프롬프트 엔지니어링"})
```

---

## 4. 에이전트와 ReAct (Reasoning & Acting)
LLM이 스스로 계획을 세우고 외부 도구를 사용하는 단계입니다.

- **ReAct**: `Thought (생각) -> Action (행동) -> Observation (관찰)`의 루프를 반복합니다.
- **Tool Calling (Function Calling)**:
    - 모델이 파이썬 코드를 직접 실행하는 것이 아닙니다. 
    - 모델은 **"이 함수에 이 인자를 넣어줘"**라는 **JSON 규격**을 뱉고, 시스템 프로그래밍이 이를 받아 실행한 뒤 결과를 돌려줍니다.
- **Agentic Executor**: LangChain의 최신 버전에서는 `LangGraph` 등을 통해 더 유연하고 복잡한 상태 기반 에이전트를 구축합니다.

---

## 5. 실무 팁 및 평가
- **MT-Bench / LLM-as-a-Judge**: 모델의 프롬프트 응답 품질을 다른 고성능 모델(예: GPT-4)이 채점하게 하는 효율적인 평가 방식입니다.
- **System Prompt vs User Prompt**: 모델의 근본적인 역할(페르소나)은 System Prompt에 설정하는 것이 보안과 일관성 측면에서 유리합니다.
- **Context Window**: 모델이 한 번에 처리할 수 있는 최대 토큰 수. 초과 시 앞부분 기억을 잊어버리거나 에러가 발생합니다.