# 📘 [학습 노트] 교재 5. RAG & Agent (검색 증강 생성 및 에이전트)

## 1. RAG (Retrieval Augmented Generation) 아키텍처
RAG는 LLM의 가장 큰 한계인 **지식 단절(Knowledge Cut-off)**과 **할루시네이션(환각)**을 외부 지식을 주입하여 해결하는 기술입니다.

### 🏗 RAG 데이터 파이프라인 단계
1.  **Ingestion (적재)**: 데이터를 불러오고(Loader) 쪼개는(Splitter) 과정입니다.
2.  **Indexing (인덱싱)**: 단어를 숫자로 바꾸고(Embedding), 검색이 가능하도록 저장(Vector DB)합니다.
3.  **Retrieval (검색)**: 사용자의 질문과 가장 유사한 데이터 조각을 찾아냅니다.
4.  **Augmentation (증강)**: 찾아낸 조각을 프롬프트에 '맥락(Context)'으로 합칩니다.
5.  **Generation (생성)**: LLM이 맥락을 바탕으로 최종 답변을 뱉습니다.

---

## 2. 데이터 처리 및 검색 최적화 기술
단순 검색(Naive RAG)을 넘어 성능을 극한으로 끌어올리는 기법들입니다.

### ✂️ 전략적 청킹 (Chunking) & 로딩
- **RecursiveCharacterTextSplitter**: 줄바꿈, 공백 등 의미적 경계를 따라 재귀적으로 쪼갭니다. `chunk_size`(크기)와 `chunk_overlap`(중복 범위) 설정이 성능의 핵심입니다.
- **Parent-Child (Small-to-Big)**: 검색은 작은 조각(Child)으로 정밀하게 하고, 모델에게는 그 조각이 포함된 큰 문맥(Parent)을 전달하여 풍부한 정보를 제공합니다.
- **Semantic Chunking**: 텍스트의 의미값이 변하는 시점을 포착하여 내용을 자릅니다.

```python
from langchain_text_splitters import RecursiveCharacterTextSplitter

# 재귀적 청킹 설정 (의미적 경계 보존)
splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\n\n", "\n", " ", ""]
)
docs = splitter.split_text("대규모 문서 내용...")
```

### ⚡ 벡터 데이터베이스와 HNSW
수백만 개의 데이터 중 유사한 것을 초고속으로 찾는 알고리즘입니다.
- **HNSW (Hierarchical Navigable Small World)**:
    - 데이터를 계층화된 그래프 구조로 저장합니다. 
    - 상위 레이어에서 크게 건너뛰고 하위 레이어에서 세밀하게 찾아가는 방식입니다. 
    - **효율(ef_construction)**과 **연결성(M)** 파라미터를 통해 속도와 정합성을 조절합니다.
- **IVF (Inverted File Index)**: 공간을 군집(Clustering)으로 나누어 검색 범위를 제한합니다.

### 🔍 고도화된 검색 (Advanced Retrieval)
- **HyDE (Hypothetical Document Embedding)**: 질문에 대한 '가상 정답'을 먼저 생성한 후, 그 가상 정답과 닮은 문서를 검색하여 의미적 거리를 좁힙니다.
- **RRF (Reciprocal Rank Fusion)**: 키워드 검색과 벡터 검색의 결과를 순위(Rank) 기반으로 합치는 알고리즘입니다. 하이브리드 검색의 표준입니다.
- **Reranking**: 가벼운 모델로 후보군을 뽑은 뒤, **Cross-Encoder** 기반의 정밀 모델로 결과의 순서를 재배치하여 정확도를 극대화합니다.
- **RAPTOR**: 전체 문서를 요약하며 트리 구조로 검색하는 최신 기법입니다.

---

## 3. 에이전트(Agent)와 도구 사용
LLM이 단순한 텍스트 생성기가 아닌, 직접 **의사결정**을 내리고 **행동**하는 시스템입니다.

### 🤖 ReAct 프레임워크
- **Thought (생각)**: 할 일에 대해 논리적으로 추론합니다.
- **Action (행동)**: 필요한 도구(검색기, 계산기, API)를 호출합니다.
- **Observation (관찰)**: 도구의 결과를 확인하고 다음 단계를 결정합니다.

### 🛠 Tool Calling의 실체
- LLM이 직접 코드를 짜서 실행하는 것이 아닙니다. 
- LLM은 함수 실행에 필요한 **인자(Arguments)**를 JSON 포맷으로 생성(Function Calling)하고, 시스템이 이를 실행한 결과를 다시 LLM에게 넘깁니다.

### 📅 LangGraph와 상태 관리
- 기존의 선형적인 체인과 달리, **순환(Loop)** 구조를 가집니다.
- **State (상태)** 객체를 통해 에이전트가 무슨 일을 했는지, 무엇을 더 해야 하는지 정보를 유지하며 복잡한 문제를 해결합니다.

---

## 4. RAG 평가 (RAGAS Framework)
RAG가 정답을 잘 내는지 측정하는 3대 핵심 지표(The RAG Triad)입니다.

1.  **Faithfulness (충실성)**: 생성된 답변이 검색된 문서(Context)에만 근거하고 있는가? (할루시네이션 방지)
2.  **Answer Relevancy (답변 관련성)**: 답변이 사용자 질문의 구체적인 요구사항을 충족하는가?
3.  **Context Precision (검색 정밀도)**: 검색된 문서들 중 정답과 관련된 문서가 상위권에 잘 배치되었는가?

---

## 5. 메모리 관리 (Memory)
- **ConversationBufferWindowMemory**: 최근 `K`개의 대화 내용만 기억하여 토큰 낭비를 방지합니다.
- **ConversationSummaryMemory**: 과거 내용을 요약하여 기억함으로써 긴 대화를 효율적으로 관리합니다.