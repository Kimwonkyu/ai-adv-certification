# 📘 [학습 노트] 교재 2. 데이터 분석 (Numpy, Pandas, 텍스트 분석)

## 1. Numpy: 고성능 수치 연산의 핵심
Numpy는 파이썬 리스트의 한계를 극복하기 위해 설계된 **벡터화 연산** 기반 라이브러리입니다.

### 🚀 벡터화와 브로드캐스팅 (Broadcasting)
- **벡터화 (Vectorization)**: 반복문 없이 배열 전체에 대해 한 번에 연산을 수행하여 C 속도로 실행됩니다.
- **브로드캐스팅**: 모양(Shape)이 다른 배열 간의 연산을 가능하게 하는 규칙입니다. (예: (3,3) 행렬과 (1,3) 벡터의 합)
```python
import numpy as np
a = np.array([1, 2, 3])
b = 2
result = a * b # [2, 4, 6] - 스칼라 2가 배열 모양으로 확장됨
```

### 🔍 선형대수와 유사도 측정
- **L2 Norm (유클리드 거리)**: `np.linalg.norm(v)` - 두 점 사이의 직선거리.
- **Dot Product (내적)**: `np.dot(a, b)` - 벡터의 방향성과 크기를 동시에 고려.
- **전치 (Transpose)**: `a.T` - 행과 열을 맞바꿈. 딥러닝 가중치 행렬 연산 시 필수.

---

## 2. Pandas: 데이터 처리 및 분석 전사
Pandas는 **Series(1차원)**와 **DataFrame(2차원)**을 통해 정형 데이터를 요리합니다.

### ⚡ 고성능 데이터 처리 (Vectorized vs Apply)
- `df.apply()`는 내부적으로 파이썬 반복문을 돌기 때문에 대용량 데이터에서 속도가 느립니다.
- 가능하다면 Pandas/Numpy 내장 벡터화 함수(`df['col'] + 10` 등)를 사용하는 것이 압도적으로 빠릅니다.

### 📊 계층적 인덱싱 (Multi-Index)
- 두 개 이상의 컬럼을 인덱스로 지정하여 고차원 데이터를 구조화합니다.
- 복잡한 그룹 통계나 시간 흐름에 따른 데이터 분석 시 유리합니다.

### 🛠 데이터 병합 전략
- `merge()`: SQL의 JOIN과 유사. 'key'를 기준으로 두 표를 결합.
- `concat()`: 물리적으로 표를 위아래(axis=0)나 옆(axis=1)으로 붙임.
- `pivot_table()`: 엑셀의 피벗 기능을 코드로 구현. 통계 요약에 최적.

---

## 3. 한국어 텍스트 전처리 (NLP Pipeline)
한국어는 영어와 달리 **교착어**이므로 공백만으로 토큰화하면 성능이 낮아집니다.

### 🇰🇷 한국어 전처리의 특수성
1.  **형태소 분석**: `KoNLPy`(Mecab, Okt 등)를 사용하여 "사과는" → "사과(명사) + 는(조사)"로 분리해야 합니다.
2.  **불용어 (Stopwords)**: "은/는/이/가" 등 빈도는 높지만 의미가 없는 조사를 제거합니다.
3.  **정규화**: "ㅋㅋㅋㅋ", "했어여" → "해당 없음", "했어요" 등으로 형태를 통일합니다.

---

## 4. 텍스트 수치화와 유사도
텍스트를 숫자로 바꾸는 기법은 LLM의 핵심 원리인 **Embedding**으로 이어집니다.

### 📉 BOW vs TF-IDF
- **Bag of Words (BOW)**: 출현 빈도만 계산. 단어의 중요도(흔한 단어 vs 희귀한 단어)를 구분 못 함.
- **TF-IDF**: 특정 문서에만 자주 나오는 단어에 가중치를 부여. 검색 키워드 추출에 유용.

### 📐 코사인 유사도 (Cosine Similarity)
- 두 벡터의 **"각도"**만 측정합니다.
- 문서의 길이가 달라도(벡터의 크기가 달라도) 주제가 비슷하면 유사도가 높게 나오므로 RAG 시스템의 표준으로 사용됩니다.
- 임베딩 벡터가 정규화(L2 norm = 1) 되어 있다면, `내적(Dot Product)`과 결과가 동일합니다.